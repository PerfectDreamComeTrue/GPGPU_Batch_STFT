//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-28845127
// Cuda compilation tools, release 11.0, V11.0.221
// Based on LLVM 3.4svn
//

.version 7.0
.target sm_70
.address_size 64

	// .globl	_occa_toPower_0
// _ZZ24_occa_Stockhoptimized6_0E6FRBank has been demoted
// _ZZ24_occa_Stockhoptimized6_0E6FIBank has been demoted
// _ZZ24_occa_Stockhoptimized6_0E6SRBank has been demoted
// _ZZ24_occa_Stockhoptimized6_0E6SIBank has been demoted
// _ZZ24_occa_Stockhoptimized7_0E6FRBank has been demoted
// _ZZ24_occa_Stockhoptimized7_0E6FIBank has been demoted
// _ZZ24_occa_Stockhoptimized7_0E6SRBank has been demoted
// _ZZ24_occa_Stockhoptimized7_0E6SIBank has been demoted
// _ZZ24_occa_Stockhoptimized8_0E6FRBank has been demoted
// _ZZ24_occa_Stockhoptimized8_0E6FIBank has been demoted
// _ZZ24_occa_Stockhoptimized8_0E6SRBank has been demoted
// _ZZ24_occa_Stockhoptimized8_0E6SIBank has been demoted
// _ZZ24_occa_Stockhoptimized9_0E6FRBank has been demoted
// _ZZ24_occa_Stockhoptimized9_0E6FIBank has been demoted
// _ZZ24_occa_Stockhoptimized9_0E6SRBank has been demoted
// _ZZ24_occa_Stockhoptimized9_0E6SIBank has been demoted
// _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6FRBank has been demoted
// _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6FIBank has been demoted
// _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6SRBank has been demoted
// _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6SIBank has been demoted
// _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E11windowAdded has been demoted
// _ZZ27_occa_preprocesses_ODW_10_0E2wr has been demoted
// _ZZ27_occa_preprocesses_ODW_10_0E11windowAdded has been demoted
// _ZZ25_occa_Stockhoptimized10_0E6FRBank has been demoted
// _ZZ25_occa_Stockhoptimized10_0E6FIBank has been demoted
// _ZZ25_occa_Stockhoptimized10_0E6SRBank has been demoted
// _ZZ25_occa_Stockhoptimized10_0E6SIBank has been demoted
// _ZZ27_occa_preprocesses_ODW_11_0E2wr has been demoted
// _ZZ27_occa_preprocesses_ODW_11_0E11windowAdded has been demoted
// _ZZ25_occa_Stockhoptimized11_0E6FRBank has been demoted
// _ZZ25_occa_Stockhoptimized11_0E6FIBank has been demoted
// _ZZ25_occa_Stockhoptimized11_0E6SRBank has been demoted
// _ZZ25_occa_Stockhoptimized11_0E6SIBank has been demoted
// _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6FRBank has been demoted
// _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6FIBank has been demoted
// _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6SRBank has been demoted
// _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6SIBank has been demoted
// _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E11windowAdded has been demoted
// _ZZ23_occa_DCRemove_Common_0E5added has been demoted
.const .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry _occa_toPower_0(
	.param .u64 _occa_toPower_0_param_0,
	.param .u64 _occa_toPower_0_param_1,
	.param .u64 _occa_toPower_0_param_2,
	.param .u32 _occa_toPower_0_param_3
)
.maxntid 64, 1, 1
{
	.reg .f32 	%f<6>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [_occa_toPower_0_param_0];
	ld.param.u64 	%rd2, [_occa_toPower_0_param_1];
	ld.param.u64 	%rd3, [_occa_toPower_0_param_2];
	cvta.to.global.u64 	%rd4, %rd1;
	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd6, %rd2;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r2, %r1, 6;
	mov.u32 	%r3, %tid.x;
	add.s32 	%r4, %r2, %r3;
	mul.wide.u32 	%rd7, %r4, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.f32 	%f1, [%rd8];
	add.s64 	%rd9, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd9];
	mul.f32 	%f3, %f2, %f2;
	fma.rn.f32 	%f4, %f1, %f1, %f3;
	sqrt.rn.f32 	%f5, %f4;
	add.s64 	%rd10, %rd4, %rd7;
	st.global.f32 	[%rd10], %f5;
	ret;
}

	// .globl	_occa_toHalfComplexFormat_0
.visible .entry _occa_toHalfComplexFormat_0(
	.param .u64 _occa_toHalfComplexFormat_0_param_0,
	.param .u64 _occa_toHalfComplexFormat_0_param_1,
	.param .u64 _occa_toHalfComplexFormat_0_param_2,
	.param .u32 _occa_toHalfComplexFormat_0_param_3,
	.param .u32 _occa_toHalfComplexFormat_0_param_4
)
.maxntid 32, 1, 1
{
	.reg .f32 	%f<3>;
	.reg .b32 	%r<14>;
	.reg .b64 	%rd<12>;


	ld.param.u64 	%rd1, [_occa_toHalfComplexFormat_0_param_0];
	ld.param.u64 	%rd2, [_occa_toHalfComplexFormat_0_param_1];
	ld.param.u64 	%rd3, [_occa_toHalfComplexFormat_0_param_2];
	ld.param.u32 	%r1, [_occa_toHalfComplexFormat_0_param_4];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.to.global.u64 	%rd5, %rd1;
	cvta.to.global.u64 	%rd6, %rd2;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 5;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	add.s32 	%r6, %r1, -1;
	mov.u32 	%r7, 1;
	shl.b32 	%r8, %r7, %r6;
	add.s32 	%r9, %r8, -1;
	and.b32  	%r10, %r5, %r9;
	shr.u32 	%r11, %r5, %r6;
	shl.b32 	%r12, %r11, %r6;
	add.s32 	%r13, %r12, %r10;
	mul.wide.u32 	%rd7, %r13, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.f32 	%f1, [%rd8];
	mul.wide.u32 	%rd9, %r5, 8;
	add.s64 	%rd10, %rd5, %rd9;
	st.global.f32 	[%rd10], %f1;
	add.s64 	%rd11, %rd4, %rd7;
	ld.global.f32 	%f2, [%rd11];
	st.global.f32 	[%rd10+4], %f2;
	ret;
}

	// .globl	_occa_Stockhoptimized6_0
.visible .entry _occa_Stockhoptimized6_0(
	.param .u64 _occa_Stockhoptimized6_0_param_0,
	.param .u64 _occa_Stockhoptimized6_0_param_1,
	.param .u32 _occa_Stockhoptimized6_0_param_2
)
.maxntid 32, 1, 1
{
	.local .align 4 .b8 	__local_depot2[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<117>;
	.reg .f32 	%f<455>;
	.reg .b32 	%r<744>;
	.reg .f64 	%fd<31>;
	.reg .b64 	%rd<134>;
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized6_0E6FRBank[256];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized6_0E6FIBank[256];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized6_0E6SRBank[256];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized6_0E6SIBank[256];

	mov.u64 	%SPL, __local_depot2;
	ld.param.u64 	%rd53, [_occa_Stockhoptimized6_0_param_0];
	ld.param.u64 	%rd54, [_occa_Stockhoptimized6_0_param_1];
	mov.u32 	%r281, %ctaid.x;
	shl.b32 	%r282, %r281, 5;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r283, %r282, %r1;
	and.b32  	%r284, %r283, 31;
	shl.b32 	%r285, %r283, 1;
	and.b32  	%r2, %r285, -64;
	add.s32 	%r286, %r2, %r284;
	cvta.to.global.u64 	%rd55, %rd53;
	mul.wide.u32 	%rd56, %r286, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.f32 	%f1, [%rd57];
	ld.global.f32 	%f2, [%rd57+128];
	mov.f32 	%f165, 0f80000000;
	cvt.rni.s32.f32	%r3, %f165;
	cvt.rn.f32.s32	%f166, %r3;
	mov.f32 	%f167, 0fBFC90FDA;
	fma.rn.f32 	%f168, %f166, %f167, %f165;
	mov.f32 	%f169, 0fB3A22168;
	fma.rn.f32 	%f170, %f166, %f169, %f168;
	mov.f32 	%f171, 0fA7C234C5;
	fma.rn.f32 	%f3, %f166, %f171, %f170;
	add.s32 	%r4, %r3, 1;
	mul.rn.f32 	%f4, %f3, %f3;
	and.b32  	%r5, %r4, 1;
	setp.eq.s32	%p1, %r5, 0;
	selp.f32	%f5, %f3, 0f3F800000, %p1;
	mov.f32 	%f172, 0f00000000;
	fma.rn.f32 	%f6, %f4, %f5, %f172;
	mov.f32 	%f421, 0fB94D4153;
	@%p1 bra 	BB2_2;

	mov.f32 	%f173, 0fBAB607ED;
	mov.f32 	%f174, 0f37CBAC00;
	fma.rn.f32 	%f421, %f174, %f4, %f173;

BB2_2:
	selp.f32	%f175, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f176, %f421, %f4, %f175;
	selp.f32	%f177, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f178, %f176, %f4, %f177;
	fma.rn.f32 	%f422, %f178, %f6, %f5;
	and.b32  	%r287, %r4, 2;
	setp.eq.s32	%p3, %r287, 0;
	@%p3 bra 	BB2_4;

	mov.f32 	%f180, 0fBF800000;
	fma.rn.f32 	%f422, %f422, %f180, %f172;

BB2_4:
	and.b32  	%r6, %r3, 1;
	setp.eq.s32	%p4, %r6, 0;
	selp.f32	%f12, %f3, 0f3F800000, %p4;
	fma.rn.f32 	%f13, %f4, %f12, %f172;
	mov.f32 	%f423, 0fB94D4153;
	@%p4 bra 	BB2_6;

	mov.f32 	%f183, 0fBAB607ED;
	mov.f32 	%f184, 0f37CBAC00;
	fma.rn.f32 	%f423, %f184, %f4, %f183;

BB2_6:
	selp.f32	%f185, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f186, %f423, %f4, %f185;
	selp.f32	%f187, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f188, %f186, %f4, %f187;
	fma.rn.f32 	%f424, %f188, %f13, %f12;
	and.b32  	%r288, %r3, 2;
	setp.eq.s32	%p6, %r288, 0;
	@%p6 bra 	BB2_8;

	mov.f32 	%f190, 0fBF800000;
	fma.rn.f32 	%f424, %f424, %f190, %f172;

BB2_8:
	mul.f32 	%f191, %f424, 0f00000000;
	mul.f32 	%f192, %f2, %f422;
	sub.f32 	%f193, %f192, %f191;
	mul.f32 	%f194, %f422, 0f00000000;
	fma.rn.f32 	%f195, %f2, %f424, %f194;
	add.f32 	%f196, %f1, %f193;
	shl.b32 	%r289, %r1, 3;
	mov.u32 	%r290, _ZZ24_occa_Stockhoptimized6_0E6FRBank;
	add.s32 	%r291, %r290, %r289;
	st.shared.f32 	[%r291], %f196;
	add.f32 	%f197, %f195, 0f00000000;
	mov.u32 	%r292, _ZZ24_occa_Stockhoptimized6_0E6FIBank;
	add.s32 	%r293, %r292, %r289;
	st.shared.f32 	[%r293], %f197;
	sub.f32 	%f198, %f1, %f193;
	st.shared.f32 	[%r291+4], %f198;
	sub.f32 	%f200, %f172, %f195;
	st.shared.f32 	[%r293+4], %f200;
	bar.sync 	0;
	shl.b32 	%r294, %r1, 2;
	add.s32 	%r296, %r290, %r294;
	ld.shared.f32 	%f19, [%r296];
	add.s32 	%r298, %r292, %r294;
	ld.shared.f32 	%f20, [%r298];
	ld.shared.f32 	%f21, [%r296+128];
	ld.shared.f32 	%f22, [%r298+128];
	shr.u32 	%r299, %r1, 31;
	add.s32 	%r300, %r1, %r299;
	and.b32  	%r301, %r300, 268435454;
	sub.s32 	%r302, %r1, %r301;
	shl.b32 	%r303, %r302, 4;
	cvt.rn.f32.s32	%f201, %r303;
	mul.f32 	%f202, %f201, 0f3C800000;
	cvt.f64.f32	%fd1, %f202;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f23, %fd2;
	mul.f32 	%f203, %f23, 0f3F22F983;
	cvt.rni.s32.f32	%r679, %f203;
	cvt.rn.f32.s32	%f204, %r679;
	fma.rn.f32 	%f206, %f204, %f167, %f23;
	fma.rn.f32 	%f208, %f204, %f169, %f206;
	fma.rn.f32 	%f428, %f204, %f171, %f208;
	abs.f32 	%f25, %f23;
	add.u64 	%rd1, %SPL, 0;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p7, %f25, 0f47CE4780;
	mov.u32 	%r671, %r679;
	mov.f32 	%f425, %f428;
	@%p7 bra 	BB2_19;

	setp.eq.f32	%p8, %f25, 0f7F800000;
	@%p8 bra 	BB2_18;
	bra.uni 	BB2_10;

BB2_18:
	mul.rn.f32 	%f425, %f23, %f172;
	mov.u32 	%r671, %r679;
	bra.uni 	BB2_19;

BB2_10:
	mov.b32 	 %r8, %f23;
	shl.b32 	%r306, %r8, 8;
	or.b32  	%r9, %r306, -2147483648;
	mov.u32 	%r665, 0;
	mov.u64 	%rd114, __cudart_i2opi_f;
	mov.u32 	%r664, -6;
	mov.u64 	%rd115, %rd1;

BB2_11:
	.pragma "nounroll";
	ld.const.u32 	%r309, [%rd114];
	// inline asm
	{
	mad.lo.cc.u32   %r307, %r309, %r9, %r665;
	madc.hi.u32     %r665, %r309, %r9,  0;
	}
	// inline asm
	st.local.u32 	[%rd115], %r307;
	add.s64 	%rd115, %rd115, 4;
	add.s64 	%rd114, %rd114, 4;
	add.s32 	%r664, %r664, 1;
	setp.ne.s32	%p9, %r664, 0;
	@%p9 bra 	BB2_11;

	bfe.u32 	%r312, %r8, 23, 8;
	add.s32 	%r313, %r312, -128;
	shr.u32 	%r314, %r313, 5;
	and.b32  	%r14, %r8, -2147483648;
	st.local.u32 	[%rd2], %r665;
	bfe.u32 	%r15, %r8, 23, 5;
	mov.u32 	%r315, 6;
	sub.s32 	%r316, %r315, %r314;
	mul.wide.s32 	%rd60, %r316, 4;
	add.s64 	%rd7, %rd1, %rd60;
	ld.local.u32 	%r667, [%rd7];
	ld.local.u32 	%r666, [%rd7+-4];
	setp.eq.s32	%p10, %r15, 0;
	@%p10 bra 	BB2_14;

	mov.u32 	%r317, 32;
	sub.s32 	%r318, %r317, %r15;
	shr.u32 	%r319, %r666, %r318;
	shl.b32 	%r320, %r667, %r15;
	add.s32 	%r667, %r319, %r320;
	ld.local.u32 	%r321, [%rd7+-8];
	shr.u32 	%r322, %r321, %r318;
	shl.b32 	%r323, %r666, %r15;
	add.s32 	%r666, %r322, %r323;

BB2_14:
	shr.u32 	%r324, %r666, 30;
	shl.b32 	%r325, %r667, 2;
	add.s32 	%r669, %r325, %r324;
	shl.b32 	%r23, %r666, 2;
	shr.u32 	%r326, %r669, 31;
	shr.u32 	%r327, %r667, 30;
	add.s32 	%r24, %r326, %r327;
	setp.eq.s32	%p11, %r326, 0;
	@%p11 bra 	BB2_15;

	not.b32 	%r328, %r669;
	neg.s32 	%r668, %r23;
	setp.eq.s32	%p12, %r23, 0;
	selp.u32	%r329, 1, 0, %p12;
	add.s32 	%r669, %r329, %r328;
	xor.b32  	%r670, %r14, -2147483648;
	bra.uni 	BB2_17;

BB2_15:
	mov.u32 	%r668, %r23;
	mov.u32 	%r670, %r14;

BB2_17:
	cvt.u64.u32	%rd61, %r669;
	cvt.u64.u32	%rd62, %r668;
	bfi.b64 	%rd63, %rd61, %rd62, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd63;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f210, %fd4;
	neg.f32 	%f211, %f210;
	setp.eq.s32	%p13, %r670, 0;
	selp.f32	%f425, %f210, %f211, %p13;
	setp.eq.s32	%p14, %r14, 0;
	neg.s32 	%r330, %r24;
	selp.b32	%r671, %r24, %r330, %p14;

BB2_19:
	add.s32 	%r33, %r671, 1;
	and.b32  	%r34, %r33, 1;
	setp.eq.s32	%p15, %r34, 0;
	selp.f32	%f29, %f425, 0f3F800000, %p15;
	mul.rn.f32 	%f30, %f425, %f425;
	fma.rn.f32 	%f31, %f30, %f29, %f172;
	mov.f32 	%f426, 0fB94D4153;
	@%p15 bra 	BB2_21;

	mov.f32 	%f215, 0fBAB607ED;
	mov.f32 	%f216, 0f37CBAC00;
	fma.rn.f32 	%f426, %f216, %f30, %f215;

BB2_21:
	selp.f32	%f217, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f218, %f426, %f30, %f217;
	selp.f32	%f219, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f220, %f218, %f30, %f219;
	fma.rn.f32 	%f427, %f220, %f31, %f29;
	and.b32  	%r331, %r33, 2;
	setp.eq.s32	%p17, %r331, 0;
	@%p17 bra 	BB2_23;

	mov.f32 	%f222, 0fBF800000;
	fma.rn.f32 	%f427, %f427, %f222, %f172;

BB2_23:
	@%p7 bra 	BB2_34;

	setp.eq.f32	%p19, %f25, 0f7F800000;
	@%p19 bra 	BB2_33;
	bra.uni 	BB2_25;

BB2_33:
	mul.rn.f32 	%f428, %f23, %f172;
	bra.uni 	BB2_34;

BB2_25:
	mov.b32 	 %r35, %f23;
	shl.b32 	%r334, %r35, 8;
	or.b32  	%r36, %r334, -2147483648;
	mov.u32 	%r673, 0;
	mov.u64 	%rd116, __cudart_i2opi_f;
	mov.u32 	%r672, -6;
	mov.u64 	%rd117, %rd1;

BB2_26:
	.pragma "nounroll";
	ld.const.u32 	%r337, [%rd116];
	// inline asm
	{
	mad.lo.cc.u32   %r335, %r337, %r36, %r673;
	madc.hi.u32     %r673, %r337, %r36,  0;
	}
	// inline asm
	st.local.u32 	[%rd117], %r335;
	add.s64 	%rd117, %rd117, 4;
	add.s64 	%rd116, %rd116, 4;
	add.s32 	%r672, %r672, 1;
	setp.ne.s32	%p20, %r672, 0;
	@%p20 bra 	BB2_26;

	bfe.u32 	%r340, %r35, 23, 8;
	add.s32 	%r341, %r340, -128;
	shr.u32 	%r342, %r341, 5;
	and.b32  	%r41, %r35, -2147483648;
	st.local.u32 	[%rd2], %r673;
	bfe.u32 	%r42, %r35, 23, 5;
	mov.u32 	%r343, 6;
	sub.s32 	%r344, %r343, %r342;
	mul.wide.s32 	%rd65, %r344, 4;
	add.s64 	%rd12, %rd1, %rd65;
	ld.local.u32 	%r675, [%rd12];
	ld.local.u32 	%r674, [%rd12+-4];
	setp.eq.s32	%p21, %r42, 0;
	@%p21 bra 	BB2_29;

	mov.u32 	%r345, 32;
	sub.s32 	%r346, %r345, %r42;
	shr.u32 	%r347, %r674, %r346;
	shl.b32 	%r348, %r675, %r42;
	add.s32 	%r675, %r347, %r348;
	ld.local.u32 	%r349, [%rd12+-8];
	shr.u32 	%r350, %r349, %r346;
	shl.b32 	%r351, %r674, %r42;
	add.s32 	%r674, %r350, %r351;

BB2_29:
	shr.u32 	%r352, %r674, 30;
	shl.b32 	%r353, %r675, 2;
	add.s32 	%r677, %r353, %r352;
	shl.b32 	%r50, %r674, 2;
	shr.u32 	%r354, %r677, 31;
	shr.u32 	%r355, %r675, 30;
	add.s32 	%r51, %r354, %r355;
	setp.eq.s32	%p22, %r354, 0;
	@%p22 bra 	BB2_30;

	not.b32 	%r356, %r677;
	neg.s32 	%r676, %r50;
	setp.eq.s32	%p23, %r50, 0;
	selp.u32	%r357, 1, 0, %p23;
	add.s32 	%r677, %r357, %r356;
	xor.b32  	%r678, %r41, -2147483648;
	bra.uni 	BB2_32;

BB2_30:
	mov.u32 	%r676, %r50;
	mov.u32 	%r678, %r41;

BB2_32:
	cvt.u64.u32	%rd66, %r677;
	cvt.u64.u32	%rd67, %r676;
	bfi.b64 	%rd68, %rd66, %rd67, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd68;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f223, %fd6;
	neg.f32 	%f224, %f223;
	setp.eq.s32	%p24, %r678, 0;
	selp.f32	%f428, %f223, %f224, %p24;
	setp.eq.s32	%p25, %r41, 0;
	neg.s32 	%r358, %r51;
	selp.b32	%r679, %r51, %r358, %p25;

BB2_34:
	and.b32  	%r60, %r679, 1;
	setp.eq.s32	%p26, %r60, 0;
	selp.f32	%f40, %f428, 0f3F800000, %p26;
	mul.rn.f32 	%f41, %f428, %f428;
	fma.rn.f32 	%f42, %f41, %f40, %f172;
	mov.f32 	%f429, 0fB94D4153;
	@%p26 bra 	BB2_36;

	mov.f32 	%f228, 0fBAB607ED;
	mov.f32 	%f229, 0f37CBAC00;
	fma.rn.f32 	%f429, %f229, %f41, %f228;

BB2_36:
	selp.f32	%f230, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f231, %f429, %f41, %f230;
	selp.f32	%f232, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f233, %f231, %f41, %f232;
	fma.rn.f32 	%f430, %f233, %f42, %f40;
	and.b32  	%r359, %r679, 2;
	setp.eq.s32	%p28, %r359, 0;
	@%p28 bra 	BB2_38;

	mov.f32 	%f235, 0fBF800000;
	fma.rn.f32 	%f430, %f430, %f235, %f172;

BB2_38:
	shl.b32 	%r360, %r1, 1;
	and.b32  	%r361, %r360, 1073741820;
	and.b32  	%r362, %r1, 1;
	add.s32 	%r363, %r361, %r362;
	mul.f32 	%f236, %f22, %f430;
	mul.f32 	%f237, %f21, %f427;
	sub.f32 	%f238, %f237, %f236;
	mul.f32 	%f239, %f22, %f427;
	fma.rn.f32 	%f240, %f21, %f430, %f239;
	add.f32 	%f241, %f19, %f238;
	shl.b32 	%r364, %r363, 2;
	mov.u32 	%r365, _ZZ24_occa_Stockhoptimized6_0E6SRBank;
	add.s32 	%r366, %r365, %r364;
	st.shared.f32 	[%r366], %f241;
	add.f32 	%f242, %f20, %f240;
	mov.u32 	%r367, _ZZ24_occa_Stockhoptimized6_0E6SIBank;
	add.s32 	%r368, %r367, %r364;
	st.shared.f32 	[%r368], %f242;
	sub.f32 	%f243, %f19, %f238;
	st.shared.f32 	[%r366+8], %f243;
	sub.f32 	%f244, %f20, %f240;
	st.shared.f32 	[%r368+8], %f244;
	bar.sync 	0;
	add.s32 	%r371, %r365, %r294;
	ld.shared.f32 	%f48, [%r371];
	add.s32 	%r373, %r367, %r294;
	ld.shared.f32 	%f49, [%r373];
	ld.shared.f32 	%f50, [%r371+128];
	ld.shared.f32 	%f51, [%r373+128];
	shr.s32 	%r374, %r1, 31;
	shr.u32 	%r375, %r374, 30;
	add.s32 	%r376, %r1, %r375;
	and.b32  	%r377, %r376, 536870908;
	sub.s32 	%r378, %r1, %r377;
	shl.b32 	%r379, %r378, 3;
	cvt.rn.f32.s32	%f245, %r379;
	mul.f32 	%f246, %f245, 0f3C800000;
	cvt.f64.f32	%fd7, %f246;
	mul.f64 	%fd8, %fd7, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f52, %fd8;
	mul.f32 	%f247, %f52, 0f3F22F983;
	cvt.rni.s32.f32	%r695, %f247;
	cvt.rn.f32.s32	%f248, %r695;
	fma.rn.f32 	%f250, %f248, %f167, %f52;
	fma.rn.f32 	%f252, %f248, %f169, %f250;
	fma.rn.f32 	%f434, %f248, %f171, %f252;
	abs.f32 	%f54, %f52;
	setp.leu.f32	%p29, %f54, 0f47CE4780;
	mov.u32 	%r687, %r695;
	mov.f32 	%f431, %f434;
	@%p29 bra 	BB2_49;

	setp.eq.f32	%p30, %f54, 0f7F800000;
	@%p30 bra 	BB2_48;
	bra.uni 	BB2_40;

BB2_48:
	mul.rn.f32 	%f431, %f52, %f172;
	mov.u32 	%r687, %r695;
	bra.uni 	BB2_49;

BB2_40:
	mov.b32 	 %r63, %f52;
	shl.b32 	%r382, %r63, 8;
	or.b32  	%r64, %r382, -2147483648;
	mov.u32 	%r681, 0;
	mov.u64 	%rd118, __cudart_i2opi_f;
	mov.u32 	%r680, -6;
	mov.u64 	%rd119, %rd1;

BB2_41:
	.pragma "nounroll";
	ld.const.u32 	%r385, [%rd118];
	// inline asm
	{
	mad.lo.cc.u32   %r383, %r385, %r64, %r681;
	madc.hi.u32     %r681, %r385, %r64,  0;
	}
	// inline asm
	st.local.u32 	[%rd119], %r383;
	add.s64 	%rd119, %rd119, 4;
	add.s64 	%rd118, %rd118, 4;
	add.s32 	%r680, %r680, 1;
	setp.ne.s32	%p31, %r680, 0;
	@%p31 bra 	BB2_41;

	bfe.u32 	%r388, %r63, 23, 8;
	add.s32 	%r389, %r388, -128;
	shr.u32 	%r390, %r389, 5;
	and.b32  	%r69, %r63, -2147483648;
	st.local.u32 	[%rd2], %r681;
	bfe.u32 	%r70, %r63, 23, 5;
	mov.u32 	%r391, 6;
	sub.s32 	%r392, %r391, %r390;
	mul.wide.s32 	%rd70, %r392, 4;
	add.s64 	%rd17, %rd1, %rd70;
	ld.local.u32 	%r683, [%rd17];
	ld.local.u32 	%r682, [%rd17+-4];
	setp.eq.s32	%p32, %r70, 0;
	@%p32 bra 	BB2_44;

	mov.u32 	%r393, 32;
	sub.s32 	%r394, %r393, %r70;
	shr.u32 	%r395, %r682, %r394;
	shl.b32 	%r396, %r683, %r70;
	add.s32 	%r683, %r395, %r396;
	ld.local.u32 	%r397, [%rd17+-8];
	shr.u32 	%r398, %r397, %r394;
	shl.b32 	%r399, %r682, %r70;
	add.s32 	%r682, %r398, %r399;

BB2_44:
	shr.u32 	%r400, %r682, 30;
	shl.b32 	%r401, %r683, 2;
	add.s32 	%r685, %r401, %r400;
	shl.b32 	%r78, %r682, 2;
	shr.u32 	%r402, %r685, 31;
	shr.u32 	%r403, %r683, 30;
	add.s32 	%r79, %r402, %r403;
	setp.eq.s32	%p33, %r402, 0;
	@%p33 bra 	BB2_45;

	not.b32 	%r404, %r685;
	neg.s32 	%r684, %r78;
	setp.eq.s32	%p34, %r78, 0;
	selp.u32	%r405, 1, 0, %p34;
	add.s32 	%r685, %r405, %r404;
	xor.b32  	%r686, %r69, -2147483648;
	bra.uni 	BB2_47;

BB2_45:
	mov.u32 	%r684, %r78;
	mov.u32 	%r686, %r69;

BB2_47:
	cvt.u64.u32	%rd71, %r685;
	cvt.u64.u32	%rd72, %r684;
	bfi.b64 	%rd73, %rd71, %rd72, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd73;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f254, %fd10;
	neg.f32 	%f255, %f254;
	setp.eq.s32	%p35, %r686, 0;
	selp.f32	%f431, %f254, %f255, %p35;
	setp.eq.s32	%p36, %r69, 0;
	neg.s32 	%r406, %r79;
	selp.b32	%r687, %r79, %r406, %p36;

BB2_49:
	add.s32 	%r88, %r687, 1;
	and.b32  	%r89, %r88, 1;
	setp.eq.s32	%p37, %r89, 0;
	selp.f32	%f58, %f431, 0f3F800000, %p37;
	mul.rn.f32 	%f59, %f431, %f431;
	fma.rn.f32 	%f60, %f59, %f58, %f172;
	mov.f32 	%f432, 0fB94D4153;
	@%p37 bra 	BB2_51;

	mov.f32 	%f259, 0fBAB607ED;
	mov.f32 	%f260, 0f37CBAC00;
	fma.rn.f32 	%f432, %f260, %f59, %f259;

BB2_51:
	selp.f32	%f261, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f262, %f432, %f59, %f261;
	selp.f32	%f263, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f264, %f262, %f59, %f263;
	fma.rn.f32 	%f433, %f264, %f60, %f58;
	and.b32  	%r407, %r88, 2;
	setp.eq.s32	%p39, %r407, 0;
	@%p39 bra 	BB2_53;

	mov.f32 	%f266, 0fBF800000;
	fma.rn.f32 	%f433, %f433, %f266, %f172;

BB2_53:
	@%p29 bra 	BB2_64;

	setp.eq.f32	%p41, %f54, 0f7F800000;
	@%p41 bra 	BB2_63;
	bra.uni 	BB2_55;

BB2_63:
	mul.rn.f32 	%f434, %f52, %f172;
	bra.uni 	BB2_64;

BB2_55:
	mov.b32 	 %r90, %f52;
	shl.b32 	%r410, %r90, 8;
	or.b32  	%r91, %r410, -2147483648;
	mov.u32 	%r689, 0;
	mov.u64 	%rd120, __cudart_i2opi_f;
	mov.u32 	%r688, -6;
	mov.u64 	%rd121, %rd1;

BB2_56:
	.pragma "nounroll";
	ld.const.u32 	%r413, [%rd120];
	// inline asm
	{
	mad.lo.cc.u32   %r411, %r413, %r91, %r689;
	madc.hi.u32     %r689, %r413, %r91,  0;
	}
	// inline asm
	st.local.u32 	[%rd121], %r411;
	add.s64 	%rd121, %rd121, 4;
	add.s64 	%rd120, %rd120, 4;
	add.s32 	%r688, %r688, 1;
	setp.ne.s32	%p42, %r688, 0;
	@%p42 bra 	BB2_56;

	bfe.u32 	%r416, %r90, 23, 8;
	add.s32 	%r417, %r416, -128;
	shr.u32 	%r418, %r417, 5;
	and.b32  	%r96, %r90, -2147483648;
	st.local.u32 	[%rd2], %r689;
	bfe.u32 	%r97, %r90, 23, 5;
	mov.u32 	%r419, 6;
	sub.s32 	%r420, %r419, %r418;
	mul.wide.s32 	%rd75, %r420, 4;
	add.s64 	%rd22, %rd1, %rd75;
	ld.local.u32 	%r691, [%rd22];
	ld.local.u32 	%r690, [%rd22+-4];
	setp.eq.s32	%p43, %r97, 0;
	@%p43 bra 	BB2_59;

	mov.u32 	%r421, 32;
	sub.s32 	%r422, %r421, %r97;
	shr.u32 	%r423, %r690, %r422;
	shl.b32 	%r424, %r691, %r97;
	add.s32 	%r691, %r423, %r424;
	ld.local.u32 	%r425, [%rd22+-8];
	shr.u32 	%r426, %r425, %r422;
	shl.b32 	%r427, %r690, %r97;
	add.s32 	%r690, %r426, %r427;

BB2_59:
	shr.u32 	%r428, %r690, 30;
	shl.b32 	%r429, %r691, 2;
	add.s32 	%r693, %r429, %r428;
	shl.b32 	%r105, %r690, 2;
	shr.u32 	%r430, %r693, 31;
	shr.u32 	%r431, %r691, 30;
	add.s32 	%r106, %r430, %r431;
	setp.eq.s32	%p44, %r430, 0;
	@%p44 bra 	BB2_60;

	not.b32 	%r432, %r693;
	neg.s32 	%r692, %r105;
	setp.eq.s32	%p45, %r105, 0;
	selp.u32	%r433, 1, 0, %p45;
	add.s32 	%r693, %r433, %r432;
	xor.b32  	%r694, %r96, -2147483648;
	bra.uni 	BB2_62;

BB2_60:
	mov.u32 	%r692, %r105;
	mov.u32 	%r694, %r96;

BB2_62:
	cvt.u64.u32	%rd76, %r693;
	cvt.u64.u32	%rd77, %r692;
	bfi.b64 	%rd78, %rd76, %rd77, 32, 32;
	cvt.rn.f64.s64	%fd11, %rd78;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f267, %fd12;
	neg.f32 	%f268, %f267;
	setp.eq.s32	%p46, %r694, 0;
	selp.f32	%f434, %f267, %f268, %p46;
	setp.eq.s32	%p47, %r96, 0;
	neg.s32 	%r434, %r106;
	selp.b32	%r695, %r106, %r434, %p47;

BB2_64:
	and.b32  	%r115, %r695, 1;
	setp.eq.s32	%p48, %r115, 0;
	selp.f32	%f69, %f434, 0f3F800000, %p48;
	mul.rn.f32 	%f70, %f434, %f434;
	fma.rn.f32 	%f71, %f70, %f69, %f172;
	mov.f32 	%f435, 0fB94D4153;
	@%p48 bra 	BB2_66;

	mov.f32 	%f272, 0fBAB607ED;
	mov.f32 	%f273, 0f37CBAC00;
	fma.rn.f32 	%f435, %f273, %f70, %f272;

BB2_66:
	selp.f32	%f274, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f275, %f435, %f70, %f274;
	selp.f32	%f276, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f277, %f275, %f70, %f276;
	fma.rn.f32 	%f436, %f277, %f71, %f69;
	and.b32  	%r435, %r695, 2;
	setp.eq.s32	%p50, %r435, 0;
	@%p50 bra 	BB2_68;

	mov.f32 	%f279, 0fBF800000;
	fma.rn.f32 	%f436, %f436, %f279, %f172;

BB2_68:
	and.b32  	%r436, %r1, 3;
	and.b32  	%r438, %r360, 1073741816;
	add.s32 	%r439, %r438, %r436;
	mul.f32 	%f280, %f51, %f436;
	mul.f32 	%f281, %f50, %f433;
	sub.f32 	%f282, %f281, %f280;
	mul.f32 	%f283, %f51, %f433;
	fma.rn.f32 	%f284, %f50, %f436, %f283;
	add.f32 	%f285, %f48, %f282;
	shl.b32 	%r440, %r439, 2;
	add.s32 	%r442, %r290, %r440;
	st.shared.f32 	[%r442], %f285;
	add.f32 	%f286, %f49, %f284;
	add.s32 	%r444, %r292, %r440;
	st.shared.f32 	[%r444], %f286;
	sub.f32 	%f287, %f48, %f282;
	st.shared.f32 	[%r442+16], %f287;
	sub.f32 	%f288, %f49, %f284;
	st.shared.f32 	[%r444+16], %f288;
	bar.sync 	0;
	ld.shared.f32 	%f77, [%r296];
	ld.shared.f32 	%f78, [%r298];
	ld.shared.f32 	%f79, [%r296+128];
	ld.shared.f32 	%f80, [%r298+128];
	shr.u32 	%r451, %r374, 29;
	add.s32 	%r452, %r1, %r451;
	and.b32  	%r453, %r452, 1073741816;
	sub.s32 	%r454, %r1, %r453;
	shl.b32 	%r455, %r454, 2;
	cvt.rn.f32.s32	%f289, %r455;
	mul.f32 	%f290, %f289, 0f3C800000;
	cvt.f64.f32	%fd13, %f290;
	mul.f64 	%fd14, %fd13, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f81, %fd14;
	mul.f32 	%f291, %f81, 0f3F22F983;
	cvt.rni.s32.f32	%r711, %f291;
	cvt.rn.f32.s32	%f292, %r711;
	fma.rn.f32 	%f294, %f292, %f167, %f81;
	fma.rn.f32 	%f296, %f292, %f169, %f294;
	fma.rn.f32 	%f440, %f292, %f171, %f296;
	abs.f32 	%f83, %f81;
	setp.leu.f32	%p51, %f83, 0f47CE4780;
	mov.u32 	%r703, %r711;
	mov.f32 	%f437, %f440;
	@%p51 bra 	BB2_79;

	setp.eq.f32	%p52, %f83, 0f7F800000;
	@%p52 bra 	BB2_78;
	bra.uni 	BB2_70;

BB2_78:
	mul.rn.f32 	%f437, %f81, %f172;
	mov.u32 	%r703, %r711;
	bra.uni 	BB2_79;

BB2_70:
	mov.b32 	 %r118, %f81;
	shl.b32 	%r458, %r118, 8;
	or.b32  	%r119, %r458, -2147483648;
	mov.u32 	%r697, 0;
	mov.u64 	%rd122, __cudart_i2opi_f;
	mov.u32 	%r696, -6;
	mov.u64 	%rd123, %rd1;

BB2_71:
	.pragma "nounroll";
	ld.const.u32 	%r461, [%rd122];
	// inline asm
	{
	mad.lo.cc.u32   %r459, %r461, %r119, %r697;
	madc.hi.u32     %r697, %r461, %r119,  0;
	}
	// inline asm
	st.local.u32 	[%rd123], %r459;
	add.s64 	%rd123, %rd123, 4;
	add.s64 	%rd122, %rd122, 4;
	add.s32 	%r696, %r696, 1;
	setp.ne.s32	%p53, %r696, 0;
	@%p53 bra 	BB2_71;

	bfe.u32 	%r464, %r118, 23, 8;
	add.s32 	%r465, %r464, -128;
	shr.u32 	%r466, %r465, 5;
	and.b32  	%r124, %r118, -2147483648;
	st.local.u32 	[%rd2], %r697;
	bfe.u32 	%r125, %r118, 23, 5;
	mov.u32 	%r467, 6;
	sub.s32 	%r468, %r467, %r466;
	mul.wide.s32 	%rd80, %r468, 4;
	add.s64 	%rd27, %rd1, %rd80;
	ld.local.u32 	%r699, [%rd27];
	ld.local.u32 	%r698, [%rd27+-4];
	setp.eq.s32	%p54, %r125, 0;
	@%p54 bra 	BB2_74;

	mov.u32 	%r469, 32;
	sub.s32 	%r470, %r469, %r125;
	shr.u32 	%r471, %r698, %r470;
	shl.b32 	%r472, %r699, %r125;
	add.s32 	%r699, %r471, %r472;
	ld.local.u32 	%r473, [%rd27+-8];
	shr.u32 	%r474, %r473, %r470;
	shl.b32 	%r475, %r698, %r125;
	add.s32 	%r698, %r474, %r475;

BB2_74:
	shr.u32 	%r476, %r698, 30;
	shl.b32 	%r477, %r699, 2;
	add.s32 	%r701, %r477, %r476;
	shl.b32 	%r133, %r698, 2;
	shr.u32 	%r478, %r701, 31;
	shr.u32 	%r479, %r699, 30;
	add.s32 	%r134, %r478, %r479;
	setp.eq.s32	%p55, %r478, 0;
	@%p55 bra 	BB2_75;

	not.b32 	%r480, %r701;
	neg.s32 	%r700, %r133;
	setp.eq.s32	%p56, %r133, 0;
	selp.u32	%r481, 1, 0, %p56;
	add.s32 	%r701, %r481, %r480;
	xor.b32  	%r702, %r124, -2147483648;
	bra.uni 	BB2_77;

BB2_75:
	mov.u32 	%r700, %r133;
	mov.u32 	%r702, %r124;

BB2_77:
	cvt.u64.u32	%rd81, %r701;
	cvt.u64.u32	%rd82, %r700;
	bfi.b64 	%rd83, %rd81, %rd82, 32, 32;
	cvt.rn.f64.s64	%fd15, %rd83;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f298, %fd16;
	neg.f32 	%f299, %f298;
	setp.eq.s32	%p57, %r702, 0;
	selp.f32	%f437, %f298, %f299, %p57;
	setp.eq.s32	%p58, %r124, 0;
	neg.s32 	%r482, %r134;
	selp.b32	%r703, %r134, %r482, %p58;

BB2_79:
	add.s32 	%r143, %r703, 1;
	and.b32  	%r144, %r143, 1;
	setp.eq.s32	%p59, %r144, 0;
	selp.f32	%f87, %f437, 0f3F800000, %p59;
	mul.rn.f32 	%f88, %f437, %f437;
	fma.rn.f32 	%f89, %f88, %f87, %f172;
	mov.f32 	%f438, 0fB94D4153;
	@%p59 bra 	BB2_81;

	mov.f32 	%f303, 0fBAB607ED;
	mov.f32 	%f304, 0f37CBAC00;
	fma.rn.f32 	%f438, %f304, %f88, %f303;

BB2_81:
	selp.f32	%f305, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f306, %f438, %f88, %f305;
	selp.f32	%f307, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f308, %f306, %f88, %f307;
	fma.rn.f32 	%f439, %f308, %f89, %f87;
	and.b32  	%r483, %r143, 2;
	setp.eq.s32	%p61, %r483, 0;
	@%p61 bra 	BB2_83;

	mov.f32 	%f310, 0fBF800000;
	fma.rn.f32 	%f439, %f439, %f310, %f172;

BB2_83:
	@%p51 bra 	BB2_94;

	setp.eq.f32	%p63, %f83, 0f7F800000;
	@%p63 bra 	BB2_93;
	bra.uni 	BB2_85;

BB2_93:
	mul.rn.f32 	%f440, %f81, %f172;
	bra.uni 	BB2_94;

BB2_85:
	mov.b32 	 %r145, %f81;
	shl.b32 	%r486, %r145, 8;
	or.b32  	%r146, %r486, -2147483648;
	mov.u32 	%r705, 0;
	mov.u64 	%rd124, __cudart_i2opi_f;
	mov.u32 	%r704, -6;
	mov.u64 	%rd125, %rd1;

BB2_86:
	.pragma "nounroll";
	ld.const.u32 	%r489, [%rd124];
	// inline asm
	{
	mad.lo.cc.u32   %r487, %r489, %r146, %r705;
	madc.hi.u32     %r705, %r489, %r146,  0;
	}
	// inline asm
	st.local.u32 	[%rd125], %r487;
	add.s64 	%rd125, %rd125, 4;
	add.s64 	%rd124, %rd124, 4;
	add.s32 	%r704, %r704, 1;
	setp.ne.s32	%p64, %r704, 0;
	@%p64 bra 	BB2_86;

	bfe.u32 	%r492, %r145, 23, 8;
	add.s32 	%r493, %r492, -128;
	shr.u32 	%r494, %r493, 5;
	and.b32  	%r151, %r145, -2147483648;
	st.local.u32 	[%rd2], %r705;
	bfe.u32 	%r152, %r145, 23, 5;
	mov.u32 	%r495, 6;
	sub.s32 	%r496, %r495, %r494;
	mul.wide.s32 	%rd85, %r496, 4;
	add.s64 	%rd32, %rd1, %rd85;
	ld.local.u32 	%r707, [%rd32];
	ld.local.u32 	%r706, [%rd32+-4];
	setp.eq.s32	%p65, %r152, 0;
	@%p65 bra 	BB2_89;

	mov.u32 	%r497, 32;
	sub.s32 	%r498, %r497, %r152;
	shr.u32 	%r499, %r706, %r498;
	shl.b32 	%r500, %r707, %r152;
	add.s32 	%r707, %r499, %r500;
	ld.local.u32 	%r501, [%rd32+-8];
	shr.u32 	%r502, %r501, %r498;
	shl.b32 	%r503, %r706, %r152;
	add.s32 	%r706, %r502, %r503;

BB2_89:
	shr.u32 	%r504, %r706, 30;
	shl.b32 	%r505, %r707, 2;
	add.s32 	%r709, %r505, %r504;
	shl.b32 	%r160, %r706, 2;
	shr.u32 	%r506, %r709, 31;
	shr.u32 	%r507, %r707, 30;
	add.s32 	%r161, %r506, %r507;
	setp.eq.s32	%p66, %r506, 0;
	@%p66 bra 	BB2_90;

	not.b32 	%r508, %r709;
	neg.s32 	%r708, %r160;
	setp.eq.s32	%p67, %r160, 0;
	selp.u32	%r509, 1, 0, %p67;
	add.s32 	%r709, %r509, %r508;
	xor.b32  	%r710, %r151, -2147483648;
	bra.uni 	BB2_92;

BB2_90:
	mov.u32 	%r708, %r160;
	mov.u32 	%r710, %r151;

BB2_92:
	cvt.u64.u32	%rd86, %r709;
	cvt.u64.u32	%rd87, %r708;
	bfi.b64 	%rd88, %rd86, %rd87, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd88;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f311, %fd18;
	neg.f32 	%f312, %f311;
	setp.eq.s32	%p68, %r710, 0;
	selp.f32	%f440, %f311, %f312, %p68;
	setp.eq.s32	%p69, %r151, 0;
	neg.s32 	%r510, %r161;
	selp.b32	%r711, %r161, %r510, %p69;

BB2_94:
	and.b32  	%r170, %r711, 1;
	setp.eq.s32	%p70, %r170, 0;
	selp.f32	%f98, %f440, 0f3F800000, %p70;
	mul.rn.f32 	%f99, %f440, %f440;
	fma.rn.f32 	%f100, %f99, %f98, %f172;
	mov.f32 	%f441, 0fB94D4153;
	@%p70 bra 	BB2_96;

	mov.f32 	%f316, 0fBAB607ED;
	mov.f32 	%f317, 0f37CBAC00;
	fma.rn.f32 	%f441, %f317, %f99, %f316;

BB2_96:
	selp.f32	%f318, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f319, %f441, %f99, %f318;
	selp.f32	%f320, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f321, %f319, %f99, %f320;
	fma.rn.f32 	%f442, %f321, %f100, %f98;
	and.b32  	%r511, %r711, 2;
	setp.eq.s32	%p72, %r511, 0;
	@%p72 bra 	BB2_98;

	mov.f32 	%f323, 0fBF800000;
	fma.rn.f32 	%f442, %f442, %f323, %f172;

BB2_98:
	and.b32  	%r512, %r1, 7;
	and.b32  	%r514, %r360, 1073741808;
	add.s32 	%r515, %r514, %r512;
	mul.f32 	%f324, %f80, %f442;
	mul.f32 	%f325, %f79, %f439;
	sub.f32 	%f326, %f325, %f324;
	mul.f32 	%f327, %f80, %f439;
	fma.rn.f32 	%f328, %f79, %f442, %f327;
	add.f32 	%f329, %f77, %f326;
	shl.b32 	%r516, %r515, 2;
	add.s32 	%r518, %r365, %r516;
	st.shared.f32 	[%r518], %f329;
	add.f32 	%f330, %f78, %f328;
	add.s32 	%r520, %r367, %r516;
	st.shared.f32 	[%r520], %f330;
	sub.f32 	%f331, %f77, %f326;
	st.shared.f32 	[%r518+32], %f331;
	sub.f32 	%f332, %f78, %f328;
	st.shared.f32 	[%r520+32], %f332;
	bar.sync 	0;
	ld.shared.f32 	%f106, [%r371];
	ld.shared.f32 	%f107, [%r373];
	ld.shared.f32 	%f108, [%r371+128];
	ld.shared.f32 	%f109, [%r373+128];
	shr.u32 	%r527, %r374, 28;
	add.s32 	%r528, %r1, %r527;
	and.b32  	%r529, %r528, 2147483632;
	sub.s32 	%r530, %r1, %r529;
	shl.b32 	%r531, %r530, 1;
	cvt.rn.f32.s32	%f333, %r531;
	mul.f32 	%f334, %f333, 0f3C800000;
	cvt.f64.f32	%fd19, %f334;
	mul.f64 	%fd20, %fd19, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f110, %fd20;
	mul.f32 	%f335, %f110, 0f3F22F983;
	cvt.rni.s32.f32	%r727, %f335;
	cvt.rn.f32.s32	%f336, %r727;
	fma.rn.f32 	%f338, %f336, %f167, %f110;
	fma.rn.f32 	%f340, %f336, %f169, %f338;
	fma.rn.f32 	%f446, %f336, %f171, %f340;
	abs.f32 	%f112, %f110;
	setp.leu.f32	%p73, %f112, 0f47CE4780;
	mov.u32 	%r719, %r727;
	mov.f32 	%f443, %f446;
	@%p73 bra 	BB2_109;

	setp.eq.f32	%p74, %f112, 0f7F800000;
	@%p74 bra 	BB2_108;
	bra.uni 	BB2_100;

BB2_108:
	mul.rn.f32 	%f443, %f110, %f172;
	mov.u32 	%r719, %r727;
	bra.uni 	BB2_109;

BB2_100:
	mov.b32 	 %r173, %f110;
	shl.b32 	%r534, %r173, 8;
	or.b32  	%r174, %r534, -2147483648;
	mov.u32 	%r713, 0;
	mov.u64 	%rd126, __cudart_i2opi_f;
	mov.u32 	%r712, -6;
	mov.u64 	%rd127, %rd1;

BB2_101:
	.pragma "nounroll";
	ld.const.u32 	%r537, [%rd126];
	// inline asm
	{
	mad.lo.cc.u32   %r535, %r537, %r174, %r713;
	madc.hi.u32     %r713, %r537, %r174,  0;
	}
	// inline asm
	st.local.u32 	[%rd127], %r535;
	add.s64 	%rd127, %rd127, 4;
	add.s64 	%rd126, %rd126, 4;
	add.s32 	%r712, %r712, 1;
	setp.ne.s32	%p75, %r712, 0;
	@%p75 bra 	BB2_101;

	bfe.u32 	%r540, %r173, 23, 8;
	add.s32 	%r541, %r540, -128;
	shr.u32 	%r542, %r541, 5;
	and.b32  	%r179, %r173, -2147483648;
	st.local.u32 	[%rd2], %r713;
	bfe.u32 	%r180, %r173, 23, 5;
	mov.u32 	%r543, 6;
	sub.s32 	%r544, %r543, %r542;
	mul.wide.s32 	%rd90, %r544, 4;
	add.s64 	%rd37, %rd1, %rd90;
	ld.local.u32 	%r715, [%rd37];
	ld.local.u32 	%r714, [%rd37+-4];
	setp.eq.s32	%p76, %r180, 0;
	@%p76 bra 	BB2_104;

	mov.u32 	%r545, 32;
	sub.s32 	%r546, %r545, %r180;
	shr.u32 	%r547, %r714, %r546;
	shl.b32 	%r548, %r715, %r180;
	add.s32 	%r715, %r547, %r548;
	ld.local.u32 	%r549, [%rd37+-8];
	shr.u32 	%r550, %r549, %r546;
	shl.b32 	%r551, %r714, %r180;
	add.s32 	%r714, %r550, %r551;

BB2_104:
	shr.u32 	%r552, %r714, 30;
	shl.b32 	%r553, %r715, 2;
	add.s32 	%r717, %r553, %r552;
	shl.b32 	%r188, %r714, 2;
	shr.u32 	%r554, %r717, 31;
	shr.u32 	%r555, %r715, 30;
	add.s32 	%r189, %r554, %r555;
	setp.eq.s32	%p77, %r554, 0;
	@%p77 bra 	BB2_105;

	not.b32 	%r556, %r717;
	neg.s32 	%r716, %r188;
	setp.eq.s32	%p78, %r188, 0;
	selp.u32	%r557, 1, 0, %p78;
	add.s32 	%r717, %r557, %r556;
	xor.b32  	%r718, %r179, -2147483648;
	bra.uni 	BB2_107;

BB2_105:
	mov.u32 	%r716, %r188;
	mov.u32 	%r718, %r179;

BB2_107:
	cvt.u64.u32	%rd91, %r717;
	cvt.u64.u32	%rd92, %r716;
	bfi.b64 	%rd93, %rd91, %rd92, 32, 32;
	cvt.rn.f64.s64	%fd21, %rd93;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f342, %fd22;
	neg.f32 	%f343, %f342;
	setp.eq.s32	%p79, %r718, 0;
	selp.f32	%f443, %f342, %f343, %p79;
	setp.eq.s32	%p80, %r179, 0;
	neg.s32 	%r558, %r189;
	selp.b32	%r719, %r189, %r558, %p80;

BB2_109:
	add.s32 	%r198, %r719, 1;
	and.b32  	%r199, %r198, 1;
	setp.eq.s32	%p81, %r199, 0;
	selp.f32	%f116, %f443, 0f3F800000, %p81;
	mul.rn.f32 	%f117, %f443, %f443;
	fma.rn.f32 	%f118, %f117, %f116, %f172;
	mov.f32 	%f444, 0fB94D4153;
	@%p81 bra 	BB2_111;

	mov.f32 	%f347, 0fBAB607ED;
	mov.f32 	%f348, 0f37CBAC00;
	fma.rn.f32 	%f444, %f348, %f117, %f347;

BB2_111:
	selp.f32	%f349, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f350, %f444, %f117, %f349;
	selp.f32	%f351, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f352, %f350, %f117, %f351;
	fma.rn.f32 	%f445, %f352, %f118, %f116;
	and.b32  	%r559, %r198, 2;
	setp.eq.s32	%p83, %r559, 0;
	@%p83 bra 	BB2_113;

	mov.f32 	%f354, 0fBF800000;
	fma.rn.f32 	%f445, %f445, %f354, %f172;

BB2_113:
	@%p73 bra 	BB2_124;

	setp.eq.f32	%p85, %f112, 0f7F800000;
	@%p85 bra 	BB2_123;
	bra.uni 	BB2_115;

BB2_123:
	mul.rn.f32 	%f446, %f110, %f172;
	bra.uni 	BB2_124;

BB2_115:
	mov.b32 	 %r200, %f110;
	shl.b32 	%r562, %r200, 8;
	or.b32  	%r201, %r562, -2147483648;
	mov.u32 	%r721, 0;
	mov.u64 	%rd128, __cudart_i2opi_f;
	mov.u32 	%r720, -6;
	mov.u64 	%rd129, %rd1;

BB2_116:
	.pragma "nounroll";
	ld.const.u32 	%r565, [%rd128];
	// inline asm
	{
	mad.lo.cc.u32   %r563, %r565, %r201, %r721;
	madc.hi.u32     %r721, %r565, %r201,  0;
	}
	// inline asm
	st.local.u32 	[%rd129], %r563;
	add.s64 	%rd129, %rd129, 4;
	add.s64 	%rd128, %rd128, 4;
	add.s32 	%r720, %r720, 1;
	setp.ne.s32	%p86, %r720, 0;
	@%p86 bra 	BB2_116;

	bfe.u32 	%r568, %r200, 23, 8;
	add.s32 	%r569, %r568, -128;
	shr.u32 	%r570, %r569, 5;
	and.b32  	%r206, %r200, -2147483648;
	st.local.u32 	[%rd2], %r721;
	bfe.u32 	%r207, %r200, 23, 5;
	mov.u32 	%r571, 6;
	sub.s32 	%r572, %r571, %r570;
	mul.wide.s32 	%rd95, %r572, 4;
	add.s64 	%rd42, %rd1, %rd95;
	ld.local.u32 	%r723, [%rd42];
	ld.local.u32 	%r722, [%rd42+-4];
	setp.eq.s32	%p87, %r207, 0;
	@%p87 bra 	BB2_119;

	mov.u32 	%r573, 32;
	sub.s32 	%r574, %r573, %r207;
	shr.u32 	%r575, %r722, %r574;
	shl.b32 	%r576, %r723, %r207;
	add.s32 	%r723, %r575, %r576;
	ld.local.u32 	%r577, [%rd42+-8];
	shr.u32 	%r578, %r577, %r574;
	shl.b32 	%r579, %r722, %r207;
	add.s32 	%r722, %r578, %r579;

BB2_119:
	shr.u32 	%r580, %r722, 30;
	shl.b32 	%r581, %r723, 2;
	add.s32 	%r725, %r581, %r580;
	shl.b32 	%r215, %r722, 2;
	shr.u32 	%r582, %r725, 31;
	shr.u32 	%r583, %r723, 30;
	add.s32 	%r216, %r582, %r583;
	setp.eq.s32	%p88, %r582, 0;
	@%p88 bra 	BB2_120;

	not.b32 	%r584, %r725;
	neg.s32 	%r724, %r215;
	setp.eq.s32	%p89, %r215, 0;
	selp.u32	%r585, 1, 0, %p89;
	add.s32 	%r725, %r585, %r584;
	xor.b32  	%r726, %r206, -2147483648;
	bra.uni 	BB2_122;

BB2_120:
	mov.u32 	%r724, %r215;
	mov.u32 	%r726, %r206;

BB2_122:
	cvt.u64.u32	%rd96, %r725;
	cvt.u64.u32	%rd97, %r724;
	bfi.b64 	%rd98, %rd96, %rd97, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd98;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f355, %fd24;
	neg.f32 	%f356, %f355;
	setp.eq.s32	%p90, %r726, 0;
	selp.f32	%f446, %f355, %f356, %p90;
	setp.eq.s32	%p91, %r206, 0;
	neg.s32 	%r586, %r216;
	selp.b32	%r727, %r216, %r586, %p91;

BB2_124:
	and.b32  	%r225, %r727, 1;
	setp.eq.s32	%p92, %r225, 0;
	selp.f32	%f127, %f446, 0f3F800000, %p92;
	mul.rn.f32 	%f128, %f446, %f446;
	fma.rn.f32 	%f129, %f128, %f127, %f172;
	mov.f32 	%f447, 0fB94D4153;
	@%p92 bra 	BB2_126;

	mov.f32 	%f360, 0fBAB607ED;
	mov.f32 	%f361, 0f37CBAC00;
	fma.rn.f32 	%f447, %f361, %f128, %f360;

BB2_126:
	selp.f32	%f362, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f363, %f447, %f128, %f362;
	selp.f32	%f364, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f365, %f363, %f128, %f364;
	fma.rn.f32 	%f448, %f365, %f129, %f127;
	and.b32  	%r587, %r727, 2;
	setp.eq.s32	%p94, %r587, 0;
	@%p94 bra 	BB2_128;

	mov.f32 	%f367, 0fBF800000;
	fma.rn.f32 	%f448, %f448, %f367, %f172;

BB2_128:
	and.b32  	%r588, %r1, 15;
	and.b32  	%r590, %r360, 1073741792;
	add.s32 	%r591, %r590, %r588;
	mul.f32 	%f368, %f109, %f448;
	mul.f32 	%f369, %f108, %f445;
	sub.f32 	%f370, %f369, %f368;
	mul.f32 	%f371, %f109, %f445;
	fma.rn.f32 	%f372, %f108, %f448, %f371;
	add.f32 	%f373, %f106, %f370;
	shl.b32 	%r592, %r591, 2;
	add.s32 	%r594, %r290, %r592;
	st.shared.f32 	[%r594], %f373;
	add.f32 	%f374, %f107, %f372;
	add.s32 	%r596, %r292, %r592;
	st.shared.f32 	[%r596], %f374;
	sub.f32 	%f375, %f106, %f370;
	st.shared.f32 	[%r594+64], %f375;
	sub.f32 	%f376, %f107, %f372;
	st.shared.f32 	[%r596+64], %f376;
	bar.sync 	0;
	ld.shared.f32 	%f135, [%r296];
	ld.shared.f32 	%f136, [%r298];
	ld.shared.f32 	%f137, [%r296+128];
	ld.shared.f32 	%f138, [%r298+128];
	add.s32 	%r226, %r2, %r1;
	shr.u32 	%r604, %r374, 27;
	add.s32 	%r605, %r1, %r604;
	and.b32  	%r606, %r605, -32;
	sub.s32 	%r607, %r1, %r606;
	cvt.rn.f32.s32	%f377, %r607;
	mul.f32 	%f378, %f377, 0f3C800000;
	cvt.f64.f32	%fd25, %f378;
	mul.f64 	%fd26, %fd25, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f139, %fd26;
	mul.f32 	%f379, %f139, 0f3F22F983;
	cvt.rni.s32.f32	%r743, %f379;
	cvt.rn.f32.s32	%f380, %r743;
	fma.rn.f32 	%f382, %f380, %f167, %f139;
	fma.rn.f32 	%f384, %f380, %f169, %f382;
	fma.rn.f32 	%f452, %f380, %f171, %f384;
	abs.f32 	%f141, %f139;
	setp.leu.f32	%p95, %f141, 0f47CE4780;
	mov.u32 	%r735, %r743;
	mov.f32 	%f449, %f452;
	@%p95 bra 	BB2_139;

	setp.eq.f32	%p96, %f141, 0f7F800000;
	@%p96 bra 	BB2_138;
	bra.uni 	BB2_130;

BB2_138:
	mul.rn.f32 	%f449, %f139, %f172;
	mov.u32 	%r735, %r743;
	bra.uni 	BB2_139;

BB2_130:
	mov.b32 	 %r228, %f139;
	shl.b32 	%r610, %r228, 8;
	or.b32  	%r229, %r610, -2147483648;
	mov.u32 	%r729, 0;
	mov.u64 	%rd130, __cudart_i2opi_f;
	mov.u32 	%r728, -6;
	mov.u64 	%rd131, %rd1;

BB2_131:
	.pragma "nounroll";
	ld.const.u32 	%r613, [%rd130];
	// inline asm
	{
	mad.lo.cc.u32   %r611, %r613, %r229, %r729;
	madc.hi.u32     %r729, %r613, %r229,  0;
	}
	// inline asm
	st.local.u32 	[%rd131], %r611;
	add.s64 	%rd131, %rd131, 4;
	add.s64 	%rd130, %rd130, 4;
	add.s32 	%r728, %r728, 1;
	setp.ne.s32	%p97, %r728, 0;
	@%p97 bra 	BB2_131;

	bfe.u32 	%r616, %r228, 23, 8;
	add.s32 	%r617, %r616, -128;
	shr.u32 	%r618, %r617, 5;
	and.b32  	%r234, %r228, -2147483648;
	st.local.u32 	[%rd2], %r729;
	bfe.u32 	%r235, %r228, 23, 5;
	mov.u32 	%r619, 6;
	sub.s32 	%r620, %r619, %r618;
	mul.wide.s32 	%rd100, %r620, 4;
	add.s64 	%rd47, %rd1, %rd100;
	ld.local.u32 	%r731, [%rd47];
	ld.local.u32 	%r730, [%rd47+-4];
	setp.eq.s32	%p98, %r235, 0;
	@%p98 bra 	BB2_134;

	mov.u32 	%r621, 32;
	sub.s32 	%r622, %r621, %r235;
	shr.u32 	%r623, %r730, %r622;
	shl.b32 	%r624, %r731, %r235;
	add.s32 	%r731, %r623, %r624;
	ld.local.u32 	%r625, [%rd47+-8];
	shr.u32 	%r626, %r625, %r622;
	shl.b32 	%r627, %r730, %r235;
	add.s32 	%r730, %r626, %r627;

BB2_134:
	shr.u32 	%r628, %r730, 30;
	shl.b32 	%r629, %r731, 2;
	add.s32 	%r733, %r629, %r628;
	shl.b32 	%r243, %r730, 2;
	shr.u32 	%r630, %r733, 31;
	shr.u32 	%r631, %r731, 30;
	add.s32 	%r244, %r630, %r631;
	setp.eq.s32	%p99, %r630, 0;
	@%p99 bra 	BB2_135;

	not.b32 	%r632, %r733;
	neg.s32 	%r732, %r243;
	setp.eq.s32	%p100, %r243, 0;
	selp.u32	%r633, 1, 0, %p100;
	add.s32 	%r733, %r633, %r632;
	xor.b32  	%r734, %r234, -2147483648;
	bra.uni 	BB2_137;

BB2_135:
	mov.u32 	%r732, %r243;
	mov.u32 	%r734, %r234;

BB2_137:
	cvt.u64.u32	%rd101, %r733;
	cvt.u64.u32	%rd102, %r732;
	bfi.b64 	%rd103, %rd101, %rd102, 32, 32;
	cvt.rn.f64.s64	%fd27, %rd103;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f386, %fd28;
	neg.f32 	%f387, %f386;
	setp.eq.s32	%p101, %r734, 0;
	selp.f32	%f449, %f386, %f387, %p101;
	setp.eq.s32	%p102, %r234, 0;
	neg.s32 	%r634, %r244;
	selp.b32	%r735, %r244, %r634, %p102;

BB2_139:
	add.s32 	%r253, %r735, 1;
	and.b32  	%r254, %r253, 1;
	setp.eq.s32	%p103, %r254, 0;
	selp.f32	%f145, %f449, 0f3F800000, %p103;
	mul.rn.f32 	%f146, %f449, %f449;
	fma.rn.f32 	%f147, %f146, %f145, %f172;
	mov.f32 	%f450, 0fB94D4153;
	@%p103 bra 	BB2_141;

	mov.f32 	%f391, 0fBAB607ED;
	mov.f32 	%f392, 0f37CBAC00;
	fma.rn.f32 	%f450, %f392, %f146, %f391;

BB2_141:
	selp.f32	%f393, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f394, %f450, %f146, %f393;
	selp.f32	%f395, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f396, %f394, %f146, %f395;
	fma.rn.f32 	%f451, %f396, %f147, %f145;
	and.b32  	%r635, %r253, 2;
	setp.eq.s32	%p105, %r635, 0;
	@%p105 bra 	BB2_143;

	mov.f32 	%f398, 0fBF800000;
	fma.rn.f32 	%f451, %f451, %f398, %f172;

BB2_143:
	@%p95 bra 	BB2_154;

	setp.eq.f32	%p107, %f141, 0f7F800000;
	@%p107 bra 	BB2_153;
	bra.uni 	BB2_145;

BB2_153:
	mul.rn.f32 	%f452, %f139, %f172;
	bra.uni 	BB2_154;

BB2_145:
	mov.b32 	 %r255, %f139;
	shl.b32 	%r638, %r255, 8;
	or.b32  	%r256, %r638, -2147483648;
	mov.u32 	%r737, 0;
	mov.u64 	%rd132, __cudart_i2opi_f;
	mov.u32 	%r736, -6;
	mov.u64 	%rd133, %rd1;

BB2_146:
	.pragma "nounroll";
	ld.const.u32 	%r641, [%rd132];
	// inline asm
	{
	mad.lo.cc.u32   %r639, %r641, %r256, %r737;
	madc.hi.u32     %r737, %r641, %r256,  0;
	}
	// inline asm
	st.local.u32 	[%rd133], %r639;
	add.s64 	%rd133, %rd133, 4;
	add.s64 	%rd132, %rd132, 4;
	add.s32 	%r736, %r736, 1;
	setp.ne.s32	%p108, %r736, 0;
	@%p108 bra 	BB2_146;

	bfe.u32 	%r644, %r255, 23, 8;
	add.s32 	%r645, %r644, -128;
	shr.u32 	%r646, %r645, 5;
	and.b32  	%r261, %r255, -2147483648;
	st.local.u32 	[%rd2], %r737;
	bfe.u32 	%r262, %r255, 23, 5;
	mov.u32 	%r647, 6;
	sub.s32 	%r648, %r647, %r646;
	mul.wide.s32 	%rd105, %r648, 4;
	add.s64 	%rd52, %rd1, %rd105;
	ld.local.u32 	%r739, [%rd52];
	ld.local.u32 	%r738, [%rd52+-4];
	setp.eq.s32	%p109, %r262, 0;
	@%p109 bra 	BB2_149;

	mov.u32 	%r649, 32;
	sub.s32 	%r650, %r649, %r262;
	shr.u32 	%r651, %r738, %r650;
	shl.b32 	%r652, %r739, %r262;
	add.s32 	%r739, %r651, %r652;
	ld.local.u32 	%r653, [%rd52+-8];
	shr.u32 	%r654, %r653, %r650;
	shl.b32 	%r655, %r738, %r262;
	add.s32 	%r738, %r654, %r655;

BB2_149:
	shr.u32 	%r656, %r738, 30;
	shl.b32 	%r657, %r739, 2;
	add.s32 	%r741, %r657, %r656;
	shl.b32 	%r270, %r738, 2;
	shr.u32 	%r658, %r741, 31;
	shr.u32 	%r659, %r739, 30;
	add.s32 	%r271, %r658, %r659;
	setp.eq.s32	%p110, %r658, 0;
	@%p110 bra 	BB2_150;

	not.b32 	%r660, %r741;
	neg.s32 	%r740, %r270;
	setp.eq.s32	%p111, %r270, 0;
	selp.u32	%r661, 1, 0, %p111;
	add.s32 	%r741, %r661, %r660;
	xor.b32  	%r742, %r261, -2147483648;
	bra.uni 	BB2_152;

BB2_150:
	mov.u32 	%r740, %r270;
	mov.u32 	%r742, %r261;

BB2_152:
	cvt.u64.u32	%rd106, %r741;
	cvt.u64.u32	%rd107, %r740;
	bfi.b64 	%rd108, %rd106, %rd107, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd108;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f399, %fd30;
	neg.f32 	%f400, %f399;
	setp.eq.s32	%p112, %r742, 0;
	selp.f32	%f452, %f399, %f400, %p112;
	setp.eq.s32	%p113, %r261, 0;
	neg.s32 	%r662, %r271;
	selp.b32	%r743, %r271, %r662, %p113;

BB2_154:
	and.b32  	%r280, %r743, 1;
	setp.eq.s32	%p114, %r280, 0;
	selp.f32	%f156, %f452, 0f3F800000, %p114;
	mul.rn.f32 	%f157, %f452, %f452;
	fma.rn.f32 	%f158, %f157, %f156, %f172;
	mov.f32 	%f453, 0fB94D4153;
	@%p114 bra 	BB2_156;

	mov.f32 	%f404, 0fBAB607ED;
	mov.f32 	%f405, 0f37CBAC00;
	fma.rn.f32 	%f453, %f405, %f157, %f404;

BB2_156:
	selp.f32	%f406, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f407, %f453, %f157, %f406;
	selp.f32	%f408, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f409, %f407, %f157, %f408;
	fma.rn.f32 	%f454, %f409, %f158, %f156;
	and.b32  	%r663, %r743, 2;
	setp.eq.s32	%p116, %r663, 0;
	@%p116 bra 	BB2_158;

	mov.f32 	%f411, 0fBF800000;
	fma.rn.f32 	%f454, %f454, %f411, %f172;

BB2_158:
	mul.f32 	%f412, %f138, %f454;
	mul.f32 	%f413, %f137, %f451;
	sub.f32 	%f414, %f413, %f412;
	mul.f32 	%f415, %f138, %f451;
	fma.rn.f32 	%f416, %f137, %f454, %f415;
	add.f32 	%f417, %f135, %f414;
	mul.wide.u32 	%rd110, %r226, 4;
	add.s64 	%rd111, %rd55, %rd110;
	st.global.f32 	[%rd111], %f417;
	add.f32 	%f418, %f136, %f416;
	cvta.to.global.u64 	%rd112, %rd54;
	add.s64 	%rd113, %rd112, %rd110;
	st.global.f32 	[%rd113], %f418;
	sub.f32 	%f419, %f135, %f414;
	st.global.f32 	[%rd111+128], %f419;
	sub.f32 	%f420, %f136, %f416;
	st.global.f32 	[%rd113+128], %f420;
	ret;
}

	// .globl	_occa_Stockhoptimized7_0
.visible .entry _occa_Stockhoptimized7_0(
	.param .u64 _occa_Stockhoptimized7_0_param_0,
	.param .u64 _occa_Stockhoptimized7_0_param_1,
	.param .u32 _occa_Stockhoptimized7_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot3[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<139>;
	.reg .f32 	%f<534>;
	.reg .b32 	%r<897>;
	.reg .f64 	%fd<37>;
	.reg .b64 	%rd<203>;
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized7_0E6FRBank[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized7_0E6FIBank[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized7_0E6SRBank[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized7_0E6SIBank[512];

	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd73, [_occa_Stockhoptimized7_0_param_0];
	ld.param.u64 	%rd74, [_occa_Stockhoptimized7_0_param_1];
	mov.u32 	%r334, %ctaid.x;
	shl.b32 	%r335, %r334, 6;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r336, %r335, %r1;
	and.b32  	%r337, %r336, 63;
	shl.b32 	%r338, %r336, 1;
	and.b32  	%r339, %r338, -128;
	add.s32 	%r340, %r339, %r337;
	cvta.to.global.u64 	%rd75, %rd73;
	mul.wide.u32 	%rd76, %r340, 4;
	add.s64 	%rd77, %rd75, %rd76;
	ld.global.f32 	%f1, [%rd77];
	ld.global.f32 	%f2, [%rd77+256];
	mov.f32 	%f194, 0f80000000;
	cvt.rni.s32.f32	%r2, %f194;
	cvt.rn.f32.s32	%f195, %r2;
	mov.f32 	%f196, 0fBFC90FDA;
	fma.rn.f32 	%f197, %f195, %f196, %f194;
	mov.f32 	%f198, 0fB3A22168;
	fma.rn.f32 	%f199, %f195, %f198, %f197;
	mov.f32 	%f200, 0fA7C234C5;
	fma.rn.f32 	%f3, %f195, %f200, %f199;
	add.s32 	%r3, %r2, 1;
	mul.rn.f32 	%f4, %f3, %f3;
	and.b32  	%r4, %r3, 1;
	setp.eq.s32	%p1, %r4, 0;
	selp.f32	%f5, %f3, 0f3F800000, %p1;
	mov.f32 	%f201, 0f00000000;
	fma.rn.f32 	%f6, %f4, %f5, %f201;
	mov.f32 	%f494, 0fB94D4153;
	@%p1 bra 	BB3_2;

	mov.f32 	%f202, 0fBAB607ED;
	mov.f32 	%f203, 0f37CBAC00;
	fma.rn.f32 	%f494, %f203, %f4, %f202;

BB3_2:
	selp.f32	%f204, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f205, %f494, %f4, %f204;
	selp.f32	%f206, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f207, %f205, %f4, %f206;
	fma.rn.f32 	%f495, %f207, %f6, %f5;
	and.b32  	%r341, %r3, 2;
	setp.eq.s32	%p3, %r341, 0;
	@%p3 bra 	BB3_4;

	mov.f32 	%f209, 0fBF800000;
	fma.rn.f32 	%f495, %f495, %f209, %f201;

BB3_4:
	and.b32  	%r5, %r2, 1;
	setp.eq.s32	%p4, %r5, 0;
	selp.f32	%f12, %f3, 0f3F800000, %p4;
	fma.rn.f32 	%f13, %f4, %f12, %f201;
	mov.f32 	%f496, 0fB94D4153;
	@%p4 bra 	BB3_6;

	mov.f32 	%f212, 0fBAB607ED;
	mov.f32 	%f213, 0f37CBAC00;
	fma.rn.f32 	%f496, %f213, %f4, %f212;

BB3_6:
	selp.f32	%f214, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f215, %f496, %f4, %f214;
	selp.f32	%f216, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f217, %f215, %f4, %f216;
	fma.rn.f32 	%f497, %f217, %f13, %f12;
	and.b32  	%r342, %r2, 2;
	setp.eq.s32	%p6, %r342, 0;
	@%p6 bra 	BB3_8;

	mov.f32 	%f219, 0fBF800000;
	fma.rn.f32 	%f497, %f497, %f219, %f201;

BB3_8:
	mul.f32 	%f220, %f497, 0f00000000;
	mul.f32 	%f221, %f2, %f495;
	sub.f32 	%f222, %f221, %f220;
	mul.f32 	%f223, %f495, 0f00000000;
	fma.rn.f32 	%f224, %f2, %f497, %f223;
	add.f32 	%f225, %f1, %f222;
	shl.b32 	%r343, %r1, 3;
	mov.u32 	%r344, _ZZ24_occa_Stockhoptimized7_0E6FRBank;
	add.s32 	%r345, %r344, %r343;
	st.shared.f32 	[%r345], %f225;
	add.f32 	%f226, %f224, 0f00000000;
	mov.u32 	%r346, _ZZ24_occa_Stockhoptimized7_0E6FIBank;
	add.s32 	%r347, %r346, %r343;
	st.shared.f32 	[%r347], %f226;
	sub.f32 	%f227, %f1, %f222;
	st.shared.f32 	[%r345+4], %f227;
	sub.f32 	%f229, %f201, %f224;
	st.shared.f32 	[%r347+4], %f229;
	bar.sync 	0;
	shl.b32 	%r348, %r1, 2;
	add.s32 	%r350, %r344, %r348;
	ld.shared.f32 	%f19, [%r350];
	add.s32 	%r352, %r346, %r348;
	ld.shared.f32 	%f20, [%r352];
	ld.shared.f32 	%f21, [%r350+256];
	ld.shared.f32 	%f22, [%r352+256];
	shr.u32 	%r353, %r1, 31;
	add.s32 	%r354, %r1, %r353;
	and.b32  	%r355, %r354, 134217726;
	sub.s32 	%r356, %r1, %r355;
	shl.b32 	%r357, %r356, 5;
	cvt.rn.f32.s32	%f230, %r357;
	mul.f32 	%f231, %f230, 0f3C000000;
	cvt.f64.f32	%fd1, %f231;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f23, %fd2;
	mul.f32 	%f232, %f23, 0f3F22F983;
	cvt.rni.s32.f32	%r816, %f232;
	cvt.rn.f32.s32	%f233, %r816;
	fma.rn.f32 	%f235, %f233, %f196, %f23;
	fma.rn.f32 	%f237, %f233, %f198, %f235;
	fma.rn.f32 	%f501, %f233, %f200, %f237;
	abs.f32 	%f25, %f23;
	setp.leu.f32	%p7, %f25, 0f47CE4780;
	mov.u32 	%r808, %r816;
	mov.f32 	%f498, %f501;
	@%p7 bra 	BB3_19;

	setp.eq.f32	%p8, %f25, 0f7F800000;
	@%p8 bra 	BB3_18;
	bra.uni 	BB3_10;

BB3_18:
	mul.rn.f32 	%f498, %f23, %f201;
	mov.u32 	%r808, %r816;
	bra.uni 	BB3_19;

BB3_10:
	mov.b32 	 %r360, %f23;
	shl.b32 	%r361, %r360, 8;
	or.b32  	%r7, %r361, -2147483648;
	add.u64 	%rd79, %SP, 0;
	add.u64 	%rd180, %SPL, 0;
	mov.u32 	%r802, 0;
	mov.u64 	%rd179, __cudart_i2opi_f;
	mov.u32 	%r801, -6;

BB3_11:
	.pragma "nounroll";
	ld.const.u32 	%r364, [%rd179];
	// inline asm
	{
	mad.lo.cc.u32   %r362, %r364, %r7, %r802;
	madc.hi.u32     %r802, %r364, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd180], %r362;
	add.s64 	%rd180, %rd180, 4;
	add.s64 	%rd179, %rd179, 4;
	add.s32 	%r801, %r801, 1;
	setp.ne.s32	%p9, %r801, 0;
	@%p9 bra 	BB3_11;

	bfe.u32 	%r368, %r360, 23, 8;
	add.s32 	%r369, %r368, -128;
	shr.u32 	%r370, %r369, 5;
	and.b32  	%r12, %r360, -2147483648;
	cvta.to.local.u64 	%rd81, %rd79;
	st.local.u32 	[%rd81+24], %r802;
	bfe.u32 	%r13, %r360, 23, 5;
	mov.u32 	%r371, 6;
	sub.s32 	%r372, %r371, %r370;
	mul.wide.s32 	%rd82, %r372, 4;
	add.s64 	%rd6, %rd81, %rd82;
	ld.local.u32 	%r804, [%rd6];
	ld.local.u32 	%r803, [%rd6+-4];
	setp.eq.s32	%p10, %r13, 0;
	@%p10 bra 	BB3_14;

	mov.u32 	%r373, 32;
	sub.s32 	%r374, %r373, %r13;
	shr.u32 	%r375, %r803, %r374;
	shl.b32 	%r376, %r804, %r13;
	add.s32 	%r804, %r375, %r376;
	ld.local.u32 	%r377, [%rd6+-8];
	shr.u32 	%r378, %r377, %r374;
	shl.b32 	%r379, %r803, %r13;
	add.s32 	%r803, %r378, %r379;

BB3_14:
	shr.u32 	%r380, %r803, 30;
	shl.b32 	%r381, %r804, 2;
	add.s32 	%r806, %r381, %r380;
	shl.b32 	%r21, %r803, 2;
	shr.u32 	%r382, %r806, 31;
	shr.u32 	%r383, %r804, 30;
	add.s32 	%r22, %r382, %r383;
	setp.eq.s32	%p11, %r382, 0;
	@%p11 bra 	BB3_15;

	not.b32 	%r384, %r806;
	neg.s32 	%r805, %r21;
	setp.eq.s32	%p12, %r21, 0;
	selp.u32	%r385, 1, 0, %p12;
	add.s32 	%r806, %r385, %r384;
	xor.b32  	%r807, %r12, -2147483648;
	bra.uni 	BB3_17;

BB3_15:
	mov.u32 	%r805, %r21;
	mov.u32 	%r807, %r12;

BB3_17:
	cvt.u64.u32	%rd83, %r806;
	cvt.u64.u32	%rd84, %r805;
	bfi.b64 	%rd85, %rd83, %rd84, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd85;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f239, %fd4;
	neg.f32 	%f240, %f239;
	setp.eq.s32	%p13, %r807, 0;
	selp.f32	%f498, %f239, %f240, %p13;
	setp.eq.s32	%p14, %r12, 0;
	neg.s32 	%r386, %r22;
	selp.b32	%r808, %r22, %r386, %p14;

BB3_19:
	add.s32 	%r31, %r808, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p15, %r32, 0;
	selp.f32	%f29, %f498, 0f3F800000, %p15;
	mul.rn.f32 	%f30, %f498, %f498;
	fma.rn.f32 	%f31, %f30, %f29, %f201;
	mov.f32 	%f499, 0fB94D4153;
	@%p15 bra 	BB3_21;

	mov.f32 	%f244, 0fBAB607ED;
	mov.f32 	%f245, 0f37CBAC00;
	fma.rn.f32 	%f499, %f245, %f30, %f244;

BB3_21:
	selp.f32	%f246, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f247, %f499, %f30, %f246;
	selp.f32	%f248, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f249, %f247, %f30, %f248;
	fma.rn.f32 	%f500, %f249, %f31, %f29;
	and.b32  	%r387, %r31, 2;
	setp.eq.s32	%p17, %r387, 0;
	@%p17 bra 	BB3_23;

	mov.f32 	%f251, 0fBF800000;
	fma.rn.f32 	%f500, %f500, %f251, %f201;

BB3_23:
	@%p7 bra 	BB3_34;

	setp.eq.f32	%p19, %f25, 0f7F800000;
	@%p19 bra 	BB3_33;
	bra.uni 	BB3_25;

BB3_33:
	mul.rn.f32 	%f501, %f23, %f201;
	bra.uni 	BB3_34;

BB3_25:
	mov.b32 	 %r33, %f23;
	shl.b32 	%r390, %r33, 8;
	or.b32  	%r34, %r390, -2147483648;
	add.u64 	%rd87, %SP, 0;
	add.u64 	%rd182, %SPL, 0;
	mov.u32 	%r810, 0;
	mov.u64 	%rd181, __cudart_i2opi_f;
	mov.u32 	%r809, -6;

BB3_26:
	.pragma "nounroll";
	ld.const.u32 	%r393, [%rd181];
	// inline asm
	{
	mad.lo.cc.u32   %r391, %r393, %r34, %r810;
	madc.hi.u32     %r810, %r393, %r34,  0;
	}
	// inline asm
	st.local.u32 	[%rd182], %r391;
	add.s64 	%rd182, %rd182, 4;
	add.s64 	%rd181, %rd181, 4;
	add.s32 	%r809, %r809, 1;
	setp.ne.s32	%p20, %r809, 0;
	@%p20 bra 	BB3_26;

	bfe.u32 	%r396, %r33, 23, 8;
	add.s32 	%r397, %r396, -128;
	shr.u32 	%r398, %r397, 5;
	and.b32  	%r39, %r33, -2147483648;
	cvta.to.local.u64 	%rd89, %rd87;
	st.local.u32 	[%rd89+24], %r810;
	bfe.u32 	%r40, %r33, 23, 5;
	mov.u32 	%r399, 6;
	sub.s32 	%r400, %r399, %r398;
	mul.wide.s32 	%rd90, %r400, 4;
	add.s64 	%rd12, %rd89, %rd90;
	ld.local.u32 	%r812, [%rd12];
	ld.local.u32 	%r811, [%rd12+-4];
	setp.eq.s32	%p21, %r40, 0;
	@%p21 bra 	BB3_29;

	mov.u32 	%r401, 32;
	sub.s32 	%r402, %r401, %r40;
	shr.u32 	%r403, %r811, %r402;
	shl.b32 	%r404, %r812, %r40;
	add.s32 	%r812, %r403, %r404;
	ld.local.u32 	%r405, [%rd12+-8];
	shr.u32 	%r406, %r405, %r402;
	shl.b32 	%r407, %r811, %r40;
	add.s32 	%r811, %r406, %r407;

BB3_29:
	shr.u32 	%r408, %r811, 30;
	shl.b32 	%r409, %r812, 2;
	add.s32 	%r814, %r409, %r408;
	shl.b32 	%r48, %r811, 2;
	shr.u32 	%r410, %r814, 31;
	shr.u32 	%r411, %r812, 30;
	add.s32 	%r49, %r410, %r411;
	setp.eq.s32	%p22, %r410, 0;
	@%p22 bra 	BB3_30;

	not.b32 	%r412, %r814;
	neg.s32 	%r813, %r48;
	setp.eq.s32	%p23, %r48, 0;
	selp.u32	%r413, 1, 0, %p23;
	add.s32 	%r814, %r413, %r412;
	xor.b32  	%r815, %r39, -2147483648;
	bra.uni 	BB3_32;

BB3_30:
	mov.u32 	%r813, %r48;
	mov.u32 	%r815, %r39;

BB3_32:
	cvt.u64.u32	%rd91, %r814;
	cvt.u64.u32	%rd92, %r813;
	bfi.b64 	%rd93, %rd91, %rd92, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd93;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f252, %fd6;
	neg.f32 	%f253, %f252;
	setp.eq.s32	%p24, %r815, 0;
	selp.f32	%f501, %f252, %f253, %p24;
	setp.eq.s32	%p25, %r39, 0;
	neg.s32 	%r414, %r49;
	selp.b32	%r816, %r49, %r414, %p25;

BB3_34:
	and.b32  	%r58, %r816, 1;
	setp.eq.s32	%p26, %r58, 0;
	selp.f32	%f40, %f501, 0f3F800000, %p26;
	mul.rn.f32 	%f41, %f501, %f501;
	fma.rn.f32 	%f42, %f41, %f40, %f201;
	mov.f32 	%f502, 0fB94D4153;
	@%p26 bra 	BB3_36;

	mov.f32 	%f257, 0fBAB607ED;
	mov.f32 	%f258, 0f37CBAC00;
	fma.rn.f32 	%f502, %f258, %f41, %f257;

BB3_36:
	selp.f32	%f259, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f260, %f502, %f41, %f259;
	selp.f32	%f261, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f262, %f260, %f41, %f261;
	fma.rn.f32 	%f503, %f262, %f42, %f40;
	and.b32  	%r415, %r816, 2;
	setp.eq.s32	%p28, %r415, 0;
	@%p28 bra 	BB3_38;

	mov.f32 	%f264, 0fBF800000;
	fma.rn.f32 	%f503, %f503, %f264, %f201;

BB3_38:
	mul.f32 	%f265, %f22, %f503;
	mul.f32 	%f266, %f21, %f500;
	sub.f32 	%f267, %f266, %f265;
	mul.f32 	%f268, %f22, %f500;
	fma.rn.f32 	%f269, %f21, %f503, %f268;
	add.f32 	%f270, %f19, %f267;
	shl.b32 	%r416, %r1, 1;
	and.b32  	%r417, %r416, 1073741820;
	and.b32  	%r418, %r1, 1;
	add.s32 	%r419, %r417, %r418;
	shl.b32 	%r420, %r419, 2;
	mov.u32 	%r421, _ZZ24_occa_Stockhoptimized7_0E6SRBank;
	add.s32 	%r422, %r421, %r420;
	st.shared.f32 	[%r422], %f270;
	add.f32 	%f271, %f20, %f269;
	mov.u32 	%r423, _ZZ24_occa_Stockhoptimized7_0E6SIBank;
	add.s32 	%r424, %r423, %r420;
	st.shared.f32 	[%r424], %f271;
	sub.f32 	%f272, %f19, %f267;
	st.shared.f32 	[%r422+8], %f272;
	sub.f32 	%f273, %f20, %f269;
	st.shared.f32 	[%r424+8], %f273;
	bar.sync 	0;
	add.s32 	%r427, %r421, %r348;
	ld.shared.f32 	%f48, [%r427];
	add.s32 	%r429, %r423, %r348;
	ld.shared.f32 	%f49, [%r429];
	ld.shared.f32 	%f50, [%r427+256];
	ld.shared.f32 	%f51, [%r429+256];
	shr.s32 	%r430, %r1, 31;
	shr.u32 	%r431, %r430, 30;
	add.s32 	%r432, %r1, %r431;
	and.b32  	%r433, %r432, 268435452;
	sub.s32 	%r434, %r1, %r433;
	shl.b32 	%r435, %r434, 4;
	cvt.rn.f32.s32	%f274, %r435;
	mul.f32 	%f275, %f274, 0f3C000000;
	cvt.f64.f32	%fd7, %f275;
	mul.f64 	%fd8, %fd7, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f52, %fd8;
	mul.f32 	%f276, %f52, 0f3F22F983;
	cvt.rni.s32.f32	%r832, %f276;
	cvt.rn.f32.s32	%f277, %r832;
	fma.rn.f32 	%f279, %f277, %f196, %f52;
	fma.rn.f32 	%f281, %f277, %f198, %f279;
	fma.rn.f32 	%f507, %f277, %f200, %f281;
	abs.f32 	%f54, %f52;
	setp.leu.f32	%p29, %f54, 0f47CE4780;
	mov.u32 	%r824, %r832;
	mov.f32 	%f504, %f507;
	@%p29 bra 	BB3_49;

	setp.eq.f32	%p30, %f54, 0f7F800000;
	@%p30 bra 	BB3_48;
	bra.uni 	BB3_40;

BB3_48:
	mul.rn.f32 	%f504, %f52, %f201;
	mov.u32 	%r824, %r832;
	bra.uni 	BB3_49;

BB3_40:
	mov.b32 	 %r61, %f52;
	shl.b32 	%r438, %r61, 8;
	or.b32  	%r62, %r438, -2147483648;
	add.u64 	%rd95, %SP, 0;
	add.u64 	%rd184, %SPL, 0;
	mov.u32 	%r818, 0;
	mov.u64 	%rd183, __cudart_i2opi_f;
	mov.u32 	%r817, -6;

BB3_41:
	.pragma "nounroll";
	ld.const.u32 	%r441, [%rd183];
	// inline asm
	{
	mad.lo.cc.u32   %r439, %r441, %r62, %r818;
	madc.hi.u32     %r818, %r441, %r62,  0;
	}
	// inline asm
	st.local.u32 	[%rd184], %r439;
	add.s64 	%rd184, %rd184, 4;
	add.s64 	%rd183, %rd183, 4;
	add.s32 	%r817, %r817, 1;
	setp.ne.s32	%p31, %r817, 0;
	@%p31 bra 	BB3_41;

	bfe.u32 	%r444, %r61, 23, 8;
	add.s32 	%r445, %r444, -128;
	shr.u32 	%r446, %r445, 5;
	and.b32  	%r67, %r61, -2147483648;
	cvta.to.local.u64 	%rd97, %rd95;
	st.local.u32 	[%rd97+24], %r818;
	bfe.u32 	%r68, %r61, 23, 5;
	mov.u32 	%r447, 6;
	sub.s32 	%r448, %r447, %r446;
	mul.wide.s32 	%rd98, %r448, 4;
	add.s64 	%rd18, %rd97, %rd98;
	ld.local.u32 	%r820, [%rd18];
	ld.local.u32 	%r819, [%rd18+-4];
	setp.eq.s32	%p32, %r68, 0;
	@%p32 bra 	BB3_44;

	mov.u32 	%r449, 32;
	sub.s32 	%r450, %r449, %r68;
	shr.u32 	%r451, %r819, %r450;
	shl.b32 	%r452, %r820, %r68;
	add.s32 	%r820, %r451, %r452;
	ld.local.u32 	%r453, [%rd18+-8];
	shr.u32 	%r454, %r453, %r450;
	shl.b32 	%r455, %r819, %r68;
	add.s32 	%r819, %r454, %r455;

BB3_44:
	shr.u32 	%r456, %r819, 30;
	shl.b32 	%r457, %r820, 2;
	add.s32 	%r822, %r457, %r456;
	shl.b32 	%r76, %r819, 2;
	shr.u32 	%r458, %r822, 31;
	shr.u32 	%r459, %r820, 30;
	add.s32 	%r77, %r458, %r459;
	setp.eq.s32	%p33, %r458, 0;
	@%p33 bra 	BB3_45;

	not.b32 	%r460, %r822;
	neg.s32 	%r821, %r76;
	setp.eq.s32	%p34, %r76, 0;
	selp.u32	%r461, 1, 0, %p34;
	add.s32 	%r822, %r461, %r460;
	xor.b32  	%r823, %r67, -2147483648;
	bra.uni 	BB3_47;

BB3_45:
	mov.u32 	%r821, %r76;
	mov.u32 	%r823, %r67;

BB3_47:
	cvt.u64.u32	%rd99, %r822;
	cvt.u64.u32	%rd100, %r821;
	bfi.b64 	%rd101, %rd99, %rd100, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd101;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f283, %fd10;
	neg.f32 	%f284, %f283;
	setp.eq.s32	%p35, %r823, 0;
	selp.f32	%f504, %f283, %f284, %p35;
	setp.eq.s32	%p36, %r67, 0;
	neg.s32 	%r462, %r77;
	selp.b32	%r824, %r77, %r462, %p36;

BB3_49:
	add.s32 	%r86, %r824, 1;
	and.b32  	%r87, %r86, 1;
	setp.eq.s32	%p37, %r87, 0;
	selp.f32	%f58, %f504, 0f3F800000, %p37;
	mul.rn.f32 	%f59, %f504, %f504;
	fma.rn.f32 	%f60, %f59, %f58, %f201;
	mov.f32 	%f505, 0fB94D4153;
	@%p37 bra 	BB3_51;

	mov.f32 	%f288, 0fBAB607ED;
	mov.f32 	%f289, 0f37CBAC00;
	fma.rn.f32 	%f505, %f289, %f59, %f288;

BB3_51:
	selp.f32	%f290, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f291, %f505, %f59, %f290;
	selp.f32	%f292, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f293, %f291, %f59, %f292;
	fma.rn.f32 	%f506, %f293, %f60, %f58;
	and.b32  	%r463, %r86, 2;
	setp.eq.s32	%p39, %r463, 0;
	@%p39 bra 	BB3_53;

	mov.f32 	%f295, 0fBF800000;
	fma.rn.f32 	%f506, %f506, %f295, %f201;

BB3_53:
	@%p29 bra 	BB3_64;

	setp.eq.f32	%p41, %f54, 0f7F800000;
	@%p41 bra 	BB3_63;
	bra.uni 	BB3_55;

BB3_63:
	mul.rn.f32 	%f507, %f52, %f201;
	bra.uni 	BB3_64;

BB3_55:
	mov.b32 	 %r88, %f52;
	shl.b32 	%r466, %r88, 8;
	or.b32  	%r89, %r466, -2147483648;
	add.u64 	%rd103, %SP, 0;
	add.u64 	%rd186, %SPL, 0;
	mov.u32 	%r826, 0;
	mov.u64 	%rd185, __cudart_i2opi_f;
	mov.u32 	%r825, -6;

BB3_56:
	.pragma "nounroll";
	ld.const.u32 	%r469, [%rd185];
	// inline asm
	{
	mad.lo.cc.u32   %r467, %r469, %r89, %r826;
	madc.hi.u32     %r826, %r469, %r89,  0;
	}
	// inline asm
	st.local.u32 	[%rd186], %r467;
	add.s64 	%rd186, %rd186, 4;
	add.s64 	%rd185, %rd185, 4;
	add.s32 	%r825, %r825, 1;
	setp.ne.s32	%p42, %r825, 0;
	@%p42 bra 	BB3_56;

	bfe.u32 	%r472, %r88, 23, 8;
	add.s32 	%r473, %r472, -128;
	shr.u32 	%r474, %r473, 5;
	and.b32  	%r94, %r88, -2147483648;
	cvta.to.local.u64 	%rd105, %rd103;
	st.local.u32 	[%rd105+24], %r826;
	bfe.u32 	%r95, %r88, 23, 5;
	mov.u32 	%r475, 6;
	sub.s32 	%r476, %r475, %r474;
	mul.wide.s32 	%rd106, %r476, 4;
	add.s64 	%rd24, %rd105, %rd106;
	ld.local.u32 	%r828, [%rd24];
	ld.local.u32 	%r827, [%rd24+-4];
	setp.eq.s32	%p43, %r95, 0;
	@%p43 bra 	BB3_59;

	mov.u32 	%r477, 32;
	sub.s32 	%r478, %r477, %r95;
	shr.u32 	%r479, %r827, %r478;
	shl.b32 	%r480, %r828, %r95;
	add.s32 	%r828, %r479, %r480;
	ld.local.u32 	%r481, [%rd24+-8];
	shr.u32 	%r482, %r481, %r478;
	shl.b32 	%r483, %r827, %r95;
	add.s32 	%r827, %r482, %r483;

BB3_59:
	shr.u32 	%r484, %r827, 30;
	shl.b32 	%r485, %r828, 2;
	add.s32 	%r830, %r485, %r484;
	shl.b32 	%r103, %r827, 2;
	shr.u32 	%r486, %r830, 31;
	shr.u32 	%r487, %r828, 30;
	add.s32 	%r104, %r486, %r487;
	setp.eq.s32	%p44, %r486, 0;
	@%p44 bra 	BB3_60;

	not.b32 	%r488, %r830;
	neg.s32 	%r829, %r103;
	setp.eq.s32	%p45, %r103, 0;
	selp.u32	%r489, 1, 0, %p45;
	add.s32 	%r830, %r489, %r488;
	xor.b32  	%r831, %r94, -2147483648;
	bra.uni 	BB3_62;

BB3_60:
	mov.u32 	%r829, %r103;
	mov.u32 	%r831, %r94;

BB3_62:
	cvt.u64.u32	%rd107, %r830;
	cvt.u64.u32	%rd108, %r829;
	bfi.b64 	%rd109, %rd107, %rd108, 32, 32;
	cvt.rn.f64.s64	%fd11, %rd109;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f296, %fd12;
	neg.f32 	%f297, %f296;
	setp.eq.s32	%p46, %r831, 0;
	selp.f32	%f507, %f296, %f297, %p46;
	setp.eq.s32	%p47, %r94, 0;
	neg.s32 	%r490, %r104;
	selp.b32	%r832, %r104, %r490, %p47;

BB3_64:
	and.b32  	%r113, %r832, 1;
	setp.eq.s32	%p48, %r113, 0;
	selp.f32	%f69, %f507, 0f3F800000, %p48;
	mul.rn.f32 	%f70, %f507, %f507;
	fma.rn.f32 	%f71, %f70, %f69, %f201;
	mov.f32 	%f508, 0fB94D4153;
	@%p48 bra 	BB3_66;

	mov.f32 	%f301, 0fBAB607ED;
	mov.f32 	%f302, 0f37CBAC00;
	fma.rn.f32 	%f508, %f302, %f70, %f301;

BB3_66:
	selp.f32	%f303, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f304, %f508, %f70, %f303;
	selp.f32	%f305, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f306, %f304, %f70, %f305;
	fma.rn.f32 	%f509, %f306, %f71, %f69;
	and.b32  	%r491, %r832, 2;
	setp.eq.s32	%p50, %r491, 0;
	@%p50 bra 	BB3_68;

	mov.f32 	%f308, 0fBF800000;
	fma.rn.f32 	%f509, %f509, %f308, %f201;

BB3_68:
	and.b32  	%r492, %r1, 3;
	and.b32  	%r494, %r416, 1073741816;
	add.s32 	%r495, %r494, %r492;
	mul.f32 	%f309, %f51, %f509;
	mul.f32 	%f310, %f50, %f506;
	sub.f32 	%f311, %f310, %f309;
	mul.f32 	%f312, %f51, %f506;
	fma.rn.f32 	%f313, %f50, %f509, %f312;
	add.f32 	%f314, %f48, %f311;
	shl.b32 	%r496, %r495, 2;
	add.s32 	%r498, %r344, %r496;
	st.shared.f32 	[%r498], %f314;
	add.f32 	%f315, %f49, %f313;
	add.s32 	%r500, %r346, %r496;
	st.shared.f32 	[%r500], %f315;
	sub.f32 	%f316, %f48, %f311;
	st.shared.f32 	[%r498+16], %f316;
	sub.f32 	%f317, %f49, %f313;
	st.shared.f32 	[%r500+16], %f317;
	bar.sync 	0;
	ld.shared.f32 	%f77, [%r350];
	ld.shared.f32 	%f78, [%r352];
	ld.shared.f32 	%f79, [%r350+256];
	ld.shared.f32 	%f80, [%r352+256];
	shr.u32 	%r507, %r430, 29;
	add.s32 	%r508, %r1, %r507;
	and.b32  	%r509, %r508, 536870904;
	sub.s32 	%r510, %r1, %r509;
	shl.b32 	%r511, %r510, 3;
	cvt.rn.f32.s32	%f318, %r511;
	mul.f32 	%f319, %f318, 0f3C000000;
	cvt.f64.f32	%fd13, %f319;
	mul.f64 	%fd14, %fd13, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f81, %fd14;
	mul.f32 	%f320, %f81, 0f3F22F983;
	cvt.rni.s32.f32	%r848, %f320;
	cvt.rn.f32.s32	%f321, %r848;
	fma.rn.f32 	%f323, %f321, %f196, %f81;
	fma.rn.f32 	%f325, %f321, %f198, %f323;
	fma.rn.f32 	%f513, %f321, %f200, %f325;
	abs.f32 	%f83, %f81;
	setp.leu.f32	%p51, %f83, 0f47CE4780;
	mov.u32 	%r840, %r848;
	mov.f32 	%f510, %f513;
	@%p51 bra 	BB3_79;

	setp.eq.f32	%p52, %f83, 0f7F800000;
	@%p52 bra 	BB3_78;
	bra.uni 	BB3_70;

BB3_78:
	mul.rn.f32 	%f510, %f81, %f201;
	mov.u32 	%r840, %r848;
	bra.uni 	BB3_79;

BB3_70:
	mov.b32 	 %r116, %f81;
	shl.b32 	%r514, %r116, 8;
	or.b32  	%r117, %r514, -2147483648;
	add.u64 	%rd111, %SP, 0;
	add.u64 	%rd188, %SPL, 0;
	mov.u32 	%r834, 0;
	mov.u64 	%rd187, __cudart_i2opi_f;
	mov.u32 	%r833, -6;

BB3_71:
	.pragma "nounroll";
	ld.const.u32 	%r517, [%rd187];
	// inline asm
	{
	mad.lo.cc.u32   %r515, %r517, %r117, %r834;
	madc.hi.u32     %r834, %r517, %r117,  0;
	}
	// inline asm
	st.local.u32 	[%rd188], %r515;
	add.s64 	%rd188, %rd188, 4;
	add.s64 	%rd187, %rd187, 4;
	add.s32 	%r833, %r833, 1;
	setp.ne.s32	%p53, %r833, 0;
	@%p53 bra 	BB3_71;

	bfe.u32 	%r520, %r116, 23, 8;
	add.s32 	%r521, %r520, -128;
	shr.u32 	%r522, %r521, 5;
	and.b32  	%r122, %r116, -2147483648;
	cvta.to.local.u64 	%rd113, %rd111;
	st.local.u32 	[%rd113+24], %r834;
	bfe.u32 	%r123, %r116, 23, 5;
	mov.u32 	%r523, 6;
	sub.s32 	%r524, %r523, %r522;
	mul.wide.s32 	%rd114, %r524, 4;
	add.s64 	%rd30, %rd113, %rd114;
	ld.local.u32 	%r836, [%rd30];
	ld.local.u32 	%r835, [%rd30+-4];
	setp.eq.s32	%p54, %r123, 0;
	@%p54 bra 	BB3_74;

	mov.u32 	%r525, 32;
	sub.s32 	%r526, %r525, %r123;
	shr.u32 	%r527, %r835, %r526;
	shl.b32 	%r528, %r836, %r123;
	add.s32 	%r836, %r527, %r528;
	ld.local.u32 	%r529, [%rd30+-8];
	shr.u32 	%r530, %r529, %r526;
	shl.b32 	%r531, %r835, %r123;
	add.s32 	%r835, %r530, %r531;

BB3_74:
	shr.u32 	%r532, %r835, 30;
	shl.b32 	%r533, %r836, 2;
	add.s32 	%r838, %r533, %r532;
	shl.b32 	%r131, %r835, 2;
	shr.u32 	%r534, %r838, 31;
	shr.u32 	%r535, %r836, 30;
	add.s32 	%r132, %r534, %r535;
	setp.eq.s32	%p55, %r534, 0;
	@%p55 bra 	BB3_75;

	not.b32 	%r536, %r838;
	neg.s32 	%r837, %r131;
	setp.eq.s32	%p56, %r131, 0;
	selp.u32	%r537, 1, 0, %p56;
	add.s32 	%r838, %r537, %r536;
	xor.b32  	%r839, %r122, -2147483648;
	bra.uni 	BB3_77;

BB3_75:
	mov.u32 	%r837, %r131;
	mov.u32 	%r839, %r122;

BB3_77:
	cvt.u64.u32	%rd115, %r838;
	cvt.u64.u32	%rd116, %r837;
	bfi.b64 	%rd117, %rd115, %rd116, 32, 32;
	cvt.rn.f64.s64	%fd15, %rd117;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f327, %fd16;
	neg.f32 	%f328, %f327;
	setp.eq.s32	%p57, %r839, 0;
	selp.f32	%f510, %f327, %f328, %p57;
	setp.eq.s32	%p58, %r122, 0;
	neg.s32 	%r538, %r132;
	selp.b32	%r840, %r132, %r538, %p58;

BB3_79:
	add.s32 	%r141, %r840, 1;
	and.b32  	%r142, %r141, 1;
	setp.eq.s32	%p59, %r142, 0;
	selp.f32	%f87, %f510, 0f3F800000, %p59;
	mul.rn.f32 	%f88, %f510, %f510;
	fma.rn.f32 	%f89, %f88, %f87, %f201;
	mov.f32 	%f511, 0fB94D4153;
	@%p59 bra 	BB3_81;

	mov.f32 	%f332, 0fBAB607ED;
	mov.f32 	%f333, 0f37CBAC00;
	fma.rn.f32 	%f511, %f333, %f88, %f332;

BB3_81:
	selp.f32	%f334, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f335, %f511, %f88, %f334;
	selp.f32	%f336, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f337, %f335, %f88, %f336;
	fma.rn.f32 	%f512, %f337, %f89, %f87;
	and.b32  	%r539, %r141, 2;
	setp.eq.s32	%p61, %r539, 0;
	@%p61 bra 	BB3_83;

	mov.f32 	%f339, 0fBF800000;
	fma.rn.f32 	%f512, %f512, %f339, %f201;

BB3_83:
	@%p51 bra 	BB3_94;

	setp.eq.f32	%p63, %f83, 0f7F800000;
	@%p63 bra 	BB3_93;
	bra.uni 	BB3_85;

BB3_93:
	mul.rn.f32 	%f513, %f81, %f201;
	bra.uni 	BB3_94;

BB3_85:
	mov.b32 	 %r143, %f81;
	shl.b32 	%r542, %r143, 8;
	or.b32  	%r144, %r542, -2147483648;
	add.u64 	%rd119, %SP, 0;
	add.u64 	%rd190, %SPL, 0;
	mov.u32 	%r842, 0;
	mov.u64 	%rd189, __cudart_i2opi_f;
	mov.u32 	%r841, -6;

BB3_86:
	.pragma "nounroll";
	ld.const.u32 	%r545, [%rd189];
	// inline asm
	{
	mad.lo.cc.u32   %r543, %r545, %r144, %r842;
	madc.hi.u32     %r842, %r545, %r144,  0;
	}
	// inline asm
	st.local.u32 	[%rd190], %r543;
	add.s64 	%rd190, %rd190, 4;
	add.s64 	%rd189, %rd189, 4;
	add.s32 	%r841, %r841, 1;
	setp.ne.s32	%p64, %r841, 0;
	@%p64 bra 	BB3_86;

	bfe.u32 	%r548, %r143, 23, 8;
	add.s32 	%r549, %r548, -128;
	shr.u32 	%r550, %r549, 5;
	and.b32  	%r149, %r143, -2147483648;
	cvta.to.local.u64 	%rd121, %rd119;
	st.local.u32 	[%rd121+24], %r842;
	bfe.u32 	%r150, %r143, 23, 5;
	mov.u32 	%r551, 6;
	sub.s32 	%r552, %r551, %r550;
	mul.wide.s32 	%rd122, %r552, 4;
	add.s64 	%rd36, %rd121, %rd122;
	ld.local.u32 	%r844, [%rd36];
	ld.local.u32 	%r843, [%rd36+-4];
	setp.eq.s32	%p65, %r150, 0;
	@%p65 bra 	BB3_89;

	mov.u32 	%r553, 32;
	sub.s32 	%r554, %r553, %r150;
	shr.u32 	%r555, %r843, %r554;
	shl.b32 	%r556, %r844, %r150;
	add.s32 	%r844, %r555, %r556;
	ld.local.u32 	%r557, [%rd36+-8];
	shr.u32 	%r558, %r557, %r554;
	shl.b32 	%r559, %r843, %r150;
	add.s32 	%r843, %r558, %r559;

BB3_89:
	shr.u32 	%r560, %r843, 30;
	shl.b32 	%r561, %r844, 2;
	add.s32 	%r846, %r561, %r560;
	shl.b32 	%r158, %r843, 2;
	shr.u32 	%r562, %r846, 31;
	shr.u32 	%r563, %r844, 30;
	add.s32 	%r159, %r562, %r563;
	setp.eq.s32	%p66, %r562, 0;
	@%p66 bra 	BB3_90;

	not.b32 	%r564, %r846;
	neg.s32 	%r845, %r158;
	setp.eq.s32	%p67, %r158, 0;
	selp.u32	%r565, 1, 0, %p67;
	add.s32 	%r846, %r565, %r564;
	xor.b32  	%r847, %r149, -2147483648;
	bra.uni 	BB3_92;

BB3_90:
	mov.u32 	%r845, %r158;
	mov.u32 	%r847, %r149;

BB3_92:
	cvt.u64.u32	%rd123, %r846;
	cvt.u64.u32	%rd124, %r845;
	bfi.b64 	%rd125, %rd123, %rd124, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd125;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f340, %fd18;
	neg.f32 	%f341, %f340;
	setp.eq.s32	%p68, %r847, 0;
	selp.f32	%f513, %f340, %f341, %p68;
	setp.eq.s32	%p69, %r149, 0;
	neg.s32 	%r566, %r159;
	selp.b32	%r848, %r159, %r566, %p69;

BB3_94:
	and.b32  	%r168, %r848, 1;
	setp.eq.s32	%p70, %r168, 0;
	selp.f32	%f98, %f513, 0f3F800000, %p70;
	mul.rn.f32 	%f99, %f513, %f513;
	fma.rn.f32 	%f100, %f99, %f98, %f201;
	mov.f32 	%f514, 0fB94D4153;
	@%p70 bra 	BB3_96;

	mov.f32 	%f345, 0fBAB607ED;
	mov.f32 	%f346, 0f37CBAC00;
	fma.rn.f32 	%f514, %f346, %f99, %f345;

BB3_96:
	selp.f32	%f347, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f348, %f514, %f99, %f347;
	selp.f32	%f349, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f350, %f348, %f99, %f349;
	fma.rn.f32 	%f515, %f350, %f100, %f98;
	and.b32  	%r567, %r848, 2;
	setp.eq.s32	%p72, %r567, 0;
	@%p72 bra 	BB3_98;

	mov.f32 	%f352, 0fBF800000;
	fma.rn.f32 	%f515, %f515, %f352, %f201;

BB3_98:
	and.b32  	%r568, %r1, 7;
	and.b32  	%r570, %r416, 1073741808;
	add.s32 	%r571, %r570, %r568;
	mul.f32 	%f353, %f80, %f515;
	mul.f32 	%f354, %f79, %f512;
	sub.f32 	%f355, %f354, %f353;
	mul.f32 	%f356, %f80, %f512;
	fma.rn.f32 	%f357, %f79, %f515, %f356;
	add.f32 	%f358, %f77, %f355;
	shl.b32 	%r572, %r571, 2;
	add.s32 	%r574, %r421, %r572;
	st.shared.f32 	[%r574], %f358;
	add.f32 	%f359, %f78, %f357;
	add.s32 	%r576, %r423, %r572;
	st.shared.f32 	[%r576], %f359;
	sub.f32 	%f360, %f77, %f355;
	st.shared.f32 	[%r574+32], %f360;
	sub.f32 	%f361, %f78, %f357;
	st.shared.f32 	[%r576+32], %f361;
	bar.sync 	0;
	ld.shared.f32 	%f106, [%r427];
	ld.shared.f32 	%f107, [%r429];
	ld.shared.f32 	%f108, [%r427+256];
	ld.shared.f32 	%f109, [%r429+256];
	shr.u32 	%r583, %r430, 28;
	add.s32 	%r584, %r1, %r583;
	and.b32  	%r585, %r584, 1073741808;
	sub.s32 	%r586, %r1, %r585;
	shl.b32 	%r587, %r586, 2;
	cvt.rn.f32.s32	%f362, %r587;
	mul.f32 	%f363, %f362, 0f3C000000;
	cvt.f64.f32	%fd19, %f363;
	mul.f64 	%fd20, %fd19, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f110, %fd20;
	mul.f32 	%f364, %f110, 0f3F22F983;
	cvt.rni.s32.f32	%r864, %f364;
	cvt.rn.f32.s32	%f365, %r864;
	fma.rn.f32 	%f367, %f365, %f196, %f110;
	fma.rn.f32 	%f369, %f365, %f198, %f367;
	fma.rn.f32 	%f519, %f365, %f200, %f369;
	abs.f32 	%f112, %f110;
	setp.leu.f32	%p73, %f112, 0f47CE4780;
	mov.u32 	%r856, %r864;
	mov.f32 	%f516, %f519;
	@%p73 bra 	BB3_109;

	setp.eq.f32	%p74, %f112, 0f7F800000;
	@%p74 bra 	BB3_108;
	bra.uni 	BB3_100;

BB3_108:
	mul.rn.f32 	%f516, %f110, %f201;
	mov.u32 	%r856, %r864;
	bra.uni 	BB3_109;

BB3_100:
	mov.b32 	 %r171, %f110;
	shl.b32 	%r590, %r171, 8;
	or.b32  	%r172, %r590, -2147483648;
	add.u64 	%rd127, %SP, 0;
	add.u64 	%rd192, %SPL, 0;
	mov.u32 	%r850, 0;
	mov.u64 	%rd191, __cudart_i2opi_f;
	mov.u32 	%r849, -6;

BB3_101:
	.pragma "nounroll";
	ld.const.u32 	%r593, [%rd191];
	// inline asm
	{
	mad.lo.cc.u32   %r591, %r593, %r172, %r850;
	madc.hi.u32     %r850, %r593, %r172,  0;
	}
	// inline asm
	st.local.u32 	[%rd192], %r591;
	add.s64 	%rd192, %rd192, 4;
	add.s64 	%rd191, %rd191, 4;
	add.s32 	%r849, %r849, 1;
	setp.ne.s32	%p75, %r849, 0;
	@%p75 bra 	BB3_101;

	bfe.u32 	%r596, %r171, 23, 8;
	add.s32 	%r597, %r596, -128;
	shr.u32 	%r598, %r597, 5;
	and.b32  	%r177, %r171, -2147483648;
	cvta.to.local.u64 	%rd129, %rd127;
	st.local.u32 	[%rd129+24], %r850;
	bfe.u32 	%r178, %r171, 23, 5;
	mov.u32 	%r599, 6;
	sub.s32 	%r600, %r599, %r598;
	mul.wide.s32 	%rd130, %r600, 4;
	add.s64 	%rd42, %rd129, %rd130;
	ld.local.u32 	%r852, [%rd42];
	ld.local.u32 	%r851, [%rd42+-4];
	setp.eq.s32	%p76, %r178, 0;
	@%p76 bra 	BB3_104;

	mov.u32 	%r601, 32;
	sub.s32 	%r602, %r601, %r178;
	shr.u32 	%r603, %r851, %r602;
	shl.b32 	%r604, %r852, %r178;
	add.s32 	%r852, %r603, %r604;
	ld.local.u32 	%r605, [%rd42+-8];
	shr.u32 	%r606, %r605, %r602;
	shl.b32 	%r607, %r851, %r178;
	add.s32 	%r851, %r606, %r607;

BB3_104:
	shr.u32 	%r608, %r851, 30;
	shl.b32 	%r609, %r852, 2;
	add.s32 	%r854, %r609, %r608;
	shl.b32 	%r186, %r851, 2;
	shr.u32 	%r610, %r854, 31;
	shr.u32 	%r611, %r852, 30;
	add.s32 	%r187, %r610, %r611;
	setp.eq.s32	%p77, %r610, 0;
	@%p77 bra 	BB3_105;

	not.b32 	%r612, %r854;
	neg.s32 	%r853, %r186;
	setp.eq.s32	%p78, %r186, 0;
	selp.u32	%r613, 1, 0, %p78;
	add.s32 	%r854, %r613, %r612;
	xor.b32  	%r855, %r177, -2147483648;
	bra.uni 	BB3_107;

BB3_105:
	mov.u32 	%r853, %r186;
	mov.u32 	%r855, %r177;

BB3_107:
	cvt.u64.u32	%rd131, %r854;
	cvt.u64.u32	%rd132, %r853;
	bfi.b64 	%rd133, %rd131, %rd132, 32, 32;
	cvt.rn.f64.s64	%fd21, %rd133;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f371, %fd22;
	neg.f32 	%f372, %f371;
	setp.eq.s32	%p79, %r855, 0;
	selp.f32	%f516, %f371, %f372, %p79;
	setp.eq.s32	%p80, %r177, 0;
	neg.s32 	%r614, %r187;
	selp.b32	%r856, %r187, %r614, %p80;

BB3_109:
	add.s32 	%r196, %r856, 1;
	and.b32  	%r197, %r196, 1;
	setp.eq.s32	%p81, %r197, 0;
	selp.f32	%f116, %f516, 0f3F800000, %p81;
	mul.rn.f32 	%f117, %f516, %f516;
	fma.rn.f32 	%f118, %f117, %f116, %f201;
	mov.f32 	%f517, 0fB94D4153;
	@%p81 bra 	BB3_111;

	mov.f32 	%f376, 0fBAB607ED;
	mov.f32 	%f377, 0f37CBAC00;
	fma.rn.f32 	%f517, %f377, %f117, %f376;

BB3_111:
	selp.f32	%f378, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f379, %f517, %f117, %f378;
	selp.f32	%f380, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f381, %f379, %f117, %f380;
	fma.rn.f32 	%f518, %f381, %f118, %f116;
	and.b32  	%r615, %r196, 2;
	setp.eq.s32	%p83, %r615, 0;
	@%p83 bra 	BB3_113;

	mov.f32 	%f383, 0fBF800000;
	fma.rn.f32 	%f518, %f518, %f383, %f201;

BB3_113:
	@%p73 bra 	BB3_124;

	setp.eq.f32	%p85, %f112, 0f7F800000;
	@%p85 bra 	BB3_123;
	bra.uni 	BB3_115;

BB3_123:
	mul.rn.f32 	%f519, %f110, %f201;
	bra.uni 	BB3_124;

BB3_115:
	mov.b32 	 %r198, %f110;
	shl.b32 	%r618, %r198, 8;
	or.b32  	%r199, %r618, -2147483648;
	add.u64 	%rd135, %SP, 0;
	add.u64 	%rd194, %SPL, 0;
	mov.u32 	%r858, 0;
	mov.u64 	%rd193, __cudart_i2opi_f;
	mov.u32 	%r857, -6;

BB3_116:
	.pragma "nounroll";
	ld.const.u32 	%r621, [%rd193];
	// inline asm
	{
	mad.lo.cc.u32   %r619, %r621, %r199, %r858;
	madc.hi.u32     %r858, %r621, %r199,  0;
	}
	// inline asm
	st.local.u32 	[%rd194], %r619;
	add.s64 	%rd194, %rd194, 4;
	add.s64 	%rd193, %rd193, 4;
	add.s32 	%r857, %r857, 1;
	setp.ne.s32	%p86, %r857, 0;
	@%p86 bra 	BB3_116;

	bfe.u32 	%r624, %r198, 23, 8;
	add.s32 	%r625, %r624, -128;
	shr.u32 	%r626, %r625, 5;
	and.b32  	%r204, %r198, -2147483648;
	cvta.to.local.u64 	%rd137, %rd135;
	st.local.u32 	[%rd137+24], %r858;
	bfe.u32 	%r205, %r198, 23, 5;
	mov.u32 	%r627, 6;
	sub.s32 	%r628, %r627, %r626;
	mul.wide.s32 	%rd138, %r628, 4;
	add.s64 	%rd48, %rd137, %rd138;
	ld.local.u32 	%r860, [%rd48];
	ld.local.u32 	%r859, [%rd48+-4];
	setp.eq.s32	%p87, %r205, 0;
	@%p87 bra 	BB3_119;

	mov.u32 	%r629, 32;
	sub.s32 	%r630, %r629, %r205;
	shr.u32 	%r631, %r859, %r630;
	shl.b32 	%r632, %r860, %r205;
	add.s32 	%r860, %r631, %r632;
	ld.local.u32 	%r633, [%rd48+-8];
	shr.u32 	%r634, %r633, %r630;
	shl.b32 	%r635, %r859, %r205;
	add.s32 	%r859, %r634, %r635;

BB3_119:
	shr.u32 	%r636, %r859, 30;
	shl.b32 	%r637, %r860, 2;
	add.s32 	%r862, %r637, %r636;
	shl.b32 	%r213, %r859, 2;
	shr.u32 	%r638, %r862, 31;
	shr.u32 	%r639, %r860, 30;
	add.s32 	%r214, %r638, %r639;
	setp.eq.s32	%p88, %r638, 0;
	@%p88 bra 	BB3_120;

	not.b32 	%r640, %r862;
	neg.s32 	%r861, %r213;
	setp.eq.s32	%p89, %r213, 0;
	selp.u32	%r641, 1, 0, %p89;
	add.s32 	%r862, %r641, %r640;
	xor.b32  	%r863, %r204, -2147483648;
	bra.uni 	BB3_122;

BB3_120:
	mov.u32 	%r861, %r213;
	mov.u32 	%r863, %r204;

BB3_122:
	cvt.u64.u32	%rd139, %r862;
	cvt.u64.u32	%rd140, %r861;
	bfi.b64 	%rd141, %rd139, %rd140, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd141;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f384, %fd24;
	neg.f32 	%f385, %f384;
	setp.eq.s32	%p90, %r863, 0;
	selp.f32	%f519, %f384, %f385, %p90;
	setp.eq.s32	%p91, %r204, 0;
	neg.s32 	%r642, %r214;
	selp.b32	%r864, %r214, %r642, %p91;

BB3_124:
	and.b32  	%r223, %r864, 1;
	setp.eq.s32	%p92, %r223, 0;
	selp.f32	%f127, %f519, 0f3F800000, %p92;
	mul.rn.f32 	%f128, %f519, %f519;
	fma.rn.f32 	%f129, %f128, %f127, %f201;
	mov.f32 	%f520, 0fB94D4153;
	@%p92 bra 	BB3_126;

	mov.f32 	%f389, 0fBAB607ED;
	mov.f32 	%f390, 0f37CBAC00;
	fma.rn.f32 	%f520, %f390, %f128, %f389;

BB3_126:
	selp.f32	%f391, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f392, %f520, %f128, %f391;
	selp.f32	%f393, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f394, %f392, %f128, %f393;
	fma.rn.f32 	%f521, %f394, %f129, %f127;
	and.b32  	%r643, %r864, 2;
	setp.eq.s32	%p94, %r643, 0;
	@%p94 bra 	BB3_128;

	mov.f32 	%f396, 0fBF800000;
	fma.rn.f32 	%f521, %f521, %f396, %f201;

BB3_128:
	and.b32  	%r644, %r1, 15;
	and.b32  	%r646, %r416, 1073741792;
	add.s32 	%r647, %r646, %r644;
	mul.f32 	%f397, %f109, %f521;
	mul.f32 	%f398, %f108, %f518;
	sub.f32 	%f399, %f398, %f397;
	mul.f32 	%f400, %f109, %f518;
	fma.rn.f32 	%f401, %f108, %f521, %f400;
	add.f32 	%f402, %f106, %f399;
	shl.b32 	%r648, %r647, 2;
	add.s32 	%r650, %r344, %r648;
	st.shared.f32 	[%r650], %f402;
	add.f32 	%f403, %f107, %f401;
	add.s32 	%r652, %r346, %r648;
	st.shared.f32 	[%r652], %f403;
	sub.f32 	%f404, %f106, %f399;
	st.shared.f32 	[%r650+64], %f404;
	sub.f32 	%f405, %f107, %f401;
	st.shared.f32 	[%r652+64], %f405;
	bar.sync 	0;
	ld.shared.f32 	%f135, [%r350];
	ld.shared.f32 	%f136, [%r352];
	ld.shared.f32 	%f137, [%r350+256];
	ld.shared.f32 	%f138, [%r352+256];
	shr.u32 	%r659, %r430, 27;
	add.s32 	%r660, %r1, %r659;
	and.b32  	%r661, %r660, 2147483616;
	sub.s32 	%r662, %r1, %r661;
	shl.b32 	%r663, %r662, 1;
	cvt.rn.f32.s32	%f406, %r663;
	mul.f32 	%f407, %f406, 0f3C000000;
	cvt.f64.f32	%fd25, %f407;
	mul.f64 	%fd26, %fd25, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f139, %fd26;
	mul.f32 	%f408, %f139, 0f3F22F983;
	cvt.rni.s32.f32	%r880, %f408;
	cvt.rn.f32.s32	%f409, %r880;
	fma.rn.f32 	%f411, %f409, %f196, %f139;
	fma.rn.f32 	%f413, %f409, %f198, %f411;
	fma.rn.f32 	%f525, %f409, %f200, %f413;
	abs.f32 	%f141, %f139;
	setp.leu.f32	%p95, %f141, 0f47CE4780;
	mov.u32 	%r872, %r880;
	mov.f32 	%f522, %f525;
	@%p95 bra 	BB3_139;

	setp.eq.f32	%p96, %f141, 0f7F800000;
	@%p96 bra 	BB3_138;
	bra.uni 	BB3_130;

BB3_138:
	mul.rn.f32 	%f522, %f139, %f201;
	mov.u32 	%r872, %r880;
	bra.uni 	BB3_139;

BB3_130:
	mov.b32 	 %r226, %f139;
	shl.b32 	%r666, %r226, 8;
	or.b32  	%r227, %r666, -2147483648;
	add.u64 	%rd143, %SP, 0;
	add.u64 	%rd196, %SPL, 0;
	mov.u32 	%r866, 0;
	mov.u64 	%rd195, __cudart_i2opi_f;
	mov.u32 	%r865, -6;

BB3_131:
	.pragma "nounroll";
	ld.const.u32 	%r669, [%rd195];
	// inline asm
	{
	mad.lo.cc.u32   %r667, %r669, %r227, %r866;
	madc.hi.u32     %r866, %r669, %r227,  0;
	}
	// inline asm
	st.local.u32 	[%rd196], %r667;
	add.s64 	%rd196, %rd196, 4;
	add.s64 	%rd195, %rd195, 4;
	add.s32 	%r865, %r865, 1;
	setp.ne.s32	%p97, %r865, 0;
	@%p97 bra 	BB3_131;

	bfe.u32 	%r672, %r226, 23, 8;
	add.s32 	%r673, %r672, -128;
	shr.u32 	%r674, %r673, 5;
	and.b32  	%r232, %r226, -2147483648;
	cvta.to.local.u64 	%rd145, %rd143;
	st.local.u32 	[%rd145+24], %r866;
	bfe.u32 	%r233, %r226, 23, 5;
	mov.u32 	%r675, 6;
	sub.s32 	%r676, %r675, %r674;
	mul.wide.s32 	%rd146, %r676, 4;
	add.s64 	%rd54, %rd145, %rd146;
	ld.local.u32 	%r868, [%rd54];
	ld.local.u32 	%r867, [%rd54+-4];
	setp.eq.s32	%p98, %r233, 0;
	@%p98 bra 	BB3_134;

	mov.u32 	%r677, 32;
	sub.s32 	%r678, %r677, %r233;
	shr.u32 	%r679, %r867, %r678;
	shl.b32 	%r680, %r868, %r233;
	add.s32 	%r868, %r679, %r680;
	ld.local.u32 	%r681, [%rd54+-8];
	shr.u32 	%r682, %r681, %r678;
	shl.b32 	%r683, %r867, %r233;
	add.s32 	%r867, %r682, %r683;

BB3_134:
	shr.u32 	%r684, %r867, 30;
	shl.b32 	%r685, %r868, 2;
	add.s32 	%r870, %r685, %r684;
	shl.b32 	%r241, %r867, 2;
	shr.u32 	%r686, %r870, 31;
	shr.u32 	%r687, %r868, 30;
	add.s32 	%r242, %r686, %r687;
	setp.eq.s32	%p99, %r686, 0;
	@%p99 bra 	BB3_135;

	not.b32 	%r688, %r870;
	neg.s32 	%r869, %r241;
	setp.eq.s32	%p100, %r241, 0;
	selp.u32	%r689, 1, 0, %p100;
	add.s32 	%r870, %r689, %r688;
	xor.b32  	%r871, %r232, -2147483648;
	bra.uni 	BB3_137;

BB3_135:
	mov.u32 	%r869, %r241;
	mov.u32 	%r871, %r232;

BB3_137:
	cvt.u64.u32	%rd147, %r870;
	cvt.u64.u32	%rd148, %r869;
	bfi.b64 	%rd149, %rd147, %rd148, 32, 32;
	cvt.rn.f64.s64	%fd27, %rd149;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f415, %fd28;
	neg.f32 	%f416, %f415;
	setp.eq.s32	%p101, %r871, 0;
	selp.f32	%f522, %f415, %f416, %p101;
	setp.eq.s32	%p102, %r232, 0;
	neg.s32 	%r690, %r242;
	selp.b32	%r872, %r242, %r690, %p102;

BB3_139:
	add.s32 	%r251, %r872, 1;
	and.b32  	%r252, %r251, 1;
	setp.eq.s32	%p103, %r252, 0;
	selp.f32	%f145, %f522, 0f3F800000, %p103;
	mul.rn.f32 	%f146, %f522, %f522;
	fma.rn.f32 	%f147, %f146, %f145, %f201;
	mov.f32 	%f523, 0fB94D4153;
	@%p103 bra 	BB3_141;

	mov.f32 	%f420, 0fBAB607ED;
	mov.f32 	%f421, 0f37CBAC00;
	fma.rn.f32 	%f523, %f421, %f146, %f420;

BB3_141:
	selp.f32	%f422, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f423, %f523, %f146, %f422;
	selp.f32	%f424, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f425, %f423, %f146, %f424;
	fma.rn.f32 	%f524, %f425, %f147, %f145;
	and.b32  	%r691, %r251, 2;
	setp.eq.s32	%p105, %r691, 0;
	@%p105 bra 	BB3_143;

	mov.f32 	%f427, 0fBF800000;
	fma.rn.f32 	%f524, %f524, %f427, %f201;

BB3_143:
	@%p95 bra 	BB3_154;

	setp.eq.f32	%p107, %f141, 0f7F800000;
	@%p107 bra 	BB3_153;
	bra.uni 	BB3_145;

BB3_153:
	mul.rn.f32 	%f525, %f139, %f201;
	bra.uni 	BB3_154;

BB3_145:
	mov.b32 	 %r253, %f139;
	shl.b32 	%r694, %r253, 8;
	or.b32  	%r254, %r694, -2147483648;
	add.u64 	%rd151, %SP, 0;
	add.u64 	%rd198, %SPL, 0;
	mov.u32 	%r874, 0;
	mov.u64 	%rd197, __cudart_i2opi_f;
	mov.u32 	%r873, -6;

BB3_146:
	.pragma "nounroll";
	ld.const.u32 	%r697, [%rd197];
	// inline asm
	{
	mad.lo.cc.u32   %r695, %r697, %r254, %r874;
	madc.hi.u32     %r874, %r697, %r254,  0;
	}
	// inline asm
	st.local.u32 	[%rd198], %r695;
	add.s64 	%rd198, %rd198, 4;
	add.s64 	%rd197, %rd197, 4;
	add.s32 	%r873, %r873, 1;
	setp.ne.s32	%p108, %r873, 0;
	@%p108 bra 	BB3_146;

	bfe.u32 	%r700, %r253, 23, 8;
	add.s32 	%r701, %r700, -128;
	shr.u32 	%r702, %r701, 5;
	and.b32  	%r259, %r253, -2147483648;
	cvta.to.local.u64 	%rd153, %rd151;
	st.local.u32 	[%rd153+24], %r874;
	bfe.u32 	%r260, %r253, 23, 5;
	mov.u32 	%r703, 6;
	sub.s32 	%r704, %r703, %r702;
	mul.wide.s32 	%rd154, %r704, 4;
	add.s64 	%rd60, %rd153, %rd154;
	ld.local.u32 	%r876, [%rd60];
	ld.local.u32 	%r875, [%rd60+-4];
	setp.eq.s32	%p109, %r260, 0;
	@%p109 bra 	BB3_149;

	mov.u32 	%r705, 32;
	sub.s32 	%r706, %r705, %r260;
	shr.u32 	%r707, %r875, %r706;
	shl.b32 	%r708, %r876, %r260;
	add.s32 	%r876, %r707, %r708;
	ld.local.u32 	%r709, [%rd60+-8];
	shr.u32 	%r710, %r709, %r706;
	shl.b32 	%r711, %r875, %r260;
	add.s32 	%r875, %r710, %r711;

BB3_149:
	shr.u32 	%r712, %r875, 30;
	shl.b32 	%r713, %r876, 2;
	add.s32 	%r878, %r713, %r712;
	shl.b32 	%r268, %r875, 2;
	shr.u32 	%r714, %r878, 31;
	shr.u32 	%r715, %r876, 30;
	add.s32 	%r269, %r714, %r715;
	setp.eq.s32	%p110, %r714, 0;
	@%p110 bra 	BB3_150;

	not.b32 	%r716, %r878;
	neg.s32 	%r877, %r268;
	setp.eq.s32	%p111, %r268, 0;
	selp.u32	%r717, 1, 0, %p111;
	add.s32 	%r878, %r717, %r716;
	xor.b32  	%r879, %r259, -2147483648;
	bra.uni 	BB3_152;

BB3_150:
	mov.u32 	%r877, %r268;
	mov.u32 	%r879, %r259;

BB3_152:
	cvt.u64.u32	%rd155, %r878;
	cvt.u64.u32	%rd156, %r877;
	bfi.b64 	%rd157, %rd155, %rd156, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd157;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f428, %fd30;
	neg.f32 	%f429, %f428;
	setp.eq.s32	%p112, %r879, 0;
	selp.f32	%f525, %f428, %f429, %p112;
	setp.eq.s32	%p113, %r259, 0;
	neg.s32 	%r718, %r269;
	selp.b32	%r880, %r269, %r718, %p113;

BB3_154:
	and.b32  	%r278, %r880, 1;
	setp.eq.s32	%p114, %r278, 0;
	selp.f32	%f156, %f525, 0f3F800000, %p114;
	mul.rn.f32 	%f157, %f525, %f525;
	fma.rn.f32 	%f158, %f157, %f156, %f201;
	mov.f32 	%f526, 0fB94D4153;
	@%p114 bra 	BB3_156;

	mov.f32 	%f433, 0fBAB607ED;
	mov.f32 	%f434, 0f37CBAC00;
	fma.rn.f32 	%f526, %f434, %f157, %f433;

BB3_156:
	selp.f32	%f435, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f436, %f526, %f157, %f435;
	selp.f32	%f437, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f438, %f436, %f157, %f437;
	fma.rn.f32 	%f527, %f438, %f158, %f156;
	and.b32  	%r719, %r880, 2;
	setp.eq.s32	%p116, %r719, 0;
	@%p116 bra 	BB3_158;

	mov.f32 	%f440, 0fBF800000;
	fma.rn.f32 	%f527, %f527, %f440, %f201;

BB3_158:
	and.b32  	%r720, %r1, 31;
	and.b32  	%r722, %r416, 1073741760;
	add.s32 	%r723, %r722, %r720;
	mul.f32 	%f441, %f138, %f527;
	mul.f32 	%f442, %f137, %f524;
	sub.f32 	%f443, %f442, %f441;
	mul.f32 	%f444, %f138, %f524;
	fma.rn.f32 	%f445, %f137, %f527, %f444;
	add.f32 	%f446, %f135, %f443;
	shl.b32 	%r724, %r723, 2;
	add.s32 	%r726, %r421, %r724;
	st.shared.f32 	[%r726], %f446;
	add.f32 	%f447, %f136, %f445;
	add.s32 	%r728, %r423, %r724;
	st.shared.f32 	[%r728], %f447;
	sub.f32 	%f448, %f135, %f443;
	st.shared.f32 	[%r726+128], %f448;
	sub.f32 	%f449, %f136, %f445;
	st.shared.f32 	[%r728+128], %f449;
	bar.sync 	0;
	ld.shared.f32 	%f164, [%r427];
	ld.shared.f32 	%f165, [%r429];
	ld.shared.f32 	%f166, [%r427+256];
	ld.shared.f32 	%f167, [%r429+256];
	shr.u32 	%r735, %r430, 26;
	add.s32 	%r736, %r1, %r735;
	and.b32  	%r737, %r736, -64;
	sub.s32 	%r738, %r1, %r737;
	cvt.rn.f32.s32	%f450, %r738;
	mul.f32 	%f451, %f450, 0f3C000000;
	cvt.f64.f32	%fd31, %f451;
	mul.f64 	%fd32, %fd31, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f168, %fd32;
	mul.f32 	%f452, %f168, 0f3F22F983;
	cvt.rni.s32.f32	%r896, %f452;
	cvt.rn.f32.s32	%f453, %r896;
	fma.rn.f32 	%f455, %f453, %f196, %f168;
	fma.rn.f32 	%f457, %f453, %f198, %f455;
	fma.rn.f32 	%f531, %f453, %f200, %f457;
	abs.f32 	%f170, %f168;
	setp.leu.f32	%p117, %f170, 0f47CE4780;
	mov.u32 	%r888, %r896;
	mov.f32 	%f528, %f531;
	@%p117 bra 	BB3_169;

	setp.eq.f32	%p118, %f170, 0f7F800000;
	@%p118 bra 	BB3_168;
	bra.uni 	BB3_160;

BB3_168:
	mul.rn.f32 	%f528, %f168, %f201;
	mov.u32 	%r888, %r896;
	bra.uni 	BB3_169;

BB3_160:
	mov.b32 	 %r281, %f168;
	shl.b32 	%r741, %r281, 8;
	or.b32  	%r282, %r741, -2147483648;
	add.u64 	%rd159, %SP, 0;
	add.u64 	%rd200, %SPL, 0;
	mov.u32 	%r882, 0;
	mov.u64 	%rd199, __cudart_i2opi_f;
	mov.u32 	%r881, -6;

BB3_161:
	.pragma "nounroll";
	ld.const.u32 	%r744, [%rd199];
	// inline asm
	{
	mad.lo.cc.u32   %r742, %r744, %r282, %r882;
	madc.hi.u32     %r882, %r744, %r282,  0;
	}
	// inline asm
	st.local.u32 	[%rd200], %r742;
	add.s64 	%rd200, %rd200, 4;
	add.s64 	%rd199, %rd199, 4;
	add.s32 	%r881, %r881, 1;
	setp.ne.s32	%p119, %r881, 0;
	@%p119 bra 	BB3_161;

	bfe.u32 	%r747, %r281, 23, 8;
	add.s32 	%r748, %r747, -128;
	shr.u32 	%r749, %r748, 5;
	and.b32  	%r287, %r281, -2147483648;
	cvta.to.local.u64 	%rd161, %rd159;
	st.local.u32 	[%rd161+24], %r882;
	bfe.u32 	%r288, %r281, 23, 5;
	mov.u32 	%r750, 6;
	sub.s32 	%r751, %r750, %r749;
	mul.wide.s32 	%rd162, %r751, 4;
	add.s64 	%rd66, %rd161, %rd162;
	ld.local.u32 	%r884, [%rd66];
	ld.local.u32 	%r883, [%rd66+-4];
	setp.eq.s32	%p120, %r288, 0;
	@%p120 bra 	BB3_164;

	mov.u32 	%r752, 32;
	sub.s32 	%r753, %r752, %r288;
	shr.u32 	%r754, %r883, %r753;
	shl.b32 	%r755, %r884, %r288;
	add.s32 	%r884, %r754, %r755;
	ld.local.u32 	%r756, [%rd66+-8];
	shr.u32 	%r757, %r756, %r753;
	shl.b32 	%r758, %r883, %r288;
	add.s32 	%r883, %r757, %r758;

BB3_164:
	shr.u32 	%r759, %r883, 30;
	shl.b32 	%r760, %r884, 2;
	add.s32 	%r886, %r760, %r759;
	shl.b32 	%r296, %r883, 2;
	shr.u32 	%r761, %r886, 31;
	shr.u32 	%r762, %r884, 30;
	add.s32 	%r297, %r761, %r762;
	setp.eq.s32	%p121, %r761, 0;
	@%p121 bra 	BB3_165;

	not.b32 	%r763, %r886;
	neg.s32 	%r885, %r296;
	setp.eq.s32	%p122, %r296, 0;
	selp.u32	%r764, 1, 0, %p122;
	add.s32 	%r886, %r764, %r763;
	xor.b32  	%r887, %r287, -2147483648;
	bra.uni 	BB3_167;

BB3_165:
	mov.u32 	%r885, %r296;
	mov.u32 	%r887, %r287;

BB3_167:
	cvt.u64.u32	%rd163, %r886;
	cvt.u64.u32	%rd164, %r885;
	bfi.b64 	%rd165, %rd163, %rd164, 32, 32;
	cvt.rn.f64.s64	%fd33, %rd165;
	mul.f64 	%fd34, %fd33, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f459, %fd34;
	neg.f32 	%f460, %f459;
	setp.eq.s32	%p123, %r887, 0;
	selp.f32	%f528, %f459, %f460, %p123;
	setp.eq.s32	%p124, %r287, 0;
	neg.s32 	%r765, %r297;
	selp.b32	%r888, %r297, %r765, %p124;

BB3_169:
	add.s32 	%r306, %r888, 1;
	and.b32  	%r307, %r306, 1;
	setp.eq.s32	%p125, %r307, 0;
	selp.f32	%f174, %f528, 0f3F800000, %p125;
	mul.rn.f32 	%f175, %f528, %f528;
	fma.rn.f32 	%f176, %f175, %f174, %f201;
	mov.f32 	%f529, 0fB94D4153;
	@%p125 bra 	BB3_171;

	mov.f32 	%f464, 0fBAB607ED;
	mov.f32 	%f465, 0f37CBAC00;
	fma.rn.f32 	%f529, %f465, %f175, %f464;

BB3_171:
	selp.f32	%f466, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f467, %f529, %f175, %f466;
	selp.f32	%f468, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f469, %f467, %f175, %f468;
	fma.rn.f32 	%f530, %f469, %f176, %f174;
	and.b32  	%r766, %r306, 2;
	setp.eq.s32	%p127, %r766, 0;
	@%p127 bra 	BB3_173;

	mov.f32 	%f471, 0fBF800000;
	fma.rn.f32 	%f530, %f530, %f471, %f201;

BB3_173:
	@%p117 bra 	BB3_184;

	setp.eq.f32	%p129, %f170, 0f7F800000;
	@%p129 bra 	BB3_183;
	bra.uni 	BB3_175;

BB3_183:
	mul.rn.f32 	%f531, %f168, %f201;
	bra.uni 	BB3_184;

BB3_175:
	mov.b32 	 %r308, %f168;
	shl.b32 	%r769, %r308, 8;
	or.b32  	%r309, %r769, -2147483648;
	add.u64 	%rd167, %SP, 0;
	add.u64 	%rd202, %SPL, 0;
	mov.u32 	%r890, 0;
	mov.u64 	%rd201, __cudart_i2opi_f;
	mov.u32 	%r889, -6;

BB3_176:
	.pragma "nounroll";
	ld.const.u32 	%r772, [%rd201];
	// inline asm
	{
	mad.lo.cc.u32   %r770, %r772, %r309, %r890;
	madc.hi.u32     %r890, %r772, %r309,  0;
	}
	// inline asm
	st.local.u32 	[%rd202], %r770;
	add.s64 	%rd202, %rd202, 4;
	add.s64 	%rd201, %rd201, 4;
	add.s32 	%r889, %r889, 1;
	setp.ne.s32	%p130, %r889, 0;
	@%p130 bra 	BB3_176;

	bfe.u32 	%r775, %r308, 23, 8;
	add.s32 	%r776, %r775, -128;
	shr.u32 	%r777, %r776, 5;
	and.b32  	%r314, %r308, -2147483648;
	cvta.to.local.u64 	%rd169, %rd167;
	st.local.u32 	[%rd169+24], %r890;
	bfe.u32 	%r315, %r308, 23, 5;
	mov.u32 	%r778, 6;
	sub.s32 	%r779, %r778, %r777;
	mul.wide.s32 	%rd170, %r779, 4;
	add.s64 	%rd72, %rd169, %rd170;
	ld.local.u32 	%r892, [%rd72];
	ld.local.u32 	%r891, [%rd72+-4];
	setp.eq.s32	%p131, %r315, 0;
	@%p131 bra 	BB3_179;

	mov.u32 	%r780, 32;
	sub.s32 	%r781, %r780, %r315;
	shr.u32 	%r782, %r891, %r781;
	shl.b32 	%r783, %r892, %r315;
	add.s32 	%r892, %r782, %r783;
	ld.local.u32 	%r784, [%rd72+-8];
	shr.u32 	%r785, %r784, %r781;
	shl.b32 	%r786, %r891, %r315;
	add.s32 	%r891, %r785, %r786;

BB3_179:
	shr.u32 	%r787, %r891, 30;
	shl.b32 	%r788, %r892, 2;
	add.s32 	%r894, %r788, %r787;
	shl.b32 	%r323, %r891, 2;
	shr.u32 	%r789, %r894, 31;
	shr.u32 	%r790, %r892, 30;
	add.s32 	%r324, %r789, %r790;
	setp.eq.s32	%p132, %r789, 0;
	@%p132 bra 	BB3_180;

	not.b32 	%r791, %r894;
	neg.s32 	%r893, %r323;
	setp.eq.s32	%p133, %r323, 0;
	selp.u32	%r792, 1, 0, %p133;
	add.s32 	%r894, %r792, %r791;
	xor.b32  	%r895, %r314, -2147483648;
	bra.uni 	BB3_182;

BB3_180:
	mov.u32 	%r893, %r323;
	mov.u32 	%r895, %r314;

BB3_182:
	cvt.u64.u32	%rd171, %r894;
	cvt.u64.u32	%rd172, %r893;
	bfi.b64 	%rd173, %rd171, %rd172, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd173;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f472, %fd36;
	neg.f32 	%f473, %f472;
	setp.eq.s32	%p134, %r895, 0;
	selp.f32	%f531, %f472, %f473, %p134;
	setp.eq.s32	%p135, %r314, 0;
	neg.s32 	%r793, %r324;
	selp.b32	%r896, %r324, %r793, %p135;

BB3_184:
	and.b32  	%r333, %r896, 1;
	setp.eq.s32	%p136, %r333, 0;
	selp.f32	%f185, %f531, 0f3F800000, %p136;
	mul.rn.f32 	%f186, %f531, %f531;
	fma.rn.f32 	%f187, %f186, %f185, %f201;
	mov.f32 	%f532, 0fB94D4153;
	@%p136 bra 	BB3_186;

	mov.f32 	%f477, 0fBAB607ED;
	mov.f32 	%f478, 0f37CBAC00;
	fma.rn.f32 	%f532, %f478, %f186, %f477;

BB3_186:
	selp.f32	%f479, 0f3C0885E4, 0f3D2AAABB, %p136;
	fma.rn.f32 	%f480, %f532, %f186, %f479;
	selp.f32	%f481, 0fBE2AAAA8, 0fBEFFFFFF, %p136;
	fma.rn.f32 	%f482, %f480, %f186, %f481;
	fma.rn.f32 	%f533, %f482, %f187, %f185;
	and.b32  	%r794, %r896, 2;
	setp.eq.s32	%p138, %r794, 0;
	@%p138 bra 	BB3_188;

	mov.f32 	%f484, 0fBF800000;
	fma.rn.f32 	%f533, %f533, %f484, %f201;

BB3_188:
	mul.f32 	%f485, %f167, %f533;
	mul.f32 	%f486, %f166, %f530;
	sub.f32 	%f487, %f486, %f485;
	mul.f32 	%f488, %f167, %f530;
	fma.rn.f32 	%f489, %f166, %f533, %f488;
	add.f32 	%f490, %f164, %f487;
	add.s32 	%r800, %r339, %r1;
	mul.wide.u32 	%rd175, %r800, 4;
	add.s64 	%rd176, %rd75, %rd175;
	st.global.f32 	[%rd176], %f490;
	add.f32 	%f491, %f165, %f489;
	cvta.to.global.u64 	%rd177, %rd74;
	add.s64 	%rd178, %rd177, %rd175;
	st.global.f32 	[%rd178], %f491;
	sub.f32 	%f492, %f164, %f487;
	st.global.f32 	[%rd176+256], %f492;
	sub.f32 	%f493, %f165, %f489;
	st.global.f32 	[%rd178+256], %f493;
	ret;
}

	// .globl	_occa_Stockhoptimized8_0
.visible .entry _occa_Stockhoptimized8_0(
	.param .u64 _occa_Stockhoptimized8_0_param_0,
	.param .u64 _occa_Stockhoptimized8_0_param_1,
	.param .u32 _occa_Stockhoptimized8_0_param_2
)
.maxntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot4[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<161>;
	.reg .f32 	%f<613>;
	.reg .b32 	%r<1044>;
	.reg .f64 	%fd<43>;
	.reg .b64 	%rd<235>;
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized8_0E6FRBank[1024];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized8_0E6FIBank[1024];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized8_0E6SRBank[1024];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized8_0E6SIBank[1024];

	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd85, [_occa_Stockhoptimized8_0_param_0];
	ld.param.u64 	%rd86, [_occa_Stockhoptimized8_0_param_1];
	mov.u32 	%r389, %ctaid.x;
	shl.b32 	%r390, %r389, 7;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r391, %r390, %r1;
	and.b32  	%r392, %r391, 127;
	shl.b32 	%r393, %r391, 1;
	and.b32  	%r394, %r393, -256;
	add.s32 	%r395, %r394, %r392;
	cvta.to.global.u64 	%rd87, %rd85;
	mul.wide.u32 	%rd88, %r395, 4;
	add.s64 	%rd89, %rd87, %rd88;
	ld.global.f32 	%f1, [%rd89];
	ld.global.f32 	%f2, [%rd89+512];
	mov.f32 	%f223, 0f80000000;
	cvt.rni.s32.f32	%r2, %f223;
	cvt.rn.f32.s32	%f224, %r2;
	mov.f32 	%f225, 0fBFC90FDA;
	fma.rn.f32 	%f226, %f224, %f225, %f223;
	mov.f32 	%f227, 0fB3A22168;
	fma.rn.f32 	%f228, %f224, %f227, %f226;
	mov.f32 	%f229, 0fA7C234C5;
	fma.rn.f32 	%f3, %f224, %f229, %f228;
	add.s32 	%r3, %r2, 1;
	mul.rn.f32 	%f4, %f3, %f3;
	and.b32  	%r4, %r3, 1;
	setp.eq.s32	%p1, %r4, 0;
	selp.f32	%f5, %f3, 0f3F800000, %p1;
	mov.f32 	%f230, 0f00000000;
	fma.rn.f32 	%f6, %f4, %f5, %f230;
	mov.f32 	%f567, 0fB94D4153;
	@%p1 bra 	BB4_2;

	mov.f32 	%f231, 0fBAB607ED;
	mov.f32 	%f232, 0f37CBAC00;
	fma.rn.f32 	%f567, %f232, %f4, %f231;

BB4_2:
	selp.f32	%f233, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f234, %f567, %f4, %f233;
	selp.f32	%f235, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f236, %f234, %f4, %f235;
	fma.rn.f32 	%f568, %f236, %f6, %f5;
	and.b32  	%r396, %r3, 2;
	setp.eq.s32	%p3, %r396, 0;
	@%p3 bra 	BB4_4;

	mov.f32 	%f238, 0fBF800000;
	fma.rn.f32 	%f568, %f568, %f238, %f230;

BB4_4:
	and.b32  	%r5, %r2, 1;
	setp.eq.s32	%p4, %r5, 0;
	selp.f32	%f12, %f3, 0f3F800000, %p4;
	fma.rn.f32 	%f13, %f4, %f12, %f230;
	mov.f32 	%f569, 0fB94D4153;
	@%p4 bra 	BB4_6;

	mov.f32 	%f241, 0fBAB607ED;
	mov.f32 	%f242, 0f37CBAC00;
	fma.rn.f32 	%f569, %f242, %f4, %f241;

BB4_6:
	selp.f32	%f243, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f244, %f569, %f4, %f243;
	selp.f32	%f245, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f246, %f244, %f4, %f245;
	fma.rn.f32 	%f570, %f246, %f13, %f12;
	and.b32  	%r397, %r2, 2;
	setp.eq.s32	%p6, %r397, 0;
	@%p6 bra 	BB4_8;

	mov.f32 	%f248, 0fBF800000;
	fma.rn.f32 	%f570, %f570, %f248, %f230;

BB4_8:
	mul.f32 	%f249, %f570, 0f00000000;
	mul.f32 	%f250, %f2, %f568;
	sub.f32 	%f251, %f250, %f249;
	mul.f32 	%f252, %f568, 0f00000000;
	fma.rn.f32 	%f253, %f2, %f570, %f252;
	add.f32 	%f254, %f1, %f251;
	shl.b32 	%r398, %r1, 3;
	mov.u32 	%r399, _ZZ24_occa_Stockhoptimized8_0E6FRBank;
	add.s32 	%r400, %r399, %r398;
	st.shared.f32 	[%r400], %f254;
	add.f32 	%f255, %f253, 0f00000000;
	mov.u32 	%r401, _ZZ24_occa_Stockhoptimized8_0E6FIBank;
	add.s32 	%r402, %r401, %r398;
	st.shared.f32 	[%r402], %f255;
	sub.f32 	%f256, %f1, %f251;
	st.shared.f32 	[%r400+4], %f256;
	sub.f32 	%f258, %f230, %f253;
	st.shared.f32 	[%r402+4], %f258;
	bar.sync 	0;
	shl.b32 	%r403, %r1, 2;
	add.s32 	%r405, %r399, %r403;
	ld.shared.f32 	%f19, [%r405];
	add.s32 	%r407, %r401, %r403;
	ld.shared.f32 	%f20, [%r407];
	ld.shared.f32 	%f21, [%r405+512];
	ld.shared.f32 	%f22, [%r407+512];
	shr.u32 	%r408, %r1, 31;
	add.s32 	%r409, %r1, %r408;
	and.b32  	%r410, %r409, 67108862;
	sub.s32 	%r411, %r1, %r410;
	shl.b32 	%r412, %r411, 6;
	cvt.rn.f32.s32	%f259, %r412;
	mul.f32 	%f260, %f259, 0f3B800000;
	cvt.f64.f32	%fd1, %f260;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f23, %fd2;
	mul.f32 	%f261, %f23, 0f3F22F983;
	cvt.rni.s32.f32	%r947, %f261;
	cvt.rn.f32.s32	%f262, %r947;
	fma.rn.f32 	%f264, %f262, %f225, %f23;
	fma.rn.f32 	%f266, %f262, %f227, %f264;
	fma.rn.f32 	%f574, %f262, %f229, %f266;
	abs.f32 	%f25, %f23;
	setp.leu.f32	%p7, %f25, 0f47CE4780;
	mov.u32 	%r939, %r947;
	mov.f32 	%f571, %f574;
	@%p7 bra 	BB4_19;

	setp.eq.f32	%p8, %f25, 0f7F800000;
	@%p8 bra 	BB4_18;
	bra.uni 	BB4_10;

BB4_18:
	mul.rn.f32 	%f571, %f23, %f230;
	mov.u32 	%r939, %r947;
	bra.uni 	BB4_19;

BB4_10:
	mov.b32 	 %r415, %f23;
	shl.b32 	%r416, %r415, 8;
	or.b32  	%r7, %r416, -2147483648;
	add.u64 	%rd91, %SP, 0;
	add.u64 	%rd208, %SPL, 0;
	mov.u32 	%r933, 0;
	mov.u64 	%rd207, __cudart_i2opi_f;
	mov.u32 	%r932, -6;

BB4_11:
	.pragma "nounroll";
	ld.const.u32 	%r419, [%rd207];
	// inline asm
	{
	mad.lo.cc.u32   %r417, %r419, %r7, %r933;
	madc.hi.u32     %r933, %r419, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd208], %r417;
	add.s64 	%rd208, %rd208, 4;
	add.s64 	%rd207, %rd207, 4;
	add.s32 	%r932, %r932, 1;
	setp.ne.s32	%p9, %r932, 0;
	@%p9 bra 	BB4_11;

	bfe.u32 	%r423, %r415, 23, 8;
	add.s32 	%r424, %r423, -128;
	shr.u32 	%r425, %r424, 5;
	and.b32  	%r12, %r415, -2147483648;
	cvta.to.local.u64 	%rd93, %rd91;
	st.local.u32 	[%rd93+24], %r933;
	bfe.u32 	%r13, %r415, 23, 5;
	mov.u32 	%r426, 6;
	sub.s32 	%r427, %r426, %r425;
	mul.wide.s32 	%rd94, %r427, 4;
	add.s64 	%rd6, %rd93, %rd94;
	ld.local.u32 	%r935, [%rd6];
	ld.local.u32 	%r934, [%rd6+-4];
	setp.eq.s32	%p10, %r13, 0;
	@%p10 bra 	BB4_14;

	mov.u32 	%r428, 32;
	sub.s32 	%r429, %r428, %r13;
	shr.u32 	%r430, %r934, %r429;
	shl.b32 	%r431, %r935, %r13;
	add.s32 	%r935, %r430, %r431;
	ld.local.u32 	%r432, [%rd6+-8];
	shr.u32 	%r433, %r432, %r429;
	shl.b32 	%r434, %r934, %r13;
	add.s32 	%r934, %r433, %r434;

BB4_14:
	shr.u32 	%r435, %r934, 30;
	shl.b32 	%r436, %r935, 2;
	add.s32 	%r937, %r436, %r435;
	shl.b32 	%r21, %r934, 2;
	shr.u32 	%r437, %r937, 31;
	shr.u32 	%r438, %r935, 30;
	add.s32 	%r22, %r437, %r438;
	setp.eq.s32	%p11, %r437, 0;
	@%p11 bra 	BB4_15;

	not.b32 	%r439, %r937;
	neg.s32 	%r936, %r21;
	setp.eq.s32	%p12, %r21, 0;
	selp.u32	%r440, 1, 0, %p12;
	add.s32 	%r937, %r440, %r439;
	xor.b32  	%r938, %r12, -2147483648;
	bra.uni 	BB4_17;

BB4_15:
	mov.u32 	%r936, %r21;
	mov.u32 	%r938, %r12;

BB4_17:
	cvt.u64.u32	%rd95, %r937;
	cvt.u64.u32	%rd96, %r936;
	bfi.b64 	%rd97, %rd95, %rd96, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd97;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f268, %fd4;
	neg.f32 	%f269, %f268;
	setp.eq.s32	%p13, %r938, 0;
	selp.f32	%f571, %f268, %f269, %p13;
	setp.eq.s32	%p14, %r12, 0;
	neg.s32 	%r441, %r22;
	selp.b32	%r939, %r22, %r441, %p14;

BB4_19:
	add.s32 	%r31, %r939, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p15, %r32, 0;
	selp.f32	%f29, %f571, 0f3F800000, %p15;
	mul.rn.f32 	%f30, %f571, %f571;
	fma.rn.f32 	%f31, %f30, %f29, %f230;
	mov.f32 	%f572, 0fB94D4153;
	@%p15 bra 	BB4_21;

	mov.f32 	%f273, 0fBAB607ED;
	mov.f32 	%f274, 0f37CBAC00;
	fma.rn.f32 	%f572, %f274, %f30, %f273;

BB4_21:
	selp.f32	%f275, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f276, %f572, %f30, %f275;
	selp.f32	%f277, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f278, %f276, %f30, %f277;
	fma.rn.f32 	%f573, %f278, %f31, %f29;
	and.b32  	%r442, %r31, 2;
	setp.eq.s32	%p17, %r442, 0;
	@%p17 bra 	BB4_23;

	mov.f32 	%f280, 0fBF800000;
	fma.rn.f32 	%f573, %f573, %f280, %f230;

BB4_23:
	@%p7 bra 	BB4_34;

	setp.eq.f32	%p19, %f25, 0f7F800000;
	@%p19 bra 	BB4_33;
	bra.uni 	BB4_25;

BB4_33:
	mul.rn.f32 	%f574, %f23, %f230;
	bra.uni 	BB4_34;

BB4_25:
	mov.b32 	 %r33, %f23;
	shl.b32 	%r445, %r33, 8;
	or.b32  	%r34, %r445, -2147483648;
	add.u64 	%rd99, %SP, 0;
	add.u64 	%rd210, %SPL, 0;
	mov.u32 	%r941, 0;
	mov.u64 	%rd209, __cudart_i2opi_f;
	mov.u32 	%r940, -6;

BB4_26:
	.pragma "nounroll";
	ld.const.u32 	%r448, [%rd209];
	// inline asm
	{
	mad.lo.cc.u32   %r446, %r448, %r34, %r941;
	madc.hi.u32     %r941, %r448, %r34,  0;
	}
	// inline asm
	st.local.u32 	[%rd210], %r446;
	add.s64 	%rd210, %rd210, 4;
	add.s64 	%rd209, %rd209, 4;
	add.s32 	%r940, %r940, 1;
	setp.ne.s32	%p20, %r940, 0;
	@%p20 bra 	BB4_26;

	bfe.u32 	%r451, %r33, 23, 8;
	add.s32 	%r452, %r451, -128;
	shr.u32 	%r453, %r452, 5;
	and.b32  	%r39, %r33, -2147483648;
	cvta.to.local.u64 	%rd101, %rd99;
	st.local.u32 	[%rd101+24], %r941;
	bfe.u32 	%r40, %r33, 23, 5;
	mov.u32 	%r454, 6;
	sub.s32 	%r455, %r454, %r453;
	mul.wide.s32 	%rd102, %r455, 4;
	add.s64 	%rd12, %rd101, %rd102;
	ld.local.u32 	%r943, [%rd12];
	ld.local.u32 	%r942, [%rd12+-4];
	setp.eq.s32	%p21, %r40, 0;
	@%p21 bra 	BB4_29;

	mov.u32 	%r456, 32;
	sub.s32 	%r457, %r456, %r40;
	shr.u32 	%r458, %r942, %r457;
	shl.b32 	%r459, %r943, %r40;
	add.s32 	%r943, %r458, %r459;
	ld.local.u32 	%r460, [%rd12+-8];
	shr.u32 	%r461, %r460, %r457;
	shl.b32 	%r462, %r942, %r40;
	add.s32 	%r942, %r461, %r462;

BB4_29:
	shr.u32 	%r463, %r942, 30;
	shl.b32 	%r464, %r943, 2;
	add.s32 	%r945, %r464, %r463;
	shl.b32 	%r48, %r942, 2;
	shr.u32 	%r465, %r945, 31;
	shr.u32 	%r466, %r943, 30;
	add.s32 	%r49, %r465, %r466;
	setp.eq.s32	%p22, %r465, 0;
	@%p22 bra 	BB4_30;

	not.b32 	%r467, %r945;
	neg.s32 	%r944, %r48;
	setp.eq.s32	%p23, %r48, 0;
	selp.u32	%r468, 1, 0, %p23;
	add.s32 	%r945, %r468, %r467;
	xor.b32  	%r946, %r39, -2147483648;
	bra.uni 	BB4_32;

BB4_30:
	mov.u32 	%r944, %r48;
	mov.u32 	%r946, %r39;

BB4_32:
	cvt.u64.u32	%rd103, %r945;
	cvt.u64.u32	%rd104, %r944;
	bfi.b64 	%rd105, %rd103, %rd104, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd105;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f281, %fd6;
	neg.f32 	%f282, %f281;
	setp.eq.s32	%p24, %r946, 0;
	selp.f32	%f574, %f281, %f282, %p24;
	setp.eq.s32	%p25, %r39, 0;
	neg.s32 	%r469, %r49;
	selp.b32	%r947, %r49, %r469, %p25;

BB4_34:
	and.b32  	%r58, %r947, 1;
	setp.eq.s32	%p26, %r58, 0;
	selp.f32	%f40, %f574, 0f3F800000, %p26;
	mul.rn.f32 	%f41, %f574, %f574;
	fma.rn.f32 	%f42, %f41, %f40, %f230;
	mov.f32 	%f575, 0fB94D4153;
	@%p26 bra 	BB4_36;

	mov.f32 	%f286, 0fBAB607ED;
	mov.f32 	%f287, 0f37CBAC00;
	fma.rn.f32 	%f575, %f287, %f41, %f286;

BB4_36:
	selp.f32	%f288, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f289, %f575, %f41, %f288;
	selp.f32	%f290, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f291, %f289, %f41, %f290;
	fma.rn.f32 	%f576, %f291, %f42, %f40;
	and.b32  	%r470, %r947, 2;
	setp.eq.s32	%p28, %r470, 0;
	@%p28 bra 	BB4_38;

	mov.f32 	%f293, 0fBF800000;
	fma.rn.f32 	%f576, %f576, %f293, %f230;

BB4_38:
	mul.f32 	%f294, %f22, %f576;
	mul.f32 	%f295, %f21, %f573;
	sub.f32 	%f296, %f295, %f294;
	mul.f32 	%f297, %f22, %f573;
	fma.rn.f32 	%f298, %f21, %f576, %f297;
	add.f32 	%f299, %f19, %f296;
	shl.b32 	%r471, %r1, 1;
	and.b32  	%r472, %r471, 1073741820;
	and.b32  	%r473, %r1, 1;
	add.s32 	%r474, %r472, %r473;
	shl.b32 	%r475, %r474, 2;
	mov.u32 	%r476, _ZZ24_occa_Stockhoptimized8_0E6SRBank;
	add.s32 	%r477, %r476, %r475;
	st.shared.f32 	[%r477], %f299;
	add.f32 	%f300, %f20, %f298;
	mov.u32 	%r478, _ZZ24_occa_Stockhoptimized8_0E6SIBank;
	add.s32 	%r479, %r478, %r475;
	st.shared.f32 	[%r479], %f300;
	sub.f32 	%f301, %f19, %f296;
	st.shared.f32 	[%r477+8], %f301;
	sub.f32 	%f302, %f20, %f298;
	st.shared.f32 	[%r479+8], %f302;
	bar.sync 	0;
	add.s32 	%r482, %r476, %r403;
	ld.shared.f32 	%f48, [%r482];
	add.s32 	%r484, %r478, %r403;
	ld.shared.f32 	%f49, [%r484];
	ld.shared.f32 	%f50, [%r482+512];
	ld.shared.f32 	%f51, [%r484+512];
	shr.s32 	%r485, %r1, 31;
	shr.u32 	%r486, %r485, 30;
	add.s32 	%r487, %r1, %r486;
	and.b32  	%r488, %r487, 134217724;
	sub.s32 	%r489, %r1, %r488;
	shl.b32 	%r490, %r489, 5;
	cvt.rn.f32.s32	%f303, %r490;
	mul.f32 	%f304, %f303, 0f3B800000;
	cvt.f64.f32	%fd7, %f304;
	mul.f64 	%fd8, %fd7, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f52, %fd8;
	mul.f32 	%f305, %f52, 0f3F22F983;
	cvt.rni.s32.f32	%r963, %f305;
	cvt.rn.f32.s32	%f306, %r963;
	fma.rn.f32 	%f308, %f306, %f225, %f52;
	fma.rn.f32 	%f310, %f306, %f227, %f308;
	fma.rn.f32 	%f580, %f306, %f229, %f310;
	abs.f32 	%f54, %f52;
	setp.leu.f32	%p29, %f54, 0f47CE4780;
	mov.u32 	%r955, %r963;
	mov.f32 	%f577, %f580;
	@%p29 bra 	BB4_49;

	setp.eq.f32	%p30, %f54, 0f7F800000;
	@%p30 bra 	BB4_48;
	bra.uni 	BB4_40;

BB4_48:
	mul.rn.f32 	%f577, %f52, %f230;
	mov.u32 	%r955, %r963;
	bra.uni 	BB4_49;

BB4_40:
	mov.b32 	 %r61, %f52;
	shl.b32 	%r493, %r61, 8;
	or.b32  	%r62, %r493, -2147483648;
	add.u64 	%rd107, %SP, 0;
	add.u64 	%rd212, %SPL, 0;
	mov.u32 	%r949, 0;
	mov.u64 	%rd211, __cudart_i2opi_f;
	mov.u32 	%r948, -6;

BB4_41:
	.pragma "nounroll";
	ld.const.u32 	%r496, [%rd211];
	// inline asm
	{
	mad.lo.cc.u32   %r494, %r496, %r62, %r949;
	madc.hi.u32     %r949, %r496, %r62,  0;
	}
	// inline asm
	st.local.u32 	[%rd212], %r494;
	add.s64 	%rd212, %rd212, 4;
	add.s64 	%rd211, %rd211, 4;
	add.s32 	%r948, %r948, 1;
	setp.ne.s32	%p31, %r948, 0;
	@%p31 bra 	BB4_41;

	bfe.u32 	%r499, %r61, 23, 8;
	add.s32 	%r500, %r499, -128;
	shr.u32 	%r501, %r500, 5;
	and.b32  	%r67, %r61, -2147483648;
	cvta.to.local.u64 	%rd109, %rd107;
	st.local.u32 	[%rd109+24], %r949;
	bfe.u32 	%r68, %r61, 23, 5;
	mov.u32 	%r502, 6;
	sub.s32 	%r503, %r502, %r501;
	mul.wide.s32 	%rd110, %r503, 4;
	add.s64 	%rd18, %rd109, %rd110;
	ld.local.u32 	%r951, [%rd18];
	ld.local.u32 	%r950, [%rd18+-4];
	setp.eq.s32	%p32, %r68, 0;
	@%p32 bra 	BB4_44;

	mov.u32 	%r504, 32;
	sub.s32 	%r505, %r504, %r68;
	shr.u32 	%r506, %r950, %r505;
	shl.b32 	%r507, %r951, %r68;
	add.s32 	%r951, %r506, %r507;
	ld.local.u32 	%r508, [%rd18+-8];
	shr.u32 	%r509, %r508, %r505;
	shl.b32 	%r510, %r950, %r68;
	add.s32 	%r950, %r509, %r510;

BB4_44:
	shr.u32 	%r511, %r950, 30;
	shl.b32 	%r512, %r951, 2;
	add.s32 	%r953, %r512, %r511;
	shl.b32 	%r76, %r950, 2;
	shr.u32 	%r513, %r953, 31;
	shr.u32 	%r514, %r951, 30;
	add.s32 	%r77, %r513, %r514;
	setp.eq.s32	%p33, %r513, 0;
	@%p33 bra 	BB4_45;

	not.b32 	%r515, %r953;
	neg.s32 	%r952, %r76;
	setp.eq.s32	%p34, %r76, 0;
	selp.u32	%r516, 1, 0, %p34;
	add.s32 	%r953, %r516, %r515;
	xor.b32  	%r954, %r67, -2147483648;
	bra.uni 	BB4_47;

BB4_45:
	mov.u32 	%r952, %r76;
	mov.u32 	%r954, %r67;

BB4_47:
	cvt.u64.u32	%rd111, %r953;
	cvt.u64.u32	%rd112, %r952;
	bfi.b64 	%rd113, %rd111, %rd112, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd113;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f312, %fd10;
	neg.f32 	%f313, %f312;
	setp.eq.s32	%p35, %r954, 0;
	selp.f32	%f577, %f312, %f313, %p35;
	setp.eq.s32	%p36, %r67, 0;
	neg.s32 	%r517, %r77;
	selp.b32	%r955, %r77, %r517, %p36;

BB4_49:
	add.s32 	%r86, %r955, 1;
	and.b32  	%r87, %r86, 1;
	setp.eq.s32	%p37, %r87, 0;
	selp.f32	%f58, %f577, 0f3F800000, %p37;
	mul.rn.f32 	%f59, %f577, %f577;
	fma.rn.f32 	%f60, %f59, %f58, %f230;
	mov.f32 	%f578, 0fB94D4153;
	@%p37 bra 	BB4_51;

	mov.f32 	%f317, 0fBAB607ED;
	mov.f32 	%f318, 0f37CBAC00;
	fma.rn.f32 	%f578, %f318, %f59, %f317;

BB4_51:
	selp.f32	%f319, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f320, %f578, %f59, %f319;
	selp.f32	%f321, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f322, %f320, %f59, %f321;
	fma.rn.f32 	%f579, %f322, %f60, %f58;
	and.b32  	%r518, %r86, 2;
	setp.eq.s32	%p39, %r518, 0;
	@%p39 bra 	BB4_53;

	mov.f32 	%f324, 0fBF800000;
	fma.rn.f32 	%f579, %f579, %f324, %f230;

BB4_53:
	@%p29 bra 	BB4_64;

	setp.eq.f32	%p41, %f54, 0f7F800000;
	@%p41 bra 	BB4_63;
	bra.uni 	BB4_55;

BB4_63:
	mul.rn.f32 	%f580, %f52, %f230;
	bra.uni 	BB4_64;

BB4_55:
	mov.b32 	 %r88, %f52;
	shl.b32 	%r521, %r88, 8;
	or.b32  	%r89, %r521, -2147483648;
	add.u64 	%rd115, %SP, 0;
	add.u64 	%rd214, %SPL, 0;
	mov.u32 	%r957, 0;
	mov.u64 	%rd213, __cudart_i2opi_f;
	mov.u32 	%r956, -6;

BB4_56:
	.pragma "nounroll";
	ld.const.u32 	%r524, [%rd213];
	// inline asm
	{
	mad.lo.cc.u32   %r522, %r524, %r89, %r957;
	madc.hi.u32     %r957, %r524, %r89,  0;
	}
	// inline asm
	st.local.u32 	[%rd214], %r522;
	add.s64 	%rd214, %rd214, 4;
	add.s64 	%rd213, %rd213, 4;
	add.s32 	%r956, %r956, 1;
	setp.ne.s32	%p42, %r956, 0;
	@%p42 bra 	BB4_56;

	bfe.u32 	%r527, %r88, 23, 8;
	add.s32 	%r528, %r527, -128;
	shr.u32 	%r529, %r528, 5;
	and.b32  	%r94, %r88, -2147483648;
	cvta.to.local.u64 	%rd117, %rd115;
	st.local.u32 	[%rd117+24], %r957;
	bfe.u32 	%r95, %r88, 23, 5;
	mov.u32 	%r530, 6;
	sub.s32 	%r531, %r530, %r529;
	mul.wide.s32 	%rd118, %r531, 4;
	add.s64 	%rd24, %rd117, %rd118;
	ld.local.u32 	%r959, [%rd24];
	ld.local.u32 	%r958, [%rd24+-4];
	setp.eq.s32	%p43, %r95, 0;
	@%p43 bra 	BB4_59;

	mov.u32 	%r532, 32;
	sub.s32 	%r533, %r532, %r95;
	shr.u32 	%r534, %r958, %r533;
	shl.b32 	%r535, %r959, %r95;
	add.s32 	%r959, %r534, %r535;
	ld.local.u32 	%r536, [%rd24+-8];
	shr.u32 	%r537, %r536, %r533;
	shl.b32 	%r538, %r958, %r95;
	add.s32 	%r958, %r537, %r538;

BB4_59:
	shr.u32 	%r539, %r958, 30;
	shl.b32 	%r540, %r959, 2;
	add.s32 	%r961, %r540, %r539;
	shl.b32 	%r103, %r958, 2;
	shr.u32 	%r541, %r961, 31;
	shr.u32 	%r542, %r959, 30;
	add.s32 	%r104, %r541, %r542;
	setp.eq.s32	%p44, %r541, 0;
	@%p44 bra 	BB4_60;

	not.b32 	%r543, %r961;
	neg.s32 	%r960, %r103;
	setp.eq.s32	%p45, %r103, 0;
	selp.u32	%r544, 1, 0, %p45;
	add.s32 	%r961, %r544, %r543;
	xor.b32  	%r962, %r94, -2147483648;
	bra.uni 	BB4_62;

BB4_60:
	mov.u32 	%r960, %r103;
	mov.u32 	%r962, %r94;

BB4_62:
	cvt.u64.u32	%rd119, %r961;
	cvt.u64.u32	%rd120, %r960;
	bfi.b64 	%rd121, %rd119, %rd120, 32, 32;
	cvt.rn.f64.s64	%fd11, %rd121;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f325, %fd12;
	neg.f32 	%f326, %f325;
	setp.eq.s32	%p46, %r962, 0;
	selp.f32	%f580, %f325, %f326, %p46;
	setp.eq.s32	%p47, %r94, 0;
	neg.s32 	%r545, %r104;
	selp.b32	%r963, %r104, %r545, %p47;

BB4_64:
	and.b32  	%r113, %r963, 1;
	setp.eq.s32	%p48, %r113, 0;
	selp.f32	%f69, %f580, 0f3F800000, %p48;
	mul.rn.f32 	%f70, %f580, %f580;
	fma.rn.f32 	%f71, %f70, %f69, %f230;
	mov.f32 	%f581, 0fB94D4153;
	@%p48 bra 	BB4_66;

	mov.f32 	%f330, 0fBAB607ED;
	mov.f32 	%f331, 0f37CBAC00;
	fma.rn.f32 	%f581, %f331, %f70, %f330;

BB4_66:
	selp.f32	%f332, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f333, %f581, %f70, %f332;
	selp.f32	%f334, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f335, %f333, %f70, %f334;
	fma.rn.f32 	%f582, %f335, %f71, %f69;
	and.b32  	%r546, %r963, 2;
	setp.eq.s32	%p50, %r546, 0;
	@%p50 bra 	BB4_68;

	mov.f32 	%f337, 0fBF800000;
	fma.rn.f32 	%f582, %f582, %f337, %f230;

BB4_68:
	and.b32  	%r547, %r1, 3;
	and.b32  	%r549, %r471, 1073741816;
	add.s32 	%r550, %r549, %r547;
	mul.f32 	%f338, %f51, %f582;
	mul.f32 	%f339, %f50, %f579;
	sub.f32 	%f340, %f339, %f338;
	mul.f32 	%f341, %f51, %f579;
	fma.rn.f32 	%f342, %f50, %f582, %f341;
	add.f32 	%f343, %f48, %f340;
	shl.b32 	%r551, %r550, 2;
	add.s32 	%r553, %r399, %r551;
	st.shared.f32 	[%r553], %f343;
	add.f32 	%f344, %f49, %f342;
	add.s32 	%r555, %r401, %r551;
	st.shared.f32 	[%r555], %f344;
	sub.f32 	%f345, %f48, %f340;
	st.shared.f32 	[%r553+16], %f345;
	sub.f32 	%f346, %f49, %f342;
	st.shared.f32 	[%r555+16], %f346;
	bar.sync 	0;
	ld.shared.f32 	%f77, [%r405];
	ld.shared.f32 	%f78, [%r407];
	ld.shared.f32 	%f79, [%r405+512];
	ld.shared.f32 	%f80, [%r407+512];
	shr.u32 	%r562, %r485, 29;
	add.s32 	%r563, %r1, %r562;
	and.b32  	%r564, %r563, 268435448;
	sub.s32 	%r565, %r1, %r564;
	shl.b32 	%r566, %r565, 4;
	cvt.rn.f32.s32	%f347, %r566;
	mul.f32 	%f348, %f347, 0f3B800000;
	cvt.f64.f32	%fd13, %f348;
	mul.f64 	%fd14, %fd13, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f81, %fd14;
	mul.f32 	%f349, %f81, 0f3F22F983;
	cvt.rni.s32.f32	%r979, %f349;
	cvt.rn.f32.s32	%f350, %r979;
	fma.rn.f32 	%f352, %f350, %f225, %f81;
	fma.rn.f32 	%f354, %f350, %f227, %f352;
	fma.rn.f32 	%f586, %f350, %f229, %f354;
	abs.f32 	%f83, %f81;
	setp.leu.f32	%p51, %f83, 0f47CE4780;
	mov.u32 	%r971, %r979;
	mov.f32 	%f583, %f586;
	@%p51 bra 	BB4_79;

	setp.eq.f32	%p52, %f83, 0f7F800000;
	@%p52 bra 	BB4_78;
	bra.uni 	BB4_70;

BB4_78:
	mul.rn.f32 	%f583, %f81, %f230;
	mov.u32 	%r971, %r979;
	bra.uni 	BB4_79;

BB4_70:
	mov.b32 	 %r116, %f81;
	shl.b32 	%r569, %r116, 8;
	or.b32  	%r117, %r569, -2147483648;
	add.u64 	%rd123, %SP, 0;
	add.u64 	%rd216, %SPL, 0;
	mov.u32 	%r965, 0;
	mov.u64 	%rd215, __cudart_i2opi_f;
	mov.u32 	%r964, -6;

BB4_71:
	.pragma "nounroll";
	ld.const.u32 	%r572, [%rd215];
	// inline asm
	{
	mad.lo.cc.u32   %r570, %r572, %r117, %r965;
	madc.hi.u32     %r965, %r572, %r117,  0;
	}
	// inline asm
	st.local.u32 	[%rd216], %r570;
	add.s64 	%rd216, %rd216, 4;
	add.s64 	%rd215, %rd215, 4;
	add.s32 	%r964, %r964, 1;
	setp.ne.s32	%p53, %r964, 0;
	@%p53 bra 	BB4_71;

	bfe.u32 	%r575, %r116, 23, 8;
	add.s32 	%r576, %r575, -128;
	shr.u32 	%r577, %r576, 5;
	and.b32  	%r122, %r116, -2147483648;
	cvta.to.local.u64 	%rd125, %rd123;
	st.local.u32 	[%rd125+24], %r965;
	bfe.u32 	%r123, %r116, 23, 5;
	mov.u32 	%r578, 6;
	sub.s32 	%r579, %r578, %r577;
	mul.wide.s32 	%rd126, %r579, 4;
	add.s64 	%rd30, %rd125, %rd126;
	ld.local.u32 	%r967, [%rd30];
	ld.local.u32 	%r966, [%rd30+-4];
	setp.eq.s32	%p54, %r123, 0;
	@%p54 bra 	BB4_74;

	mov.u32 	%r580, 32;
	sub.s32 	%r581, %r580, %r123;
	shr.u32 	%r582, %r966, %r581;
	shl.b32 	%r583, %r967, %r123;
	add.s32 	%r967, %r582, %r583;
	ld.local.u32 	%r584, [%rd30+-8];
	shr.u32 	%r585, %r584, %r581;
	shl.b32 	%r586, %r966, %r123;
	add.s32 	%r966, %r585, %r586;

BB4_74:
	shr.u32 	%r587, %r966, 30;
	shl.b32 	%r588, %r967, 2;
	add.s32 	%r969, %r588, %r587;
	shl.b32 	%r131, %r966, 2;
	shr.u32 	%r589, %r969, 31;
	shr.u32 	%r590, %r967, 30;
	add.s32 	%r132, %r589, %r590;
	setp.eq.s32	%p55, %r589, 0;
	@%p55 bra 	BB4_75;

	not.b32 	%r591, %r969;
	neg.s32 	%r968, %r131;
	setp.eq.s32	%p56, %r131, 0;
	selp.u32	%r592, 1, 0, %p56;
	add.s32 	%r969, %r592, %r591;
	xor.b32  	%r970, %r122, -2147483648;
	bra.uni 	BB4_77;

BB4_75:
	mov.u32 	%r968, %r131;
	mov.u32 	%r970, %r122;

BB4_77:
	cvt.u64.u32	%rd127, %r969;
	cvt.u64.u32	%rd128, %r968;
	bfi.b64 	%rd129, %rd127, %rd128, 32, 32;
	cvt.rn.f64.s64	%fd15, %rd129;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f356, %fd16;
	neg.f32 	%f357, %f356;
	setp.eq.s32	%p57, %r970, 0;
	selp.f32	%f583, %f356, %f357, %p57;
	setp.eq.s32	%p58, %r122, 0;
	neg.s32 	%r593, %r132;
	selp.b32	%r971, %r132, %r593, %p58;

BB4_79:
	add.s32 	%r141, %r971, 1;
	and.b32  	%r142, %r141, 1;
	setp.eq.s32	%p59, %r142, 0;
	selp.f32	%f87, %f583, 0f3F800000, %p59;
	mul.rn.f32 	%f88, %f583, %f583;
	fma.rn.f32 	%f89, %f88, %f87, %f230;
	mov.f32 	%f584, 0fB94D4153;
	@%p59 bra 	BB4_81;

	mov.f32 	%f361, 0fBAB607ED;
	mov.f32 	%f362, 0f37CBAC00;
	fma.rn.f32 	%f584, %f362, %f88, %f361;

BB4_81:
	selp.f32	%f363, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f364, %f584, %f88, %f363;
	selp.f32	%f365, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f366, %f364, %f88, %f365;
	fma.rn.f32 	%f585, %f366, %f89, %f87;
	and.b32  	%r594, %r141, 2;
	setp.eq.s32	%p61, %r594, 0;
	@%p61 bra 	BB4_83;

	mov.f32 	%f368, 0fBF800000;
	fma.rn.f32 	%f585, %f585, %f368, %f230;

BB4_83:
	@%p51 bra 	BB4_94;

	setp.eq.f32	%p63, %f83, 0f7F800000;
	@%p63 bra 	BB4_93;
	bra.uni 	BB4_85;

BB4_93:
	mul.rn.f32 	%f586, %f81, %f230;
	bra.uni 	BB4_94;

BB4_85:
	mov.b32 	 %r143, %f81;
	shl.b32 	%r597, %r143, 8;
	or.b32  	%r144, %r597, -2147483648;
	add.u64 	%rd131, %SP, 0;
	add.u64 	%rd218, %SPL, 0;
	mov.u32 	%r973, 0;
	mov.u64 	%rd217, __cudart_i2opi_f;
	mov.u32 	%r972, -6;

BB4_86:
	.pragma "nounroll";
	ld.const.u32 	%r600, [%rd217];
	// inline asm
	{
	mad.lo.cc.u32   %r598, %r600, %r144, %r973;
	madc.hi.u32     %r973, %r600, %r144,  0;
	}
	// inline asm
	st.local.u32 	[%rd218], %r598;
	add.s64 	%rd218, %rd218, 4;
	add.s64 	%rd217, %rd217, 4;
	add.s32 	%r972, %r972, 1;
	setp.ne.s32	%p64, %r972, 0;
	@%p64 bra 	BB4_86;

	bfe.u32 	%r603, %r143, 23, 8;
	add.s32 	%r604, %r603, -128;
	shr.u32 	%r605, %r604, 5;
	and.b32  	%r149, %r143, -2147483648;
	cvta.to.local.u64 	%rd133, %rd131;
	st.local.u32 	[%rd133+24], %r973;
	bfe.u32 	%r150, %r143, 23, 5;
	mov.u32 	%r606, 6;
	sub.s32 	%r607, %r606, %r605;
	mul.wide.s32 	%rd134, %r607, 4;
	add.s64 	%rd36, %rd133, %rd134;
	ld.local.u32 	%r975, [%rd36];
	ld.local.u32 	%r974, [%rd36+-4];
	setp.eq.s32	%p65, %r150, 0;
	@%p65 bra 	BB4_89;

	mov.u32 	%r608, 32;
	sub.s32 	%r609, %r608, %r150;
	shr.u32 	%r610, %r974, %r609;
	shl.b32 	%r611, %r975, %r150;
	add.s32 	%r975, %r610, %r611;
	ld.local.u32 	%r612, [%rd36+-8];
	shr.u32 	%r613, %r612, %r609;
	shl.b32 	%r614, %r974, %r150;
	add.s32 	%r974, %r613, %r614;

BB4_89:
	shr.u32 	%r615, %r974, 30;
	shl.b32 	%r616, %r975, 2;
	add.s32 	%r977, %r616, %r615;
	shl.b32 	%r158, %r974, 2;
	shr.u32 	%r617, %r977, 31;
	shr.u32 	%r618, %r975, 30;
	add.s32 	%r159, %r617, %r618;
	setp.eq.s32	%p66, %r617, 0;
	@%p66 bra 	BB4_90;

	not.b32 	%r619, %r977;
	neg.s32 	%r976, %r158;
	setp.eq.s32	%p67, %r158, 0;
	selp.u32	%r620, 1, 0, %p67;
	add.s32 	%r977, %r620, %r619;
	xor.b32  	%r978, %r149, -2147483648;
	bra.uni 	BB4_92;

BB4_90:
	mov.u32 	%r976, %r158;
	mov.u32 	%r978, %r149;

BB4_92:
	cvt.u64.u32	%rd135, %r977;
	cvt.u64.u32	%rd136, %r976;
	bfi.b64 	%rd137, %rd135, %rd136, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd137;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f369, %fd18;
	neg.f32 	%f370, %f369;
	setp.eq.s32	%p68, %r978, 0;
	selp.f32	%f586, %f369, %f370, %p68;
	setp.eq.s32	%p69, %r149, 0;
	neg.s32 	%r621, %r159;
	selp.b32	%r979, %r159, %r621, %p69;

BB4_94:
	and.b32  	%r168, %r979, 1;
	setp.eq.s32	%p70, %r168, 0;
	selp.f32	%f98, %f586, 0f3F800000, %p70;
	mul.rn.f32 	%f99, %f586, %f586;
	fma.rn.f32 	%f100, %f99, %f98, %f230;
	mov.f32 	%f587, 0fB94D4153;
	@%p70 bra 	BB4_96;

	mov.f32 	%f374, 0fBAB607ED;
	mov.f32 	%f375, 0f37CBAC00;
	fma.rn.f32 	%f587, %f375, %f99, %f374;

BB4_96:
	selp.f32	%f376, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f377, %f587, %f99, %f376;
	selp.f32	%f378, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f379, %f377, %f99, %f378;
	fma.rn.f32 	%f588, %f379, %f100, %f98;
	and.b32  	%r622, %r979, 2;
	setp.eq.s32	%p72, %r622, 0;
	@%p72 bra 	BB4_98;

	mov.f32 	%f381, 0fBF800000;
	fma.rn.f32 	%f588, %f588, %f381, %f230;

BB4_98:
	and.b32  	%r623, %r1, 7;
	and.b32  	%r625, %r471, 1073741808;
	add.s32 	%r626, %r625, %r623;
	mul.f32 	%f382, %f80, %f588;
	mul.f32 	%f383, %f79, %f585;
	sub.f32 	%f384, %f383, %f382;
	mul.f32 	%f385, %f80, %f585;
	fma.rn.f32 	%f386, %f79, %f588, %f385;
	add.f32 	%f387, %f77, %f384;
	shl.b32 	%r627, %r626, 2;
	add.s32 	%r629, %r476, %r627;
	st.shared.f32 	[%r629], %f387;
	add.f32 	%f388, %f78, %f386;
	add.s32 	%r631, %r478, %r627;
	st.shared.f32 	[%r631], %f388;
	sub.f32 	%f389, %f77, %f384;
	st.shared.f32 	[%r629+32], %f389;
	sub.f32 	%f390, %f78, %f386;
	st.shared.f32 	[%r631+32], %f390;
	bar.sync 	0;
	ld.shared.f32 	%f106, [%r482];
	ld.shared.f32 	%f107, [%r484];
	ld.shared.f32 	%f108, [%r482+512];
	ld.shared.f32 	%f109, [%r484+512];
	shr.u32 	%r638, %r485, 28;
	add.s32 	%r639, %r1, %r638;
	and.b32  	%r640, %r639, 536870896;
	sub.s32 	%r641, %r1, %r640;
	shl.b32 	%r642, %r641, 3;
	cvt.rn.f32.s32	%f391, %r642;
	mul.f32 	%f392, %f391, 0f3B800000;
	cvt.f64.f32	%fd19, %f392;
	mul.f64 	%fd20, %fd19, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f110, %fd20;
	mul.f32 	%f393, %f110, 0f3F22F983;
	cvt.rni.s32.f32	%r995, %f393;
	cvt.rn.f32.s32	%f394, %r995;
	fma.rn.f32 	%f396, %f394, %f225, %f110;
	fma.rn.f32 	%f398, %f394, %f227, %f396;
	fma.rn.f32 	%f592, %f394, %f229, %f398;
	abs.f32 	%f112, %f110;
	setp.leu.f32	%p73, %f112, 0f47CE4780;
	mov.u32 	%r987, %r995;
	mov.f32 	%f589, %f592;
	@%p73 bra 	BB4_109;

	setp.eq.f32	%p74, %f112, 0f7F800000;
	@%p74 bra 	BB4_108;
	bra.uni 	BB4_100;

BB4_108:
	mul.rn.f32 	%f589, %f110, %f230;
	mov.u32 	%r987, %r995;
	bra.uni 	BB4_109;

BB4_100:
	mov.b32 	 %r171, %f110;
	shl.b32 	%r645, %r171, 8;
	or.b32  	%r172, %r645, -2147483648;
	add.u64 	%rd139, %SP, 0;
	add.u64 	%rd220, %SPL, 0;
	mov.u32 	%r981, 0;
	mov.u64 	%rd219, __cudart_i2opi_f;
	mov.u32 	%r980, -6;

BB4_101:
	.pragma "nounroll";
	ld.const.u32 	%r648, [%rd219];
	// inline asm
	{
	mad.lo.cc.u32   %r646, %r648, %r172, %r981;
	madc.hi.u32     %r981, %r648, %r172,  0;
	}
	// inline asm
	st.local.u32 	[%rd220], %r646;
	add.s64 	%rd220, %rd220, 4;
	add.s64 	%rd219, %rd219, 4;
	add.s32 	%r980, %r980, 1;
	setp.ne.s32	%p75, %r980, 0;
	@%p75 bra 	BB4_101;

	bfe.u32 	%r651, %r171, 23, 8;
	add.s32 	%r652, %r651, -128;
	shr.u32 	%r653, %r652, 5;
	and.b32  	%r177, %r171, -2147483648;
	cvta.to.local.u64 	%rd141, %rd139;
	st.local.u32 	[%rd141+24], %r981;
	bfe.u32 	%r178, %r171, 23, 5;
	mov.u32 	%r654, 6;
	sub.s32 	%r655, %r654, %r653;
	mul.wide.s32 	%rd142, %r655, 4;
	add.s64 	%rd42, %rd141, %rd142;
	ld.local.u32 	%r983, [%rd42];
	ld.local.u32 	%r982, [%rd42+-4];
	setp.eq.s32	%p76, %r178, 0;
	@%p76 bra 	BB4_104;

	mov.u32 	%r656, 32;
	sub.s32 	%r657, %r656, %r178;
	shr.u32 	%r658, %r982, %r657;
	shl.b32 	%r659, %r983, %r178;
	add.s32 	%r983, %r658, %r659;
	ld.local.u32 	%r660, [%rd42+-8];
	shr.u32 	%r661, %r660, %r657;
	shl.b32 	%r662, %r982, %r178;
	add.s32 	%r982, %r661, %r662;

BB4_104:
	shr.u32 	%r663, %r982, 30;
	shl.b32 	%r664, %r983, 2;
	add.s32 	%r985, %r664, %r663;
	shl.b32 	%r186, %r982, 2;
	shr.u32 	%r665, %r985, 31;
	shr.u32 	%r666, %r983, 30;
	add.s32 	%r187, %r665, %r666;
	setp.eq.s32	%p77, %r665, 0;
	@%p77 bra 	BB4_105;

	not.b32 	%r667, %r985;
	neg.s32 	%r984, %r186;
	setp.eq.s32	%p78, %r186, 0;
	selp.u32	%r668, 1, 0, %p78;
	add.s32 	%r985, %r668, %r667;
	xor.b32  	%r986, %r177, -2147483648;
	bra.uni 	BB4_107;

BB4_105:
	mov.u32 	%r984, %r186;
	mov.u32 	%r986, %r177;

BB4_107:
	cvt.u64.u32	%rd143, %r985;
	cvt.u64.u32	%rd144, %r984;
	bfi.b64 	%rd145, %rd143, %rd144, 32, 32;
	cvt.rn.f64.s64	%fd21, %rd145;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f400, %fd22;
	neg.f32 	%f401, %f400;
	setp.eq.s32	%p79, %r986, 0;
	selp.f32	%f589, %f400, %f401, %p79;
	setp.eq.s32	%p80, %r177, 0;
	neg.s32 	%r669, %r187;
	selp.b32	%r987, %r187, %r669, %p80;

BB4_109:
	add.s32 	%r196, %r987, 1;
	and.b32  	%r197, %r196, 1;
	setp.eq.s32	%p81, %r197, 0;
	selp.f32	%f116, %f589, 0f3F800000, %p81;
	mul.rn.f32 	%f117, %f589, %f589;
	fma.rn.f32 	%f118, %f117, %f116, %f230;
	mov.f32 	%f590, 0fB94D4153;
	@%p81 bra 	BB4_111;

	mov.f32 	%f405, 0fBAB607ED;
	mov.f32 	%f406, 0f37CBAC00;
	fma.rn.f32 	%f590, %f406, %f117, %f405;

BB4_111:
	selp.f32	%f407, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f408, %f590, %f117, %f407;
	selp.f32	%f409, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f410, %f408, %f117, %f409;
	fma.rn.f32 	%f591, %f410, %f118, %f116;
	and.b32  	%r670, %r196, 2;
	setp.eq.s32	%p83, %r670, 0;
	@%p83 bra 	BB4_113;

	mov.f32 	%f412, 0fBF800000;
	fma.rn.f32 	%f591, %f591, %f412, %f230;

BB4_113:
	@%p73 bra 	BB4_124;

	setp.eq.f32	%p85, %f112, 0f7F800000;
	@%p85 bra 	BB4_123;
	bra.uni 	BB4_115;

BB4_123:
	mul.rn.f32 	%f592, %f110, %f230;
	bra.uni 	BB4_124;

BB4_115:
	mov.b32 	 %r198, %f110;
	shl.b32 	%r673, %r198, 8;
	or.b32  	%r199, %r673, -2147483648;
	add.u64 	%rd147, %SP, 0;
	add.u64 	%rd222, %SPL, 0;
	mov.u32 	%r989, 0;
	mov.u64 	%rd221, __cudart_i2opi_f;
	mov.u32 	%r988, -6;

BB4_116:
	.pragma "nounroll";
	ld.const.u32 	%r676, [%rd221];
	// inline asm
	{
	mad.lo.cc.u32   %r674, %r676, %r199, %r989;
	madc.hi.u32     %r989, %r676, %r199,  0;
	}
	// inline asm
	st.local.u32 	[%rd222], %r674;
	add.s64 	%rd222, %rd222, 4;
	add.s64 	%rd221, %rd221, 4;
	add.s32 	%r988, %r988, 1;
	setp.ne.s32	%p86, %r988, 0;
	@%p86 bra 	BB4_116;

	bfe.u32 	%r679, %r198, 23, 8;
	add.s32 	%r680, %r679, -128;
	shr.u32 	%r681, %r680, 5;
	and.b32  	%r204, %r198, -2147483648;
	cvta.to.local.u64 	%rd149, %rd147;
	st.local.u32 	[%rd149+24], %r989;
	bfe.u32 	%r205, %r198, 23, 5;
	mov.u32 	%r682, 6;
	sub.s32 	%r683, %r682, %r681;
	mul.wide.s32 	%rd150, %r683, 4;
	add.s64 	%rd48, %rd149, %rd150;
	ld.local.u32 	%r991, [%rd48];
	ld.local.u32 	%r990, [%rd48+-4];
	setp.eq.s32	%p87, %r205, 0;
	@%p87 bra 	BB4_119;

	mov.u32 	%r684, 32;
	sub.s32 	%r685, %r684, %r205;
	shr.u32 	%r686, %r990, %r685;
	shl.b32 	%r687, %r991, %r205;
	add.s32 	%r991, %r686, %r687;
	ld.local.u32 	%r688, [%rd48+-8];
	shr.u32 	%r689, %r688, %r685;
	shl.b32 	%r690, %r990, %r205;
	add.s32 	%r990, %r689, %r690;

BB4_119:
	shr.u32 	%r691, %r990, 30;
	shl.b32 	%r692, %r991, 2;
	add.s32 	%r993, %r692, %r691;
	shl.b32 	%r213, %r990, 2;
	shr.u32 	%r693, %r993, 31;
	shr.u32 	%r694, %r991, 30;
	add.s32 	%r214, %r693, %r694;
	setp.eq.s32	%p88, %r693, 0;
	@%p88 bra 	BB4_120;

	not.b32 	%r695, %r993;
	neg.s32 	%r992, %r213;
	setp.eq.s32	%p89, %r213, 0;
	selp.u32	%r696, 1, 0, %p89;
	add.s32 	%r993, %r696, %r695;
	xor.b32  	%r994, %r204, -2147483648;
	bra.uni 	BB4_122;

BB4_120:
	mov.u32 	%r992, %r213;
	mov.u32 	%r994, %r204;

BB4_122:
	cvt.u64.u32	%rd151, %r993;
	cvt.u64.u32	%rd152, %r992;
	bfi.b64 	%rd153, %rd151, %rd152, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd153;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f413, %fd24;
	neg.f32 	%f414, %f413;
	setp.eq.s32	%p90, %r994, 0;
	selp.f32	%f592, %f413, %f414, %p90;
	setp.eq.s32	%p91, %r204, 0;
	neg.s32 	%r697, %r214;
	selp.b32	%r995, %r214, %r697, %p91;

BB4_124:
	and.b32  	%r223, %r995, 1;
	setp.eq.s32	%p92, %r223, 0;
	selp.f32	%f127, %f592, 0f3F800000, %p92;
	mul.rn.f32 	%f128, %f592, %f592;
	fma.rn.f32 	%f129, %f128, %f127, %f230;
	mov.f32 	%f593, 0fB94D4153;
	@%p92 bra 	BB4_126;

	mov.f32 	%f418, 0fBAB607ED;
	mov.f32 	%f419, 0f37CBAC00;
	fma.rn.f32 	%f593, %f419, %f128, %f418;

BB4_126:
	selp.f32	%f420, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f421, %f593, %f128, %f420;
	selp.f32	%f422, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f423, %f421, %f128, %f422;
	fma.rn.f32 	%f594, %f423, %f129, %f127;
	and.b32  	%r698, %r995, 2;
	setp.eq.s32	%p94, %r698, 0;
	@%p94 bra 	BB4_128;

	mov.f32 	%f425, 0fBF800000;
	fma.rn.f32 	%f594, %f594, %f425, %f230;

BB4_128:
	and.b32  	%r699, %r1, 15;
	and.b32  	%r701, %r471, 1073741792;
	add.s32 	%r702, %r701, %r699;
	mul.f32 	%f426, %f109, %f594;
	mul.f32 	%f427, %f108, %f591;
	sub.f32 	%f428, %f427, %f426;
	mul.f32 	%f429, %f109, %f591;
	fma.rn.f32 	%f430, %f108, %f594, %f429;
	add.f32 	%f431, %f106, %f428;
	shl.b32 	%r703, %r702, 2;
	add.s32 	%r705, %r399, %r703;
	st.shared.f32 	[%r705], %f431;
	add.f32 	%f432, %f107, %f430;
	add.s32 	%r707, %r401, %r703;
	st.shared.f32 	[%r707], %f432;
	sub.f32 	%f433, %f106, %f428;
	st.shared.f32 	[%r705+64], %f433;
	sub.f32 	%f434, %f107, %f430;
	st.shared.f32 	[%r707+64], %f434;
	bar.sync 	0;
	ld.shared.f32 	%f135, [%r405];
	ld.shared.f32 	%f136, [%r407];
	ld.shared.f32 	%f137, [%r405+512];
	ld.shared.f32 	%f138, [%r407+512];
	shr.u32 	%r714, %r485, 27;
	add.s32 	%r715, %r1, %r714;
	and.b32  	%r716, %r715, 1073741792;
	sub.s32 	%r717, %r1, %r716;
	shl.b32 	%r718, %r717, 2;
	cvt.rn.f32.s32	%f435, %r718;
	mul.f32 	%f436, %f435, 0f3B800000;
	cvt.f64.f32	%fd25, %f436;
	mul.f64 	%fd26, %fd25, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f139, %fd26;
	mul.f32 	%f437, %f139, 0f3F22F983;
	cvt.rni.s32.f32	%r1011, %f437;
	cvt.rn.f32.s32	%f438, %r1011;
	fma.rn.f32 	%f440, %f438, %f225, %f139;
	fma.rn.f32 	%f442, %f438, %f227, %f440;
	fma.rn.f32 	%f598, %f438, %f229, %f442;
	abs.f32 	%f141, %f139;
	setp.leu.f32	%p95, %f141, 0f47CE4780;
	mov.u32 	%r1003, %r1011;
	mov.f32 	%f595, %f598;
	@%p95 bra 	BB4_139;

	setp.eq.f32	%p96, %f141, 0f7F800000;
	@%p96 bra 	BB4_138;
	bra.uni 	BB4_130;

BB4_138:
	mul.rn.f32 	%f595, %f139, %f230;
	mov.u32 	%r1003, %r1011;
	bra.uni 	BB4_139;

BB4_130:
	mov.b32 	 %r226, %f139;
	shl.b32 	%r721, %r226, 8;
	or.b32  	%r227, %r721, -2147483648;
	add.u64 	%rd155, %SP, 0;
	add.u64 	%rd224, %SPL, 0;
	mov.u32 	%r997, 0;
	mov.u64 	%rd223, __cudart_i2opi_f;
	mov.u32 	%r996, -6;

BB4_131:
	.pragma "nounroll";
	ld.const.u32 	%r724, [%rd223];
	// inline asm
	{
	mad.lo.cc.u32   %r722, %r724, %r227, %r997;
	madc.hi.u32     %r997, %r724, %r227,  0;
	}
	// inline asm
	st.local.u32 	[%rd224], %r722;
	add.s64 	%rd224, %rd224, 4;
	add.s64 	%rd223, %rd223, 4;
	add.s32 	%r996, %r996, 1;
	setp.ne.s32	%p97, %r996, 0;
	@%p97 bra 	BB4_131;

	bfe.u32 	%r727, %r226, 23, 8;
	add.s32 	%r728, %r727, -128;
	shr.u32 	%r729, %r728, 5;
	and.b32  	%r232, %r226, -2147483648;
	cvta.to.local.u64 	%rd157, %rd155;
	st.local.u32 	[%rd157+24], %r997;
	bfe.u32 	%r233, %r226, 23, 5;
	mov.u32 	%r730, 6;
	sub.s32 	%r731, %r730, %r729;
	mul.wide.s32 	%rd158, %r731, 4;
	add.s64 	%rd54, %rd157, %rd158;
	ld.local.u32 	%r999, [%rd54];
	ld.local.u32 	%r998, [%rd54+-4];
	setp.eq.s32	%p98, %r233, 0;
	@%p98 bra 	BB4_134;

	mov.u32 	%r732, 32;
	sub.s32 	%r733, %r732, %r233;
	shr.u32 	%r734, %r998, %r733;
	shl.b32 	%r735, %r999, %r233;
	add.s32 	%r999, %r734, %r735;
	ld.local.u32 	%r736, [%rd54+-8];
	shr.u32 	%r737, %r736, %r733;
	shl.b32 	%r738, %r998, %r233;
	add.s32 	%r998, %r737, %r738;

BB4_134:
	shr.u32 	%r739, %r998, 30;
	shl.b32 	%r740, %r999, 2;
	add.s32 	%r1001, %r740, %r739;
	shl.b32 	%r241, %r998, 2;
	shr.u32 	%r741, %r1001, 31;
	shr.u32 	%r742, %r999, 30;
	add.s32 	%r242, %r741, %r742;
	setp.eq.s32	%p99, %r741, 0;
	@%p99 bra 	BB4_135;

	not.b32 	%r743, %r1001;
	neg.s32 	%r1000, %r241;
	setp.eq.s32	%p100, %r241, 0;
	selp.u32	%r744, 1, 0, %p100;
	add.s32 	%r1001, %r744, %r743;
	xor.b32  	%r1002, %r232, -2147483648;
	bra.uni 	BB4_137;

BB4_135:
	mov.u32 	%r1000, %r241;
	mov.u32 	%r1002, %r232;

BB4_137:
	cvt.u64.u32	%rd159, %r1001;
	cvt.u64.u32	%rd160, %r1000;
	bfi.b64 	%rd161, %rd159, %rd160, 32, 32;
	cvt.rn.f64.s64	%fd27, %rd161;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f444, %fd28;
	neg.f32 	%f445, %f444;
	setp.eq.s32	%p101, %r1002, 0;
	selp.f32	%f595, %f444, %f445, %p101;
	setp.eq.s32	%p102, %r232, 0;
	neg.s32 	%r745, %r242;
	selp.b32	%r1003, %r242, %r745, %p102;

BB4_139:
	add.s32 	%r251, %r1003, 1;
	and.b32  	%r252, %r251, 1;
	setp.eq.s32	%p103, %r252, 0;
	selp.f32	%f145, %f595, 0f3F800000, %p103;
	mul.rn.f32 	%f146, %f595, %f595;
	fma.rn.f32 	%f147, %f146, %f145, %f230;
	mov.f32 	%f596, 0fB94D4153;
	@%p103 bra 	BB4_141;

	mov.f32 	%f449, 0fBAB607ED;
	mov.f32 	%f450, 0f37CBAC00;
	fma.rn.f32 	%f596, %f450, %f146, %f449;

BB4_141:
	selp.f32	%f451, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f452, %f596, %f146, %f451;
	selp.f32	%f453, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f454, %f452, %f146, %f453;
	fma.rn.f32 	%f597, %f454, %f147, %f145;
	and.b32  	%r746, %r251, 2;
	setp.eq.s32	%p105, %r746, 0;
	@%p105 bra 	BB4_143;

	mov.f32 	%f456, 0fBF800000;
	fma.rn.f32 	%f597, %f597, %f456, %f230;

BB4_143:
	@%p95 bra 	BB4_154;

	setp.eq.f32	%p107, %f141, 0f7F800000;
	@%p107 bra 	BB4_153;
	bra.uni 	BB4_145;

BB4_153:
	mul.rn.f32 	%f598, %f139, %f230;
	bra.uni 	BB4_154;

BB4_145:
	mov.b32 	 %r253, %f139;
	shl.b32 	%r749, %r253, 8;
	or.b32  	%r254, %r749, -2147483648;
	add.u64 	%rd163, %SP, 0;
	add.u64 	%rd226, %SPL, 0;
	mov.u32 	%r1005, 0;
	mov.u64 	%rd225, __cudart_i2opi_f;
	mov.u32 	%r1004, -6;

BB4_146:
	.pragma "nounroll";
	ld.const.u32 	%r752, [%rd225];
	// inline asm
	{
	mad.lo.cc.u32   %r750, %r752, %r254, %r1005;
	madc.hi.u32     %r1005, %r752, %r254,  0;
	}
	// inline asm
	st.local.u32 	[%rd226], %r750;
	add.s64 	%rd226, %rd226, 4;
	add.s64 	%rd225, %rd225, 4;
	add.s32 	%r1004, %r1004, 1;
	setp.ne.s32	%p108, %r1004, 0;
	@%p108 bra 	BB4_146;

	bfe.u32 	%r755, %r253, 23, 8;
	add.s32 	%r756, %r755, -128;
	shr.u32 	%r757, %r756, 5;
	and.b32  	%r259, %r253, -2147483648;
	cvta.to.local.u64 	%rd165, %rd163;
	st.local.u32 	[%rd165+24], %r1005;
	bfe.u32 	%r260, %r253, 23, 5;
	mov.u32 	%r758, 6;
	sub.s32 	%r759, %r758, %r757;
	mul.wide.s32 	%rd166, %r759, 4;
	add.s64 	%rd60, %rd165, %rd166;
	ld.local.u32 	%r1007, [%rd60];
	ld.local.u32 	%r1006, [%rd60+-4];
	setp.eq.s32	%p109, %r260, 0;
	@%p109 bra 	BB4_149;

	mov.u32 	%r760, 32;
	sub.s32 	%r761, %r760, %r260;
	shr.u32 	%r762, %r1006, %r761;
	shl.b32 	%r763, %r1007, %r260;
	add.s32 	%r1007, %r762, %r763;
	ld.local.u32 	%r764, [%rd60+-8];
	shr.u32 	%r765, %r764, %r761;
	shl.b32 	%r766, %r1006, %r260;
	add.s32 	%r1006, %r765, %r766;

BB4_149:
	shr.u32 	%r767, %r1006, 30;
	shl.b32 	%r768, %r1007, 2;
	add.s32 	%r1009, %r768, %r767;
	shl.b32 	%r268, %r1006, 2;
	shr.u32 	%r769, %r1009, 31;
	shr.u32 	%r770, %r1007, 30;
	add.s32 	%r269, %r769, %r770;
	setp.eq.s32	%p110, %r769, 0;
	@%p110 bra 	BB4_150;

	not.b32 	%r771, %r1009;
	neg.s32 	%r1008, %r268;
	setp.eq.s32	%p111, %r268, 0;
	selp.u32	%r772, 1, 0, %p111;
	add.s32 	%r1009, %r772, %r771;
	xor.b32  	%r1010, %r259, -2147483648;
	bra.uni 	BB4_152;

BB4_150:
	mov.u32 	%r1008, %r268;
	mov.u32 	%r1010, %r259;

BB4_152:
	cvt.u64.u32	%rd167, %r1009;
	cvt.u64.u32	%rd168, %r1008;
	bfi.b64 	%rd169, %rd167, %rd168, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd169;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f457, %fd30;
	neg.f32 	%f458, %f457;
	setp.eq.s32	%p112, %r1010, 0;
	selp.f32	%f598, %f457, %f458, %p112;
	setp.eq.s32	%p113, %r259, 0;
	neg.s32 	%r773, %r269;
	selp.b32	%r1011, %r269, %r773, %p113;

BB4_154:
	and.b32  	%r278, %r1011, 1;
	setp.eq.s32	%p114, %r278, 0;
	selp.f32	%f156, %f598, 0f3F800000, %p114;
	mul.rn.f32 	%f157, %f598, %f598;
	fma.rn.f32 	%f158, %f157, %f156, %f230;
	mov.f32 	%f599, 0fB94D4153;
	@%p114 bra 	BB4_156;

	mov.f32 	%f462, 0fBAB607ED;
	mov.f32 	%f463, 0f37CBAC00;
	fma.rn.f32 	%f599, %f463, %f157, %f462;

BB4_156:
	selp.f32	%f464, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f465, %f599, %f157, %f464;
	selp.f32	%f466, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f467, %f465, %f157, %f466;
	fma.rn.f32 	%f600, %f467, %f158, %f156;
	and.b32  	%r774, %r1011, 2;
	setp.eq.s32	%p116, %r774, 0;
	@%p116 bra 	BB4_158;

	mov.f32 	%f469, 0fBF800000;
	fma.rn.f32 	%f600, %f600, %f469, %f230;

BB4_158:
	and.b32  	%r775, %r1, 31;
	and.b32  	%r777, %r471, 1073741760;
	add.s32 	%r778, %r777, %r775;
	mul.f32 	%f470, %f138, %f600;
	mul.f32 	%f471, %f137, %f597;
	sub.f32 	%f472, %f471, %f470;
	mul.f32 	%f473, %f138, %f597;
	fma.rn.f32 	%f474, %f137, %f600, %f473;
	add.f32 	%f475, %f135, %f472;
	shl.b32 	%r779, %r778, 2;
	add.s32 	%r781, %r476, %r779;
	st.shared.f32 	[%r781], %f475;
	add.f32 	%f476, %f136, %f474;
	add.s32 	%r783, %r478, %r779;
	st.shared.f32 	[%r783], %f476;
	sub.f32 	%f477, %f135, %f472;
	st.shared.f32 	[%r781+128], %f477;
	sub.f32 	%f478, %f136, %f474;
	st.shared.f32 	[%r783+128], %f478;
	bar.sync 	0;
	ld.shared.f32 	%f164, [%r482];
	ld.shared.f32 	%f165, [%r484];
	ld.shared.f32 	%f166, [%r482+512];
	ld.shared.f32 	%f167, [%r484+512];
	shr.u32 	%r790, %r485, 26;
	add.s32 	%r791, %r1, %r790;
	and.b32  	%r792, %r791, 2147483584;
	sub.s32 	%r793, %r1, %r792;
	shl.b32 	%r794, %r793, 1;
	cvt.rn.f32.s32	%f479, %r794;
	mul.f32 	%f480, %f479, 0f3B800000;
	cvt.f64.f32	%fd31, %f480;
	mul.f64 	%fd32, %fd31, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f168, %fd32;
	mul.f32 	%f481, %f168, 0f3F22F983;
	cvt.rni.s32.f32	%r1027, %f481;
	cvt.rn.f32.s32	%f482, %r1027;
	fma.rn.f32 	%f484, %f482, %f225, %f168;
	fma.rn.f32 	%f486, %f482, %f227, %f484;
	fma.rn.f32 	%f604, %f482, %f229, %f486;
	abs.f32 	%f170, %f168;
	setp.leu.f32	%p117, %f170, 0f47CE4780;
	mov.u32 	%r1019, %r1027;
	mov.f32 	%f601, %f604;
	@%p117 bra 	BB4_169;

	setp.eq.f32	%p118, %f170, 0f7F800000;
	@%p118 bra 	BB4_168;
	bra.uni 	BB4_160;

BB4_168:
	mul.rn.f32 	%f601, %f168, %f230;
	mov.u32 	%r1019, %r1027;
	bra.uni 	BB4_169;

BB4_160:
	mov.b32 	 %r281, %f168;
	shl.b32 	%r797, %r281, 8;
	or.b32  	%r282, %r797, -2147483648;
	add.u64 	%rd171, %SP, 0;
	add.u64 	%rd228, %SPL, 0;
	mov.u32 	%r1013, 0;
	mov.u64 	%rd227, __cudart_i2opi_f;
	mov.u32 	%r1012, -6;

BB4_161:
	.pragma "nounroll";
	ld.const.u32 	%r800, [%rd227];
	// inline asm
	{
	mad.lo.cc.u32   %r798, %r800, %r282, %r1013;
	madc.hi.u32     %r1013, %r800, %r282,  0;
	}
	// inline asm
	st.local.u32 	[%rd228], %r798;
	add.s64 	%rd228, %rd228, 4;
	add.s64 	%rd227, %rd227, 4;
	add.s32 	%r1012, %r1012, 1;
	setp.ne.s32	%p119, %r1012, 0;
	@%p119 bra 	BB4_161;

	bfe.u32 	%r803, %r281, 23, 8;
	add.s32 	%r804, %r803, -128;
	shr.u32 	%r805, %r804, 5;
	and.b32  	%r287, %r281, -2147483648;
	cvta.to.local.u64 	%rd173, %rd171;
	st.local.u32 	[%rd173+24], %r1013;
	bfe.u32 	%r288, %r281, 23, 5;
	mov.u32 	%r806, 6;
	sub.s32 	%r807, %r806, %r805;
	mul.wide.s32 	%rd174, %r807, 4;
	add.s64 	%rd66, %rd173, %rd174;
	ld.local.u32 	%r1015, [%rd66];
	ld.local.u32 	%r1014, [%rd66+-4];
	setp.eq.s32	%p120, %r288, 0;
	@%p120 bra 	BB4_164;

	mov.u32 	%r808, 32;
	sub.s32 	%r809, %r808, %r288;
	shr.u32 	%r810, %r1014, %r809;
	shl.b32 	%r811, %r1015, %r288;
	add.s32 	%r1015, %r810, %r811;
	ld.local.u32 	%r812, [%rd66+-8];
	shr.u32 	%r813, %r812, %r809;
	shl.b32 	%r814, %r1014, %r288;
	add.s32 	%r1014, %r813, %r814;

BB4_164:
	shr.u32 	%r815, %r1014, 30;
	shl.b32 	%r816, %r1015, 2;
	add.s32 	%r1017, %r816, %r815;
	shl.b32 	%r296, %r1014, 2;
	shr.u32 	%r817, %r1017, 31;
	shr.u32 	%r818, %r1015, 30;
	add.s32 	%r297, %r817, %r818;
	setp.eq.s32	%p121, %r817, 0;
	@%p121 bra 	BB4_165;

	not.b32 	%r819, %r1017;
	neg.s32 	%r1016, %r296;
	setp.eq.s32	%p122, %r296, 0;
	selp.u32	%r820, 1, 0, %p122;
	add.s32 	%r1017, %r820, %r819;
	xor.b32  	%r1018, %r287, -2147483648;
	bra.uni 	BB4_167;

BB4_165:
	mov.u32 	%r1016, %r296;
	mov.u32 	%r1018, %r287;

BB4_167:
	cvt.u64.u32	%rd175, %r1017;
	cvt.u64.u32	%rd176, %r1016;
	bfi.b64 	%rd177, %rd175, %rd176, 32, 32;
	cvt.rn.f64.s64	%fd33, %rd177;
	mul.f64 	%fd34, %fd33, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f488, %fd34;
	neg.f32 	%f489, %f488;
	setp.eq.s32	%p123, %r1018, 0;
	selp.f32	%f601, %f488, %f489, %p123;
	setp.eq.s32	%p124, %r287, 0;
	neg.s32 	%r821, %r297;
	selp.b32	%r1019, %r297, %r821, %p124;

BB4_169:
	add.s32 	%r306, %r1019, 1;
	and.b32  	%r307, %r306, 1;
	setp.eq.s32	%p125, %r307, 0;
	selp.f32	%f174, %f601, 0f3F800000, %p125;
	mul.rn.f32 	%f175, %f601, %f601;
	fma.rn.f32 	%f176, %f175, %f174, %f230;
	mov.f32 	%f602, 0fB94D4153;
	@%p125 bra 	BB4_171;

	mov.f32 	%f493, 0fBAB607ED;
	mov.f32 	%f494, 0f37CBAC00;
	fma.rn.f32 	%f602, %f494, %f175, %f493;

BB4_171:
	selp.f32	%f495, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f496, %f602, %f175, %f495;
	selp.f32	%f497, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f498, %f496, %f175, %f497;
	fma.rn.f32 	%f603, %f498, %f176, %f174;
	and.b32  	%r822, %r306, 2;
	setp.eq.s32	%p127, %r822, 0;
	@%p127 bra 	BB4_173;

	mov.f32 	%f500, 0fBF800000;
	fma.rn.f32 	%f603, %f603, %f500, %f230;

BB4_173:
	@%p117 bra 	BB4_184;

	setp.eq.f32	%p129, %f170, 0f7F800000;
	@%p129 bra 	BB4_183;
	bra.uni 	BB4_175;

BB4_183:
	mul.rn.f32 	%f604, %f168, %f230;
	bra.uni 	BB4_184;

BB4_175:
	mov.b32 	 %r308, %f168;
	shl.b32 	%r825, %r308, 8;
	or.b32  	%r309, %r825, -2147483648;
	add.u64 	%rd179, %SP, 0;
	add.u64 	%rd230, %SPL, 0;
	mov.u32 	%r1021, 0;
	mov.u64 	%rd229, __cudart_i2opi_f;
	mov.u32 	%r1020, -6;

BB4_176:
	.pragma "nounroll";
	ld.const.u32 	%r828, [%rd229];
	// inline asm
	{
	mad.lo.cc.u32   %r826, %r828, %r309, %r1021;
	madc.hi.u32     %r1021, %r828, %r309,  0;
	}
	// inline asm
	st.local.u32 	[%rd230], %r826;
	add.s64 	%rd230, %rd230, 4;
	add.s64 	%rd229, %rd229, 4;
	add.s32 	%r1020, %r1020, 1;
	setp.ne.s32	%p130, %r1020, 0;
	@%p130 bra 	BB4_176;

	bfe.u32 	%r831, %r308, 23, 8;
	add.s32 	%r832, %r831, -128;
	shr.u32 	%r833, %r832, 5;
	and.b32  	%r314, %r308, -2147483648;
	cvta.to.local.u64 	%rd181, %rd179;
	st.local.u32 	[%rd181+24], %r1021;
	bfe.u32 	%r315, %r308, 23, 5;
	mov.u32 	%r834, 6;
	sub.s32 	%r835, %r834, %r833;
	mul.wide.s32 	%rd182, %r835, 4;
	add.s64 	%rd72, %rd181, %rd182;
	ld.local.u32 	%r1023, [%rd72];
	ld.local.u32 	%r1022, [%rd72+-4];
	setp.eq.s32	%p131, %r315, 0;
	@%p131 bra 	BB4_179;

	mov.u32 	%r836, 32;
	sub.s32 	%r837, %r836, %r315;
	shr.u32 	%r838, %r1022, %r837;
	shl.b32 	%r839, %r1023, %r315;
	add.s32 	%r1023, %r838, %r839;
	ld.local.u32 	%r840, [%rd72+-8];
	shr.u32 	%r841, %r840, %r837;
	shl.b32 	%r842, %r1022, %r315;
	add.s32 	%r1022, %r841, %r842;

BB4_179:
	shr.u32 	%r843, %r1022, 30;
	shl.b32 	%r844, %r1023, 2;
	add.s32 	%r1025, %r844, %r843;
	shl.b32 	%r323, %r1022, 2;
	shr.u32 	%r845, %r1025, 31;
	shr.u32 	%r846, %r1023, 30;
	add.s32 	%r324, %r845, %r846;
	setp.eq.s32	%p132, %r845, 0;
	@%p132 bra 	BB4_180;

	not.b32 	%r847, %r1025;
	neg.s32 	%r1024, %r323;
	setp.eq.s32	%p133, %r323, 0;
	selp.u32	%r848, 1, 0, %p133;
	add.s32 	%r1025, %r848, %r847;
	xor.b32  	%r1026, %r314, -2147483648;
	bra.uni 	BB4_182;

BB4_180:
	mov.u32 	%r1024, %r323;
	mov.u32 	%r1026, %r314;

BB4_182:
	cvt.u64.u32	%rd183, %r1025;
	cvt.u64.u32	%rd184, %r1024;
	bfi.b64 	%rd185, %rd183, %rd184, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd185;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f501, %fd36;
	neg.f32 	%f502, %f501;
	setp.eq.s32	%p134, %r1026, 0;
	selp.f32	%f604, %f501, %f502, %p134;
	setp.eq.s32	%p135, %r314, 0;
	neg.s32 	%r849, %r324;
	selp.b32	%r1027, %r324, %r849, %p135;

BB4_184:
	and.b32  	%r333, %r1027, 1;
	setp.eq.s32	%p136, %r333, 0;
	selp.f32	%f185, %f604, 0f3F800000, %p136;
	mul.rn.f32 	%f186, %f604, %f604;
	fma.rn.f32 	%f187, %f186, %f185, %f230;
	mov.f32 	%f605, 0fB94D4153;
	@%p136 bra 	BB4_186;

	mov.f32 	%f506, 0fBAB607ED;
	mov.f32 	%f507, 0f37CBAC00;
	fma.rn.f32 	%f605, %f507, %f186, %f506;

BB4_186:
	selp.f32	%f508, 0f3C0885E4, 0f3D2AAABB, %p136;
	fma.rn.f32 	%f509, %f605, %f186, %f508;
	selp.f32	%f510, 0fBE2AAAA8, 0fBEFFFFFF, %p136;
	fma.rn.f32 	%f511, %f509, %f186, %f510;
	fma.rn.f32 	%f606, %f511, %f187, %f185;
	and.b32  	%r850, %r1027, 2;
	setp.eq.s32	%p138, %r850, 0;
	@%p138 bra 	BB4_188;

	mov.f32 	%f513, 0fBF800000;
	fma.rn.f32 	%f606, %f606, %f513, %f230;

BB4_188:
	and.b32  	%r851, %r1, 63;
	and.b32  	%r853, %r471, 1073741696;
	add.s32 	%r854, %r853, %r851;
	mul.f32 	%f514, %f167, %f606;
	mul.f32 	%f515, %f166, %f603;
	sub.f32 	%f516, %f515, %f514;
	mul.f32 	%f517, %f167, %f603;
	fma.rn.f32 	%f518, %f166, %f606, %f517;
	add.f32 	%f519, %f164, %f516;
	shl.b32 	%r855, %r854, 2;
	add.s32 	%r857, %r399, %r855;
	st.shared.f32 	[%r857], %f519;
	add.f32 	%f520, %f165, %f518;
	add.s32 	%r859, %r401, %r855;
	st.shared.f32 	[%r859], %f520;
	sub.f32 	%f521, %f164, %f516;
	st.shared.f32 	[%r857+256], %f521;
	sub.f32 	%f522, %f165, %f518;
	st.shared.f32 	[%r859+256], %f522;
	bar.sync 	0;
	ld.shared.f32 	%f193, [%r405];
	ld.shared.f32 	%f194, [%r407];
	ld.shared.f32 	%f195, [%r405+512];
	ld.shared.f32 	%f196, [%r407+512];
	shr.u32 	%r866, %r485, 25;
	add.s32 	%r867, %r1, %r866;
	and.b32  	%r868, %r867, -128;
	sub.s32 	%r869, %r1, %r868;
	cvt.rn.f32.s32	%f523, %r869;
	mul.f32 	%f524, %f523, 0f3B800000;
	cvt.f64.f32	%fd37, %f524;
	mul.f64 	%fd38, %fd37, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f197, %fd38;
	mul.f32 	%f525, %f197, 0f3F22F983;
	cvt.rni.s32.f32	%r1043, %f525;
	cvt.rn.f32.s32	%f526, %r1043;
	fma.rn.f32 	%f528, %f526, %f225, %f197;
	fma.rn.f32 	%f530, %f526, %f227, %f528;
	fma.rn.f32 	%f610, %f526, %f229, %f530;
	abs.f32 	%f199, %f197;
	setp.leu.f32	%p139, %f199, 0f47CE4780;
	mov.u32 	%r1035, %r1043;
	mov.f32 	%f607, %f610;
	@%p139 bra 	BB4_199;

	setp.eq.f32	%p140, %f199, 0f7F800000;
	@%p140 bra 	BB4_198;
	bra.uni 	BB4_190;

BB4_198:
	mul.rn.f32 	%f607, %f197, %f230;
	mov.u32 	%r1035, %r1043;
	bra.uni 	BB4_199;

BB4_190:
	mov.b32 	 %r336, %f197;
	shl.b32 	%r872, %r336, 8;
	or.b32  	%r337, %r872, -2147483648;
	add.u64 	%rd187, %SP, 0;
	add.u64 	%rd232, %SPL, 0;
	mov.u32 	%r1029, 0;
	mov.u64 	%rd231, __cudart_i2opi_f;
	mov.u32 	%r1028, -6;

BB4_191:
	.pragma "nounroll";
	ld.const.u32 	%r875, [%rd231];
	// inline asm
	{
	mad.lo.cc.u32   %r873, %r875, %r337, %r1029;
	madc.hi.u32     %r1029, %r875, %r337,  0;
	}
	// inline asm
	st.local.u32 	[%rd232], %r873;
	add.s64 	%rd232, %rd232, 4;
	add.s64 	%rd231, %rd231, 4;
	add.s32 	%r1028, %r1028, 1;
	setp.ne.s32	%p141, %r1028, 0;
	@%p141 bra 	BB4_191;

	bfe.u32 	%r878, %r336, 23, 8;
	add.s32 	%r879, %r878, -128;
	shr.u32 	%r880, %r879, 5;
	and.b32  	%r342, %r336, -2147483648;
	cvta.to.local.u64 	%rd189, %rd187;
	st.local.u32 	[%rd189+24], %r1029;
	bfe.u32 	%r343, %r336, 23, 5;
	mov.u32 	%r881, 6;
	sub.s32 	%r882, %r881, %r880;
	mul.wide.s32 	%rd190, %r882, 4;
	add.s64 	%rd78, %rd189, %rd190;
	ld.local.u32 	%r1031, [%rd78];
	ld.local.u32 	%r1030, [%rd78+-4];
	setp.eq.s32	%p142, %r343, 0;
	@%p142 bra 	BB4_194;

	mov.u32 	%r883, 32;
	sub.s32 	%r884, %r883, %r343;
	shr.u32 	%r885, %r1030, %r884;
	shl.b32 	%r886, %r1031, %r343;
	add.s32 	%r1031, %r885, %r886;
	ld.local.u32 	%r887, [%rd78+-8];
	shr.u32 	%r888, %r887, %r884;
	shl.b32 	%r889, %r1030, %r343;
	add.s32 	%r1030, %r888, %r889;

BB4_194:
	shr.u32 	%r890, %r1030, 30;
	shl.b32 	%r891, %r1031, 2;
	add.s32 	%r1033, %r891, %r890;
	shl.b32 	%r351, %r1030, 2;
	shr.u32 	%r892, %r1033, 31;
	shr.u32 	%r893, %r1031, 30;
	add.s32 	%r352, %r892, %r893;
	setp.eq.s32	%p143, %r892, 0;
	@%p143 bra 	BB4_195;

	not.b32 	%r894, %r1033;
	neg.s32 	%r1032, %r351;
	setp.eq.s32	%p144, %r351, 0;
	selp.u32	%r895, 1, 0, %p144;
	add.s32 	%r1033, %r895, %r894;
	xor.b32  	%r1034, %r342, -2147483648;
	bra.uni 	BB4_197;

BB4_195:
	mov.u32 	%r1032, %r351;
	mov.u32 	%r1034, %r342;

BB4_197:
	cvt.u64.u32	%rd191, %r1033;
	cvt.u64.u32	%rd192, %r1032;
	bfi.b64 	%rd193, %rd191, %rd192, 32, 32;
	cvt.rn.f64.s64	%fd39, %rd193;
	mul.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f532, %fd40;
	neg.f32 	%f533, %f532;
	setp.eq.s32	%p145, %r1034, 0;
	selp.f32	%f607, %f532, %f533, %p145;
	setp.eq.s32	%p146, %r342, 0;
	neg.s32 	%r896, %r352;
	selp.b32	%r1035, %r352, %r896, %p146;

BB4_199:
	add.s32 	%r361, %r1035, 1;
	and.b32  	%r362, %r361, 1;
	setp.eq.s32	%p147, %r362, 0;
	selp.f32	%f203, %f607, 0f3F800000, %p147;
	mul.rn.f32 	%f204, %f607, %f607;
	fma.rn.f32 	%f205, %f204, %f203, %f230;
	mov.f32 	%f608, 0fB94D4153;
	@%p147 bra 	BB4_201;

	mov.f32 	%f537, 0fBAB607ED;
	mov.f32 	%f538, 0f37CBAC00;
	fma.rn.f32 	%f608, %f538, %f204, %f537;

BB4_201:
	selp.f32	%f539, 0f3C0885E4, 0f3D2AAABB, %p147;
	fma.rn.f32 	%f540, %f608, %f204, %f539;
	selp.f32	%f541, 0fBE2AAAA8, 0fBEFFFFFF, %p147;
	fma.rn.f32 	%f542, %f540, %f204, %f541;
	fma.rn.f32 	%f609, %f542, %f205, %f203;
	and.b32  	%r897, %r361, 2;
	setp.eq.s32	%p149, %r897, 0;
	@%p149 bra 	BB4_203;

	mov.f32 	%f544, 0fBF800000;
	fma.rn.f32 	%f609, %f609, %f544, %f230;

BB4_203:
	@%p139 bra 	BB4_214;

	setp.eq.f32	%p151, %f199, 0f7F800000;
	@%p151 bra 	BB4_213;
	bra.uni 	BB4_205;

BB4_213:
	mul.rn.f32 	%f610, %f197, %f230;
	bra.uni 	BB4_214;

BB4_205:
	mov.b32 	 %r363, %f197;
	shl.b32 	%r900, %r363, 8;
	or.b32  	%r364, %r900, -2147483648;
	add.u64 	%rd195, %SP, 0;
	add.u64 	%rd234, %SPL, 0;
	mov.u32 	%r1037, 0;
	mov.u64 	%rd233, __cudart_i2opi_f;
	mov.u32 	%r1036, -6;

BB4_206:
	.pragma "nounroll";
	ld.const.u32 	%r903, [%rd233];
	// inline asm
	{
	mad.lo.cc.u32   %r901, %r903, %r364, %r1037;
	madc.hi.u32     %r1037, %r903, %r364,  0;
	}
	// inline asm
	st.local.u32 	[%rd234], %r901;
	add.s64 	%rd234, %rd234, 4;
	add.s64 	%rd233, %rd233, 4;
	add.s32 	%r1036, %r1036, 1;
	setp.ne.s32	%p152, %r1036, 0;
	@%p152 bra 	BB4_206;

	bfe.u32 	%r906, %r363, 23, 8;
	add.s32 	%r907, %r906, -128;
	shr.u32 	%r908, %r907, 5;
	and.b32  	%r369, %r363, -2147483648;
	cvta.to.local.u64 	%rd197, %rd195;
	st.local.u32 	[%rd197+24], %r1037;
	bfe.u32 	%r370, %r363, 23, 5;
	mov.u32 	%r909, 6;
	sub.s32 	%r910, %r909, %r908;
	mul.wide.s32 	%rd198, %r910, 4;
	add.s64 	%rd84, %rd197, %rd198;
	ld.local.u32 	%r1039, [%rd84];
	ld.local.u32 	%r1038, [%rd84+-4];
	setp.eq.s32	%p153, %r370, 0;
	@%p153 bra 	BB4_209;

	mov.u32 	%r911, 32;
	sub.s32 	%r912, %r911, %r370;
	shr.u32 	%r913, %r1038, %r912;
	shl.b32 	%r914, %r1039, %r370;
	add.s32 	%r1039, %r913, %r914;
	ld.local.u32 	%r915, [%rd84+-8];
	shr.u32 	%r916, %r915, %r912;
	shl.b32 	%r917, %r1038, %r370;
	add.s32 	%r1038, %r916, %r917;

BB4_209:
	shr.u32 	%r918, %r1038, 30;
	shl.b32 	%r919, %r1039, 2;
	add.s32 	%r1041, %r919, %r918;
	shl.b32 	%r378, %r1038, 2;
	shr.u32 	%r920, %r1041, 31;
	shr.u32 	%r921, %r1039, 30;
	add.s32 	%r379, %r920, %r921;
	setp.eq.s32	%p154, %r920, 0;
	@%p154 bra 	BB4_210;

	not.b32 	%r922, %r1041;
	neg.s32 	%r1040, %r378;
	setp.eq.s32	%p155, %r378, 0;
	selp.u32	%r923, 1, 0, %p155;
	add.s32 	%r1041, %r923, %r922;
	xor.b32  	%r1042, %r369, -2147483648;
	bra.uni 	BB4_212;

BB4_210:
	mov.u32 	%r1040, %r378;
	mov.u32 	%r1042, %r369;

BB4_212:
	cvt.u64.u32	%rd199, %r1041;
	cvt.u64.u32	%rd200, %r1040;
	bfi.b64 	%rd201, %rd199, %rd200, 32, 32;
	cvt.rn.f64.s64	%fd41, %rd201;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f545, %fd42;
	neg.f32 	%f546, %f545;
	setp.eq.s32	%p156, %r1042, 0;
	selp.f32	%f610, %f545, %f546, %p156;
	setp.eq.s32	%p157, %r369, 0;
	neg.s32 	%r924, %r379;
	selp.b32	%r1043, %r379, %r924, %p157;

BB4_214:
	and.b32  	%r388, %r1043, 1;
	setp.eq.s32	%p158, %r388, 0;
	selp.f32	%f214, %f610, 0f3F800000, %p158;
	mul.rn.f32 	%f215, %f610, %f610;
	fma.rn.f32 	%f216, %f215, %f214, %f230;
	mov.f32 	%f611, 0fB94D4153;
	@%p158 bra 	BB4_216;

	mov.f32 	%f550, 0fBAB607ED;
	mov.f32 	%f551, 0f37CBAC00;
	fma.rn.f32 	%f611, %f551, %f215, %f550;

BB4_216:
	selp.f32	%f552, 0f3C0885E4, 0f3D2AAABB, %p158;
	fma.rn.f32 	%f553, %f611, %f215, %f552;
	selp.f32	%f554, 0fBE2AAAA8, 0fBEFFFFFF, %p158;
	fma.rn.f32 	%f555, %f553, %f215, %f554;
	fma.rn.f32 	%f612, %f555, %f216, %f214;
	and.b32  	%r925, %r1043, 2;
	setp.eq.s32	%p160, %r925, 0;
	@%p160 bra 	BB4_218;

	mov.f32 	%f557, 0fBF800000;
	fma.rn.f32 	%f612, %f612, %f557, %f230;

BB4_218:
	mul.f32 	%f558, %f196, %f612;
	mul.f32 	%f559, %f195, %f609;
	sub.f32 	%f560, %f559, %f558;
	mul.f32 	%f561, %f196, %f609;
	fma.rn.f32 	%f562, %f195, %f612, %f561;
	add.f32 	%f563, %f193, %f560;
	add.s32 	%r931, %r394, %r1;
	mul.wide.u32 	%rd203, %r931, 4;
	add.s64 	%rd204, %rd87, %rd203;
	st.global.f32 	[%rd204], %f563;
	add.f32 	%f564, %f194, %f562;
	cvta.to.global.u64 	%rd205, %rd86;
	add.s64 	%rd206, %rd205, %rd203;
	st.global.f32 	[%rd206], %f564;
	sub.f32 	%f565, %f193, %f560;
	st.global.f32 	[%rd204+512], %f565;
	sub.f32 	%f566, %f194, %f562;
	st.global.f32 	[%rd206+512], %f566;
	ret;
}

	// .globl	_occa_Stockhoptimized9_0
.visible .entry _occa_Stockhoptimized9_0(
	.param .u64 _occa_Stockhoptimized9_0_param_0,
	.param .u64 _occa_Stockhoptimized9_0_param_1,
	.param .u32 _occa_Stockhoptimized9_0_param_2
)
.maxntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot5[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<183>;
	.reg .f32 	%f<692>;
	.reg .b32 	%r<1191>;
	.reg .f64 	%fd<49>;
	.reg .b64 	%rd<267>;
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized9_0E6FRBank[2048];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized9_0E6FIBank[2048];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized9_0E6SRBank[2048];
	// demoted variable
	.shared .align 4 .b8 _ZZ24_occa_Stockhoptimized9_0E6SIBank[2048];

	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd97, [_occa_Stockhoptimized9_0_param_0];
	ld.param.u64 	%rd98, [_occa_Stockhoptimized9_0_param_1];
	mov.u32 	%r444, %ctaid.x;
	shl.b32 	%r445, %r444, 8;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r446, %r445, %r1;
	and.b32  	%r447, %r446, 255;
	shl.b32 	%r448, %r446, 1;
	and.b32  	%r449, %r448, -512;
	add.s32 	%r450, %r449, %r447;
	cvta.to.global.u64 	%rd99, %rd97;
	mul.wide.u32 	%rd100, %r450, 4;
	add.s64 	%rd101, %rd99, %rd100;
	ld.global.f32 	%f1, [%rd101];
	ld.global.f32 	%f2, [%rd101+1024];
	mov.f32 	%f252, 0f80000000;
	cvt.rni.s32.f32	%r2, %f252;
	cvt.rn.f32.s32	%f253, %r2;
	mov.f32 	%f254, 0fBFC90FDA;
	fma.rn.f32 	%f255, %f253, %f254, %f252;
	mov.f32 	%f256, 0fB3A22168;
	fma.rn.f32 	%f257, %f253, %f256, %f255;
	mov.f32 	%f258, 0fA7C234C5;
	fma.rn.f32 	%f3, %f253, %f258, %f257;
	add.s32 	%r3, %r2, 1;
	mul.rn.f32 	%f4, %f3, %f3;
	and.b32  	%r4, %r3, 1;
	setp.eq.s32	%p1, %r4, 0;
	selp.f32	%f5, %f3, 0f3F800000, %p1;
	mov.f32 	%f259, 0f00000000;
	fma.rn.f32 	%f6, %f4, %f5, %f259;
	mov.f32 	%f640, 0fB94D4153;
	@%p1 bra 	BB5_2;

	mov.f32 	%f260, 0fBAB607ED;
	mov.f32 	%f261, 0f37CBAC00;
	fma.rn.f32 	%f640, %f261, %f4, %f260;

BB5_2:
	selp.f32	%f262, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f263, %f640, %f4, %f262;
	selp.f32	%f264, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f265, %f263, %f4, %f264;
	fma.rn.f32 	%f641, %f265, %f6, %f5;
	and.b32  	%r451, %r3, 2;
	setp.eq.s32	%p3, %r451, 0;
	@%p3 bra 	BB5_4;

	mov.f32 	%f267, 0fBF800000;
	fma.rn.f32 	%f641, %f641, %f267, %f259;

BB5_4:
	and.b32  	%r5, %r2, 1;
	setp.eq.s32	%p4, %r5, 0;
	selp.f32	%f12, %f3, 0f3F800000, %p4;
	fma.rn.f32 	%f13, %f4, %f12, %f259;
	mov.f32 	%f642, 0fB94D4153;
	@%p4 bra 	BB5_6;

	mov.f32 	%f270, 0fBAB607ED;
	mov.f32 	%f271, 0f37CBAC00;
	fma.rn.f32 	%f642, %f271, %f4, %f270;

BB5_6:
	selp.f32	%f272, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f273, %f642, %f4, %f272;
	selp.f32	%f274, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f275, %f273, %f4, %f274;
	fma.rn.f32 	%f643, %f275, %f13, %f12;
	and.b32  	%r452, %r2, 2;
	setp.eq.s32	%p6, %r452, 0;
	@%p6 bra 	BB5_8;

	mov.f32 	%f277, 0fBF800000;
	fma.rn.f32 	%f643, %f643, %f277, %f259;

BB5_8:
	mul.f32 	%f278, %f643, 0f00000000;
	mul.f32 	%f279, %f2, %f641;
	sub.f32 	%f280, %f279, %f278;
	mul.f32 	%f281, %f641, 0f00000000;
	fma.rn.f32 	%f282, %f2, %f643, %f281;
	add.f32 	%f283, %f1, %f280;
	shl.b32 	%r453, %r1, 3;
	mov.u32 	%r454, _ZZ24_occa_Stockhoptimized9_0E6FRBank;
	add.s32 	%r455, %r454, %r453;
	st.shared.f32 	[%r455], %f283;
	add.f32 	%f284, %f282, 0f00000000;
	mov.u32 	%r456, _ZZ24_occa_Stockhoptimized9_0E6FIBank;
	add.s32 	%r457, %r456, %r453;
	st.shared.f32 	[%r457], %f284;
	sub.f32 	%f285, %f1, %f280;
	st.shared.f32 	[%r455+4], %f285;
	sub.f32 	%f287, %f259, %f282;
	st.shared.f32 	[%r457+4], %f287;
	bar.sync 	0;
	shl.b32 	%r458, %r1, 2;
	add.s32 	%r460, %r454, %r458;
	ld.shared.f32 	%f19, [%r460];
	add.s32 	%r462, %r456, %r458;
	ld.shared.f32 	%f20, [%r462];
	ld.shared.f32 	%f21, [%r460+1024];
	ld.shared.f32 	%f22, [%r462+1024];
	shr.u32 	%r463, %r1, 31;
	add.s32 	%r464, %r1, %r463;
	and.b32  	%r465, %r464, 33554430;
	sub.s32 	%r466, %r1, %r465;
	shl.b32 	%r467, %r466, 7;
	cvt.rn.f32.s32	%f288, %r467;
	mul.f32 	%f289, %f288, 0f3B000000;
	cvt.f64.f32	%fd1, %f289;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f23, %fd2;
	mul.f32 	%f290, %f23, 0f3F22F983;
	cvt.rni.s32.f32	%r1078, %f290;
	cvt.rn.f32.s32	%f291, %r1078;
	fma.rn.f32 	%f293, %f291, %f254, %f23;
	fma.rn.f32 	%f295, %f291, %f256, %f293;
	fma.rn.f32 	%f647, %f291, %f258, %f295;
	abs.f32 	%f25, %f23;
	setp.leu.f32	%p7, %f25, 0f47CE4780;
	mov.u32 	%r1070, %r1078;
	mov.f32 	%f644, %f647;
	@%p7 bra 	BB5_19;

	setp.eq.f32	%p8, %f25, 0f7F800000;
	@%p8 bra 	BB5_18;
	bra.uni 	BB5_10;

BB5_18:
	mul.rn.f32 	%f644, %f23, %f259;
	mov.u32 	%r1070, %r1078;
	bra.uni 	BB5_19;

BB5_10:
	mov.b32 	 %r470, %f23;
	shl.b32 	%r471, %r470, 8;
	or.b32  	%r7, %r471, -2147483648;
	add.u64 	%rd103, %SP, 0;
	add.u64 	%rd236, %SPL, 0;
	mov.u32 	%r1064, 0;
	mov.u64 	%rd235, __cudart_i2opi_f;
	mov.u32 	%r1063, -6;

BB5_11:
	.pragma "nounroll";
	ld.const.u32 	%r474, [%rd235];
	// inline asm
	{
	mad.lo.cc.u32   %r472, %r474, %r7, %r1064;
	madc.hi.u32     %r1064, %r474, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd236], %r472;
	add.s64 	%rd236, %rd236, 4;
	add.s64 	%rd235, %rd235, 4;
	add.s32 	%r1063, %r1063, 1;
	setp.ne.s32	%p9, %r1063, 0;
	@%p9 bra 	BB5_11;

	bfe.u32 	%r478, %r470, 23, 8;
	add.s32 	%r479, %r478, -128;
	shr.u32 	%r480, %r479, 5;
	and.b32  	%r12, %r470, -2147483648;
	cvta.to.local.u64 	%rd105, %rd103;
	st.local.u32 	[%rd105+24], %r1064;
	bfe.u32 	%r13, %r470, 23, 5;
	mov.u32 	%r481, 6;
	sub.s32 	%r482, %r481, %r480;
	mul.wide.s32 	%rd106, %r482, 4;
	add.s64 	%rd6, %rd105, %rd106;
	ld.local.u32 	%r1066, [%rd6];
	ld.local.u32 	%r1065, [%rd6+-4];
	setp.eq.s32	%p10, %r13, 0;
	@%p10 bra 	BB5_14;

	mov.u32 	%r483, 32;
	sub.s32 	%r484, %r483, %r13;
	shr.u32 	%r485, %r1065, %r484;
	shl.b32 	%r486, %r1066, %r13;
	add.s32 	%r1066, %r485, %r486;
	ld.local.u32 	%r487, [%rd6+-8];
	shr.u32 	%r488, %r487, %r484;
	shl.b32 	%r489, %r1065, %r13;
	add.s32 	%r1065, %r488, %r489;

BB5_14:
	shr.u32 	%r490, %r1065, 30;
	shl.b32 	%r491, %r1066, 2;
	add.s32 	%r1068, %r491, %r490;
	shl.b32 	%r21, %r1065, 2;
	shr.u32 	%r492, %r1068, 31;
	shr.u32 	%r493, %r1066, 30;
	add.s32 	%r22, %r492, %r493;
	setp.eq.s32	%p11, %r492, 0;
	@%p11 bra 	BB5_15;

	not.b32 	%r494, %r1068;
	neg.s32 	%r1067, %r21;
	setp.eq.s32	%p12, %r21, 0;
	selp.u32	%r495, 1, 0, %p12;
	add.s32 	%r1068, %r495, %r494;
	xor.b32  	%r1069, %r12, -2147483648;
	bra.uni 	BB5_17;

BB5_15:
	mov.u32 	%r1067, %r21;
	mov.u32 	%r1069, %r12;

BB5_17:
	cvt.u64.u32	%rd107, %r1068;
	cvt.u64.u32	%rd108, %r1067;
	bfi.b64 	%rd109, %rd107, %rd108, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd109;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f297, %fd4;
	neg.f32 	%f298, %f297;
	setp.eq.s32	%p13, %r1069, 0;
	selp.f32	%f644, %f297, %f298, %p13;
	setp.eq.s32	%p14, %r12, 0;
	neg.s32 	%r496, %r22;
	selp.b32	%r1070, %r22, %r496, %p14;

BB5_19:
	add.s32 	%r31, %r1070, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p15, %r32, 0;
	selp.f32	%f29, %f644, 0f3F800000, %p15;
	mul.rn.f32 	%f30, %f644, %f644;
	fma.rn.f32 	%f31, %f30, %f29, %f259;
	mov.f32 	%f645, 0fB94D4153;
	@%p15 bra 	BB5_21;

	mov.f32 	%f302, 0fBAB607ED;
	mov.f32 	%f303, 0f37CBAC00;
	fma.rn.f32 	%f645, %f303, %f30, %f302;

BB5_21:
	selp.f32	%f304, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f305, %f645, %f30, %f304;
	selp.f32	%f306, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f307, %f305, %f30, %f306;
	fma.rn.f32 	%f646, %f307, %f31, %f29;
	and.b32  	%r497, %r31, 2;
	setp.eq.s32	%p17, %r497, 0;
	@%p17 bra 	BB5_23;

	mov.f32 	%f309, 0fBF800000;
	fma.rn.f32 	%f646, %f646, %f309, %f259;

BB5_23:
	@%p7 bra 	BB5_34;

	setp.eq.f32	%p19, %f25, 0f7F800000;
	@%p19 bra 	BB5_33;
	bra.uni 	BB5_25;

BB5_33:
	mul.rn.f32 	%f647, %f23, %f259;
	bra.uni 	BB5_34;

BB5_25:
	mov.b32 	 %r33, %f23;
	shl.b32 	%r500, %r33, 8;
	or.b32  	%r34, %r500, -2147483648;
	add.u64 	%rd111, %SP, 0;
	add.u64 	%rd238, %SPL, 0;
	mov.u32 	%r1072, 0;
	mov.u64 	%rd237, __cudart_i2opi_f;
	mov.u32 	%r1071, -6;

BB5_26:
	.pragma "nounroll";
	ld.const.u32 	%r503, [%rd237];
	// inline asm
	{
	mad.lo.cc.u32   %r501, %r503, %r34, %r1072;
	madc.hi.u32     %r1072, %r503, %r34,  0;
	}
	// inline asm
	st.local.u32 	[%rd238], %r501;
	add.s64 	%rd238, %rd238, 4;
	add.s64 	%rd237, %rd237, 4;
	add.s32 	%r1071, %r1071, 1;
	setp.ne.s32	%p20, %r1071, 0;
	@%p20 bra 	BB5_26;

	bfe.u32 	%r506, %r33, 23, 8;
	add.s32 	%r507, %r506, -128;
	shr.u32 	%r508, %r507, 5;
	and.b32  	%r39, %r33, -2147483648;
	cvta.to.local.u64 	%rd113, %rd111;
	st.local.u32 	[%rd113+24], %r1072;
	bfe.u32 	%r40, %r33, 23, 5;
	mov.u32 	%r509, 6;
	sub.s32 	%r510, %r509, %r508;
	mul.wide.s32 	%rd114, %r510, 4;
	add.s64 	%rd12, %rd113, %rd114;
	ld.local.u32 	%r1074, [%rd12];
	ld.local.u32 	%r1073, [%rd12+-4];
	setp.eq.s32	%p21, %r40, 0;
	@%p21 bra 	BB5_29;

	mov.u32 	%r511, 32;
	sub.s32 	%r512, %r511, %r40;
	shr.u32 	%r513, %r1073, %r512;
	shl.b32 	%r514, %r1074, %r40;
	add.s32 	%r1074, %r513, %r514;
	ld.local.u32 	%r515, [%rd12+-8];
	shr.u32 	%r516, %r515, %r512;
	shl.b32 	%r517, %r1073, %r40;
	add.s32 	%r1073, %r516, %r517;

BB5_29:
	shr.u32 	%r518, %r1073, 30;
	shl.b32 	%r519, %r1074, 2;
	add.s32 	%r1076, %r519, %r518;
	shl.b32 	%r48, %r1073, 2;
	shr.u32 	%r520, %r1076, 31;
	shr.u32 	%r521, %r1074, 30;
	add.s32 	%r49, %r520, %r521;
	setp.eq.s32	%p22, %r520, 0;
	@%p22 bra 	BB5_30;

	not.b32 	%r522, %r1076;
	neg.s32 	%r1075, %r48;
	setp.eq.s32	%p23, %r48, 0;
	selp.u32	%r523, 1, 0, %p23;
	add.s32 	%r1076, %r523, %r522;
	xor.b32  	%r1077, %r39, -2147483648;
	bra.uni 	BB5_32;

BB5_30:
	mov.u32 	%r1075, %r48;
	mov.u32 	%r1077, %r39;

BB5_32:
	cvt.u64.u32	%rd115, %r1076;
	cvt.u64.u32	%rd116, %r1075;
	bfi.b64 	%rd117, %rd115, %rd116, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd117;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f310, %fd6;
	neg.f32 	%f311, %f310;
	setp.eq.s32	%p24, %r1077, 0;
	selp.f32	%f647, %f310, %f311, %p24;
	setp.eq.s32	%p25, %r39, 0;
	neg.s32 	%r524, %r49;
	selp.b32	%r1078, %r49, %r524, %p25;

BB5_34:
	and.b32  	%r58, %r1078, 1;
	setp.eq.s32	%p26, %r58, 0;
	selp.f32	%f40, %f647, 0f3F800000, %p26;
	mul.rn.f32 	%f41, %f647, %f647;
	fma.rn.f32 	%f42, %f41, %f40, %f259;
	mov.f32 	%f648, 0fB94D4153;
	@%p26 bra 	BB5_36;

	mov.f32 	%f315, 0fBAB607ED;
	mov.f32 	%f316, 0f37CBAC00;
	fma.rn.f32 	%f648, %f316, %f41, %f315;

BB5_36:
	selp.f32	%f317, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f318, %f648, %f41, %f317;
	selp.f32	%f319, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f320, %f318, %f41, %f319;
	fma.rn.f32 	%f649, %f320, %f42, %f40;
	and.b32  	%r525, %r1078, 2;
	setp.eq.s32	%p28, %r525, 0;
	@%p28 bra 	BB5_38;

	mov.f32 	%f322, 0fBF800000;
	fma.rn.f32 	%f649, %f649, %f322, %f259;

BB5_38:
	mul.f32 	%f323, %f22, %f649;
	mul.f32 	%f324, %f21, %f646;
	sub.f32 	%f325, %f324, %f323;
	mul.f32 	%f326, %f22, %f646;
	fma.rn.f32 	%f327, %f21, %f649, %f326;
	add.f32 	%f328, %f19, %f325;
	shl.b32 	%r526, %r1, 1;
	and.b32  	%r527, %r526, 1073741820;
	and.b32  	%r528, %r1, 1;
	add.s32 	%r529, %r527, %r528;
	shl.b32 	%r530, %r529, 2;
	mov.u32 	%r531, _ZZ24_occa_Stockhoptimized9_0E6SRBank;
	add.s32 	%r532, %r531, %r530;
	st.shared.f32 	[%r532], %f328;
	add.f32 	%f329, %f20, %f327;
	mov.u32 	%r533, _ZZ24_occa_Stockhoptimized9_0E6SIBank;
	add.s32 	%r534, %r533, %r530;
	st.shared.f32 	[%r534], %f329;
	sub.f32 	%f330, %f19, %f325;
	st.shared.f32 	[%r532+8], %f330;
	sub.f32 	%f331, %f20, %f327;
	st.shared.f32 	[%r534+8], %f331;
	bar.sync 	0;
	add.s32 	%r537, %r531, %r458;
	ld.shared.f32 	%f48, [%r537];
	add.s32 	%r539, %r533, %r458;
	ld.shared.f32 	%f49, [%r539];
	ld.shared.f32 	%f50, [%r537+1024];
	ld.shared.f32 	%f51, [%r539+1024];
	shr.s32 	%r540, %r1, 31;
	shr.u32 	%r541, %r540, 30;
	add.s32 	%r542, %r1, %r541;
	and.b32  	%r543, %r542, 67108860;
	sub.s32 	%r544, %r1, %r543;
	shl.b32 	%r545, %r544, 6;
	cvt.rn.f32.s32	%f332, %r545;
	mul.f32 	%f333, %f332, 0f3B000000;
	cvt.f64.f32	%fd7, %f333;
	mul.f64 	%fd8, %fd7, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f52, %fd8;
	mul.f32 	%f334, %f52, 0f3F22F983;
	cvt.rni.s32.f32	%r1094, %f334;
	cvt.rn.f32.s32	%f335, %r1094;
	fma.rn.f32 	%f337, %f335, %f254, %f52;
	fma.rn.f32 	%f339, %f335, %f256, %f337;
	fma.rn.f32 	%f653, %f335, %f258, %f339;
	abs.f32 	%f54, %f52;
	setp.leu.f32	%p29, %f54, 0f47CE4780;
	mov.u32 	%r1086, %r1094;
	mov.f32 	%f650, %f653;
	@%p29 bra 	BB5_49;

	setp.eq.f32	%p30, %f54, 0f7F800000;
	@%p30 bra 	BB5_48;
	bra.uni 	BB5_40;

BB5_48:
	mul.rn.f32 	%f650, %f52, %f259;
	mov.u32 	%r1086, %r1094;
	bra.uni 	BB5_49;

BB5_40:
	mov.b32 	 %r61, %f52;
	shl.b32 	%r548, %r61, 8;
	or.b32  	%r62, %r548, -2147483648;
	add.u64 	%rd119, %SP, 0;
	add.u64 	%rd240, %SPL, 0;
	mov.u32 	%r1080, 0;
	mov.u64 	%rd239, __cudart_i2opi_f;
	mov.u32 	%r1079, -6;

BB5_41:
	.pragma "nounroll";
	ld.const.u32 	%r551, [%rd239];
	// inline asm
	{
	mad.lo.cc.u32   %r549, %r551, %r62, %r1080;
	madc.hi.u32     %r1080, %r551, %r62,  0;
	}
	// inline asm
	st.local.u32 	[%rd240], %r549;
	add.s64 	%rd240, %rd240, 4;
	add.s64 	%rd239, %rd239, 4;
	add.s32 	%r1079, %r1079, 1;
	setp.ne.s32	%p31, %r1079, 0;
	@%p31 bra 	BB5_41;

	bfe.u32 	%r554, %r61, 23, 8;
	add.s32 	%r555, %r554, -128;
	shr.u32 	%r556, %r555, 5;
	and.b32  	%r67, %r61, -2147483648;
	cvta.to.local.u64 	%rd121, %rd119;
	st.local.u32 	[%rd121+24], %r1080;
	bfe.u32 	%r68, %r61, 23, 5;
	mov.u32 	%r557, 6;
	sub.s32 	%r558, %r557, %r556;
	mul.wide.s32 	%rd122, %r558, 4;
	add.s64 	%rd18, %rd121, %rd122;
	ld.local.u32 	%r1082, [%rd18];
	ld.local.u32 	%r1081, [%rd18+-4];
	setp.eq.s32	%p32, %r68, 0;
	@%p32 bra 	BB5_44;

	mov.u32 	%r559, 32;
	sub.s32 	%r560, %r559, %r68;
	shr.u32 	%r561, %r1081, %r560;
	shl.b32 	%r562, %r1082, %r68;
	add.s32 	%r1082, %r561, %r562;
	ld.local.u32 	%r563, [%rd18+-8];
	shr.u32 	%r564, %r563, %r560;
	shl.b32 	%r565, %r1081, %r68;
	add.s32 	%r1081, %r564, %r565;

BB5_44:
	shr.u32 	%r566, %r1081, 30;
	shl.b32 	%r567, %r1082, 2;
	add.s32 	%r1084, %r567, %r566;
	shl.b32 	%r76, %r1081, 2;
	shr.u32 	%r568, %r1084, 31;
	shr.u32 	%r569, %r1082, 30;
	add.s32 	%r77, %r568, %r569;
	setp.eq.s32	%p33, %r568, 0;
	@%p33 bra 	BB5_45;

	not.b32 	%r570, %r1084;
	neg.s32 	%r1083, %r76;
	setp.eq.s32	%p34, %r76, 0;
	selp.u32	%r571, 1, 0, %p34;
	add.s32 	%r1084, %r571, %r570;
	xor.b32  	%r1085, %r67, -2147483648;
	bra.uni 	BB5_47;

BB5_45:
	mov.u32 	%r1083, %r76;
	mov.u32 	%r1085, %r67;

BB5_47:
	cvt.u64.u32	%rd123, %r1084;
	cvt.u64.u32	%rd124, %r1083;
	bfi.b64 	%rd125, %rd123, %rd124, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd125;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f341, %fd10;
	neg.f32 	%f342, %f341;
	setp.eq.s32	%p35, %r1085, 0;
	selp.f32	%f650, %f341, %f342, %p35;
	setp.eq.s32	%p36, %r67, 0;
	neg.s32 	%r572, %r77;
	selp.b32	%r1086, %r77, %r572, %p36;

BB5_49:
	add.s32 	%r86, %r1086, 1;
	and.b32  	%r87, %r86, 1;
	setp.eq.s32	%p37, %r87, 0;
	selp.f32	%f58, %f650, 0f3F800000, %p37;
	mul.rn.f32 	%f59, %f650, %f650;
	fma.rn.f32 	%f60, %f59, %f58, %f259;
	mov.f32 	%f651, 0fB94D4153;
	@%p37 bra 	BB5_51;

	mov.f32 	%f346, 0fBAB607ED;
	mov.f32 	%f347, 0f37CBAC00;
	fma.rn.f32 	%f651, %f347, %f59, %f346;

BB5_51:
	selp.f32	%f348, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f349, %f651, %f59, %f348;
	selp.f32	%f350, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f351, %f349, %f59, %f350;
	fma.rn.f32 	%f652, %f351, %f60, %f58;
	and.b32  	%r573, %r86, 2;
	setp.eq.s32	%p39, %r573, 0;
	@%p39 bra 	BB5_53;

	mov.f32 	%f353, 0fBF800000;
	fma.rn.f32 	%f652, %f652, %f353, %f259;

BB5_53:
	@%p29 bra 	BB5_64;

	setp.eq.f32	%p41, %f54, 0f7F800000;
	@%p41 bra 	BB5_63;
	bra.uni 	BB5_55;

BB5_63:
	mul.rn.f32 	%f653, %f52, %f259;
	bra.uni 	BB5_64;

BB5_55:
	mov.b32 	 %r88, %f52;
	shl.b32 	%r576, %r88, 8;
	or.b32  	%r89, %r576, -2147483648;
	add.u64 	%rd127, %SP, 0;
	add.u64 	%rd242, %SPL, 0;
	mov.u32 	%r1088, 0;
	mov.u64 	%rd241, __cudart_i2opi_f;
	mov.u32 	%r1087, -6;

BB5_56:
	.pragma "nounroll";
	ld.const.u32 	%r579, [%rd241];
	// inline asm
	{
	mad.lo.cc.u32   %r577, %r579, %r89, %r1088;
	madc.hi.u32     %r1088, %r579, %r89,  0;
	}
	// inline asm
	st.local.u32 	[%rd242], %r577;
	add.s64 	%rd242, %rd242, 4;
	add.s64 	%rd241, %rd241, 4;
	add.s32 	%r1087, %r1087, 1;
	setp.ne.s32	%p42, %r1087, 0;
	@%p42 bra 	BB5_56;

	bfe.u32 	%r582, %r88, 23, 8;
	add.s32 	%r583, %r582, -128;
	shr.u32 	%r584, %r583, 5;
	and.b32  	%r94, %r88, -2147483648;
	cvta.to.local.u64 	%rd129, %rd127;
	st.local.u32 	[%rd129+24], %r1088;
	bfe.u32 	%r95, %r88, 23, 5;
	mov.u32 	%r585, 6;
	sub.s32 	%r586, %r585, %r584;
	mul.wide.s32 	%rd130, %r586, 4;
	add.s64 	%rd24, %rd129, %rd130;
	ld.local.u32 	%r1090, [%rd24];
	ld.local.u32 	%r1089, [%rd24+-4];
	setp.eq.s32	%p43, %r95, 0;
	@%p43 bra 	BB5_59;

	mov.u32 	%r587, 32;
	sub.s32 	%r588, %r587, %r95;
	shr.u32 	%r589, %r1089, %r588;
	shl.b32 	%r590, %r1090, %r95;
	add.s32 	%r1090, %r589, %r590;
	ld.local.u32 	%r591, [%rd24+-8];
	shr.u32 	%r592, %r591, %r588;
	shl.b32 	%r593, %r1089, %r95;
	add.s32 	%r1089, %r592, %r593;

BB5_59:
	shr.u32 	%r594, %r1089, 30;
	shl.b32 	%r595, %r1090, 2;
	add.s32 	%r1092, %r595, %r594;
	shl.b32 	%r103, %r1089, 2;
	shr.u32 	%r596, %r1092, 31;
	shr.u32 	%r597, %r1090, 30;
	add.s32 	%r104, %r596, %r597;
	setp.eq.s32	%p44, %r596, 0;
	@%p44 bra 	BB5_60;

	not.b32 	%r598, %r1092;
	neg.s32 	%r1091, %r103;
	setp.eq.s32	%p45, %r103, 0;
	selp.u32	%r599, 1, 0, %p45;
	add.s32 	%r1092, %r599, %r598;
	xor.b32  	%r1093, %r94, -2147483648;
	bra.uni 	BB5_62;

BB5_60:
	mov.u32 	%r1091, %r103;
	mov.u32 	%r1093, %r94;

BB5_62:
	cvt.u64.u32	%rd131, %r1092;
	cvt.u64.u32	%rd132, %r1091;
	bfi.b64 	%rd133, %rd131, %rd132, 32, 32;
	cvt.rn.f64.s64	%fd11, %rd133;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f354, %fd12;
	neg.f32 	%f355, %f354;
	setp.eq.s32	%p46, %r1093, 0;
	selp.f32	%f653, %f354, %f355, %p46;
	setp.eq.s32	%p47, %r94, 0;
	neg.s32 	%r600, %r104;
	selp.b32	%r1094, %r104, %r600, %p47;

BB5_64:
	and.b32  	%r113, %r1094, 1;
	setp.eq.s32	%p48, %r113, 0;
	selp.f32	%f69, %f653, 0f3F800000, %p48;
	mul.rn.f32 	%f70, %f653, %f653;
	fma.rn.f32 	%f71, %f70, %f69, %f259;
	mov.f32 	%f654, 0fB94D4153;
	@%p48 bra 	BB5_66;

	mov.f32 	%f359, 0fBAB607ED;
	mov.f32 	%f360, 0f37CBAC00;
	fma.rn.f32 	%f654, %f360, %f70, %f359;

BB5_66:
	selp.f32	%f361, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f362, %f654, %f70, %f361;
	selp.f32	%f363, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f364, %f362, %f70, %f363;
	fma.rn.f32 	%f655, %f364, %f71, %f69;
	and.b32  	%r601, %r1094, 2;
	setp.eq.s32	%p50, %r601, 0;
	@%p50 bra 	BB5_68;

	mov.f32 	%f366, 0fBF800000;
	fma.rn.f32 	%f655, %f655, %f366, %f259;

BB5_68:
	and.b32  	%r602, %r1, 3;
	and.b32  	%r604, %r526, 1073741816;
	add.s32 	%r605, %r604, %r602;
	mul.f32 	%f367, %f51, %f655;
	mul.f32 	%f368, %f50, %f652;
	sub.f32 	%f369, %f368, %f367;
	mul.f32 	%f370, %f51, %f652;
	fma.rn.f32 	%f371, %f50, %f655, %f370;
	add.f32 	%f372, %f48, %f369;
	shl.b32 	%r606, %r605, 2;
	add.s32 	%r608, %r454, %r606;
	st.shared.f32 	[%r608], %f372;
	add.f32 	%f373, %f49, %f371;
	add.s32 	%r610, %r456, %r606;
	st.shared.f32 	[%r610], %f373;
	sub.f32 	%f374, %f48, %f369;
	st.shared.f32 	[%r608+16], %f374;
	sub.f32 	%f375, %f49, %f371;
	st.shared.f32 	[%r610+16], %f375;
	bar.sync 	0;
	ld.shared.f32 	%f77, [%r460];
	ld.shared.f32 	%f78, [%r462];
	ld.shared.f32 	%f79, [%r460+1024];
	ld.shared.f32 	%f80, [%r462+1024];
	shr.u32 	%r617, %r540, 29;
	add.s32 	%r618, %r1, %r617;
	and.b32  	%r619, %r618, 134217720;
	sub.s32 	%r620, %r1, %r619;
	shl.b32 	%r621, %r620, 5;
	cvt.rn.f32.s32	%f376, %r621;
	mul.f32 	%f377, %f376, 0f3B000000;
	cvt.f64.f32	%fd13, %f377;
	mul.f64 	%fd14, %fd13, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f81, %fd14;
	mul.f32 	%f378, %f81, 0f3F22F983;
	cvt.rni.s32.f32	%r1110, %f378;
	cvt.rn.f32.s32	%f379, %r1110;
	fma.rn.f32 	%f381, %f379, %f254, %f81;
	fma.rn.f32 	%f383, %f379, %f256, %f381;
	fma.rn.f32 	%f659, %f379, %f258, %f383;
	abs.f32 	%f83, %f81;
	setp.leu.f32	%p51, %f83, 0f47CE4780;
	mov.u32 	%r1102, %r1110;
	mov.f32 	%f656, %f659;
	@%p51 bra 	BB5_79;

	setp.eq.f32	%p52, %f83, 0f7F800000;
	@%p52 bra 	BB5_78;
	bra.uni 	BB5_70;

BB5_78:
	mul.rn.f32 	%f656, %f81, %f259;
	mov.u32 	%r1102, %r1110;
	bra.uni 	BB5_79;

BB5_70:
	mov.b32 	 %r116, %f81;
	shl.b32 	%r624, %r116, 8;
	or.b32  	%r117, %r624, -2147483648;
	add.u64 	%rd135, %SP, 0;
	add.u64 	%rd244, %SPL, 0;
	mov.u32 	%r1096, 0;
	mov.u64 	%rd243, __cudart_i2opi_f;
	mov.u32 	%r1095, -6;

BB5_71:
	.pragma "nounroll";
	ld.const.u32 	%r627, [%rd243];
	// inline asm
	{
	mad.lo.cc.u32   %r625, %r627, %r117, %r1096;
	madc.hi.u32     %r1096, %r627, %r117,  0;
	}
	// inline asm
	st.local.u32 	[%rd244], %r625;
	add.s64 	%rd244, %rd244, 4;
	add.s64 	%rd243, %rd243, 4;
	add.s32 	%r1095, %r1095, 1;
	setp.ne.s32	%p53, %r1095, 0;
	@%p53 bra 	BB5_71;

	bfe.u32 	%r630, %r116, 23, 8;
	add.s32 	%r631, %r630, -128;
	shr.u32 	%r632, %r631, 5;
	and.b32  	%r122, %r116, -2147483648;
	cvta.to.local.u64 	%rd137, %rd135;
	st.local.u32 	[%rd137+24], %r1096;
	bfe.u32 	%r123, %r116, 23, 5;
	mov.u32 	%r633, 6;
	sub.s32 	%r634, %r633, %r632;
	mul.wide.s32 	%rd138, %r634, 4;
	add.s64 	%rd30, %rd137, %rd138;
	ld.local.u32 	%r1098, [%rd30];
	ld.local.u32 	%r1097, [%rd30+-4];
	setp.eq.s32	%p54, %r123, 0;
	@%p54 bra 	BB5_74;

	mov.u32 	%r635, 32;
	sub.s32 	%r636, %r635, %r123;
	shr.u32 	%r637, %r1097, %r636;
	shl.b32 	%r638, %r1098, %r123;
	add.s32 	%r1098, %r637, %r638;
	ld.local.u32 	%r639, [%rd30+-8];
	shr.u32 	%r640, %r639, %r636;
	shl.b32 	%r641, %r1097, %r123;
	add.s32 	%r1097, %r640, %r641;

BB5_74:
	shr.u32 	%r642, %r1097, 30;
	shl.b32 	%r643, %r1098, 2;
	add.s32 	%r1100, %r643, %r642;
	shl.b32 	%r131, %r1097, 2;
	shr.u32 	%r644, %r1100, 31;
	shr.u32 	%r645, %r1098, 30;
	add.s32 	%r132, %r644, %r645;
	setp.eq.s32	%p55, %r644, 0;
	@%p55 bra 	BB5_75;

	not.b32 	%r646, %r1100;
	neg.s32 	%r1099, %r131;
	setp.eq.s32	%p56, %r131, 0;
	selp.u32	%r647, 1, 0, %p56;
	add.s32 	%r1100, %r647, %r646;
	xor.b32  	%r1101, %r122, -2147483648;
	bra.uni 	BB5_77;

BB5_75:
	mov.u32 	%r1099, %r131;
	mov.u32 	%r1101, %r122;

BB5_77:
	cvt.u64.u32	%rd139, %r1100;
	cvt.u64.u32	%rd140, %r1099;
	bfi.b64 	%rd141, %rd139, %rd140, 32, 32;
	cvt.rn.f64.s64	%fd15, %rd141;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f385, %fd16;
	neg.f32 	%f386, %f385;
	setp.eq.s32	%p57, %r1101, 0;
	selp.f32	%f656, %f385, %f386, %p57;
	setp.eq.s32	%p58, %r122, 0;
	neg.s32 	%r648, %r132;
	selp.b32	%r1102, %r132, %r648, %p58;

BB5_79:
	add.s32 	%r141, %r1102, 1;
	and.b32  	%r142, %r141, 1;
	setp.eq.s32	%p59, %r142, 0;
	selp.f32	%f87, %f656, 0f3F800000, %p59;
	mul.rn.f32 	%f88, %f656, %f656;
	fma.rn.f32 	%f89, %f88, %f87, %f259;
	mov.f32 	%f657, 0fB94D4153;
	@%p59 bra 	BB5_81;

	mov.f32 	%f390, 0fBAB607ED;
	mov.f32 	%f391, 0f37CBAC00;
	fma.rn.f32 	%f657, %f391, %f88, %f390;

BB5_81:
	selp.f32	%f392, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f393, %f657, %f88, %f392;
	selp.f32	%f394, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f395, %f393, %f88, %f394;
	fma.rn.f32 	%f658, %f395, %f89, %f87;
	and.b32  	%r649, %r141, 2;
	setp.eq.s32	%p61, %r649, 0;
	@%p61 bra 	BB5_83;

	mov.f32 	%f397, 0fBF800000;
	fma.rn.f32 	%f658, %f658, %f397, %f259;

BB5_83:
	@%p51 bra 	BB5_94;

	setp.eq.f32	%p63, %f83, 0f7F800000;
	@%p63 bra 	BB5_93;
	bra.uni 	BB5_85;

BB5_93:
	mul.rn.f32 	%f659, %f81, %f259;
	bra.uni 	BB5_94;

BB5_85:
	mov.b32 	 %r143, %f81;
	shl.b32 	%r652, %r143, 8;
	or.b32  	%r144, %r652, -2147483648;
	add.u64 	%rd143, %SP, 0;
	add.u64 	%rd246, %SPL, 0;
	mov.u32 	%r1104, 0;
	mov.u64 	%rd245, __cudart_i2opi_f;
	mov.u32 	%r1103, -6;

BB5_86:
	.pragma "nounroll";
	ld.const.u32 	%r655, [%rd245];
	// inline asm
	{
	mad.lo.cc.u32   %r653, %r655, %r144, %r1104;
	madc.hi.u32     %r1104, %r655, %r144,  0;
	}
	// inline asm
	st.local.u32 	[%rd246], %r653;
	add.s64 	%rd246, %rd246, 4;
	add.s64 	%rd245, %rd245, 4;
	add.s32 	%r1103, %r1103, 1;
	setp.ne.s32	%p64, %r1103, 0;
	@%p64 bra 	BB5_86;

	bfe.u32 	%r658, %r143, 23, 8;
	add.s32 	%r659, %r658, -128;
	shr.u32 	%r660, %r659, 5;
	and.b32  	%r149, %r143, -2147483648;
	cvta.to.local.u64 	%rd145, %rd143;
	st.local.u32 	[%rd145+24], %r1104;
	bfe.u32 	%r150, %r143, 23, 5;
	mov.u32 	%r661, 6;
	sub.s32 	%r662, %r661, %r660;
	mul.wide.s32 	%rd146, %r662, 4;
	add.s64 	%rd36, %rd145, %rd146;
	ld.local.u32 	%r1106, [%rd36];
	ld.local.u32 	%r1105, [%rd36+-4];
	setp.eq.s32	%p65, %r150, 0;
	@%p65 bra 	BB5_89;

	mov.u32 	%r663, 32;
	sub.s32 	%r664, %r663, %r150;
	shr.u32 	%r665, %r1105, %r664;
	shl.b32 	%r666, %r1106, %r150;
	add.s32 	%r1106, %r665, %r666;
	ld.local.u32 	%r667, [%rd36+-8];
	shr.u32 	%r668, %r667, %r664;
	shl.b32 	%r669, %r1105, %r150;
	add.s32 	%r1105, %r668, %r669;

BB5_89:
	shr.u32 	%r670, %r1105, 30;
	shl.b32 	%r671, %r1106, 2;
	add.s32 	%r1108, %r671, %r670;
	shl.b32 	%r158, %r1105, 2;
	shr.u32 	%r672, %r1108, 31;
	shr.u32 	%r673, %r1106, 30;
	add.s32 	%r159, %r672, %r673;
	setp.eq.s32	%p66, %r672, 0;
	@%p66 bra 	BB5_90;

	not.b32 	%r674, %r1108;
	neg.s32 	%r1107, %r158;
	setp.eq.s32	%p67, %r158, 0;
	selp.u32	%r675, 1, 0, %p67;
	add.s32 	%r1108, %r675, %r674;
	xor.b32  	%r1109, %r149, -2147483648;
	bra.uni 	BB5_92;

BB5_90:
	mov.u32 	%r1107, %r158;
	mov.u32 	%r1109, %r149;

BB5_92:
	cvt.u64.u32	%rd147, %r1108;
	cvt.u64.u32	%rd148, %r1107;
	bfi.b64 	%rd149, %rd147, %rd148, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd149;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f398, %fd18;
	neg.f32 	%f399, %f398;
	setp.eq.s32	%p68, %r1109, 0;
	selp.f32	%f659, %f398, %f399, %p68;
	setp.eq.s32	%p69, %r149, 0;
	neg.s32 	%r676, %r159;
	selp.b32	%r1110, %r159, %r676, %p69;

BB5_94:
	and.b32  	%r168, %r1110, 1;
	setp.eq.s32	%p70, %r168, 0;
	selp.f32	%f98, %f659, 0f3F800000, %p70;
	mul.rn.f32 	%f99, %f659, %f659;
	fma.rn.f32 	%f100, %f99, %f98, %f259;
	mov.f32 	%f660, 0fB94D4153;
	@%p70 bra 	BB5_96;

	mov.f32 	%f403, 0fBAB607ED;
	mov.f32 	%f404, 0f37CBAC00;
	fma.rn.f32 	%f660, %f404, %f99, %f403;

BB5_96:
	selp.f32	%f405, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f406, %f660, %f99, %f405;
	selp.f32	%f407, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f408, %f406, %f99, %f407;
	fma.rn.f32 	%f661, %f408, %f100, %f98;
	and.b32  	%r677, %r1110, 2;
	setp.eq.s32	%p72, %r677, 0;
	@%p72 bra 	BB5_98;

	mov.f32 	%f410, 0fBF800000;
	fma.rn.f32 	%f661, %f661, %f410, %f259;

BB5_98:
	and.b32  	%r678, %r1, 7;
	and.b32  	%r680, %r526, 1073741808;
	add.s32 	%r681, %r680, %r678;
	mul.f32 	%f411, %f80, %f661;
	mul.f32 	%f412, %f79, %f658;
	sub.f32 	%f413, %f412, %f411;
	mul.f32 	%f414, %f80, %f658;
	fma.rn.f32 	%f415, %f79, %f661, %f414;
	add.f32 	%f416, %f77, %f413;
	shl.b32 	%r682, %r681, 2;
	add.s32 	%r684, %r531, %r682;
	st.shared.f32 	[%r684], %f416;
	add.f32 	%f417, %f78, %f415;
	add.s32 	%r686, %r533, %r682;
	st.shared.f32 	[%r686], %f417;
	sub.f32 	%f418, %f77, %f413;
	st.shared.f32 	[%r684+32], %f418;
	sub.f32 	%f419, %f78, %f415;
	st.shared.f32 	[%r686+32], %f419;
	bar.sync 	0;
	ld.shared.f32 	%f106, [%r537];
	ld.shared.f32 	%f107, [%r539];
	ld.shared.f32 	%f108, [%r537+1024];
	ld.shared.f32 	%f109, [%r539+1024];
	shr.u32 	%r693, %r540, 28;
	add.s32 	%r694, %r1, %r693;
	and.b32  	%r695, %r694, 268435440;
	sub.s32 	%r696, %r1, %r695;
	shl.b32 	%r697, %r696, 4;
	cvt.rn.f32.s32	%f420, %r697;
	mul.f32 	%f421, %f420, 0f3B000000;
	cvt.f64.f32	%fd19, %f421;
	mul.f64 	%fd20, %fd19, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f110, %fd20;
	mul.f32 	%f422, %f110, 0f3F22F983;
	cvt.rni.s32.f32	%r1126, %f422;
	cvt.rn.f32.s32	%f423, %r1126;
	fma.rn.f32 	%f425, %f423, %f254, %f110;
	fma.rn.f32 	%f427, %f423, %f256, %f425;
	fma.rn.f32 	%f665, %f423, %f258, %f427;
	abs.f32 	%f112, %f110;
	setp.leu.f32	%p73, %f112, 0f47CE4780;
	mov.u32 	%r1118, %r1126;
	mov.f32 	%f662, %f665;
	@%p73 bra 	BB5_109;

	setp.eq.f32	%p74, %f112, 0f7F800000;
	@%p74 bra 	BB5_108;
	bra.uni 	BB5_100;

BB5_108:
	mul.rn.f32 	%f662, %f110, %f259;
	mov.u32 	%r1118, %r1126;
	bra.uni 	BB5_109;

BB5_100:
	mov.b32 	 %r171, %f110;
	shl.b32 	%r700, %r171, 8;
	or.b32  	%r172, %r700, -2147483648;
	add.u64 	%rd151, %SP, 0;
	add.u64 	%rd248, %SPL, 0;
	mov.u32 	%r1112, 0;
	mov.u64 	%rd247, __cudart_i2opi_f;
	mov.u32 	%r1111, -6;

BB5_101:
	.pragma "nounroll";
	ld.const.u32 	%r703, [%rd247];
	// inline asm
	{
	mad.lo.cc.u32   %r701, %r703, %r172, %r1112;
	madc.hi.u32     %r1112, %r703, %r172,  0;
	}
	// inline asm
	st.local.u32 	[%rd248], %r701;
	add.s64 	%rd248, %rd248, 4;
	add.s64 	%rd247, %rd247, 4;
	add.s32 	%r1111, %r1111, 1;
	setp.ne.s32	%p75, %r1111, 0;
	@%p75 bra 	BB5_101;

	bfe.u32 	%r706, %r171, 23, 8;
	add.s32 	%r707, %r706, -128;
	shr.u32 	%r708, %r707, 5;
	and.b32  	%r177, %r171, -2147483648;
	cvta.to.local.u64 	%rd153, %rd151;
	st.local.u32 	[%rd153+24], %r1112;
	bfe.u32 	%r178, %r171, 23, 5;
	mov.u32 	%r709, 6;
	sub.s32 	%r710, %r709, %r708;
	mul.wide.s32 	%rd154, %r710, 4;
	add.s64 	%rd42, %rd153, %rd154;
	ld.local.u32 	%r1114, [%rd42];
	ld.local.u32 	%r1113, [%rd42+-4];
	setp.eq.s32	%p76, %r178, 0;
	@%p76 bra 	BB5_104;

	mov.u32 	%r711, 32;
	sub.s32 	%r712, %r711, %r178;
	shr.u32 	%r713, %r1113, %r712;
	shl.b32 	%r714, %r1114, %r178;
	add.s32 	%r1114, %r713, %r714;
	ld.local.u32 	%r715, [%rd42+-8];
	shr.u32 	%r716, %r715, %r712;
	shl.b32 	%r717, %r1113, %r178;
	add.s32 	%r1113, %r716, %r717;

BB5_104:
	shr.u32 	%r718, %r1113, 30;
	shl.b32 	%r719, %r1114, 2;
	add.s32 	%r1116, %r719, %r718;
	shl.b32 	%r186, %r1113, 2;
	shr.u32 	%r720, %r1116, 31;
	shr.u32 	%r721, %r1114, 30;
	add.s32 	%r187, %r720, %r721;
	setp.eq.s32	%p77, %r720, 0;
	@%p77 bra 	BB5_105;

	not.b32 	%r722, %r1116;
	neg.s32 	%r1115, %r186;
	setp.eq.s32	%p78, %r186, 0;
	selp.u32	%r723, 1, 0, %p78;
	add.s32 	%r1116, %r723, %r722;
	xor.b32  	%r1117, %r177, -2147483648;
	bra.uni 	BB5_107;

BB5_105:
	mov.u32 	%r1115, %r186;
	mov.u32 	%r1117, %r177;

BB5_107:
	cvt.u64.u32	%rd155, %r1116;
	cvt.u64.u32	%rd156, %r1115;
	bfi.b64 	%rd157, %rd155, %rd156, 32, 32;
	cvt.rn.f64.s64	%fd21, %rd157;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f429, %fd22;
	neg.f32 	%f430, %f429;
	setp.eq.s32	%p79, %r1117, 0;
	selp.f32	%f662, %f429, %f430, %p79;
	setp.eq.s32	%p80, %r177, 0;
	neg.s32 	%r724, %r187;
	selp.b32	%r1118, %r187, %r724, %p80;

BB5_109:
	add.s32 	%r196, %r1118, 1;
	and.b32  	%r197, %r196, 1;
	setp.eq.s32	%p81, %r197, 0;
	selp.f32	%f116, %f662, 0f3F800000, %p81;
	mul.rn.f32 	%f117, %f662, %f662;
	fma.rn.f32 	%f118, %f117, %f116, %f259;
	mov.f32 	%f663, 0fB94D4153;
	@%p81 bra 	BB5_111;

	mov.f32 	%f434, 0fBAB607ED;
	mov.f32 	%f435, 0f37CBAC00;
	fma.rn.f32 	%f663, %f435, %f117, %f434;

BB5_111:
	selp.f32	%f436, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f437, %f663, %f117, %f436;
	selp.f32	%f438, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f439, %f437, %f117, %f438;
	fma.rn.f32 	%f664, %f439, %f118, %f116;
	and.b32  	%r725, %r196, 2;
	setp.eq.s32	%p83, %r725, 0;
	@%p83 bra 	BB5_113;

	mov.f32 	%f441, 0fBF800000;
	fma.rn.f32 	%f664, %f664, %f441, %f259;

BB5_113:
	@%p73 bra 	BB5_124;

	setp.eq.f32	%p85, %f112, 0f7F800000;
	@%p85 bra 	BB5_123;
	bra.uni 	BB5_115;

BB5_123:
	mul.rn.f32 	%f665, %f110, %f259;
	bra.uni 	BB5_124;

BB5_115:
	mov.b32 	 %r198, %f110;
	shl.b32 	%r728, %r198, 8;
	or.b32  	%r199, %r728, -2147483648;
	add.u64 	%rd159, %SP, 0;
	add.u64 	%rd250, %SPL, 0;
	mov.u32 	%r1120, 0;
	mov.u64 	%rd249, __cudart_i2opi_f;
	mov.u32 	%r1119, -6;

BB5_116:
	.pragma "nounroll";
	ld.const.u32 	%r731, [%rd249];
	// inline asm
	{
	mad.lo.cc.u32   %r729, %r731, %r199, %r1120;
	madc.hi.u32     %r1120, %r731, %r199,  0;
	}
	// inline asm
	st.local.u32 	[%rd250], %r729;
	add.s64 	%rd250, %rd250, 4;
	add.s64 	%rd249, %rd249, 4;
	add.s32 	%r1119, %r1119, 1;
	setp.ne.s32	%p86, %r1119, 0;
	@%p86 bra 	BB5_116;

	bfe.u32 	%r734, %r198, 23, 8;
	add.s32 	%r735, %r734, -128;
	shr.u32 	%r736, %r735, 5;
	and.b32  	%r204, %r198, -2147483648;
	cvta.to.local.u64 	%rd161, %rd159;
	st.local.u32 	[%rd161+24], %r1120;
	bfe.u32 	%r205, %r198, 23, 5;
	mov.u32 	%r737, 6;
	sub.s32 	%r738, %r737, %r736;
	mul.wide.s32 	%rd162, %r738, 4;
	add.s64 	%rd48, %rd161, %rd162;
	ld.local.u32 	%r1122, [%rd48];
	ld.local.u32 	%r1121, [%rd48+-4];
	setp.eq.s32	%p87, %r205, 0;
	@%p87 bra 	BB5_119;

	mov.u32 	%r739, 32;
	sub.s32 	%r740, %r739, %r205;
	shr.u32 	%r741, %r1121, %r740;
	shl.b32 	%r742, %r1122, %r205;
	add.s32 	%r1122, %r741, %r742;
	ld.local.u32 	%r743, [%rd48+-8];
	shr.u32 	%r744, %r743, %r740;
	shl.b32 	%r745, %r1121, %r205;
	add.s32 	%r1121, %r744, %r745;

BB5_119:
	shr.u32 	%r746, %r1121, 30;
	shl.b32 	%r747, %r1122, 2;
	add.s32 	%r1124, %r747, %r746;
	shl.b32 	%r213, %r1121, 2;
	shr.u32 	%r748, %r1124, 31;
	shr.u32 	%r749, %r1122, 30;
	add.s32 	%r214, %r748, %r749;
	setp.eq.s32	%p88, %r748, 0;
	@%p88 bra 	BB5_120;

	not.b32 	%r750, %r1124;
	neg.s32 	%r1123, %r213;
	setp.eq.s32	%p89, %r213, 0;
	selp.u32	%r751, 1, 0, %p89;
	add.s32 	%r1124, %r751, %r750;
	xor.b32  	%r1125, %r204, -2147483648;
	bra.uni 	BB5_122;

BB5_120:
	mov.u32 	%r1123, %r213;
	mov.u32 	%r1125, %r204;

BB5_122:
	cvt.u64.u32	%rd163, %r1124;
	cvt.u64.u32	%rd164, %r1123;
	bfi.b64 	%rd165, %rd163, %rd164, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd165;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f442, %fd24;
	neg.f32 	%f443, %f442;
	setp.eq.s32	%p90, %r1125, 0;
	selp.f32	%f665, %f442, %f443, %p90;
	setp.eq.s32	%p91, %r204, 0;
	neg.s32 	%r752, %r214;
	selp.b32	%r1126, %r214, %r752, %p91;

BB5_124:
	and.b32  	%r223, %r1126, 1;
	setp.eq.s32	%p92, %r223, 0;
	selp.f32	%f127, %f665, 0f3F800000, %p92;
	mul.rn.f32 	%f128, %f665, %f665;
	fma.rn.f32 	%f129, %f128, %f127, %f259;
	mov.f32 	%f666, 0fB94D4153;
	@%p92 bra 	BB5_126;

	mov.f32 	%f447, 0fBAB607ED;
	mov.f32 	%f448, 0f37CBAC00;
	fma.rn.f32 	%f666, %f448, %f128, %f447;

BB5_126:
	selp.f32	%f449, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f450, %f666, %f128, %f449;
	selp.f32	%f451, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f452, %f450, %f128, %f451;
	fma.rn.f32 	%f667, %f452, %f129, %f127;
	and.b32  	%r753, %r1126, 2;
	setp.eq.s32	%p94, %r753, 0;
	@%p94 bra 	BB5_128;

	mov.f32 	%f454, 0fBF800000;
	fma.rn.f32 	%f667, %f667, %f454, %f259;

BB5_128:
	and.b32  	%r754, %r1, 15;
	and.b32  	%r756, %r526, 1073741792;
	add.s32 	%r757, %r756, %r754;
	mul.f32 	%f455, %f109, %f667;
	mul.f32 	%f456, %f108, %f664;
	sub.f32 	%f457, %f456, %f455;
	mul.f32 	%f458, %f109, %f664;
	fma.rn.f32 	%f459, %f108, %f667, %f458;
	add.f32 	%f460, %f106, %f457;
	shl.b32 	%r758, %r757, 2;
	add.s32 	%r760, %r454, %r758;
	st.shared.f32 	[%r760], %f460;
	add.f32 	%f461, %f107, %f459;
	add.s32 	%r762, %r456, %r758;
	st.shared.f32 	[%r762], %f461;
	sub.f32 	%f462, %f106, %f457;
	st.shared.f32 	[%r760+64], %f462;
	sub.f32 	%f463, %f107, %f459;
	st.shared.f32 	[%r762+64], %f463;
	bar.sync 	0;
	ld.shared.f32 	%f135, [%r460];
	ld.shared.f32 	%f136, [%r462];
	ld.shared.f32 	%f137, [%r460+1024];
	ld.shared.f32 	%f138, [%r462+1024];
	shr.u32 	%r769, %r540, 27;
	add.s32 	%r770, %r1, %r769;
	and.b32  	%r771, %r770, 536870880;
	sub.s32 	%r772, %r1, %r771;
	shl.b32 	%r773, %r772, 3;
	cvt.rn.f32.s32	%f464, %r773;
	mul.f32 	%f465, %f464, 0f3B000000;
	cvt.f64.f32	%fd25, %f465;
	mul.f64 	%fd26, %fd25, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f139, %fd26;
	mul.f32 	%f466, %f139, 0f3F22F983;
	cvt.rni.s32.f32	%r1142, %f466;
	cvt.rn.f32.s32	%f467, %r1142;
	fma.rn.f32 	%f469, %f467, %f254, %f139;
	fma.rn.f32 	%f471, %f467, %f256, %f469;
	fma.rn.f32 	%f671, %f467, %f258, %f471;
	abs.f32 	%f141, %f139;
	setp.leu.f32	%p95, %f141, 0f47CE4780;
	mov.u32 	%r1134, %r1142;
	mov.f32 	%f668, %f671;
	@%p95 bra 	BB5_139;

	setp.eq.f32	%p96, %f141, 0f7F800000;
	@%p96 bra 	BB5_138;
	bra.uni 	BB5_130;

BB5_138:
	mul.rn.f32 	%f668, %f139, %f259;
	mov.u32 	%r1134, %r1142;
	bra.uni 	BB5_139;

BB5_130:
	mov.b32 	 %r226, %f139;
	shl.b32 	%r776, %r226, 8;
	or.b32  	%r227, %r776, -2147483648;
	add.u64 	%rd167, %SP, 0;
	add.u64 	%rd252, %SPL, 0;
	mov.u32 	%r1128, 0;
	mov.u64 	%rd251, __cudart_i2opi_f;
	mov.u32 	%r1127, -6;

BB5_131:
	.pragma "nounroll";
	ld.const.u32 	%r779, [%rd251];
	// inline asm
	{
	mad.lo.cc.u32   %r777, %r779, %r227, %r1128;
	madc.hi.u32     %r1128, %r779, %r227,  0;
	}
	// inline asm
	st.local.u32 	[%rd252], %r777;
	add.s64 	%rd252, %rd252, 4;
	add.s64 	%rd251, %rd251, 4;
	add.s32 	%r1127, %r1127, 1;
	setp.ne.s32	%p97, %r1127, 0;
	@%p97 bra 	BB5_131;

	bfe.u32 	%r782, %r226, 23, 8;
	add.s32 	%r783, %r782, -128;
	shr.u32 	%r784, %r783, 5;
	and.b32  	%r232, %r226, -2147483648;
	cvta.to.local.u64 	%rd169, %rd167;
	st.local.u32 	[%rd169+24], %r1128;
	bfe.u32 	%r233, %r226, 23, 5;
	mov.u32 	%r785, 6;
	sub.s32 	%r786, %r785, %r784;
	mul.wide.s32 	%rd170, %r786, 4;
	add.s64 	%rd54, %rd169, %rd170;
	ld.local.u32 	%r1130, [%rd54];
	ld.local.u32 	%r1129, [%rd54+-4];
	setp.eq.s32	%p98, %r233, 0;
	@%p98 bra 	BB5_134;

	mov.u32 	%r787, 32;
	sub.s32 	%r788, %r787, %r233;
	shr.u32 	%r789, %r1129, %r788;
	shl.b32 	%r790, %r1130, %r233;
	add.s32 	%r1130, %r789, %r790;
	ld.local.u32 	%r791, [%rd54+-8];
	shr.u32 	%r792, %r791, %r788;
	shl.b32 	%r793, %r1129, %r233;
	add.s32 	%r1129, %r792, %r793;

BB5_134:
	shr.u32 	%r794, %r1129, 30;
	shl.b32 	%r795, %r1130, 2;
	add.s32 	%r1132, %r795, %r794;
	shl.b32 	%r241, %r1129, 2;
	shr.u32 	%r796, %r1132, 31;
	shr.u32 	%r797, %r1130, 30;
	add.s32 	%r242, %r796, %r797;
	setp.eq.s32	%p99, %r796, 0;
	@%p99 bra 	BB5_135;

	not.b32 	%r798, %r1132;
	neg.s32 	%r1131, %r241;
	setp.eq.s32	%p100, %r241, 0;
	selp.u32	%r799, 1, 0, %p100;
	add.s32 	%r1132, %r799, %r798;
	xor.b32  	%r1133, %r232, -2147483648;
	bra.uni 	BB5_137;

BB5_135:
	mov.u32 	%r1131, %r241;
	mov.u32 	%r1133, %r232;

BB5_137:
	cvt.u64.u32	%rd171, %r1132;
	cvt.u64.u32	%rd172, %r1131;
	bfi.b64 	%rd173, %rd171, %rd172, 32, 32;
	cvt.rn.f64.s64	%fd27, %rd173;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f473, %fd28;
	neg.f32 	%f474, %f473;
	setp.eq.s32	%p101, %r1133, 0;
	selp.f32	%f668, %f473, %f474, %p101;
	setp.eq.s32	%p102, %r232, 0;
	neg.s32 	%r800, %r242;
	selp.b32	%r1134, %r242, %r800, %p102;

BB5_139:
	add.s32 	%r251, %r1134, 1;
	and.b32  	%r252, %r251, 1;
	setp.eq.s32	%p103, %r252, 0;
	selp.f32	%f145, %f668, 0f3F800000, %p103;
	mul.rn.f32 	%f146, %f668, %f668;
	fma.rn.f32 	%f147, %f146, %f145, %f259;
	mov.f32 	%f669, 0fB94D4153;
	@%p103 bra 	BB5_141;

	mov.f32 	%f478, 0fBAB607ED;
	mov.f32 	%f479, 0f37CBAC00;
	fma.rn.f32 	%f669, %f479, %f146, %f478;

BB5_141:
	selp.f32	%f480, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f481, %f669, %f146, %f480;
	selp.f32	%f482, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f483, %f481, %f146, %f482;
	fma.rn.f32 	%f670, %f483, %f147, %f145;
	and.b32  	%r801, %r251, 2;
	setp.eq.s32	%p105, %r801, 0;
	@%p105 bra 	BB5_143;

	mov.f32 	%f485, 0fBF800000;
	fma.rn.f32 	%f670, %f670, %f485, %f259;

BB5_143:
	@%p95 bra 	BB5_154;

	setp.eq.f32	%p107, %f141, 0f7F800000;
	@%p107 bra 	BB5_153;
	bra.uni 	BB5_145;

BB5_153:
	mul.rn.f32 	%f671, %f139, %f259;
	bra.uni 	BB5_154;

BB5_145:
	mov.b32 	 %r253, %f139;
	shl.b32 	%r804, %r253, 8;
	or.b32  	%r254, %r804, -2147483648;
	add.u64 	%rd175, %SP, 0;
	add.u64 	%rd254, %SPL, 0;
	mov.u32 	%r1136, 0;
	mov.u64 	%rd253, __cudart_i2opi_f;
	mov.u32 	%r1135, -6;

BB5_146:
	.pragma "nounroll";
	ld.const.u32 	%r807, [%rd253];
	// inline asm
	{
	mad.lo.cc.u32   %r805, %r807, %r254, %r1136;
	madc.hi.u32     %r1136, %r807, %r254,  0;
	}
	// inline asm
	st.local.u32 	[%rd254], %r805;
	add.s64 	%rd254, %rd254, 4;
	add.s64 	%rd253, %rd253, 4;
	add.s32 	%r1135, %r1135, 1;
	setp.ne.s32	%p108, %r1135, 0;
	@%p108 bra 	BB5_146;

	bfe.u32 	%r810, %r253, 23, 8;
	add.s32 	%r811, %r810, -128;
	shr.u32 	%r812, %r811, 5;
	and.b32  	%r259, %r253, -2147483648;
	cvta.to.local.u64 	%rd177, %rd175;
	st.local.u32 	[%rd177+24], %r1136;
	bfe.u32 	%r260, %r253, 23, 5;
	mov.u32 	%r813, 6;
	sub.s32 	%r814, %r813, %r812;
	mul.wide.s32 	%rd178, %r814, 4;
	add.s64 	%rd60, %rd177, %rd178;
	ld.local.u32 	%r1138, [%rd60];
	ld.local.u32 	%r1137, [%rd60+-4];
	setp.eq.s32	%p109, %r260, 0;
	@%p109 bra 	BB5_149;

	mov.u32 	%r815, 32;
	sub.s32 	%r816, %r815, %r260;
	shr.u32 	%r817, %r1137, %r816;
	shl.b32 	%r818, %r1138, %r260;
	add.s32 	%r1138, %r817, %r818;
	ld.local.u32 	%r819, [%rd60+-8];
	shr.u32 	%r820, %r819, %r816;
	shl.b32 	%r821, %r1137, %r260;
	add.s32 	%r1137, %r820, %r821;

BB5_149:
	shr.u32 	%r822, %r1137, 30;
	shl.b32 	%r823, %r1138, 2;
	add.s32 	%r1140, %r823, %r822;
	shl.b32 	%r268, %r1137, 2;
	shr.u32 	%r824, %r1140, 31;
	shr.u32 	%r825, %r1138, 30;
	add.s32 	%r269, %r824, %r825;
	setp.eq.s32	%p110, %r824, 0;
	@%p110 bra 	BB5_150;

	not.b32 	%r826, %r1140;
	neg.s32 	%r1139, %r268;
	setp.eq.s32	%p111, %r268, 0;
	selp.u32	%r827, 1, 0, %p111;
	add.s32 	%r1140, %r827, %r826;
	xor.b32  	%r1141, %r259, -2147483648;
	bra.uni 	BB5_152;

BB5_150:
	mov.u32 	%r1139, %r268;
	mov.u32 	%r1141, %r259;

BB5_152:
	cvt.u64.u32	%rd179, %r1140;
	cvt.u64.u32	%rd180, %r1139;
	bfi.b64 	%rd181, %rd179, %rd180, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd181;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f486, %fd30;
	neg.f32 	%f487, %f486;
	setp.eq.s32	%p112, %r1141, 0;
	selp.f32	%f671, %f486, %f487, %p112;
	setp.eq.s32	%p113, %r259, 0;
	neg.s32 	%r828, %r269;
	selp.b32	%r1142, %r269, %r828, %p113;

BB5_154:
	and.b32  	%r278, %r1142, 1;
	setp.eq.s32	%p114, %r278, 0;
	selp.f32	%f156, %f671, 0f3F800000, %p114;
	mul.rn.f32 	%f157, %f671, %f671;
	fma.rn.f32 	%f158, %f157, %f156, %f259;
	mov.f32 	%f672, 0fB94D4153;
	@%p114 bra 	BB5_156;

	mov.f32 	%f491, 0fBAB607ED;
	mov.f32 	%f492, 0f37CBAC00;
	fma.rn.f32 	%f672, %f492, %f157, %f491;

BB5_156:
	selp.f32	%f493, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f494, %f672, %f157, %f493;
	selp.f32	%f495, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f496, %f494, %f157, %f495;
	fma.rn.f32 	%f673, %f496, %f158, %f156;
	and.b32  	%r829, %r1142, 2;
	setp.eq.s32	%p116, %r829, 0;
	@%p116 bra 	BB5_158;

	mov.f32 	%f498, 0fBF800000;
	fma.rn.f32 	%f673, %f673, %f498, %f259;

BB5_158:
	and.b32  	%r830, %r1, 31;
	and.b32  	%r832, %r526, 1073741760;
	add.s32 	%r833, %r832, %r830;
	mul.f32 	%f499, %f138, %f673;
	mul.f32 	%f500, %f137, %f670;
	sub.f32 	%f501, %f500, %f499;
	mul.f32 	%f502, %f138, %f670;
	fma.rn.f32 	%f503, %f137, %f673, %f502;
	add.f32 	%f504, %f135, %f501;
	shl.b32 	%r834, %r833, 2;
	add.s32 	%r836, %r531, %r834;
	st.shared.f32 	[%r836], %f504;
	add.f32 	%f505, %f136, %f503;
	add.s32 	%r838, %r533, %r834;
	st.shared.f32 	[%r838], %f505;
	sub.f32 	%f506, %f135, %f501;
	st.shared.f32 	[%r836+128], %f506;
	sub.f32 	%f507, %f136, %f503;
	st.shared.f32 	[%r838+128], %f507;
	bar.sync 	0;
	ld.shared.f32 	%f164, [%r537];
	ld.shared.f32 	%f165, [%r539];
	ld.shared.f32 	%f166, [%r537+1024];
	ld.shared.f32 	%f167, [%r539+1024];
	shr.u32 	%r845, %r540, 26;
	add.s32 	%r846, %r1, %r845;
	and.b32  	%r847, %r846, 1073741760;
	sub.s32 	%r848, %r1, %r847;
	shl.b32 	%r849, %r848, 2;
	cvt.rn.f32.s32	%f508, %r849;
	mul.f32 	%f509, %f508, 0f3B000000;
	cvt.f64.f32	%fd31, %f509;
	mul.f64 	%fd32, %fd31, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f168, %fd32;
	mul.f32 	%f510, %f168, 0f3F22F983;
	cvt.rni.s32.f32	%r1158, %f510;
	cvt.rn.f32.s32	%f511, %r1158;
	fma.rn.f32 	%f513, %f511, %f254, %f168;
	fma.rn.f32 	%f515, %f511, %f256, %f513;
	fma.rn.f32 	%f677, %f511, %f258, %f515;
	abs.f32 	%f170, %f168;
	setp.leu.f32	%p117, %f170, 0f47CE4780;
	mov.u32 	%r1150, %r1158;
	mov.f32 	%f674, %f677;
	@%p117 bra 	BB5_169;

	setp.eq.f32	%p118, %f170, 0f7F800000;
	@%p118 bra 	BB5_168;
	bra.uni 	BB5_160;

BB5_168:
	mul.rn.f32 	%f674, %f168, %f259;
	mov.u32 	%r1150, %r1158;
	bra.uni 	BB5_169;

BB5_160:
	mov.b32 	 %r281, %f168;
	shl.b32 	%r852, %r281, 8;
	or.b32  	%r282, %r852, -2147483648;
	add.u64 	%rd183, %SP, 0;
	add.u64 	%rd256, %SPL, 0;
	mov.u32 	%r1144, 0;
	mov.u64 	%rd255, __cudart_i2opi_f;
	mov.u32 	%r1143, -6;

BB5_161:
	.pragma "nounroll";
	ld.const.u32 	%r855, [%rd255];
	// inline asm
	{
	mad.lo.cc.u32   %r853, %r855, %r282, %r1144;
	madc.hi.u32     %r1144, %r855, %r282,  0;
	}
	// inline asm
	st.local.u32 	[%rd256], %r853;
	add.s64 	%rd256, %rd256, 4;
	add.s64 	%rd255, %rd255, 4;
	add.s32 	%r1143, %r1143, 1;
	setp.ne.s32	%p119, %r1143, 0;
	@%p119 bra 	BB5_161;

	bfe.u32 	%r858, %r281, 23, 8;
	add.s32 	%r859, %r858, -128;
	shr.u32 	%r860, %r859, 5;
	and.b32  	%r287, %r281, -2147483648;
	cvta.to.local.u64 	%rd185, %rd183;
	st.local.u32 	[%rd185+24], %r1144;
	bfe.u32 	%r288, %r281, 23, 5;
	mov.u32 	%r861, 6;
	sub.s32 	%r862, %r861, %r860;
	mul.wide.s32 	%rd186, %r862, 4;
	add.s64 	%rd66, %rd185, %rd186;
	ld.local.u32 	%r1146, [%rd66];
	ld.local.u32 	%r1145, [%rd66+-4];
	setp.eq.s32	%p120, %r288, 0;
	@%p120 bra 	BB5_164;

	mov.u32 	%r863, 32;
	sub.s32 	%r864, %r863, %r288;
	shr.u32 	%r865, %r1145, %r864;
	shl.b32 	%r866, %r1146, %r288;
	add.s32 	%r1146, %r865, %r866;
	ld.local.u32 	%r867, [%rd66+-8];
	shr.u32 	%r868, %r867, %r864;
	shl.b32 	%r869, %r1145, %r288;
	add.s32 	%r1145, %r868, %r869;

BB5_164:
	shr.u32 	%r870, %r1145, 30;
	shl.b32 	%r871, %r1146, 2;
	add.s32 	%r1148, %r871, %r870;
	shl.b32 	%r296, %r1145, 2;
	shr.u32 	%r872, %r1148, 31;
	shr.u32 	%r873, %r1146, 30;
	add.s32 	%r297, %r872, %r873;
	setp.eq.s32	%p121, %r872, 0;
	@%p121 bra 	BB5_165;

	not.b32 	%r874, %r1148;
	neg.s32 	%r1147, %r296;
	setp.eq.s32	%p122, %r296, 0;
	selp.u32	%r875, 1, 0, %p122;
	add.s32 	%r1148, %r875, %r874;
	xor.b32  	%r1149, %r287, -2147483648;
	bra.uni 	BB5_167;

BB5_165:
	mov.u32 	%r1147, %r296;
	mov.u32 	%r1149, %r287;

BB5_167:
	cvt.u64.u32	%rd187, %r1148;
	cvt.u64.u32	%rd188, %r1147;
	bfi.b64 	%rd189, %rd187, %rd188, 32, 32;
	cvt.rn.f64.s64	%fd33, %rd189;
	mul.f64 	%fd34, %fd33, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f517, %fd34;
	neg.f32 	%f518, %f517;
	setp.eq.s32	%p123, %r1149, 0;
	selp.f32	%f674, %f517, %f518, %p123;
	setp.eq.s32	%p124, %r287, 0;
	neg.s32 	%r876, %r297;
	selp.b32	%r1150, %r297, %r876, %p124;

BB5_169:
	add.s32 	%r306, %r1150, 1;
	and.b32  	%r307, %r306, 1;
	setp.eq.s32	%p125, %r307, 0;
	selp.f32	%f174, %f674, 0f3F800000, %p125;
	mul.rn.f32 	%f175, %f674, %f674;
	fma.rn.f32 	%f176, %f175, %f174, %f259;
	mov.f32 	%f675, 0fB94D4153;
	@%p125 bra 	BB5_171;

	mov.f32 	%f522, 0fBAB607ED;
	mov.f32 	%f523, 0f37CBAC00;
	fma.rn.f32 	%f675, %f523, %f175, %f522;

BB5_171:
	selp.f32	%f524, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f525, %f675, %f175, %f524;
	selp.f32	%f526, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f527, %f525, %f175, %f526;
	fma.rn.f32 	%f676, %f527, %f176, %f174;
	and.b32  	%r877, %r306, 2;
	setp.eq.s32	%p127, %r877, 0;
	@%p127 bra 	BB5_173;

	mov.f32 	%f529, 0fBF800000;
	fma.rn.f32 	%f676, %f676, %f529, %f259;

BB5_173:
	@%p117 bra 	BB5_184;

	setp.eq.f32	%p129, %f170, 0f7F800000;
	@%p129 bra 	BB5_183;
	bra.uni 	BB5_175;

BB5_183:
	mul.rn.f32 	%f677, %f168, %f259;
	bra.uni 	BB5_184;

BB5_175:
	mov.b32 	 %r308, %f168;
	shl.b32 	%r880, %r308, 8;
	or.b32  	%r309, %r880, -2147483648;
	add.u64 	%rd191, %SP, 0;
	add.u64 	%rd258, %SPL, 0;
	mov.u32 	%r1152, 0;
	mov.u64 	%rd257, __cudart_i2opi_f;
	mov.u32 	%r1151, -6;

BB5_176:
	.pragma "nounroll";
	ld.const.u32 	%r883, [%rd257];
	// inline asm
	{
	mad.lo.cc.u32   %r881, %r883, %r309, %r1152;
	madc.hi.u32     %r1152, %r883, %r309,  0;
	}
	// inline asm
	st.local.u32 	[%rd258], %r881;
	add.s64 	%rd258, %rd258, 4;
	add.s64 	%rd257, %rd257, 4;
	add.s32 	%r1151, %r1151, 1;
	setp.ne.s32	%p130, %r1151, 0;
	@%p130 bra 	BB5_176;

	bfe.u32 	%r886, %r308, 23, 8;
	add.s32 	%r887, %r886, -128;
	shr.u32 	%r888, %r887, 5;
	and.b32  	%r314, %r308, -2147483648;
	cvta.to.local.u64 	%rd193, %rd191;
	st.local.u32 	[%rd193+24], %r1152;
	bfe.u32 	%r315, %r308, 23, 5;
	mov.u32 	%r889, 6;
	sub.s32 	%r890, %r889, %r888;
	mul.wide.s32 	%rd194, %r890, 4;
	add.s64 	%rd72, %rd193, %rd194;
	ld.local.u32 	%r1154, [%rd72];
	ld.local.u32 	%r1153, [%rd72+-4];
	setp.eq.s32	%p131, %r315, 0;
	@%p131 bra 	BB5_179;

	mov.u32 	%r891, 32;
	sub.s32 	%r892, %r891, %r315;
	shr.u32 	%r893, %r1153, %r892;
	shl.b32 	%r894, %r1154, %r315;
	add.s32 	%r1154, %r893, %r894;
	ld.local.u32 	%r895, [%rd72+-8];
	shr.u32 	%r896, %r895, %r892;
	shl.b32 	%r897, %r1153, %r315;
	add.s32 	%r1153, %r896, %r897;

BB5_179:
	shr.u32 	%r898, %r1153, 30;
	shl.b32 	%r899, %r1154, 2;
	add.s32 	%r1156, %r899, %r898;
	shl.b32 	%r323, %r1153, 2;
	shr.u32 	%r900, %r1156, 31;
	shr.u32 	%r901, %r1154, 30;
	add.s32 	%r324, %r900, %r901;
	setp.eq.s32	%p132, %r900, 0;
	@%p132 bra 	BB5_180;

	not.b32 	%r902, %r1156;
	neg.s32 	%r1155, %r323;
	setp.eq.s32	%p133, %r323, 0;
	selp.u32	%r903, 1, 0, %p133;
	add.s32 	%r1156, %r903, %r902;
	xor.b32  	%r1157, %r314, -2147483648;
	bra.uni 	BB5_182;

BB5_180:
	mov.u32 	%r1155, %r323;
	mov.u32 	%r1157, %r314;

BB5_182:
	cvt.u64.u32	%rd195, %r1156;
	cvt.u64.u32	%rd196, %r1155;
	bfi.b64 	%rd197, %rd195, %rd196, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd197;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f530, %fd36;
	neg.f32 	%f531, %f530;
	setp.eq.s32	%p134, %r1157, 0;
	selp.f32	%f677, %f530, %f531, %p134;
	setp.eq.s32	%p135, %r314, 0;
	neg.s32 	%r904, %r324;
	selp.b32	%r1158, %r324, %r904, %p135;

BB5_184:
	and.b32  	%r333, %r1158, 1;
	setp.eq.s32	%p136, %r333, 0;
	selp.f32	%f185, %f677, 0f3F800000, %p136;
	mul.rn.f32 	%f186, %f677, %f677;
	fma.rn.f32 	%f187, %f186, %f185, %f259;
	mov.f32 	%f678, 0fB94D4153;
	@%p136 bra 	BB5_186;

	mov.f32 	%f535, 0fBAB607ED;
	mov.f32 	%f536, 0f37CBAC00;
	fma.rn.f32 	%f678, %f536, %f186, %f535;

BB5_186:
	selp.f32	%f537, 0f3C0885E4, 0f3D2AAABB, %p136;
	fma.rn.f32 	%f538, %f678, %f186, %f537;
	selp.f32	%f539, 0fBE2AAAA8, 0fBEFFFFFF, %p136;
	fma.rn.f32 	%f540, %f538, %f186, %f539;
	fma.rn.f32 	%f679, %f540, %f187, %f185;
	and.b32  	%r905, %r1158, 2;
	setp.eq.s32	%p138, %r905, 0;
	@%p138 bra 	BB5_188;

	mov.f32 	%f542, 0fBF800000;
	fma.rn.f32 	%f679, %f679, %f542, %f259;

BB5_188:
	and.b32  	%r906, %r1, 63;
	and.b32  	%r908, %r526, 1073741696;
	add.s32 	%r909, %r908, %r906;
	mul.f32 	%f543, %f167, %f679;
	mul.f32 	%f544, %f166, %f676;
	sub.f32 	%f545, %f544, %f543;
	mul.f32 	%f546, %f167, %f676;
	fma.rn.f32 	%f547, %f166, %f679, %f546;
	add.f32 	%f548, %f164, %f545;
	shl.b32 	%r910, %r909, 2;
	add.s32 	%r912, %r454, %r910;
	st.shared.f32 	[%r912], %f548;
	add.f32 	%f549, %f165, %f547;
	add.s32 	%r914, %r456, %r910;
	st.shared.f32 	[%r914], %f549;
	sub.f32 	%f550, %f164, %f545;
	st.shared.f32 	[%r912+256], %f550;
	sub.f32 	%f551, %f165, %f547;
	st.shared.f32 	[%r914+256], %f551;
	bar.sync 	0;
	ld.shared.f32 	%f193, [%r460];
	ld.shared.f32 	%f194, [%r462];
	ld.shared.f32 	%f195, [%r460+1024];
	ld.shared.f32 	%f196, [%r462+1024];
	shr.u32 	%r921, %r540, 25;
	add.s32 	%r922, %r1, %r921;
	and.b32  	%r923, %r922, 2147483520;
	sub.s32 	%r924, %r1, %r923;
	shl.b32 	%r925, %r924, 1;
	cvt.rn.f32.s32	%f552, %r925;
	mul.f32 	%f553, %f552, 0f3B000000;
	cvt.f64.f32	%fd37, %f553;
	mul.f64 	%fd38, %fd37, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f197, %fd38;
	mul.f32 	%f554, %f197, 0f3F22F983;
	cvt.rni.s32.f32	%r1174, %f554;
	cvt.rn.f32.s32	%f555, %r1174;
	fma.rn.f32 	%f557, %f555, %f254, %f197;
	fma.rn.f32 	%f559, %f555, %f256, %f557;
	fma.rn.f32 	%f683, %f555, %f258, %f559;
	abs.f32 	%f199, %f197;
	setp.leu.f32	%p139, %f199, 0f47CE4780;
	mov.u32 	%r1166, %r1174;
	mov.f32 	%f680, %f683;
	@%p139 bra 	BB5_199;

	setp.eq.f32	%p140, %f199, 0f7F800000;
	@%p140 bra 	BB5_198;
	bra.uni 	BB5_190;

BB5_198:
	mul.rn.f32 	%f680, %f197, %f259;
	mov.u32 	%r1166, %r1174;
	bra.uni 	BB5_199;

BB5_190:
	mov.b32 	 %r336, %f197;
	shl.b32 	%r928, %r336, 8;
	or.b32  	%r337, %r928, -2147483648;
	add.u64 	%rd199, %SP, 0;
	add.u64 	%rd260, %SPL, 0;
	mov.u32 	%r1160, 0;
	mov.u64 	%rd259, __cudart_i2opi_f;
	mov.u32 	%r1159, -6;

BB5_191:
	.pragma "nounroll";
	ld.const.u32 	%r931, [%rd259];
	// inline asm
	{
	mad.lo.cc.u32   %r929, %r931, %r337, %r1160;
	madc.hi.u32     %r1160, %r931, %r337,  0;
	}
	// inline asm
	st.local.u32 	[%rd260], %r929;
	add.s64 	%rd260, %rd260, 4;
	add.s64 	%rd259, %rd259, 4;
	add.s32 	%r1159, %r1159, 1;
	setp.ne.s32	%p141, %r1159, 0;
	@%p141 bra 	BB5_191;

	bfe.u32 	%r934, %r336, 23, 8;
	add.s32 	%r935, %r934, -128;
	shr.u32 	%r936, %r935, 5;
	and.b32  	%r342, %r336, -2147483648;
	cvta.to.local.u64 	%rd201, %rd199;
	st.local.u32 	[%rd201+24], %r1160;
	bfe.u32 	%r343, %r336, 23, 5;
	mov.u32 	%r937, 6;
	sub.s32 	%r938, %r937, %r936;
	mul.wide.s32 	%rd202, %r938, 4;
	add.s64 	%rd78, %rd201, %rd202;
	ld.local.u32 	%r1162, [%rd78];
	ld.local.u32 	%r1161, [%rd78+-4];
	setp.eq.s32	%p142, %r343, 0;
	@%p142 bra 	BB5_194;

	mov.u32 	%r939, 32;
	sub.s32 	%r940, %r939, %r343;
	shr.u32 	%r941, %r1161, %r940;
	shl.b32 	%r942, %r1162, %r343;
	add.s32 	%r1162, %r941, %r942;
	ld.local.u32 	%r943, [%rd78+-8];
	shr.u32 	%r944, %r943, %r940;
	shl.b32 	%r945, %r1161, %r343;
	add.s32 	%r1161, %r944, %r945;

BB5_194:
	shr.u32 	%r946, %r1161, 30;
	shl.b32 	%r947, %r1162, 2;
	add.s32 	%r1164, %r947, %r946;
	shl.b32 	%r351, %r1161, 2;
	shr.u32 	%r948, %r1164, 31;
	shr.u32 	%r949, %r1162, 30;
	add.s32 	%r352, %r948, %r949;
	setp.eq.s32	%p143, %r948, 0;
	@%p143 bra 	BB5_195;

	not.b32 	%r950, %r1164;
	neg.s32 	%r1163, %r351;
	setp.eq.s32	%p144, %r351, 0;
	selp.u32	%r951, 1, 0, %p144;
	add.s32 	%r1164, %r951, %r950;
	xor.b32  	%r1165, %r342, -2147483648;
	bra.uni 	BB5_197;

BB5_195:
	mov.u32 	%r1163, %r351;
	mov.u32 	%r1165, %r342;

BB5_197:
	cvt.u64.u32	%rd203, %r1164;
	cvt.u64.u32	%rd204, %r1163;
	bfi.b64 	%rd205, %rd203, %rd204, 32, 32;
	cvt.rn.f64.s64	%fd39, %rd205;
	mul.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f561, %fd40;
	neg.f32 	%f562, %f561;
	setp.eq.s32	%p145, %r1165, 0;
	selp.f32	%f680, %f561, %f562, %p145;
	setp.eq.s32	%p146, %r342, 0;
	neg.s32 	%r952, %r352;
	selp.b32	%r1166, %r352, %r952, %p146;

BB5_199:
	add.s32 	%r361, %r1166, 1;
	and.b32  	%r362, %r361, 1;
	setp.eq.s32	%p147, %r362, 0;
	selp.f32	%f203, %f680, 0f3F800000, %p147;
	mul.rn.f32 	%f204, %f680, %f680;
	fma.rn.f32 	%f205, %f204, %f203, %f259;
	mov.f32 	%f681, 0fB94D4153;
	@%p147 bra 	BB5_201;

	mov.f32 	%f566, 0fBAB607ED;
	mov.f32 	%f567, 0f37CBAC00;
	fma.rn.f32 	%f681, %f567, %f204, %f566;

BB5_201:
	selp.f32	%f568, 0f3C0885E4, 0f3D2AAABB, %p147;
	fma.rn.f32 	%f569, %f681, %f204, %f568;
	selp.f32	%f570, 0fBE2AAAA8, 0fBEFFFFFF, %p147;
	fma.rn.f32 	%f571, %f569, %f204, %f570;
	fma.rn.f32 	%f682, %f571, %f205, %f203;
	and.b32  	%r953, %r361, 2;
	setp.eq.s32	%p149, %r953, 0;
	@%p149 bra 	BB5_203;

	mov.f32 	%f573, 0fBF800000;
	fma.rn.f32 	%f682, %f682, %f573, %f259;

BB5_203:
	@%p139 bra 	BB5_214;

	setp.eq.f32	%p151, %f199, 0f7F800000;
	@%p151 bra 	BB5_213;
	bra.uni 	BB5_205;

BB5_213:
	mul.rn.f32 	%f683, %f197, %f259;
	bra.uni 	BB5_214;

BB5_205:
	mov.b32 	 %r363, %f197;
	shl.b32 	%r956, %r363, 8;
	or.b32  	%r364, %r956, -2147483648;
	add.u64 	%rd207, %SP, 0;
	add.u64 	%rd262, %SPL, 0;
	mov.u32 	%r1168, 0;
	mov.u64 	%rd261, __cudart_i2opi_f;
	mov.u32 	%r1167, -6;

BB5_206:
	.pragma "nounroll";
	ld.const.u32 	%r959, [%rd261];
	// inline asm
	{
	mad.lo.cc.u32   %r957, %r959, %r364, %r1168;
	madc.hi.u32     %r1168, %r959, %r364,  0;
	}
	// inline asm
	st.local.u32 	[%rd262], %r957;
	add.s64 	%rd262, %rd262, 4;
	add.s64 	%rd261, %rd261, 4;
	add.s32 	%r1167, %r1167, 1;
	setp.ne.s32	%p152, %r1167, 0;
	@%p152 bra 	BB5_206;

	bfe.u32 	%r962, %r363, 23, 8;
	add.s32 	%r963, %r962, -128;
	shr.u32 	%r964, %r963, 5;
	and.b32  	%r369, %r363, -2147483648;
	cvta.to.local.u64 	%rd209, %rd207;
	st.local.u32 	[%rd209+24], %r1168;
	bfe.u32 	%r370, %r363, 23, 5;
	mov.u32 	%r965, 6;
	sub.s32 	%r966, %r965, %r964;
	mul.wide.s32 	%rd210, %r966, 4;
	add.s64 	%rd84, %rd209, %rd210;
	ld.local.u32 	%r1170, [%rd84];
	ld.local.u32 	%r1169, [%rd84+-4];
	setp.eq.s32	%p153, %r370, 0;
	@%p153 bra 	BB5_209;

	mov.u32 	%r967, 32;
	sub.s32 	%r968, %r967, %r370;
	shr.u32 	%r969, %r1169, %r968;
	shl.b32 	%r970, %r1170, %r370;
	add.s32 	%r1170, %r969, %r970;
	ld.local.u32 	%r971, [%rd84+-8];
	shr.u32 	%r972, %r971, %r968;
	shl.b32 	%r973, %r1169, %r370;
	add.s32 	%r1169, %r972, %r973;

BB5_209:
	shr.u32 	%r974, %r1169, 30;
	shl.b32 	%r975, %r1170, 2;
	add.s32 	%r1172, %r975, %r974;
	shl.b32 	%r378, %r1169, 2;
	shr.u32 	%r976, %r1172, 31;
	shr.u32 	%r977, %r1170, 30;
	add.s32 	%r379, %r976, %r977;
	setp.eq.s32	%p154, %r976, 0;
	@%p154 bra 	BB5_210;

	not.b32 	%r978, %r1172;
	neg.s32 	%r1171, %r378;
	setp.eq.s32	%p155, %r378, 0;
	selp.u32	%r979, 1, 0, %p155;
	add.s32 	%r1172, %r979, %r978;
	xor.b32  	%r1173, %r369, -2147483648;
	bra.uni 	BB5_212;

BB5_210:
	mov.u32 	%r1171, %r378;
	mov.u32 	%r1173, %r369;

BB5_212:
	cvt.u64.u32	%rd211, %r1172;
	cvt.u64.u32	%rd212, %r1171;
	bfi.b64 	%rd213, %rd211, %rd212, 32, 32;
	cvt.rn.f64.s64	%fd41, %rd213;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f574, %fd42;
	neg.f32 	%f575, %f574;
	setp.eq.s32	%p156, %r1173, 0;
	selp.f32	%f683, %f574, %f575, %p156;
	setp.eq.s32	%p157, %r369, 0;
	neg.s32 	%r980, %r379;
	selp.b32	%r1174, %r379, %r980, %p157;

BB5_214:
	and.b32  	%r388, %r1174, 1;
	setp.eq.s32	%p158, %r388, 0;
	selp.f32	%f214, %f683, 0f3F800000, %p158;
	mul.rn.f32 	%f215, %f683, %f683;
	fma.rn.f32 	%f216, %f215, %f214, %f259;
	mov.f32 	%f684, 0fB94D4153;
	@%p158 bra 	BB5_216;

	mov.f32 	%f579, 0fBAB607ED;
	mov.f32 	%f580, 0f37CBAC00;
	fma.rn.f32 	%f684, %f580, %f215, %f579;

BB5_216:
	selp.f32	%f581, 0f3C0885E4, 0f3D2AAABB, %p158;
	fma.rn.f32 	%f582, %f684, %f215, %f581;
	selp.f32	%f583, 0fBE2AAAA8, 0fBEFFFFFF, %p158;
	fma.rn.f32 	%f584, %f582, %f215, %f583;
	fma.rn.f32 	%f685, %f584, %f216, %f214;
	and.b32  	%r981, %r1174, 2;
	setp.eq.s32	%p160, %r981, 0;
	@%p160 bra 	BB5_218;

	mov.f32 	%f586, 0fBF800000;
	fma.rn.f32 	%f685, %f685, %f586, %f259;

BB5_218:
	and.b32  	%r982, %r1, 127;
	and.b32  	%r984, %r526, 1073741568;
	add.s32 	%r985, %r984, %r982;
	mul.f32 	%f587, %f196, %f685;
	mul.f32 	%f588, %f195, %f682;
	sub.f32 	%f589, %f588, %f587;
	mul.f32 	%f590, %f196, %f682;
	fma.rn.f32 	%f591, %f195, %f685, %f590;
	add.f32 	%f592, %f193, %f589;
	shl.b32 	%r986, %r985, 2;
	add.s32 	%r988, %r531, %r986;
	st.shared.f32 	[%r988], %f592;
	add.f32 	%f593, %f194, %f591;
	add.s32 	%r990, %r533, %r986;
	st.shared.f32 	[%r990], %f593;
	sub.f32 	%f594, %f193, %f589;
	st.shared.f32 	[%r988+512], %f594;
	sub.f32 	%f595, %f194, %f591;
	st.shared.f32 	[%r990+512], %f595;
	bar.sync 	0;
	ld.shared.f32 	%f222, [%r537];
	ld.shared.f32 	%f223, [%r539];
	ld.shared.f32 	%f224, [%r537+1024];
	ld.shared.f32 	%f225, [%r539+1024];
	shr.u32 	%r997, %r540, 24;
	add.s32 	%r998, %r1, %r997;
	and.b32  	%r999, %r998, -256;
	sub.s32 	%r1000, %r1, %r999;
	cvt.rn.f32.s32	%f596, %r1000;
	mul.f32 	%f597, %f596, 0f3B000000;
	cvt.f64.f32	%fd43, %f597;
	mul.f64 	%fd44, %fd43, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f226, %fd44;
	mul.f32 	%f598, %f226, 0f3F22F983;
	cvt.rni.s32.f32	%r1190, %f598;
	cvt.rn.f32.s32	%f599, %r1190;
	fma.rn.f32 	%f601, %f599, %f254, %f226;
	fma.rn.f32 	%f603, %f599, %f256, %f601;
	fma.rn.f32 	%f689, %f599, %f258, %f603;
	abs.f32 	%f228, %f226;
	setp.leu.f32	%p161, %f228, 0f47CE4780;
	mov.u32 	%r1182, %r1190;
	mov.f32 	%f686, %f689;
	@%p161 bra 	BB5_229;

	setp.eq.f32	%p162, %f228, 0f7F800000;
	@%p162 bra 	BB5_228;
	bra.uni 	BB5_220;

BB5_228:
	mul.rn.f32 	%f686, %f226, %f259;
	mov.u32 	%r1182, %r1190;
	bra.uni 	BB5_229;

BB5_220:
	mov.b32 	 %r391, %f226;
	shl.b32 	%r1003, %r391, 8;
	or.b32  	%r392, %r1003, -2147483648;
	add.u64 	%rd215, %SP, 0;
	add.u64 	%rd264, %SPL, 0;
	mov.u32 	%r1176, 0;
	mov.u64 	%rd263, __cudart_i2opi_f;
	mov.u32 	%r1175, -6;

BB5_221:
	.pragma "nounroll";
	ld.const.u32 	%r1006, [%rd263];
	// inline asm
	{
	mad.lo.cc.u32   %r1004, %r1006, %r392, %r1176;
	madc.hi.u32     %r1176, %r1006, %r392,  0;
	}
	// inline asm
	st.local.u32 	[%rd264], %r1004;
	add.s64 	%rd264, %rd264, 4;
	add.s64 	%rd263, %rd263, 4;
	add.s32 	%r1175, %r1175, 1;
	setp.ne.s32	%p163, %r1175, 0;
	@%p163 bra 	BB5_221;

	bfe.u32 	%r1009, %r391, 23, 8;
	add.s32 	%r1010, %r1009, -128;
	shr.u32 	%r1011, %r1010, 5;
	and.b32  	%r397, %r391, -2147483648;
	cvta.to.local.u64 	%rd217, %rd215;
	st.local.u32 	[%rd217+24], %r1176;
	bfe.u32 	%r398, %r391, 23, 5;
	mov.u32 	%r1012, 6;
	sub.s32 	%r1013, %r1012, %r1011;
	mul.wide.s32 	%rd218, %r1013, 4;
	add.s64 	%rd90, %rd217, %rd218;
	ld.local.u32 	%r1178, [%rd90];
	ld.local.u32 	%r1177, [%rd90+-4];
	setp.eq.s32	%p164, %r398, 0;
	@%p164 bra 	BB5_224;

	mov.u32 	%r1014, 32;
	sub.s32 	%r1015, %r1014, %r398;
	shr.u32 	%r1016, %r1177, %r1015;
	shl.b32 	%r1017, %r1178, %r398;
	add.s32 	%r1178, %r1016, %r1017;
	ld.local.u32 	%r1018, [%rd90+-8];
	shr.u32 	%r1019, %r1018, %r1015;
	shl.b32 	%r1020, %r1177, %r398;
	add.s32 	%r1177, %r1019, %r1020;

BB5_224:
	shr.u32 	%r1021, %r1177, 30;
	shl.b32 	%r1022, %r1178, 2;
	add.s32 	%r1180, %r1022, %r1021;
	shl.b32 	%r406, %r1177, 2;
	shr.u32 	%r1023, %r1180, 31;
	shr.u32 	%r1024, %r1178, 30;
	add.s32 	%r407, %r1023, %r1024;
	setp.eq.s32	%p165, %r1023, 0;
	@%p165 bra 	BB5_225;

	not.b32 	%r1025, %r1180;
	neg.s32 	%r1179, %r406;
	setp.eq.s32	%p166, %r406, 0;
	selp.u32	%r1026, 1, 0, %p166;
	add.s32 	%r1180, %r1026, %r1025;
	xor.b32  	%r1181, %r397, -2147483648;
	bra.uni 	BB5_227;

BB5_225:
	mov.u32 	%r1179, %r406;
	mov.u32 	%r1181, %r397;

BB5_227:
	cvt.u64.u32	%rd219, %r1180;
	cvt.u64.u32	%rd220, %r1179;
	bfi.b64 	%rd221, %rd219, %rd220, 32, 32;
	cvt.rn.f64.s64	%fd45, %rd221;
	mul.f64 	%fd46, %fd45, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f605, %fd46;
	neg.f32 	%f606, %f605;
	setp.eq.s32	%p167, %r1181, 0;
	selp.f32	%f686, %f605, %f606, %p167;
	setp.eq.s32	%p168, %r397, 0;
	neg.s32 	%r1027, %r407;
	selp.b32	%r1182, %r407, %r1027, %p168;

BB5_229:
	add.s32 	%r416, %r1182, 1;
	and.b32  	%r417, %r416, 1;
	setp.eq.s32	%p169, %r417, 0;
	selp.f32	%f232, %f686, 0f3F800000, %p169;
	mul.rn.f32 	%f233, %f686, %f686;
	fma.rn.f32 	%f234, %f233, %f232, %f259;
	mov.f32 	%f687, 0fB94D4153;
	@%p169 bra 	BB5_231;

	mov.f32 	%f610, 0fBAB607ED;
	mov.f32 	%f611, 0f37CBAC00;
	fma.rn.f32 	%f687, %f611, %f233, %f610;

BB5_231:
	selp.f32	%f612, 0f3C0885E4, 0f3D2AAABB, %p169;
	fma.rn.f32 	%f613, %f687, %f233, %f612;
	selp.f32	%f614, 0fBE2AAAA8, 0fBEFFFFFF, %p169;
	fma.rn.f32 	%f615, %f613, %f233, %f614;
	fma.rn.f32 	%f688, %f615, %f234, %f232;
	and.b32  	%r1028, %r416, 2;
	setp.eq.s32	%p171, %r1028, 0;
	@%p171 bra 	BB5_233;

	mov.f32 	%f617, 0fBF800000;
	fma.rn.f32 	%f688, %f688, %f617, %f259;

BB5_233:
	@%p161 bra 	BB5_244;

	setp.eq.f32	%p173, %f228, 0f7F800000;
	@%p173 bra 	BB5_243;
	bra.uni 	BB5_235;

BB5_243:
	mul.rn.f32 	%f689, %f226, %f259;
	bra.uni 	BB5_244;

BB5_235:
	mov.b32 	 %r418, %f226;
	shl.b32 	%r1031, %r418, 8;
	or.b32  	%r419, %r1031, -2147483648;
	add.u64 	%rd223, %SP, 0;
	add.u64 	%rd266, %SPL, 0;
	mov.u32 	%r1184, 0;
	mov.u64 	%rd265, __cudart_i2opi_f;
	mov.u32 	%r1183, -6;

BB5_236:
	.pragma "nounroll";
	ld.const.u32 	%r1034, [%rd265];
	// inline asm
	{
	mad.lo.cc.u32   %r1032, %r1034, %r419, %r1184;
	madc.hi.u32     %r1184, %r1034, %r419,  0;
	}
	// inline asm
	st.local.u32 	[%rd266], %r1032;
	add.s64 	%rd266, %rd266, 4;
	add.s64 	%rd265, %rd265, 4;
	add.s32 	%r1183, %r1183, 1;
	setp.ne.s32	%p174, %r1183, 0;
	@%p174 bra 	BB5_236;

	bfe.u32 	%r1037, %r418, 23, 8;
	add.s32 	%r1038, %r1037, -128;
	shr.u32 	%r1039, %r1038, 5;
	and.b32  	%r424, %r418, -2147483648;
	cvta.to.local.u64 	%rd225, %rd223;
	st.local.u32 	[%rd225+24], %r1184;
	bfe.u32 	%r425, %r418, 23, 5;
	mov.u32 	%r1040, 6;
	sub.s32 	%r1041, %r1040, %r1039;
	mul.wide.s32 	%rd226, %r1041, 4;
	add.s64 	%rd96, %rd225, %rd226;
	ld.local.u32 	%r1186, [%rd96];
	ld.local.u32 	%r1185, [%rd96+-4];
	setp.eq.s32	%p175, %r425, 0;
	@%p175 bra 	BB5_239;

	mov.u32 	%r1042, 32;
	sub.s32 	%r1043, %r1042, %r425;
	shr.u32 	%r1044, %r1185, %r1043;
	shl.b32 	%r1045, %r1186, %r425;
	add.s32 	%r1186, %r1044, %r1045;
	ld.local.u32 	%r1046, [%rd96+-8];
	shr.u32 	%r1047, %r1046, %r1043;
	shl.b32 	%r1048, %r1185, %r425;
	add.s32 	%r1185, %r1047, %r1048;

BB5_239:
	shr.u32 	%r1049, %r1185, 30;
	shl.b32 	%r1050, %r1186, 2;
	add.s32 	%r1188, %r1050, %r1049;
	shl.b32 	%r433, %r1185, 2;
	shr.u32 	%r1051, %r1188, 31;
	shr.u32 	%r1052, %r1186, 30;
	add.s32 	%r434, %r1051, %r1052;
	setp.eq.s32	%p176, %r1051, 0;
	@%p176 bra 	BB5_240;

	not.b32 	%r1053, %r1188;
	neg.s32 	%r1187, %r433;
	setp.eq.s32	%p177, %r433, 0;
	selp.u32	%r1054, 1, 0, %p177;
	add.s32 	%r1188, %r1054, %r1053;
	xor.b32  	%r1189, %r424, -2147483648;
	bra.uni 	BB5_242;

BB5_240:
	mov.u32 	%r1187, %r433;
	mov.u32 	%r1189, %r424;

BB5_242:
	cvt.u64.u32	%rd227, %r1188;
	cvt.u64.u32	%rd228, %r1187;
	bfi.b64 	%rd229, %rd227, %rd228, 32, 32;
	cvt.rn.f64.s64	%fd47, %rd229;
	mul.f64 	%fd48, %fd47, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f618, %fd48;
	neg.f32 	%f619, %f618;
	setp.eq.s32	%p178, %r1189, 0;
	selp.f32	%f689, %f618, %f619, %p178;
	setp.eq.s32	%p179, %r424, 0;
	neg.s32 	%r1055, %r434;
	selp.b32	%r1190, %r434, %r1055, %p179;

BB5_244:
	and.b32  	%r443, %r1190, 1;
	setp.eq.s32	%p180, %r443, 0;
	selp.f32	%f243, %f689, 0f3F800000, %p180;
	mul.rn.f32 	%f244, %f689, %f689;
	fma.rn.f32 	%f245, %f244, %f243, %f259;
	mov.f32 	%f690, 0fB94D4153;
	@%p180 bra 	BB5_246;

	mov.f32 	%f623, 0fBAB607ED;
	mov.f32 	%f624, 0f37CBAC00;
	fma.rn.f32 	%f690, %f624, %f244, %f623;

BB5_246:
	selp.f32	%f625, 0f3C0885E4, 0f3D2AAABB, %p180;
	fma.rn.f32 	%f626, %f690, %f244, %f625;
	selp.f32	%f627, 0fBE2AAAA8, 0fBEFFFFFF, %p180;
	fma.rn.f32 	%f628, %f626, %f244, %f627;
	fma.rn.f32 	%f691, %f628, %f245, %f243;
	and.b32  	%r1056, %r1190, 2;
	setp.eq.s32	%p182, %r1056, 0;
	@%p182 bra 	BB5_248;

	mov.f32 	%f630, 0fBF800000;
	fma.rn.f32 	%f691, %f691, %f630, %f259;

BB5_248:
	mul.f32 	%f631, %f225, %f691;
	mul.f32 	%f632, %f224, %f688;
	sub.f32 	%f633, %f632, %f631;
	mul.f32 	%f634, %f225, %f688;
	fma.rn.f32 	%f635, %f224, %f691, %f634;
	add.f32 	%f636, %f222, %f633;
	add.s32 	%r1062, %r449, %r1;
	mul.wide.u32 	%rd231, %r1062, 4;
	add.s64 	%rd232, %rd99, %rd231;
	st.global.f32 	[%rd232], %f636;
	add.f32 	%f637, %f223, %f635;
	cvta.to.global.u64 	%rd233, %rd98;
	add.s64 	%rd234, %rd233, %rd231;
	st.global.f32 	[%rd234], %f637;
	sub.f32 	%f638, %f222, %f633;
	st.global.f32 	[%rd232+1024], %f638;
	sub.f32 	%f639, %f223, %f635;
	st.global.f32 	[%rd234+1024], %f639;
	ret;
}

	// .globl	_occa_preprocessed_ODW10_STH_STFT_0
.visible .entry _occa_preprocessed_ODW10_STH_STFT_0(
	.param .u64 _occa_preprocessed_ODW10_STH_STFT_0_param_0,
	.param .u32 _occa_preprocessed_ODW10_STH_STFT_0_param_1,
	.param .u32 _occa_preprocessed_ODW10_STH_STFT_0_param_2,
	.param .u32 _occa_preprocessed_ODW10_STH_STFT_0_param_3,
	.param .u32 _occa_preprocessed_ODW10_STH_STFT_0_param_4,
	.param .u64 _occa_preprocessed_ODW10_STH_STFT_0_param_5,
	.param .u64 _occa_preprocessed_ODW10_STH_STFT_0_param_6
)
.maxntid 512, 1, 1
{
	.local .align 4 .b8 	__local_depot6[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<238>;
	.reg .b16 	%rs<9>;
	.reg .f32 	%f<915>;
	.reg .b32 	%r<1531>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<333>;
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6FRBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6FIBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6SRBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6SIBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E11windowAdded[2048];

	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd123, [_occa_preprocessed_ODW10_STH_STFT_0_param_0];
	ld.param.u32 	%r559, [_occa_preprocessed_ODW10_STH_STFT_0_param_2];
	ld.param.u32 	%r560, [_occa_preprocessed_ODW10_STH_STFT_0_param_3];
	ld.param.u64 	%rd121, [_occa_preprocessed_ODW10_STH_STFT_0_param_5];
	ld.param.u64 	%rd122, [_occa_preprocessed_ODW10_STH_STFT_0_param_6];
	mov.u32 	%r561, %ctaid.x;
	and.b32  	%r562, %r561, 8388607;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r563, %r562, %r560, %r1;
	add.s32 	%r564, %r563, 512;
	setp.lt.u32	%p1, %r563, %r559;
	setp.lt.u32	%p2, %r564, %r559;
	cvt.u64.u32	%rd124, %r563;
	selp.b64	%rd125, %rd124, 0, %p1;
	cvta.to.global.u64 	%rd126, %rd123;
	shl.b64 	%rd127, %rd125, 2;
	add.s64 	%rd128, %rd126, %rd127;
	ld.global.f32 	%f312, [%rd128];
	selp.f32	%f313, %f312, 0f00000000, %p1;
	shl.b32 	%r565, %r1, 2;
	mov.u32 	%r566, _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6FRBank;
	add.s32 	%r2, %r566, %r565;
	st.shared.f32 	[%r2], %f313;
	mov.u32 	%r567, _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6FIBank;
	add.s32 	%r3, %r567, %r565;
	mov.u32 	%r1524, 0;
	st.shared.u32 	[%r3], %r1524;
	cvt.u64.u32	%rd129, %r564;
	selp.b64	%rd130, %rd129, 0, %p2;
	shl.b64 	%rd131, %rd130, 2;
	add.s64 	%rd132, %rd126, %rd131;
	ld.global.f32 	%f314, [%rd132];
	selp.f32	%f315, %f314, 0f00000000, %p2;
	st.shared.f32 	[%r2+2048], %f315;
	st.shared.u32 	[%r3+2048], %r1524;
	bar.sync 	0;
	ld.shared.f32 	%f316, [%r2+2048];
	ld.shared.f32 	%f317, [%r2];
	add.f32 	%f318, %f317, %f316;
	mov.u32 	%r570, _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E11windowAdded;
	add.s32 	%r4, %r570, %r565;
	st.shared.f32 	[%r4], %f318;
	bar.sync 	0;
	setp.lt.s32	%p3, %r1, 256;
	selp.u16	%rs1, 1, 0, %p3;
	mul.wide.u16 	%r571, %rs1, 256;
	add.s32 	%r572, %r571, %r1;
	shl.b32 	%r573, %r572, 2;
	add.s32 	%r575, %r570, %r573;
	ld.shared.f32 	%f319, [%r575];
	ld.shared.f32 	%f320, [%r4];
	add.f32 	%f321, %f320, %f319;
	selp.u32	%r576, 1, 0, %p3;
	cvt.rn.f32.u32	%f322, %r576;
	mul.f32 	%f323, %f322, %f321;
	st.shared.f32 	[%r4], %f323;
	bar.sync 	0;
	setp.lt.s32	%p4, %r1, 128;
	selp.u16	%rs2, 1, 0, %p4;
	mul.wide.u16 	%r577, %rs2, 128;
	add.s32 	%r578, %r577, %r1;
	shl.b32 	%r579, %r578, 2;
	add.s32 	%r581, %r570, %r579;
	ld.shared.f32 	%f324, [%r581];
	ld.shared.f32 	%f325, [%r4];
	add.f32 	%f326, %f325, %f324;
	selp.u32	%r582, 1, 0, %p4;
	cvt.rn.f32.u32	%f327, %r582;
	mul.f32 	%f328, %f327, %f326;
	st.shared.f32 	[%r4], %f328;
	bar.sync 	0;
	setp.lt.s32	%p5, %r1, 64;
	selp.u16	%rs3, 1, 0, %p5;
	mul.wide.u16 	%r583, %rs3, 64;
	add.s32 	%r584, %r583, %r1;
	shl.b32 	%r585, %r584, 2;
	add.s32 	%r587, %r570, %r585;
	ld.shared.f32 	%f329, [%r587];
	ld.shared.f32 	%f330, [%r4];
	add.f32 	%f331, %f330, %f329;
	selp.u32	%r588, 1, 0, %p5;
	cvt.rn.f32.u32	%f332, %r588;
	mul.f32 	%f333, %f332, %f331;
	st.shared.f32 	[%r4], %f333;
	bar.sync 	0;
	setp.lt.s32	%p6, %r1, 32;
	selp.u16	%rs4, 1, 0, %p6;
	mul.wide.u16 	%r589, %rs4, 32;
	add.s32 	%r590, %r589, %r1;
	shl.b32 	%r591, %r590, 2;
	add.s32 	%r593, %r570, %r591;
	ld.shared.f32 	%f334, [%r593];
	ld.shared.f32 	%f335, [%r4];
	add.f32 	%f336, %f335, %f334;
	selp.u32	%r594, 1, 0, %p6;
	cvt.rn.f32.u32	%f337, %r594;
	mul.f32 	%f338, %f337, %f336;
	st.shared.f32 	[%r4], %f338;
	bar.sync 	0;
	setp.lt.s32	%p7, %r1, 16;
	selp.u16	%rs5, 1, 0, %p7;
	mul.wide.u16 	%r595, %rs5, 16;
	add.s32 	%r596, %r595, %r1;
	shl.b32 	%r597, %r596, 2;
	add.s32 	%r599, %r570, %r597;
	ld.shared.f32 	%f339, [%r599];
	ld.shared.f32 	%f340, [%r4];
	add.f32 	%f341, %f340, %f339;
	selp.u32	%r600, 1, 0, %p7;
	cvt.rn.f32.u32	%f342, %r600;
	mul.f32 	%f343, %f342, %f341;
	st.shared.f32 	[%r4], %f343;
	bar.sync 	0;
	setp.lt.s32	%p8, %r1, 8;
	selp.u16	%rs6, 1, 0, %p8;
	mul.wide.u16 	%r601, %rs6, 8;
	add.s32 	%r602, %r601, %r1;
	shl.b32 	%r603, %r602, 2;
	add.s32 	%r605, %r570, %r603;
	ld.shared.f32 	%f344, [%r605];
	ld.shared.f32 	%f345, [%r4];
	add.f32 	%f346, %f345, %f344;
	selp.u32	%r606, 1, 0, %p8;
	cvt.rn.f32.u32	%f347, %r606;
	mul.f32 	%f348, %f347, %f346;
	st.shared.f32 	[%r4], %f348;
	bar.sync 	0;
	setp.lt.s32	%p9, %r1, 4;
	selp.u16	%rs7, 1, 0, %p9;
	mul.wide.u16 	%r607, %rs7, 4;
	add.s32 	%r608, %r607, %r1;
	shl.b32 	%r609, %r608, 2;
	add.s32 	%r611, %r570, %r609;
	ld.shared.f32 	%f349, [%r611];
	ld.shared.f32 	%f350, [%r4];
	add.f32 	%f351, %f350, %f349;
	selp.u32	%r612, 1, 0, %p9;
	cvt.rn.f32.u32	%f352, %r612;
	mul.f32 	%f353, %f352, %f351;
	st.shared.f32 	[%r4], %f353;
	bar.sync 	0;
	setp.lt.s32	%p10, %r1, 2;
	selp.u16	%rs8, 1, 0, %p10;
	mul.wide.u16 	%r613, %rs8, 2;
	add.s32 	%r614, %r613, %r1;
	shl.b32 	%r615, %r614, 2;
	add.s32 	%r617, %r570, %r615;
	ld.shared.f32 	%f354, [%r617];
	ld.shared.f32 	%f355, [%r4];
	add.f32 	%f356, %f355, %f354;
	selp.u32	%r618, 1, 0, %p10;
	cvt.rn.f32.u32	%f357, %r618;
	mul.f32 	%f358, %f357, %f356;
	st.shared.f32 	[%r4], %f358;
	bar.sync 	0;
	setp.lt.s32	%p11, %r1, 1;
	selp.u32	%r619, 1, 0, %p11;
	add.s32 	%r620, %r619, %r1;
	shl.b32 	%r621, %r620, 2;
	add.s32 	%r623, %r570, %r621;
	ld.shared.f32 	%f359, [%r623];
	ld.shared.f32 	%f360, [%r4];
	add.f32 	%f361, %f360, %f359;
	cvt.rn.f32.u32	%f362, %r619;
	mul.f32 	%f363, %f362, %f361;
	st.shared.f32 	[%r4], %f363;
	bar.sync 	0;
	ld.shared.f32 	%f364, [_ZZ35_occa_preprocessed_ODW10_STH_STFT_0E11windowAdded];
	cvt.f64.f32	%fd2, %f364;
	mul.f64 	%fd1, %fd2, 0d3F50000000000000;
	ld.shared.f32 	%f365, [%r2];
	cvt.f64.f32	%fd3, %f365;
	sub.f64 	%fd4, %fd3, %fd1;
	cvt.rn.f32.f64	%f1, %fd4;
	st.shared.f32 	[%r2], %f1;
	cvt.rn.f32.s32	%f366, %r1;
	div.rn.f32 	%f367, %f366, 0f447FC000;
	cvt.f64.f32	%fd5, %f367;
	mul.f64 	%fd6, %fd5, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f2, %fd6;
	add.u64 	%rd133, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mul.f32 	%f368, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r1378, %f368;
	cvt.rn.f32.s32	%f369, %r1378;
	mov.f32 	%f370, 0fBFC90FDA;
	fma.rn.f32 	%f371, %f369, %f370, %f2;
	mov.f32 	%f372, 0fB3A22168;
	fma.rn.f32 	%f373, %f369, %f372, %f371;
	mov.f32 	%f374, 0fA7C234C5;
	fma.rn.f32 	%f851, %f369, %f374, %f373;
	abs.f32 	%f4, %f2;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p12, %f4, 0f47CE4780;
	@%p12 bra 	BB6_11;

	setp.eq.f32	%p13, %f4, 0f7F800000;
	@%p13 bra 	BB6_10;
	bra.uni 	BB6_2;

BB6_10:
	mov.f32 	%f377, 0f00000000;
	mul.rn.f32 	%f851, %f2, %f377;
	bra.uni 	BB6_11;

BB6_2:
	mov.b32 	 %r6, %f2;
	shl.b32 	%r626, %r6, 8;
	or.b32  	%r7, %r626, -2147483648;
	mov.u32 	%r1372, 0;
	mov.u64 	%rd293, __cudart_i2opi_f;
	mov.u32 	%r1371, -6;
	mov.u64 	%rd294, %rd1;

BB6_3:
	.pragma "nounroll";
	ld.const.u32 	%r629, [%rd293];
	// inline asm
	{
	mad.lo.cc.u32   %r627, %r629, %r7, %r1372;
	madc.hi.u32     %r1372, %r629, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd294], %r627;
	add.s64 	%rd294, %rd294, 4;
	add.s64 	%rd293, %rd293, 4;
	add.s32 	%r1371, %r1371, 1;
	setp.ne.s32	%p14, %r1371, 0;
	@%p14 bra 	BB6_3;

	bfe.u32 	%r632, %r6, 23, 8;
	add.s32 	%r633, %r632, -128;
	shr.u32 	%r634, %r633, 5;
	and.b32  	%r12, %r6, -2147483648;
	st.local.u32 	[%rd2], %r1372;
	bfe.u32 	%r13, %r6, 23, 5;
	mov.u32 	%r635, 6;
	sub.s32 	%r636, %r635, %r634;
	mul.wide.s32 	%rd135, %r636, 4;
	add.s64 	%rd7, %rd1, %rd135;
	ld.local.u32 	%r1374, [%rd7];
	ld.local.u32 	%r1373, [%rd7+-4];
	setp.eq.s32	%p15, %r13, 0;
	@%p15 bra 	BB6_6;

	mov.u32 	%r637, 32;
	sub.s32 	%r638, %r637, %r13;
	shr.u32 	%r639, %r1373, %r638;
	shl.b32 	%r640, %r1374, %r13;
	add.s32 	%r1374, %r639, %r640;
	ld.local.u32 	%r641, [%rd7+-8];
	shr.u32 	%r642, %r641, %r638;
	shl.b32 	%r643, %r1373, %r13;
	add.s32 	%r1373, %r642, %r643;

BB6_6:
	shr.u32 	%r644, %r1373, 30;
	shl.b32 	%r645, %r1374, 2;
	add.s32 	%r1376, %r645, %r644;
	shl.b32 	%r21, %r1373, 2;
	shr.u32 	%r646, %r1376, 31;
	shr.u32 	%r647, %r1374, 30;
	add.s32 	%r22, %r646, %r647;
	setp.eq.s32	%p16, %r646, 0;
	@%p16 bra 	BB6_7;

	not.b32 	%r648, %r1376;
	neg.s32 	%r1375, %r21;
	setp.eq.s32	%p17, %r21, 0;
	selp.u32	%r649, 1, 0, %p17;
	add.s32 	%r1376, %r649, %r648;
	xor.b32  	%r1377, %r12, -2147483648;
	bra.uni 	BB6_9;

BB6_7:
	mov.u32 	%r1375, %r21;
	mov.u32 	%r1377, %r12;

BB6_9:
	cvt.u64.u32	%rd136, %r1376;
	cvt.u64.u32	%rd137, %r1375;
	bfi.b64 	%rd138, %rd136, %rd137, 32, 32;
	cvt.rn.f64.s64	%fd7, %rd138;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f375, %fd8;
	neg.f32 	%f376, %f375;
	setp.eq.s32	%p18, %r1377, 0;
	selp.f32	%f851, %f375, %f376, %p18;
	setp.eq.s32	%p19, %r12, 0;
	neg.s32 	%r650, %r22;
	selp.b32	%r1378, %r22, %r650, %p19;

BB6_11:
	add.s32 	%r31, %r1378, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p20, %r32, 0;
	selp.f32	%f8, %f851, 0f3F800000, %p20;
	mul.rn.f32 	%f9, %f851, %f851;
	mov.f32 	%f379, 0f00000000;
	fma.rn.f32 	%f10, %f9, %f8, %f379;
	mov.f32 	%f852, 0fB94D4153;
	@%p20 bra 	BB6_13;

	mov.f32 	%f380, 0fBAB607ED;
	mov.f32 	%f381, 0f37CBAC00;
	fma.rn.f32 	%f852, %f381, %f9, %f380;

BB6_13:
	selp.f32	%f382, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f383, %f852, %f9, %f382;
	selp.f32	%f384, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f385, %f383, %f9, %f384;
	fma.rn.f32 	%f853, %f385, %f10, %f8;
	and.b32  	%r651, %r31, 2;
	setp.eq.s32	%p22, %r651, 0;
	@%p22 bra 	BB6_15;

	mov.f32 	%f387, 0fBF800000;
	fma.rn.f32 	%f853, %f853, %f387, %f379;

BB6_15:
	mov.f32 	%f388, 0f3F800000;
	sub.f32 	%f389, %f388, %f853;
	mul.f32 	%f390, %f389, 0f3F000000;
	mul.f32 	%f391, %f1, %f390;
	st.shared.f32 	[%r2], %f391;
	ld.shared.f32 	%f392, [%r2+2048];
	cvt.f64.f32	%fd9, %f392;
	sub.f64 	%fd10, %fd9, %fd1;
	cvt.rn.f32.f64	%f16, %fd10;
	st.shared.f32 	[%r2+2048], %f16;
	add.s32 	%r652, %r1, 512;
	cvt.rn.f32.s32	%f393, %r652;
	div.rn.f32 	%f394, %f393, 0f447FC000;
	cvt.f64.f32	%fd11, %f394;
	mul.f64 	%fd12, %fd11, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f17, %fd12;
	mul.f32 	%f395, %f17, 0f3F22F983;
	cvt.rni.s32.f32	%r1386, %f395;
	cvt.rn.f32.s32	%f396, %r1386;
	fma.rn.f32 	%f398, %f396, %f370, %f17;
	fma.rn.f32 	%f400, %f396, %f372, %f398;
	fma.rn.f32 	%f854, %f396, %f374, %f400;
	abs.f32 	%f19, %f17;
	setp.leu.f32	%p23, %f19, 0f47CE4780;
	@%p23 bra 	BB6_26;

	setp.eq.f32	%p24, %f19, 0f7F800000;
	@%p24 bra 	BB6_25;
	bra.uni 	BB6_17;

BB6_25:
	mul.rn.f32 	%f854, %f17, %f379;
	bra.uni 	BB6_26;

BB6_17:
	mov.b32 	 %r34, %f17;
	shl.b32 	%r655, %r34, 8;
	or.b32  	%r35, %r655, -2147483648;
	mov.u32 	%r1380, 0;
	mov.u64 	%rd295, __cudart_i2opi_f;
	mov.u32 	%r1379, -6;
	mov.u64 	%rd296, %rd1;

BB6_18:
	.pragma "nounroll";
	ld.const.u32 	%r658, [%rd295];
	// inline asm
	{
	mad.lo.cc.u32   %r656, %r658, %r35, %r1380;
	madc.hi.u32     %r1380, %r658, %r35,  0;
	}
	// inline asm
	st.local.u32 	[%rd296], %r656;
	add.s64 	%rd296, %rd296, 4;
	add.s64 	%rd295, %rd295, 4;
	add.s32 	%r1379, %r1379, 1;
	setp.ne.s32	%p25, %r1379, 0;
	@%p25 bra 	BB6_18;

	bfe.u32 	%r661, %r34, 23, 8;
	add.s32 	%r662, %r661, -128;
	shr.u32 	%r663, %r662, 5;
	and.b32  	%r40, %r34, -2147483648;
	st.local.u32 	[%rd2], %r1380;
	bfe.u32 	%r41, %r34, 23, 5;
	mov.u32 	%r664, 6;
	sub.s32 	%r665, %r664, %r663;
	mul.wide.s32 	%rd140, %r665, 4;
	add.s64 	%rd12, %rd1, %rd140;
	ld.local.u32 	%r1382, [%rd12];
	ld.local.u32 	%r1381, [%rd12+-4];
	setp.eq.s32	%p26, %r41, 0;
	@%p26 bra 	BB6_21;

	mov.u32 	%r666, 32;
	sub.s32 	%r667, %r666, %r41;
	shr.u32 	%r668, %r1381, %r667;
	shl.b32 	%r669, %r1382, %r41;
	add.s32 	%r1382, %r668, %r669;
	ld.local.u32 	%r670, [%rd12+-8];
	shr.u32 	%r671, %r670, %r667;
	shl.b32 	%r672, %r1381, %r41;
	add.s32 	%r1381, %r671, %r672;

BB6_21:
	shr.u32 	%r673, %r1381, 30;
	shl.b32 	%r674, %r1382, 2;
	add.s32 	%r1384, %r674, %r673;
	shl.b32 	%r49, %r1381, 2;
	shr.u32 	%r675, %r1384, 31;
	shr.u32 	%r676, %r1382, 30;
	add.s32 	%r50, %r675, %r676;
	setp.eq.s32	%p27, %r675, 0;
	@%p27 bra 	BB6_22;

	not.b32 	%r677, %r1384;
	neg.s32 	%r1383, %r49;
	setp.eq.s32	%p28, %r49, 0;
	selp.u32	%r678, 1, 0, %p28;
	add.s32 	%r1384, %r678, %r677;
	xor.b32  	%r1385, %r40, -2147483648;
	bra.uni 	BB6_24;

BB6_22:
	mov.u32 	%r1383, %r49;
	mov.u32 	%r1385, %r40;

BB6_24:
	cvt.u64.u32	%rd141, %r1384;
	cvt.u64.u32	%rd142, %r1383;
	bfi.b64 	%rd143, %rd141, %rd142, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd143;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f402, %fd14;
	neg.f32 	%f403, %f402;
	setp.eq.s32	%p29, %r1385, 0;
	selp.f32	%f854, %f402, %f403, %p29;
	setp.eq.s32	%p30, %r40, 0;
	neg.s32 	%r679, %r50;
	selp.b32	%r1386, %r50, %r679, %p30;

BB6_26:
	add.s32 	%r59, %r1386, 1;
	and.b32  	%r60, %r59, 1;
	setp.eq.s32	%p31, %r60, 0;
	selp.f32	%f23, %f854, 0f3F800000, %p31;
	mul.rn.f32 	%f24, %f854, %f854;
	fma.rn.f32 	%f25, %f24, %f23, %f379;
	mov.f32 	%f855, 0fB94D4153;
	@%p31 bra 	BB6_28;

	mov.f32 	%f407, 0fBAB607ED;
	mov.f32 	%f408, 0f37CBAC00;
	fma.rn.f32 	%f855, %f408, %f24, %f407;

BB6_28:
	selp.f32	%f409, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f410, %f855, %f24, %f409;
	selp.f32	%f411, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f412, %f410, %f24, %f411;
	fma.rn.f32 	%f856, %f412, %f25, %f23;
	and.b32  	%r680, %r59, 2;
	setp.eq.s32	%p33, %r680, 0;
	@%p33 bra 	BB6_30;

	mov.f32 	%f414, 0fBF800000;
	fma.rn.f32 	%f856, %f856, %f414, %f379;

BB6_30:
	sub.f32 	%f416, %f388, %f856;
	mul.f32 	%f417, %f416, 0f3F000000;
	mul.f32 	%f418, %f16, %f417;
	st.shared.f32 	[%r2+2048], %f418;
	bar.sync 	0;
	ld.shared.f32 	%f31, [%r2];
	ld.shared.f32 	%f32, [%r3];
	ld.shared.f32 	%f33, [%r2+2048];
	ld.shared.f32 	%f34, [%r3+2048];
	mov.f32 	%f420, 0f80000000;
	cvt.rni.s32.f32	%r62, %f420;
	cvt.rn.f32.s32	%f421, %r62;
	fma.rn.f32 	%f423, %f421, %f370, %f420;
	fma.rn.f32 	%f425, %f421, %f372, %f423;
	fma.rn.f32 	%f35, %f421, %f374, %f425;
	mul.rn.f32 	%f36, %f35, %f35;
	add.s32 	%r681, %r62, 1;
	and.b32  	%r63, %r681, 1;
	setp.eq.s32	%p34, %r63, 0;
	selp.f32	%f37, %f35, 0f3F800000, %p34;
	fma.rn.f32 	%f38, %f36, %f37, %f379;
	mov.f32 	%f857, 0fB94D4153;
	@%p34 bra 	BB6_32;

	mov.f32 	%f428, 0fBAB607ED;
	mov.f32 	%f429, 0f37CBAC00;
	fma.rn.f32 	%f857, %f429, %f36, %f428;

BB6_32:
	selp.f32	%f430, 0f3C0885E4, 0f3D2AAABB, %p34;
	fma.rn.f32 	%f431, %f857, %f36, %f430;
	selp.f32	%f432, 0fBE2AAAA8, 0fBEFFFFFF, %p34;
	fma.rn.f32 	%f433, %f431, %f36, %f432;
	fma.rn.f32 	%f858, %f433, %f38, %f37;
	and.b32  	%r683, %r681, 2;
	setp.eq.s32	%p36, %r683, 0;
	@%p36 bra 	BB6_34;

	mov.f32 	%f435, 0fBF800000;
	fma.rn.f32 	%f858, %f858, %f435, %f379;

BB6_34:
	and.b32  	%r64, %r62, 1;
	setp.eq.s32	%p37, %r64, 0;
	selp.f32	%f44, %f35, 0f3F800000, %p37;
	fma.rn.f32 	%f45, %f36, %f44, %f379;
	mov.f32 	%f859, 0fB94D4153;
	@%p37 bra 	BB6_36;

	mov.f32 	%f438, 0fBAB607ED;
	mov.f32 	%f439, 0f37CBAC00;
	fma.rn.f32 	%f859, %f439, %f36, %f438;

BB6_36:
	selp.f32	%f440, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f441, %f859, %f36, %f440;
	selp.f32	%f442, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f443, %f441, %f36, %f442;
	fma.rn.f32 	%f860, %f443, %f45, %f44;
	and.b32  	%r684, %r62, 2;
	setp.eq.s32	%p39, %r684, 0;
	@%p39 bra 	BB6_38;

	mov.f32 	%f445, 0fBF800000;
	fma.rn.f32 	%f860, %f860, %f445, %f379;

BB6_38:
	mul.f32 	%f446, %f34, %f860;
	mul.f32 	%f447, %f33, %f858;
	sub.f32 	%f448, %f447, %f446;
	mul.f32 	%f449, %f34, %f858;
	fma.rn.f32 	%f450, %f33, %f860, %f449;
	add.f32 	%f451, %f31, %f448;
	shl.b32 	%r685, %r1, 3;
	mov.u32 	%r686, _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6SRBank;
	add.s32 	%r687, %r686, %r685;
	st.shared.f32 	[%r687], %f451;
	add.f32 	%f452, %f32, %f450;
	mov.u32 	%r688, _ZZ35_occa_preprocessed_ODW10_STH_STFT_0E6SIBank;
	add.s32 	%r689, %r688, %r685;
	st.shared.f32 	[%r689], %f452;
	sub.f32 	%f453, %f31, %f448;
	st.shared.f32 	[%r687+4], %f453;
	sub.f32 	%f454, %f32, %f450;
	st.shared.f32 	[%r689+4], %f454;
	bar.sync 	0;
	add.s32 	%r692, %r686, %r565;
	ld.shared.f32 	%f51, [%r692];
	add.s32 	%r694, %r688, %r565;
	ld.shared.f32 	%f52, [%r694];
	ld.shared.f32 	%f53, [%r692+2048];
	ld.shared.f32 	%f54, [%r694+2048];
	shr.u32 	%r695, %r1, 31;
	add.s32 	%r696, %r1, %r695;
	and.b32  	%r697, %r696, 16777214;
	sub.s32 	%r698, %r1, %r697;
	shl.b32 	%r699, %r698, 8;
	cvt.rn.f32.s32	%f455, %r699;
	mul.f32 	%f456, %f455, 0f3A800000;
	cvt.f64.f32	%fd15, %f456;
	mul.f64 	%fd16, %fd15, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f55, %fd16;
	mul.f32 	%f457, %f55, 0f3F22F983;
	cvt.rni.s32.f32	%r1402, %f457;
	cvt.rn.f32.s32	%f458, %r1402;
	fma.rn.f32 	%f460, %f458, %f370, %f55;
	fma.rn.f32 	%f462, %f458, %f372, %f460;
	fma.rn.f32 	%f864, %f458, %f374, %f462;
	abs.f32 	%f57, %f55;
	setp.leu.f32	%p40, %f57, 0f47CE4780;
	mov.u32 	%r1394, %r1402;
	mov.f32 	%f861, %f864;
	@%p40 bra 	BB6_49;

	setp.eq.f32	%p41, %f57, 0f7F800000;
	@%p41 bra 	BB6_48;
	bra.uni 	BB6_40;

BB6_48:
	mul.rn.f32 	%f861, %f55, %f379;
	mov.u32 	%r1394, %r1402;
	bra.uni 	BB6_49;

BB6_40:
	mov.b32 	 %r702, %f55;
	shl.b32 	%r703, %r702, 8;
	or.b32  	%r67, %r703, -2147483648;
	cvta.to.local.u64 	%rd298, %rd133;
	mov.u32 	%r1388, 0;
	mov.u64 	%rd297, __cudart_i2opi_f;
	mov.u32 	%r1387, -6;

BB6_41:
	.pragma "nounroll";
	ld.const.u32 	%r706, [%rd297];
	// inline asm
	{
	mad.lo.cc.u32   %r704, %r706, %r67, %r1388;
	madc.hi.u32     %r1388, %r706, %r67,  0;
	}
	// inline asm
	st.local.u32 	[%rd298], %r704;
	add.s64 	%rd298, %rd298, 4;
	add.s64 	%rd297, %rd297, 4;
	add.s32 	%r1387, %r1387, 1;
	setp.ne.s32	%p42, %r1387, 0;
	@%p42 bra 	BB6_41;

	bfe.u32 	%r710, %r702, 23, 8;
	add.s32 	%r711, %r710, -128;
	shr.u32 	%r712, %r711, 5;
	and.b32  	%r72, %r702, -2147483648;
	cvta.to.local.u64 	%rd147, %rd133;
	st.local.u32 	[%rd147+24], %r1388;
	bfe.u32 	%r73, %r702, 23, 5;
	mov.u32 	%r713, 6;
	sub.s32 	%r714, %r713, %r712;
	mul.wide.s32 	%rd148, %r714, 4;
	add.s64 	%rd18, %rd147, %rd148;
	ld.local.u32 	%r1390, [%rd18];
	ld.local.u32 	%r1389, [%rd18+-4];
	setp.eq.s32	%p43, %r73, 0;
	@%p43 bra 	BB6_44;

	mov.u32 	%r715, 32;
	sub.s32 	%r716, %r715, %r73;
	shr.u32 	%r717, %r1389, %r716;
	shl.b32 	%r718, %r1390, %r73;
	add.s32 	%r1390, %r717, %r718;
	ld.local.u32 	%r719, [%rd18+-8];
	shr.u32 	%r720, %r719, %r716;
	shl.b32 	%r721, %r1389, %r73;
	add.s32 	%r1389, %r720, %r721;

BB6_44:
	shr.u32 	%r722, %r1389, 30;
	shl.b32 	%r723, %r1390, 2;
	add.s32 	%r1392, %r723, %r722;
	shl.b32 	%r81, %r1389, 2;
	shr.u32 	%r724, %r1392, 31;
	shr.u32 	%r725, %r1390, 30;
	add.s32 	%r82, %r724, %r725;
	setp.eq.s32	%p44, %r724, 0;
	@%p44 bra 	BB6_45;

	not.b32 	%r726, %r1392;
	neg.s32 	%r1391, %r81;
	setp.eq.s32	%p45, %r81, 0;
	selp.u32	%r727, 1, 0, %p45;
	add.s32 	%r1392, %r727, %r726;
	xor.b32  	%r1393, %r72, -2147483648;
	bra.uni 	BB6_47;

BB6_45:
	mov.u32 	%r1391, %r81;
	mov.u32 	%r1393, %r72;

BB6_47:
	cvt.u64.u32	%rd149, %r1392;
	cvt.u64.u32	%rd150, %r1391;
	bfi.b64 	%rd151, %rd149, %rd150, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd151;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f464, %fd18;
	neg.f32 	%f465, %f464;
	setp.eq.s32	%p46, %r1393, 0;
	selp.f32	%f861, %f464, %f465, %p46;
	setp.eq.s32	%p47, %r72, 0;
	neg.s32 	%r728, %r82;
	selp.b32	%r1394, %r82, %r728, %p47;

BB6_49:
	add.s32 	%r91, %r1394, 1;
	and.b32  	%r92, %r91, 1;
	setp.eq.s32	%p48, %r92, 0;
	selp.f32	%f61, %f861, 0f3F800000, %p48;
	mul.rn.f32 	%f62, %f861, %f861;
	fma.rn.f32 	%f63, %f62, %f61, %f379;
	mov.f32 	%f862, 0fB94D4153;
	@%p48 bra 	BB6_51;

	mov.f32 	%f469, 0fBAB607ED;
	mov.f32 	%f470, 0f37CBAC00;
	fma.rn.f32 	%f862, %f470, %f62, %f469;

BB6_51:
	selp.f32	%f471, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f472, %f862, %f62, %f471;
	selp.f32	%f473, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f474, %f472, %f62, %f473;
	fma.rn.f32 	%f863, %f474, %f63, %f61;
	and.b32  	%r729, %r91, 2;
	setp.eq.s32	%p50, %r729, 0;
	@%p50 bra 	BB6_53;

	mov.f32 	%f476, 0fBF800000;
	fma.rn.f32 	%f863, %f863, %f476, %f379;

BB6_53:
	@%p40 bra 	BB6_64;

	setp.eq.f32	%p52, %f57, 0f7F800000;
	@%p52 bra 	BB6_63;
	bra.uni 	BB6_55;

BB6_63:
	mul.rn.f32 	%f864, %f55, %f379;
	bra.uni 	BB6_64;

BB6_55:
	mov.b32 	 %r93, %f55;
	shl.b32 	%r732, %r93, 8;
	or.b32  	%r94, %r732, -2147483648;
	cvta.to.local.u64 	%rd300, %rd133;
	mov.u32 	%r1396, 0;
	mov.u64 	%rd299, __cudart_i2opi_f;
	mov.u32 	%r1395, -6;

BB6_56:
	.pragma "nounroll";
	ld.const.u32 	%r735, [%rd299];
	// inline asm
	{
	mad.lo.cc.u32   %r733, %r735, %r94, %r1396;
	madc.hi.u32     %r1396, %r735, %r94,  0;
	}
	// inline asm
	st.local.u32 	[%rd300], %r733;
	add.s64 	%rd300, %rd300, 4;
	add.s64 	%rd299, %rd299, 4;
	add.s32 	%r1395, %r1395, 1;
	setp.ne.s32	%p53, %r1395, 0;
	@%p53 bra 	BB6_56;

	bfe.u32 	%r738, %r93, 23, 8;
	add.s32 	%r739, %r738, -128;
	shr.u32 	%r740, %r739, 5;
	and.b32  	%r99, %r93, -2147483648;
	cvta.to.local.u64 	%rd155, %rd133;
	st.local.u32 	[%rd155+24], %r1396;
	bfe.u32 	%r100, %r93, 23, 5;
	mov.u32 	%r741, 6;
	sub.s32 	%r742, %r741, %r740;
	mul.wide.s32 	%rd156, %r742, 4;
	add.s64 	%rd24, %rd155, %rd156;
	ld.local.u32 	%r1398, [%rd24];
	ld.local.u32 	%r1397, [%rd24+-4];
	setp.eq.s32	%p54, %r100, 0;
	@%p54 bra 	BB6_59;

	mov.u32 	%r743, 32;
	sub.s32 	%r744, %r743, %r100;
	shr.u32 	%r745, %r1397, %r744;
	shl.b32 	%r746, %r1398, %r100;
	add.s32 	%r1398, %r745, %r746;
	ld.local.u32 	%r747, [%rd24+-8];
	shr.u32 	%r748, %r747, %r744;
	shl.b32 	%r749, %r1397, %r100;
	add.s32 	%r1397, %r748, %r749;

BB6_59:
	shr.u32 	%r750, %r1397, 30;
	shl.b32 	%r751, %r1398, 2;
	add.s32 	%r1400, %r751, %r750;
	shl.b32 	%r108, %r1397, 2;
	shr.u32 	%r752, %r1400, 31;
	shr.u32 	%r753, %r1398, 30;
	add.s32 	%r109, %r752, %r753;
	setp.eq.s32	%p55, %r752, 0;
	@%p55 bra 	BB6_60;

	not.b32 	%r754, %r1400;
	neg.s32 	%r1399, %r108;
	setp.eq.s32	%p56, %r108, 0;
	selp.u32	%r755, 1, 0, %p56;
	add.s32 	%r1400, %r755, %r754;
	xor.b32  	%r1401, %r99, -2147483648;
	bra.uni 	BB6_62;

BB6_60:
	mov.u32 	%r1399, %r108;
	mov.u32 	%r1401, %r99;

BB6_62:
	cvt.u64.u32	%rd157, %r1400;
	cvt.u64.u32	%rd158, %r1399;
	bfi.b64 	%rd159, %rd157, %rd158, 32, 32;
	cvt.rn.f64.s64	%fd19, %rd159;
	mul.f64 	%fd20, %fd19, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f477, %fd20;
	neg.f32 	%f478, %f477;
	setp.eq.s32	%p57, %r1401, 0;
	selp.f32	%f864, %f477, %f478, %p57;
	setp.eq.s32	%p58, %r99, 0;
	neg.s32 	%r756, %r109;
	selp.b32	%r1402, %r109, %r756, %p58;

BB6_64:
	and.b32  	%r118, %r1402, 1;
	setp.eq.s32	%p59, %r118, 0;
	selp.f32	%f72, %f864, 0f3F800000, %p59;
	mul.rn.f32 	%f73, %f864, %f864;
	fma.rn.f32 	%f74, %f73, %f72, %f379;
	mov.f32 	%f865, 0fB94D4153;
	@%p59 bra 	BB6_66;

	mov.f32 	%f482, 0fBAB607ED;
	mov.f32 	%f483, 0f37CBAC00;
	fma.rn.f32 	%f865, %f483, %f73, %f482;

BB6_66:
	selp.f32	%f484, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f485, %f865, %f73, %f484;
	selp.f32	%f486, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f487, %f485, %f73, %f486;
	fma.rn.f32 	%f866, %f487, %f74, %f72;
	and.b32  	%r757, %r1402, 2;
	setp.eq.s32	%p61, %r757, 0;
	@%p61 bra 	BB6_68;

	mov.f32 	%f489, 0fBF800000;
	fma.rn.f32 	%f866, %f866, %f489, %f379;

BB6_68:
	and.b32  	%r758, %r1, 1;
	shl.b32 	%r759, %r1, 1;
	and.b32  	%r760, %r759, 1073741820;
	add.s32 	%r761, %r760, %r758;
	mul.f32 	%f490, %f54, %f866;
	mul.f32 	%f491, %f53, %f863;
	sub.f32 	%f492, %f491, %f490;
	mul.f32 	%f493, %f54, %f863;
	fma.rn.f32 	%f494, %f53, %f866, %f493;
	add.f32 	%f495, %f51, %f492;
	shl.b32 	%r762, %r761, 2;
	add.s32 	%r764, %r566, %r762;
	st.shared.f32 	[%r764], %f495;
	add.f32 	%f496, %f52, %f494;
	add.s32 	%r766, %r567, %r762;
	st.shared.f32 	[%r766], %f496;
	sub.f32 	%f497, %f51, %f492;
	st.shared.f32 	[%r764+8], %f497;
	sub.f32 	%f498, %f52, %f494;
	st.shared.f32 	[%r766+8], %f498;
	bar.sync 	0;
	ld.shared.f32 	%f80, [%r2];
	ld.shared.f32 	%f81, [%r3];
	ld.shared.f32 	%f82, [%r2+2048];
	ld.shared.f32 	%f83, [%r3+2048];
	shr.s32 	%r772, %r1, 31;
	shr.u32 	%r773, %r772, 30;
	add.s32 	%r774, %r1, %r773;
	and.b32  	%r775, %r774, 33554428;
	sub.s32 	%r776, %r1, %r775;
	shl.b32 	%r777, %r776, 7;
	cvt.rn.f32.s32	%f499, %r777;
	mul.f32 	%f500, %f499, 0f3A800000;
	cvt.f64.f32	%fd21, %f500;
	mul.f64 	%fd22, %fd21, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f84, %fd22;
	mul.f32 	%f501, %f84, 0f3F22F983;
	cvt.rni.s32.f32	%r1418, %f501;
	cvt.rn.f32.s32	%f502, %r1418;
	fma.rn.f32 	%f504, %f502, %f370, %f84;
	fma.rn.f32 	%f506, %f502, %f372, %f504;
	fma.rn.f32 	%f870, %f502, %f374, %f506;
	abs.f32 	%f86, %f84;
	setp.leu.f32	%p62, %f86, 0f47CE4780;
	mov.u32 	%r1410, %r1418;
	mov.f32 	%f867, %f870;
	@%p62 bra 	BB6_79;

	setp.eq.f32	%p63, %f86, 0f7F800000;
	@%p63 bra 	BB6_78;
	bra.uni 	BB6_70;

BB6_78:
	mul.rn.f32 	%f867, %f84, %f379;
	mov.u32 	%r1410, %r1418;
	bra.uni 	BB6_79;

BB6_70:
	mov.b32 	 %r121, %f84;
	shl.b32 	%r780, %r121, 8;
	or.b32  	%r122, %r780, -2147483648;
	cvta.to.local.u64 	%rd302, %rd133;
	mov.u32 	%r1404, 0;
	mov.u64 	%rd301, __cudart_i2opi_f;
	mov.u32 	%r1403, -6;

BB6_71:
	.pragma "nounroll";
	ld.const.u32 	%r783, [%rd301];
	// inline asm
	{
	mad.lo.cc.u32   %r781, %r783, %r122, %r1404;
	madc.hi.u32     %r1404, %r783, %r122,  0;
	}
	// inline asm
	st.local.u32 	[%rd302], %r781;
	add.s64 	%rd302, %rd302, 4;
	add.s64 	%rd301, %rd301, 4;
	add.s32 	%r1403, %r1403, 1;
	setp.ne.s32	%p64, %r1403, 0;
	@%p64 bra 	BB6_71;

	bfe.u32 	%r786, %r121, 23, 8;
	add.s32 	%r787, %r786, -128;
	shr.u32 	%r788, %r787, 5;
	and.b32  	%r127, %r121, -2147483648;
	cvta.to.local.u64 	%rd163, %rd133;
	st.local.u32 	[%rd163+24], %r1404;
	bfe.u32 	%r128, %r121, 23, 5;
	mov.u32 	%r789, 6;
	sub.s32 	%r790, %r789, %r788;
	mul.wide.s32 	%rd164, %r790, 4;
	add.s64 	%rd30, %rd163, %rd164;
	ld.local.u32 	%r1406, [%rd30];
	ld.local.u32 	%r1405, [%rd30+-4];
	setp.eq.s32	%p65, %r128, 0;
	@%p65 bra 	BB6_74;

	mov.u32 	%r791, 32;
	sub.s32 	%r792, %r791, %r128;
	shr.u32 	%r793, %r1405, %r792;
	shl.b32 	%r794, %r1406, %r128;
	add.s32 	%r1406, %r793, %r794;
	ld.local.u32 	%r795, [%rd30+-8];
	shr.u32 	%r796, %r795, %r792;
	shl.b32 	%r797, %r1405, %r128;
	add.s32 	%r1405, %r796, %r797;

BB6_74:
	shr.u32 	%r798, %r1405, 30;
	shl.b32 	%r799, %r1406, 2;
	add.s32 	%r1408, %r799, %r798;
	shl.b32 	%r136, %r1405, 2;
	shr.u32 	%r800, %r1408, 31;
	shr.u32 	%r801, %r1406, 30;
	add.s32 	%r137, %r800, %r801;
	setp.eq.s32	%p66, %r800, 0;
	@%p66 bra 	BB6_75;

	not.b32 	%r802, %r1408;
	neg.s32 	%r1407, %r136;
	setp.eq.s32	%p67, %r136, 0;
	selp.u32	%r803, 1, 0, %p67;
	add.s32 	%r1408, %r803, %r802;
	xor.b32  	%r1409, %r127, -2147483648;
	bra.uni 	BB6_77;

BB6_75:
	mov.u32 	%r1407, %r136;
	mov.u32 	%r1409, %r127;

BB6_77:
	cvt.u64.u32	%rd165, %r1408;
	cvt.u64.u32	%rd166, %r1407;
	bfi.b64 	%rd167, %rd165, %rd166, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd167;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f508, %fd24;
	neg.f32 	%f509, %f508;
	setp.eq.s32	%p68, %r1409, 0;
	selp.f32	%f867, %f508, %f509, %p68;
	setp.eq.s32	%p69, %r127, 0;
	neg.s32 	%r804, %r137;
	selp.b32	%r1410, %r137, %r804, %p69;

BB6_79:
	add.s32 	%r146, %r1410, 1;
	and.b32  	%r147, %r146, 1;
	setp.eq.s32	%p70, %r147, 0;
	selp.f32	%f90, %f867, 0f3F800000, %p70;
	mul.rn.f32 	%f91, %f867, %f867;
	fma.rn.f32 	%f92, %f91, %f90, %f379;
	mov.f32 	%f868, 0fB94D4153;
	@%p70 bra 	BB6_81;

	mov.f32 	%f513, 0fBAB607ED;
	mov.f32 	%f514, 0f37CBAC00;
	fma.rn.f32 	%f868, %f514, %f91, %f513;

BB6_81:
	selp.f32	%f515, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f516, %f868, %f91, %f515;
	selp.f32	%f517, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f518, %f516, %f91, %f517;
	fma.rn.f32 	%f869, %f518, %f92, %f90;
	and.b32  	%r805, %r146, 2;
	setp.eq.s32	%p72, %r805, 0;
	@%p72 bra 	BB6_83;

	mov.f32 	%f520, 0fBF800000;
	fma.rn.f32 	%f869, %f869, %f520, %f379;

BB6_83:
	@%p62 bra 	BB6_94;

	setp.eq.f32	%p74, %f86, 0f7F800000;
	@%p74 bra 	BB6_93;
	bra.uni 	BB6_85;

BB6_93:
	mul.rn.f32 	%f870, %f84, %f379;
	bra.uni 	BB6_94;

BB6_85:
	mov.b32 	 %r148, %f84;
	shl.b32 	%r808, %r148, 8;
	or.b32  	%r149, %r808, -2147483648;
	cvta.to.local.u64 	%rd304, %rd133;
	mov.u32 	%r1412, 0;
	mov.u64 	%rd303, __cudart_i2opi_f;
	mov.u32 	%r1411, -6;

BB6_86:
	.pragma "nounroll";
	ld.const.u32 	%r811, [%rd303];
	// inline asm
	{
	mad.lo.cc.u32   %r809, %r811, %r149, %r1412;
	madc.hi.u32     %r1412, %r811, %r149,  0;
	}
	// inline asm
	st.local.u32 	[%rd304], %r809;
	add.s64 	%rd304, %rd304, 4;
	add.s64 	%rd303, %rd303, 4;
	add.s32 	%r1411, %r1411, 1;
	setp.ne.s32	%p75, %r1411, 0;
	@%p75 bra 	BB6_86;

	bfe.u32 	%r814, %r148, 23, 8;
	add.s32 	%r815, %r814, -128;
	shr.u32 	%r816, %r815, 5;
	and.b32  	%r154, %r148, -2147483648;
	cvta.to.local.u64 	%rd171, %rd133;
	st.local.u32 	[%rd171+24], %r1412;
	bfe.u32 	%r155, %r148, 23, 5;
	mov.u32 	%r817, 6;
	sub.s32 	%r818, %r817, %r816;
	mul.wide.s32 	%rd172, %r818, 4;
	add.s64 	%rd36, %rd171, %rd172;
	ld.local.u32 	%r1414, [%rd36];
	ld.local.u32 	%r1413, [%rd36+-4];
	setp.eq.s32	%p76, %r155, 0;
	@%p76 bra 	BB6_89;

	mov.u32 	%r819, 32;
	sub.s32 	%r820, %r819, %r155;
	shr.u32 	%r821, %r1413, %r820;
	shl.b32 	%r822, %r1414, %r155;
	add.s32 	%r1414, %r821, %r822;
	ld.local.u32 	%r823, [%rd36+-8];
	shr.u32 	%r824, %r823, %r820;
	shl.b32 	%r825, %r1413, %r155;
	add.s32 	%r1413, %r824, %r825;

BB6_89:
	shr.u32 	%r826, %r1413, 30;
	shl.b32 	%r827, %r1414, 2;
	add.s32 	%r1416, %r827, %r826;
	shl.b32 	%r163, %r1413, 2;
	shr.u32 	%r828, %r1416, 31;
	shr.u32 	%r829, %r1414, 30;
	add.s32 	%r164, %r828, %r829;
	setp.eq.s32	%p77, %r828, 0;
	@%p77 bra 	BB6_90;

	not.b32 	%r830, %r1416;
	neg.s32 	%r1415, %r163;
	setp.eq.s32	%p78, %r163, 0;
	selp.u32	%r831, 1, 0, %p78;
	add.s32 	%r1416, %r831, %r830;
	xor.b32  	%r1417, %r154, -2147483648;
	bra.uni 	BB6_92;

BB6_90:
	mov.u32 	%r1415, %r163;
	mov.u32 	%r1417, %r154;

BB6_92:
	cvt.u64.u32	%rd173, %r1416;
	cvt.u64.u32	%rd174, %r1415;
	bfi.b64 	%rd175, %rd173, %rd174, 32, 32;
	cvt.rn.f64.s64	%fd25, %rd175;
	mul.f64 	%fd26, %fd25, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f521, %fd26;
	neg.f32 	%f522, %f521;
	setp.eq.s32	%p79, %r1417, 0;
	selp.f32	%f870, %f521, %f522, %p79;
	setp.eq.s32	%p80, %r154, 0;
	neg.s32 	%r832, %r164;
	selp.b32	%r1418, %r164, %r832, %p80;

BB6_94:
	and.b32  	%r173, %r1418, 1;
	setp.eq.s32	%p81, %r173, 0;
	selp.f32	%f101, %f870, 0f3F800000, %p81;
	mul.rn.f32 	%f102, %f870, %f870;
	fma.rn.f32 	%f103, %f102, %f101, %f379;
	mov.f32 	%f871, 0fB94D4153;
	@%p81 bra 	BB6_96;

	mov.f32 	%f526, 0fBAB607ED;
	mov.f32 	%f527, 0f37CBAC00;
	fma.rn.f32 	%f871, %f527, %f102, %f526;

BB6_96:
	selp.f32	%f528, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f529, %f871, %f102, %f528;
	selp.f32	%f530, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f531, %f529, %f102, %f530;
	fma.rn.f32 	%f872, %f531, %f103, %f101;
	and.b32  	%r833, %r1418, 2;
	setp.eq.s32	%p83, %r833, 0;
	@%p83 bra 	BB6_98;

	mov.f32 	%f533, 0fBF800000;
	fma.rn.f32 	%f872, %f872, %f533, %f379;

BB6_98:
	and.b32  	%r834, %r1, 3;
	and.b32  	%r836, %r759, 1073741816;
	add.s32 	%r837, %r836, %r834;
	mul.f32 	%f534, %f83, %f872;
	mul.f32 	%f535, %f82, %f869;
	sub.f32 	%f536, %f535, %f534;
	mul.f32 	%f537, %f83, %f869;
	fma.rn.f32 	%f538, %f82, %f872, %f537;
	add.f32 	%f539, %f80, %f536;
	shl.b32 	%r838, %r837, 2;
	add.s32 	%r840, %r686, %r838;
	st.shared.f32 	[%r840], %f539;
	add.f32 	%f540, %f81, %f538;
	add.s32 	%r842, %r688, %r838;
	st.shared.f32 	[%r842], %f540;
	sub.f32 	%f541, %f80, %f536;
	st.shared.f32 	[%r840+16], %f541;
	sub.f32 	%f542, %f81, %f538;
	st.shared.f32 	[%r842+16], %f542;
	bar.sync 	0;
	ld.shared.f32 	%f109, [%r692];
	ld.shared.f32 	%f110, [%r694];
	ld.shared.f32 	%f111, [%r692+2048];
	ld.shared.f32 	%f112, [%r694+2048];
	shr.u32 	%r849, %r772, 29;
	add.s32 	%r850, %r1, %r849;
	and.b32  	%r851, %r850, 67108856;
	sub.s32 	%r852, %r1, %r851;
	shl.b32 	%r853, %r852, 6;
	cvt.rn.f32.s32	%f543, %r853;
	mul.f32 	%f544, %f543, 0f3A800000;
	cvt.f64.f32	%fd27, %f544;
	mul.f64 	%fd28, %fd27, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f113, %fd28;
	mul.f32 	%f545, %f113, 0f3F22F983;
	cvt.rni.s32.f32	%r1434, %f545;
	cvt.rn.f32.s32	%f546, %r1434;
	fma.rn.f32 	%f548, %f546, %f370, %f113;
	fma.rn.f32 	%f550, %f546, %f372, %f548;
	fma.rn.f32 	%f876, %f546, %f374, %f550;
	abs.f32 	%f115, %f113;
	setp.leu.f32	%p84, %f115, 0f47CE4780;
	mov.u32 	%r1426, %r1434;
	mov.f32 	%f873, %f876;
	@%p84 bra 	BB6_109;

	setp.eq.f32	%p85, %f115, 0f7F800000;
	@%p85 bra 	BB6_108;
	bra.uni 	BB6_100;

BB6_108:
	mul.rn.f32 	%f873, %f113, %f379;
	mov.u32 	%r1426, %r1434;
	bra.uni 	BB6_109;

BB6_100:
	mov.b32 	 %r176, %f113;
	shl.b32 	%r856, %r176, 8;
	or.b32  	%r177, %r856, -2147483648;
	cvta.to.local.u64 	%rd306, %rd133;
	mov.u32 	%r1420, 0;
	mov.u64 	%rd305, __cudart_i2opi_f;
	mov.u32 	%r1419, -6;

BB6_101:
	.pragma "nounroll";
	ld.const.u32 	%r859, [%rd305];
	// inline asm
	{
	mad.lo.cc.u32   %r857, %r859, %r177, %r1420;
	madc.hi.u32     %r1420, %r859, %r177,  0;
	}
	// inline asm
	st.local.u32 	[%rd306], %r857;
	add.s64 	%rd306, %rd306, 4;
	add.s64 	%rd305, %rd305, 4;
	add.s32 	%r1419, %r1419, 1;
	setp.ne.s32	%p86, %r1419, 0;
	@%p86 bra 	BB6_101;

	bfe.u32 	%r862, %r176, 23, 8;
	add.s32 	%r863, %r862, -128;
	shr.u32 	%r864, %r863, 5;
	and.b32  	%r182, %r176, -2147483648;
	cvta.to.local.u64 	%rd179, %rd133;
	st.local.u32 	[%rd179+24], %r1420;
	bfe.u32 	%r183, %r176, 23, 5;
	mov.u32 	%r865, 6;
	sub.s32 	%r866, %r865, %r864;
	mul.wide.s32 	%rd180, %r866, 4;
	add.s64 	%rd42, %rd179, %rd180;
	ld.local.u32 	%r1422, [%rd42];
	ld.local.u32 	%r1421, [%rd42+-4];
	setp.eq.s32	%p87, %r183, 0;
	@%p87 bra 	BB6_104;

	mov.u32 	%r867, 32;
	sub.s32 	%r868, %r867, %r183;
	shr.u32 	%r869, %r1421, %r868;
	shl.b32 	%r870, %r1422, %r183;
	add.s32 	%r1422, %r869, %r870;
	ld.local.u32 	%r871, [%rd42+-8];
	shr.u32 	%r872, %r871, %r868;
	shl.b32 	%r873, %r1421, %r183;
	add.s32 	%r1421, %r872, %r873;

BB6_104:
	shr.u32 	%r874, %r1421, 30;
	shl.b32 	%r875, %r1422, 2;
	add.s32 	%r1424, %r875, %r874;
	shl.b32 	%r191, %r1421, 2;
	shr.u32 	%r876, %r1424, 31;
	shr.u32 	%r877, %r1422, 30;
	add.s32 	%r192, %r876, %r877;
	setp.eq.s32	%p88, %r876, 0;
	@%p88 bra 	BB6_105;

	not.b32 	%r878, %r1424;
	neg.s32 	%r1423, %r191;
	setp.eq.s32	%p89, %r191, 0;
	selp.u32	%r879, 1, 0, %p89;
	add.s32 	%r1424, %r879, %r878;
	xor.b32  	%r1425, %r182, -2147483648;
	bra.uni 	BB6_107;

BB6_105:
	mov.u32 	%r1423, %r191;
	mov.u32 	%r1425, %r182;

BB6_107:
	cvt.u64.u32	%rd181, %r1424;
	cvt.u64.u32	%rd182, %r1423;
	bfi.b64 	%rd183, %rd181, %rd182, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd183;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f552, %fd30;
	neg.f32 	%f553, %f552;
	setp.eq.s32	%p90, %r1425, 0;
	selp.f32	%f873, %f552, %f553, %p90;
	setp.eq.s32	%p91, %r182, 0;
	neg.s32 	%r880, %r192;
	selp.b32	%r1426, %r192, %r880, %p91;

BB6_109:
	add.s32 	%r201, %r1426, 1;
	and.b32  	%r202, %r201, 1;
	setp.eq.s32	%p92, %r202, 0;
	selp.f32	%f119, %f873, 0f3F800000, %p92;
	mul.rn.f32 	%f120, %f873, %f873;
	fma.rn.f32 	%f121, %f120, %f119, %f379;
	mov.f32 	%f874, 0fB94D4153;
	@%p92 bra 	BB6_111;

	mov.f32 	%f557, 0fBAB607ED;
	mov.f32 	%f558, 0f37CBAC00;
	fma.rn.f32 	%f874, %f558, %f120, %f557;

BB6_111:
	selp.f32	%f559, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f560, %f874, %f120, %f559;
	selp.f32	%f561, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f562, %f560, %f120, %f561;
	fma.rn.f32 	%f875, %f562, %f121, %f119;
	and.b32  	%r881, %r201, 2;
	setp.eq.s32	%p94, %r881, 0;
	@%p94 bra 	BB6_113;

	mov.f32 	%f564, 0fBF800000;
	fma.rn.f32 	%f875, %f875, %f564, %f379;

BB6_113:
	@%p84 bra 	BB6_124;

	setp.eq.f32	%p96, %f115, 0f7F800000;
	@%p96 bra 	BB6_123;
	bra.uni 	BB6_115;

BB6_123:
	mul.rn.f32 	%f876, %f113, %f379;
	bra.uni 	BB6_124;

BB6_115:
	mov.b32 	 %r203, %f113;
	shl.b32 	%r884, %r203, 8;
	or.b32  	%r204, %r884, -2147483648;
	cvta.to.local.u64 	%rd308, %rd133;
	mov.u32 	%r1428, 0;
	mov.u64 	%rd307, __cudart_i2opi_f;
	mov.u32 	%r1427, -6;

BB6_116:
	.pragma "nounroll";
	ld.const.u32 	%r887, [%rd307];
	// inline asm
	{
	mad.lo.cc.u32   %r885, %r887, %r204, %r1428;
	madc.hi.u32     %r1428, %r887, %r204,  0;
	}
	// inline asm
	st.local.u32 	[%rd308], %r885;
	add.s64 	%rd308, %rd308, 4;
	add.s64 	%rd307, %rd307, 4;
	add.s32 	%r1427, %r1427, 1;
	setp.ne.s32	%p97, %r1427, 0;
	@%p97 bra 	BB6_116;

	bfe.u32 	%r890, %r203, 23, 8;
	add.s32 	%r891, %r890, -128;
	shr.u32 	%r892, %r891, 5;
	and.b32  	%r209, %r203, -2147483648;
	cvta.to.local.u64 	%rd187, %rd133;
	st.local.u32 	[%rd187+24], %r1428;
	bfe.u32 	%r210, %r203, 23, 5;
	mov.u32 	%r893, 6;
	sub.s32 	%r894, %r893, %r892;
	mul.wide.s32 	%rd188, %r894, 4;
	add.s64 	%rd48, %rd187, %rd188;
	ld.local.u32 	%r1430, [%rd48];
	ld.local.u32 	%r1429, [%rd48+-4];
	setp.eq.s32	%p98, %r210, 0;
	@%p98 bra 	BB6_119;

	mov.u32 	%r895, 32;
	sub.s32 	%r896, %r895, %r210;
	shr.u32 	%r897, %r1429, %r896;
	shl.b32 	%r898, %r1430, %r210;
	add.s32 	%r1430, %r897, %r898;
	ld.local.u32 	%r899, [%rd48+-8];
	shr.u32 	%r900, %r899, %r896;
	shl.b32 	%r901, %r1429, %r210;
	add.s32 	%r1429, %r900, %r901;

BB6_119:
	shr.u32 	%r902, %r1429, 30;
	shl.b32 	%r903, %r1430, 2;
	add.s32 	%r1432, %r903, %r902;
	shl.b32 	%r218, %r1429, 2;
	shr.u32 	%r904, %r1432, 31;
	shr.u32 	%r905, %r1430, 30;
	add.s32 	%r219, %r904, %r905;
	setp.eq.s32	%p99, %r904, 0;
	@%p99 bra 	BB6_120;

	not.b32 	%r906, %r1432;
	neg.s32 	%r1431, %r218;
	setp.eq.s32	%p100, %r218, 0;
	selp.u32	%r907, 1, 0, %p100;
	add.s32 	%r1432, %r907, %r906;
	xor.b32  	%r1433, %r209, -2147483648;
	bra.uni 	BB6_122;

BB6_120:
	mov.u32 	%r1431, %r218;
	mov.u32 	%r1433, %r209;

BB6_122:
	cvt.u64.u32	%rd189, %r1432;
	cvt.u64.u32	%rd190, %r1431;
	bfi.b64 	%rd191, %rd189, %rd190, 32, 32;
	cvt.rn.f64.s64	%fd31, %rd191;
	mul.f64 	%fd32, %fd31, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f565, %fd32;
	neg.f32 	%f566, %f565;
	setp.eq.s32	%p101, %r1433, 0;
	selp.f32	%f876, %f565, %f566, %p101;
	setp.eq.s32	%p102, %r209, 0;
	neg.s32 	%r908, %r219;
	selp.b32	%r1434, %r219, %r908, %p102;

BB6_124:
	and.b32  	%r228, %r1434, 1;
	setp.eq.s32	%p103, %r228, 0;
	selp.f32	%f130, %f876, 0f3F800000, %p103;
	mul.rn.f32 	%f131, %f876, %f876;
	fma.rn.f32 	%f132, %f131, %f130, %f379;
	mov.f32 	%f877, 0fB94D4153;
	@%p103 bra 	BB6_126;

	mov.f32 	%f570, 0fBAB607ED;
	mov.f32 	%f571, 0f37CBAC00;
	fma.rn.f32 	%f877, %f571, %f131, %f570;

BB6_126:
	selp.f32	%f572, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f573, %f877, %f131, %f572;
	selp.f32	%f574, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f575, %f573, %f131, %f574;
	fma.rn.f32 	%f878, %f575, %f132, %f130;
	and.b32  	%r909, %r1434, 2;
	setp.eq.s32	%p105, %r909, 0;
	@%p105 bra 	BB6_128;

	mov.f32 	%f577, 0fBF800000;
	fma.rn.f32 	%f878, %f878, %f577, %f379;

BB6_128:
	and.b32  	%r910, %r1, 7;
	and.b32  	%r912, %r759, 1073741808;
	add.s32 	%r913, %r912, %r910;
	mul.f32 	%f578, %f112, %f878;
	mul.f32 	%f579, %f111, %f875;
	sub.f32 	%f580, %f579, %f578;
	mul.f32 	%f581, %f112, %f875;
	fma.rn.f32 	%f582, %f111, %f878, %f581;
	add.f32 	%f583, %f109, %f580;
	shl.b32 	%r914, %r913, 2;
	add.s32 	%r916, %r566, %r914;
	st.shared.f32 	[%r916], %f583;
	add.f32 	%f584, %f110, %f582;
	add.s32 	%r918, %r567, %r914;
	st.shared.f32 	[%r918], %f584;
	sub.f32 	%f585, %f109, %f580;
	st.shared.f32 	[%r916+32], %f585;
	sub.f32 	%f586, %f110, %f582;
	st.shared.f32 	[%r918+32], %f586;
	bar.sync 	0;
	ld.shared.f32 	%f138, [%r2];
	ld.shared.f32 	%f139, [%r3];
	ld.shared.f32 	%f140, [%r2+2048];
	ld.shared.f32 	%f141, [%r3+2048];
	shr.u32 	%r925, %r772, 28;
	add.s32 	%r926, %r1, %r925;
	and.b32  	%r927, %r926, 134217712;
	sub.s32 	%r928, %r1, %r927;
	shl.b32 	%r929, %r928, 5;
	cvt.rn.f32.s32	%f587, %r929;
	mul.f32 	%f588, %f587, 0f3A800000;
	cvt.f64.f32	%fd33, %f588;
	mul.f64 	%fd34, %fd33, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f142, %fd34;
	mul.f32 	%f589, %f142, 0f3F22F983;
	cvt.rni.s32.f32	%r1450, %f589;
	cvt.rn.f32.s32	%f590, %r1450;
	fma.rn.f32 	%f592, %f590, %f370, %f142;
	fma.rn.f32 	%f594, %f590, %f372, %f592;
	fma.rn.f32 	%f882, %f590, %f374, %f594;
	abs.f32 	%f144, %f142;
	setp.leu.f32	%p106, %f144, 0f47CE4780;
	mov.u32 	%r1442, %r1450;
	mov.f32 	%f879, %f882;
	@%p106 bra 	BB6_139;

	setp.eq.f32	%p107, %f144, 0f7F800000;
	@%p107 bra 	BB6_138;
	bra.uni 	BB6_130;

BB6_138:
	mul.rn.f32 	%f879, %f142, %f379;
	mov.u32 	%r1442, %r1450;
	bra.uni 	BB6_139;

BB6_130:
	mov.b32 	 %r231, %f142;
	shl.b32 	%r932, %r231, 8;
	or.b32  	%r232, %r932, -2147483648;
	cvta.to.local.u64 	%rd310, %rd133;
	mov.u32 	%r1436, 0;
	mov.u64 	%rd309, __cudart_i2opi_f;
	mov.u32 	%r1435, -6;

BB6_131:
	.pragma "nounroll";
	ld.const.u32 	%r935, [%rd309];
	// inline asm
	{
	mad.lo.cc.u32   %r933, %r935, %r232, %r1436;
	madc.hi.u32     %r1436, %r935, %r232,  0;
	}
	// inline asm
	st.local.u32 	[%rd310], %r933;
	add.s64 	%rd310, %rd310, 4;
	add.s64 	%rd309, %rd309, 4;
	add.s32 	%r1435, %r1435, 1;
	setp.ne.s32	%p108, %r1435, 0;
	@%p108 bra 	BB6_131;

	bfe.u32 	%r938, %r231, 23, 8;
	add.s32 	%r939, %r938, -128;
	shr.u32 	%r940, %r939, 5;
	and.b32  	%r237, %r231, -2147483648;
	cvta.to.local.u64 	%rd195, %rd133;
	st.local.u32 	[%rd195+24], %r1436;
	bfe.u32 	%r238, %r231, 23, 5;
	mov.u32 	%r941, 6;
	sub.s32 	%r942, %r941, %r940;
	mul.wide.s32 	%rd196, %r942, 4;
	add.s64 	%rd54, %rd195, %rd196;
	ld.local.u32 	%r1438, [%rd54];
	ld.local.u32 	%r1437, [%rd54+-4];
	setp.eq.s32	%p109, %r238, 0;
	@%p109 bra 	BB6_134;

	mov.u32 	%r943, 32;
	sub.s32 	%r944, %r943, %r238;
	shr.u32 	%r945, %r1437, %r944;
	shl.b32 	%r946, %r1438, %r238;
	add.s32 	%r1438, %r945, %r946;
	ld.local.u32 	%r947, [%rd54+-8];
	shr.u32 	%r948, %r947, %r944;
	shl.b32 	%r949, %r1437, %r238;
	add.s32 	%r1437, %r948, %r949;

BB6_134:
	shr.u32 	%r950, %r1437, 30;
	shl.b32 	%r951, %r1438, 2;
	add.s32 	%r1440, %r951, %r950;
	shl.b32 	%r246, %r1437, 2;
	shr.u32 	%r952, %r1440, 31;
	shr.u32 	%r953, %r1438, 30;
	add.s32 	%r247, %r952, %r953;
	setp.eq.s32	%p110, %r952, 0;
	@%p110 bra 	BB6_135;

	not.b32 	%r954, %r1440;
	neg.s32 	%r1439, %r246;
	setp.eq.s32	%p111, %r246, 0;
	selp.u32	%r955, 1, 0, %p111;
	add.s32 	%r1440, %r955, %r954;
	xor.b32  	%r1441, %r237, -2147483648;
	bra.uni 	BB6_137;

BB6_135:
	mov.u32 	%r1439, %r246;
	mov.u32 	%r1441, %r237;

BB6_137:
	cvt.u64.u32	%rd197, %r1440;
	cvt.u64.u32	%rd198, %r1439;
	bfi.b64 	%rd199, %rd197, %rd198, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd199;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f596, %fd36;
	neg.f32 	%f597, %f596;
	setp.eq.s32	%p112, %r1441, 0;
	selp.f32	%f879, %f596, %f597, %p112;
	setp.eq.s32	%p113, %r237, 0;
	neg.s32 	%r956, %r247;
	selp.b32	%r1442, %r247, %r956, %p113;

BB6_139:
	add.s32 	%r256, %r1442, 1;
	and.b32  	%r257, %r256, 1;
	setp.eq.s32	%p114, %r257, 0;
	selp.f32	%f148, %f879, 0f3F800000, %p114;
	mul.rn.f32 	%f149, %f879, %f879;
	fma.rn.f32 	%f150, %f149, %f148, %f379;
	mov.f32 	%f880, 0fB94D4153;
	@%p114 bra 	BB6_141;

	mov.f32 	%f601, 0fBAB607ED;
	mov.f32 	%f602, 0f37CBAC00;
	fma.rn.f32 	%f880, %f602, %f149, %f601;

BB6_141:
	selp.f32	%f603, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f604, %f880, %f149, %f603;
	selp.f32	%f605, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f606, %f604, %f149, %f605;
	fma.rn.f32 	%f881, %f606, %f150, %f148;
	and.b32  	%r957, %r256, 2;
	setp.eq.s32	%p116, %r957, 0;
	@%p116 bra 	BB6_143;

	mov.f32 	%f608, 0fBF800000;
	fma.rn.f32 	%f881, %f881, %f608, %f379;

BB6_143:
	@%p106 bra 	BB6_154;

	setp.eq.f32	%p118, %f144, 0f7F800000;
	@%p118 bra 	BB6_153;
	bra.uni 	BB6_145;

BB6_153:
	mul.rn.f32 	%f882, %f142, %f379;
	bra.uni 	BB6_154;

BB6_145:
	mov.b32 	 %r258, %f142;
	shl.b32 	%r960, %r258, 8;
	or.b32  	%r259, %r960, -2147483648;
	cvta.to.local.u64 	%rd312, %rd133;
	mov.u32 	%r1444, 0;
	mov.u64 	%rd311, __cudart_i2opi_f;
	mov.u32 	%r1443, -6;

BB6_146:
	.pragma "nounroll";
	ld.const.u32 	%r963, [%rd311];
	// inline asm
	{
	mad.lo.cc.u32   %r961, %r963, %r259, %r1444;
	madc.hi.u32     %r1444, %r963, %r259,  0;
	}
	// inline asm
	st.local.u32 	[%rd312], %r961;
	add.s64 	%rd312, %rd312, 4;
	add.s64 	%rd311, %rd311, 4;
	add.s32 	%r1443, %r1443, 1;
	setp.ne.s32	%p119, %r1443, 0;
	@%p119 bra 	BB6_146;

	bfe.u32 	%r966, %r258, 23, 8;
	add.s32 	%r967, %r966, -128;
	shr.u32 	%r968, %r967, 5;
	and.b32  	%r264, %r258, -2147483648;
	cvta.to.local.u64 	%rd203, %rd133;
	st.local.u32 	[%rd203+24], %r1444;
	bfe.u32 	%r265, %r258, 23, 5;
	mov.u32 	%r969, 6;
	sub.s32 	%r970, %r969, %r968;
	mul.wide.s32 	%rd204, %r970, 4;
	add.s64 	%rd60, %rd203, %rd204;
	ld.local.u32 	%r1446, [%rd60];
	ld.local.u32 	%r1445, [%rd60+-4];
	setp.eq.s32	%p120, %r265, 0;
	@%p120 bra 	BB6_149;

	mov.u32 	%r971, 32;
	sub.s32 	%r972, %r971, %r265;
	shr.u32 	%r973, %r1445, %r972;
	shl.b32 	%r974, %r1446, %r265;
	add.s32 	%r1446, %r973, %r974;
	ld.local.u32 	%r975, [%rd60+-8];
	shr.u32 	%r976, %r975, %r972;
	shl.b32 	%r977, %r1445, %r265;
	add.s32 	%r1445, %r976, %r977;

BB6_149:
	shr.u32 	%r978, %r1445, 30;
	shl.b32 	%r979, %r1446, 2;
	add.s32 	%r1448, %r979, %r978;
	shl.b32 	%r273, %r1445, 2;
	shr.u32 	%r980, %r1448, 31;
	shr.u32 	%r981, %r1446, 30;
	add.s32 	%r274, %r980, %r981;
	setp.eq.s32	%p121, %r980, 0;
	@%p121 bra 	BB6_150;

	not.b32 	%r982, %r1448;
	neg.s32 	%r1447, %r273;
	setp.eq.s32	%p122, %r273, 0;
	selp.u32	%r983, 1, 0, %p122;
	add.s32 	%r1448, %r983, %r982;
	xor.b32  	%r1449, %r264, -2147483648;
	bra.uni 	BB6_152;

BB6_150:
	mov.u32 	%r1447, %r273;
	mov.u32 	%r1449, %r264;

BB6_152:
	cvt.u64.u32	%rd205, %r1448;
	cvt.u64.u32	%rd206, %r1447;
	bfi.b64 	%rd207, %rd205, %rd206, 32, 32;
	cvt.rn.f64.s64	%fd37, %rd207;
	mul.f64 	%fd38, %fd37, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f609, %fd38;
	neg.f32 	%f610, %f609;
	setp.eq.s32	%p123, %r1449, 0;
	selp.f32	%f882, %f609, %f610, %p123;
	setp.eq.s32	%p124, %r264, 0;
	neg.s32 	%r984, %r274;
	selp.b32	%r1450, %r274, %r984, %p124;

BB6_154:
	and.b32  	%r283, %r1450, 1;
	setp.eq.s32	%p125, %r283, 0;
	selp.f32	%f159, %f882, 0f3F800000, %p125;
	mul.rn.f32 	%f160, %f882, %f882;
	fma.rn.f32 	%f161, %f160, %f159, %f379;
	mov.f32 	%f883, 0fB94D4153;
	@%p125 bra 	BB6_156;

	mov.f32 	%f614, 0fBAB607ED;
	mov.f32 	%f615, 0f37CBAC00;
	fma.rn.f32 	%f883, %f615, %f160, %f614;

BB6_156:
	selp.f32	%f616, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f617, %f883, %f160, %f616;
	selp.f32	%f618, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f619, %f617, %f160, %f618;
	fma.rn.f32 	%f884, %f619, %f161, %f159;
	and.b32  	%r985, %r1450, 2;
	setp.eq.s32	%p127, %r985, 0;
	@%p127 bra 	BB6_158;

	mov.f32 	%f621, 0fBF800000;
	fma.rn.f32 	%f884, %f884, %f621, %f379;

BB6_158:
	and.b32  	%r986, %r1, 15;
	and.b32  	%r988, %r759, 1073741792;
	add.s32 	%r989, %r988, %r986;
	mul.f32 	%f622, %f141, %f884;
	mul.f32 	%f623, %f140, %f881;
	sub.f32 	%f624, %f623, %f622;
	mul.f32 	%f625, %f141, %f881;
	fma.rn.f32 	%f626, %f140, %f884, %f625;
	add.f32 	%f627, %f138, %f624;
	shl.b32 	%r990, %r989, 2;
	add.s32 	%r992, %r686, %r990;
	st.shared.f32 	[%r992], %f627;
	add.f32 	%f628, %f139, %f626;
	add.s32 	%r994, %r688, %r990;
	st.shared.f32 	[%r994], %f628;
	sub.f32 	%f629, %f138, %f624;
	st.shared.f32 	[%r992+64], %f629;
	sub.f32 	%f630, %f139, %f626;
	st.shared.f32 	[%r994+64], %f630;
	bar.sync 	0;
	ld.shared.f32 	%f167, [%r692];
	ld.shared.f32 	%f168, [%r694];
	ld.shared.f32 	%f169, [%r692+2048];
	ld.shared.f32 	%f170, [%r694+2048];
	shr.u32 	%r1001, %r772, 27;
	add.s32 	%r1002, %r1, %r1001;
	and.b32  	%r1003, %r1002, 268435424;
	sub.s32 	%r1004, %r1, %r1003;
	shl.b32 	%r1005, %r1004, 4;
	cvt.rn.f32.s32	%f631, %r1005;
	mul.f32 	%f632, %f631, 0f3A800000;
	cvt.f64.f32	%fd39, %f632;
	mul.f64 	%fd40, %fd39, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f171, %fd40;
	mul.f32 	%f633, %f171, 0f3F22F983;
	cvt.rni.s32.f32	%r1466, %f633;
	cvt.rn.f32.s32	%f634, %r1466;
	fma.rn.f32 	%f636, %f634, %f370, %f171;
	fma.rn.f32 	%f638, %f634, %f372, %f636;
	fma.rn.f32 	%f888, %f634, %f374, %f638;
	abs.f32 	%f173, %f171;
	setp.leu.f32	%p128, %f173, 0f47CE4780;
	mov.u32 	%r1458, %r1466;
	mov.f32 	%f885, %f888;
	@%p128 bra 	BB6_169;

	setp.eq.f32	%p129, %f173, 0f7F800000;
	@%p129 bra 	BB6_168;
	bra.uni 	BB6_160;

BB6_168:
	mul.rn.f32 	%f885, %f171, %f379;
	mov.u32 	%r1458, %r1466;
	bra.uni 	BB6_169;

BB6_160:
	mov.b32 	 %r286, %f171;
	shl.b32 	%r1008, %r286, 8;
	or.b32  	%r287, %r1008, -2147483648;
	cvta.to.local.u64 	%rd314, %rd133;
	mov.u32 	%r1452, 0;
	mov.u64 	%rd313, __cudart_i2opi_f;
	mov.u32 	%r1451, -6;

BB6_161:
	.pragma "nounroll";
	ld.const.u32 	%r1011, [%rd313];
	// inline asm
	{
	mad.lo.cc.u32   %r1009, %r1011, %r287, %r1452;
	madc.hi.u32     %r1452, %r1011, %r287,  0;
	}
	// inline asm
	st.local.u32 	[%rd314], %r1009;
	add.s64 	%rd314, %rd314, 4;
	add.s64 	%rd313, %rd313, 4;
	add.s32 	%r1451, %r1451, 1;
	setp.ne.s32	%p130, %r1451, 0;
	@%p130 bra 	BB6_161;

	bfe.u32 	%r1014, %r286, 23, 8;
	add.s32 	%r1015, %r1014, -128;
	shr.u32 	%r1016, %r1015, 5;
	and.b32  	%r292, %r286, -2147483648;
	cvta.to.local.u64 	%rd211, %rd133;
	st.local.u32 	[%rd211+24], %r1452;
	bfe.u32 	%r293, %r286, 23, 5;
	mov.u32 	%r1017, 6;
	sub.s32 	%r1018, %r1017, %r1016;
	mul.wide.s32 	%rd212, %r1018, 4;
	add.s64 	%rd66, %rd211, %rd212;
	ld.local.u32 	%r1454, [%rd66];
	ld.local.u32 	%r1453, [%rd66+-4];
	setp.eq.s32	%p131, %r293, 0;
	@%p131 bra 	BB6_164;

	mov.u32 	%r1019, 32;
	sub.s32 	%r1020, %r1019, %r293;
	shr.u32 	%r1021, %r1453, %r1020;
	shl.b32 	%r1022, %r1454, %r293;
	add.s32 	%r1454, %r1021, %r1022;
	ld.local.u32 	%r1023, [%rd66+-8];
	shr.u32 	%r1024, %r1023, %r1020;
	shl.b32 	%r1025, %r1453, %r293;
	add.s32 	%r1453, %r1024, %r1025;

BB6_164:
	shr.u32 	%r1026, %r1453, 30;
	shl.b32 	%r1027, %r1454, 2;
	add.s32 	%r1456, %r1027, %r1026;
	shl.b32 	%r301, %r1453, 2;
	shr.u32 	%r1028, %r1456, 31;
	shr.u32 	%r1029, %r1454, 30;
	add.s32 	%r302, %r1028, %r1029;
	setp.eq.s32	%p132, %r1028, 0;
	@%p132 bra 	BB6_165;

	not.b32 	%r1030, %r1456;
	neg.s32 	%r1455, %r301;
	setp.eq.s32	%p133, %r301, 0;
	selp.u32	%r1031, 1, 0, %p133;
	add.s32 	%r1456, %r1031, %r1030;
	xor.b32  	%r1457, %r292, -2147483648;
	bra.uni 	BB6_167;

BB6_165:
	mov.u32 	%r1455, %r301;
	mov.u32 	%r1457, %r292;

BB6_167:
	cvt.u64.u32	%rd213, %r1456;
	cvt.u64.u32	%rd214, %r1455;
	bfi.b64 	%rd215, %rd213, %rd214, 32, 32;
	cvt.rn.f64.s64	%fd41, %rd215;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f640, %fd42;
	neg.f32 	%f641, %f640;
	setp.eq.s32	%p134, %r1457, 0;
	selp.f32	%f885, %f640, %f641, %p134;
	setp.eq.s32	%p135, %r292, 0;
	neg.s32 	%r1032, %r302;
	selp.b32	%r1458, %r302, %r1032, %p135;

BB6_169:
	add.s32 	%r311, %r1458, 1;
	and.b32  	%r312, %r311, 1;
	setp.eq.s32	%p136, %r312, 0;
	selp.f32	%f177, %f885, 0f3F800000, %p136;
	mul.rn.f32 	%f178, %f885, %f885;
	fma.rn.f32 	%f179, %f178, %f177, %f379;
	mov.f32 	%f886, 0fB94D4153;
	@%p136 bra 	BB6_171;

	mov.f32 	%f645, 0fBAB607ED;
	mov.f32 	%f646, 0f37CBAC00;
	fma.rn.f32 	%f886, %f646, %f178, %f645;

BB6_171:
	selp.f32	%f647, 0f3C0885E4, 0f3D2AAABB, %p136;
	fma.rn.f32 	%f648, %f886, %f178, %f647;
	selp.f32	%f649, 0fBE2AAAA8, 0fBEFFFFFF, %p136;
	fma.rn.f32 	%f650, %f648, %f178, %f649;
	fma.rn.f32 	%f887, %f650, %f179, %f177;
	and.b32  	%r1033, %r311, 2;
	setp.eq.s32	%p138, %r1033, 0;
	@%p138 bra 	BB6_173;

	mov.f32 	%f652, 0fBF800000;
	fma.rn.f32 	%f887, %f887, %f652, %f379;

BB6_173:
	@%p128 bra 	BB6_184;

	setp.eq.f32	%p140, %f173, 0f7F800000;
	@%p140 bra 	BB6_183;
	bra.uni 	BB6_175;

BB6_183:
	mul.rn.f32 	%f888, %f171, %f379;
	bra.uni 	BB6_184;

BB6_175:
	mov.b32 	 %r313, %f171;
	shl.b32 	%r1036, %r313, 8;
	or.b32  	%r314, %r1036, -2147483648;
	cvta.to.local.u64 	%rd316, %rd133;
	mov.u32 	%r1460, 0;
	mov.u64 	%rd315, __cudart_i2opi_f;
	mov.u32 	%r1459, -6;

BB6_176:
	.pragma "nounroll";
	ld.const.u32 	%r1039, [%rd315];
	// inline asm
	{
	mad.lo.cc.u32   %r1037, %r1039, %r314, %r1460;
	madc.hi.u32     %r1460, %r1039, %r314,  0;
	}
	// inline asm
	st.local.u32 	[%rd316], %r1037;
	add.s64 	%rd316, %rd316, 4;
	add.s64 	%rd315, %rd315, 4;
	add.s32 	%r1459, %r1459, 1;
	setp.ne.s32	%p141, %r1459, 0;
	@%p141 bra 	BB6_176;

	bfe.u32 	%r1042, %r313, 23, 8;
	add.s32 	%r1043, %r1042, -128;
	shr.u32 	%r1044, %r1043, 5;
	and.b32  	%r319, %r313, -2147483648;
	cvta.to.local.u64 	%rd219, %rd133;
	st.local.u32 	[%rd219+24], %r1460;
	bfe.u32 	%r320, %r313, 23, 5;
	mov.u32 	%r1045, 6;
	sub.s32 	%r1046, %r1045, %r1044;
	mul.wide.s32 	%rd220, %r1046, 4;
	add.s64 	%rd72, %rd219, %rd220;
	ld.local.u32 	%r1462, [%rd72];
	ld.local.u32 	%r1461, [%rd72+-4];
	setp.eq.s32	%p142, %r320, 0;
	@%p142 bra 	BB6_179;

	mov.u32 	%r1047, 32;
	sub.s32 	%r1048, %r1047, %r320;
	shr.u32 	%r1049, %r1461, %r1048;
	shl.b32 	%r1050, %r1462, %r320;
	add.s32 	%r1462, %r1049, %r1050;
	ld.local.u32 	%r1051, [%rd72+-8];
	shr.u32 	%r1052, %r1051, %r1048;
	shl.b32 	%r1053, %r1461, %r320;
	add.s32 	%r1461, %r1052, %r1053;

BB6_179:
	shr.u32 	%r1054, %r1461, 30;
	shl.b32 	%r1055, %r1462, 2;
	add.s32 	%r1464, %r1055, %r1054;
	shl.b32 	%r328, %r1461, 2;
	shr.u32 	%r1056, %r1464, 31;
	shr.u32 	%r1057, %r1462, 30;
	add.s32 	%r329, %r1056, %r1057;
	setp.eq.s32	%p143, %r1056, 0;
	@%p143 bra 	BB6_180;

	not.b32 	%r1058, %r1464;
	neg.s32 	%r1463, %r328;
	setp.eq.s32	%p144, %r328, 0;
	selp.u32	%r1059, 1, 0, %p144;
	add.s32 	%r1464, %r1059, %r1058;
	xor.b32  	%r1465, %r319, -2147483648;
	bra.uni 	BB6_182;

BB6_180:
	mov.u32 	%r1463, %r328;
	mov.u32 	%r1465, %r319;

BB6_182:
	cvt.u64.u32	%rd221, %r1464;
	cvt.u64.u32	%rd222, %r1463;
	bfi.b64 	%rd223, %rd221, %rd222, 32, 32;
	cvt.rn.f64.s64	%fd43, %rd223;
	mul.f64 	%fd44, %fd43, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f653, %fd44;
	neg.f32 	%f654, %f653;
	setp.eq.s32	%p145, %r1465, 0;
	selp.f32	%f888, %f653, %f654, %p145;
	setp.eq.s32	%p146, %r319, 0;
	neg.s32 	%r1060, %r329;
	selp.b32	%r1466, %r329, %r1060, %p146;

BB6_184:
	and.b32  	%r338, %r1466, 1;
	setp.eq.s32	%p147, %r338, 0;
	selp.f32	%f188, %f888, 0f3F800000, %p147;
	mul.rn.f32 	%f189, %f888, %f888;
	fma.rn.f32 	%f190, %f189, %f188, %f379;
	mov.f32 	%f889, 0fB94D4153;
	@%p147 bra 	BB6_186;

	mov.f32 	%f658, 0fBAB607ED;
	mov.f32 	%f659, 0f37CBAC00;
	fma.rn.f32 	%f889, %f659, %f189, %f658;

BB6_186:
	selp.f32	%f660, 0f3C0885E4, 0f3D2AAABB, %p147;
	fma.rn.f32 	%f661, %f889, %f189, %f660;
	selp.f32	%f662, 0fBE2AAAA8, 0fBEFFFFFF, %p147;
	fma.rn.f32 	%f663, %f661, %f189, %f662;
	fma.rn.f32 	%f890, %f663, %f190, %f188;
	and.b32  	%r1061, %r1466, 2;
	setp.eq.s32	%p149, %r1061, 0;
	@%p149 bra 	BB6_188;

	mov.f32 	%f665, 0fBF800000;
	fma.rn.f32 	%f890, %f890, %f665, %f379;

BB6_188:
	and.b32  	%r1062, %r1, 31;
	and.b32  	%r1064, %r759, 1073741760;
	add.s32 	%r1065, %r1064, %r1062;
	mul.f32 	%f666, %f170, %f890;
	mul.f32 	%f667, %f169, %f887;
	sub.f32 	%f668, %f667, %f666;
	mul.f32 	%f669, %f170, %f887;
	fma.rn.f32 	%f670, %f169, %f890, %f669;
	add.f32 	%f671, %f167, %f668;
	shl.b32 	%r1066, %r1065, 2;
	add.s32 	%r1068, %r566, %r1066;
	st.shared.f32 	[%r1068], %f671;
	add.f32 	%f672, %f168, %f670;
	add.s32 	%r1070, %r567, %r1066;
	st.shared.f32 	[%r1070], %f672;
	sub.f32 	%f673, %f167, %f668;
	st.shared.f32 	[%r1068+128], %f673;
	sub.f32 	%f674, %f168, %f670;
	st.shared.f32 	[%r1070+128], %f674;
	bar.sync 	0;
	ld.shared.f32 	%f196, [%r2];
	ld.shared.f32 	%f197, [%r3];
	ld.shared.f32 	%f198, [%r2+2048];
	ld.shared.f32 	%f199, [%r3+2048];
	shr.u32 	%r1077, %r772, 26;
	add.s32 	%r1078, %r1, %r1077;
	and.b32  	%r1079, %r1078, 536870848;
	sub.s32 	%r1080, %r1, %r1079;
	shl.b32 	%r1081, %r1080, 3;
	cvt.rn.f32.s32	%f675, %r1081;
	mul.f32 	%f676, %f675, 0f3A800000;
	cvt.f64.f32	%fd45, %f676;
	mul.f64 	%fd46, %fd45, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f200, %fd46;
	mul.f32 	%f677, %f200, 0f3F22F983;
	cvt.rni.s32.f32	%r1482, %f677;
	cvt.rn.f32.s32	%f678, %r1482;
	fma.rn.f32 	%f680, %f678, %f370, %f200;
	fma.rn.f32 	%f682, %f678, %f372, %f680;
	fma.rn.f32 	%f894, %f678, %f374, %f682;
	abs.f32 	%f202, %f200;
	setp.leu.f32	%p150, %f202, 0f47CE4780;
	mov.u32 	%r1474, %r1482;
	mov.f32 	%f891, %f894;
	@%p150 bra 	BB6_199;

	setp.eq.f32	%p151, %f202, 0f7F800000;
	@%p151 bra 	BB6_198;
	bra.uni 	BB6_190;

BB6_198:
	mul.rn.f32 	%f891, %f200, %f379;
	mov.u32 	%r1474, %r1482;
	bra.uni 	BB6_199;

BB6_190:
	mov.b32 	 %r341, %f200;
	shl.b32 	%r1084, %r341, 8;
	or.b32  	%r342, %r1084, -2147483648;
	cvta.to.local.u64 	%rd318, %rd133;
	mov.u32 	%r1468, 0;
	mov.u64 	%rd317, __cudart_i2opi_f;
	mov.u32 	%r1467, -6;

BB6_191:
	.pragma "nounroll";
	ld.const.u32 	%r1087, [%rd317];
	// inline asm
	{
	mad.lo.cc.u32   %r1085, %r1087, %r342, %r1468;
	madc.hi.u32     %r1468, %r1087, %r342,  0;
	}
	// inline asm
	st.local.u32 	[%rd318], %r1085;
	add.s64 	%rd318, %rd318, 4;
	add.s64 	%rd317, %rd317, 4;
	add.s32 	%r1467, %r1467, 1;
	setp.ne.s32	%p152, %r1467, 0;
	@%p152 bra 	BB6_191;

	bfe.u32 	%r1090, %r341, 23, 8;
	add.s32 	%r1091, %r1090, -128;
	shr.u32 	%r1092, %r1091, 5;
	and.b32  	%r347, %r341, -2147483648;
	cvta.to.local.u64 	%rd227, %rd133;
	st.local.u32 	[%rd227+24], %r1468;
	bfe.u32 	%r348, %r341, 23, 5;
	mov.u32 	%r1093, 6;
	sub.s32 	%r1094, %r1093, %r1092;
	mul.wide.s32 	%rd228, %r1094, 4;
	add.s64 	%rd78, %rd227, %rd228;
	ld.local.u32 	%r1470, [%rd78];
	ld.local.u32 	%r1469, [%rd78+-4];
	setp.eq.s32	%p153, %r348, 0;
	@%p153 bra 	BB6_194;

	mov.u32 	%r1095, 32;
	sub.s32 	%r1096, %r1095, %r348;
	shr.u32 	%r1097, %r1469, %r1096;
	shl.b32 	%r1098, %r1470, %r348;
	add.s32 	%r1470, %r1097, %r1098;
	ld.local.u32 	%r1099, [%rd78+-8];
	shr.u32 	%r1100, %r1099, %r1096;
	shl.b32 	%r1101, %r1469, %r348;
	add.s32 	%r1469, %r1100, %r1101;

BB6_194:
	shr.u32 	%r1102, %r1469, 30;
	shl.b32 	%r1103, %r1470, 2;
	add.s32 	%r1472, %r1103, %r1102;
	shl.b32 	%r356, %r1469, 2;
	shr.u32 	%r1104, %r1472, 31;
	shr.u32 	%r1105, %r1470, 30;
	add.s32 	%r357, %r1104, %r1105;
	setp.eq.s32	%p154, %r1104, 0;
	@%p154 bra 	BB6_195;

	not.b32 	%r1106, %r1472;
	neg.s32 	%r1471, %r356;
	setp.eq.s32	%p155, %r356, 0;
	selp.u32	%r1107, 1, 0, %p155;
	add.s32 	%r1472, %r1107, %r1106;
	xor.b32  	%r1473, %r347, -2147483648;
	bra.uni 	BB6_197;

BB6_195:
	mov.u32 	%r1471, %r356;
	mov.u32 	%r1473, %r347;

BB6_197:
	cvt.u64.u32	%rd229, %r1472;
	cvt.u64.u32	%rd230, %r1471;
	bfi.b64 	%rd231, %rd229, %rd230, 32, 32;
	cvt.rn.f64.s64	%fd47, %rd231;
	mul.f64 	%fd48, %fd47, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f684, %fd48;
	neg.f32 	%f685, %f684;
	setp.eq.s32	%p156, %r1473, 0;
	selp.f32	%f891, %f684, %f685, %p156;
	setp.eq.s32	%p157, %r347, 0;
	neg.s32 	%r1108, %r357;
	selp.b32	%r1474, %r357, %r1108, %p157;

BB6_199:
	add.s32 	%r366, %r1474, 1;
	and.b32  	%r367, %r366, 1;
	setp.eq.s32	%p158, %r367, 0;
	selp.f32	%f206, %f891, 0f3F800000, %p158;
	mul.rn.f32 	%f207, %f891, %f891;
	fma.rn.f32 	%f208, %f207, %f206, %f379;
	mov.f32 	%f892, 0fB94D4153;
	@%p158 bra 	BB6_201;

	mov.f32 	%f689, 0fBAB607ED;
	mov.f32 	%f690, 0f37CBAC00;
	fma.rn.f32 	%f892, %f690, %f207, %f689;

BB6_201:
	selp.f32	%f691, 0f3C0885E4, 0f3D2AAABB, %p158;
	fma.rn.f32 	%f692, %f892, %f207, %f691;
	selp.f32	%f693, 0fBE2AAAA8, 0fBEFFFFFF, %p158;
	fma.rn.f32 	%f694, %f692, %f207, %f693;
	fma.rn.f32 	%f893, %f694, %f208, %f206;
	and.b32  	%r1109, %r366, 2;
	setp.eq.s32	%p160, %r1109, 0;
	@%p160 bra 	BB6_203;

	mov.f32 	%f696, 0fBF800000;
	fma.rn.f32 	%f893, %f893, %f696, %f379;

BB6_203:
	@%p150 bra 	BB6_214;

	setp.eq.f32	%p162, %f202, 0f7F800000;
	@%p162 bra 	BB6_213;
	bra.uni 	BB6_205;

BB6_213:
	mul.rn.f32 	%f894, %f200, %f379;
	bra.uni 	BB6_214;

BB6_205:
	mov.b32 	 %r368, %f200;
	shl.b32 	%r1112, %r368, 8;
	or.b32  	%r369, %r1112, -2147483648;
	cvta.to.local.u64 	%rd320, %rd133;
	mov.u32 	%r1476, 0;
	mov.u64 	%rd319, __cudart_i2opi_f;
	mov.u32 	%r1475, -6;

BB6_206:
	.pragma "nounroll";
	ld.const.u32 	%r1115, [%rd319];
	// inline asm
	{
	mad.lo.cc.u32   %r1113, %r1115, %r369, %r1476;
	madc.hi.u32     %r1476, %r1115, %r369,  0;
	}
	// inline asm
	st.local.u32 	[%rd320], %r1113;
	add.s64 	%rd320, %rd320, 4;
	add.s64 	%rd319, %rd319, 4;
	add.s32 	%r1475, %r1475, 1;
	setp.ne.s32	%p163, %r1475, 0;
	@%p163 bra 	BB6_206;

	bfe.u32 	%r1118, %r368, 23, 8;
	add.s32 	%r1119, %r1118, -128;
	shr.u32 	%r1120, %r1119, 5;
	and.b32  	%r374, %r368, -2147483648;
	cvta.to.local.u64 	%rd235, %rd133;
	st.local.u32 	[%rd235+24], %r1476;
	bfe.u32 	%r375, %r368, 23, 5;
	mov.u32 	%r1121, 6;
	sub.s32 	%r1122, %r1121, %r1120;
	mul.wide.s32 	%rd236, %r1122, 4;
	add.s64 	%rd84, %rd235, %rd236;
	ld.local.u32 	%r1478, [%rd84];
	ld.local.u32 	%r1477, [%rd84+-4];
	setp.eq.s32	%p164, %r375, 0;
	@%p164 bra 	BB6_209;

	mov.u32 	%r1123, 32;
	sub.s32 	%r1124, %r1123, %r375;
	shr.u32 	%r1125, %r1477, %r1124;
	shl.b32 	%r1126, %r1478, %r375;
	add.s32 	%r1478, %r1125, %r1126;
	ld.local.u32 	%r1127, [%rd84+-8];
	shr.u32 	%r1128, %r1127, %r1124;
	shl.b32 	%r1129, %r1477, %r375;
	add.s32 	%r1477, %r1128, %r1129;

BB6_209:
	shr.u32 	%r1130, %r1477, 30;
	shl.b32 	%r1131, %r1478, 2;
	add.s32 	%r1480, %r1131, %r1130;
	shl.b32 	%r383, %r1477, 2;
	shr.u32 	%r1132, %r1480, 31;
	shr.u32 	%r1133, %r1478, 30;
	add.s32 	%r384, %r1132, %r1133;
	setp.eq.s32	%p165, %r1132, 0;
	@%p165 bra 	BB6_210;

	not.b32 	%r1134, %r1480;
	neg.s32 	%r1479, %r383;
	setp.eq.s32	%p166, %r383, 0;
	selp.u32	%r1135, 1, 0, %p166;
	add.s32 	%r1480, %r1135, %r1134;
	xor.b32  	%r1481, %r374, -2147483648;
	bra.uni 	BB6_212;

BB6_210:
	mov.u32 	%r1479, %r383;
	mov.u32 	%r1481, %r374;

BB6_212:
	cvt.u64.u32	%rd237, %r1480;
	cvt.u64.u32	%rd238, %r1479;
	bfi.b64 	%rd239, %rd237, %rd238, 32, 32;
	cvt.rn.f64.s64	%fd49, %rd239;
	mul.f64 	%fd50, %fd49, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f697, %fd50;
	neg.f32 	%f698, %f697;
	setp.eq.s32	%p167, %r1481, 0;
	selp.f32	%f894, %f697, %f698, %p167;
	setp.eq.s32	%p168, %r374, 0;
	neg.s32 	%r1136, %r384;
	selp.b32	%r1482, %r384, %r1136, %p168;

BB6_214:
	and.b32  	%r393, %r1482, 1;
	setp.eq.s32	%p169, %r393, 0;
	selp.f32	%f217, %f894, 0f3F800000, %p169;
	mul.rn.f32 	%f218, %f894, %f894;
	fma.rn.f32 	%f219, %f218, %f217, %f379;
	mov.f32 	%f895, 0fB94D4153;
	@%p169 bra 	BB6_216;

	mov.f32 	%f702, 0fBAB607ED;
	mov.f32 	%f703, 0f37CBAC00;
	fma.rn.f32 	%f895, %f703, %f218, %f702;

BB6_216:
	selp.f32	%f704, 0f3C0885E4, 0f3D2AAABB, %p169;
	fma.rn.f32 	%f705, %f895, %f218, %f704;
	selp.f32	%f706, 0fBE2AAAA8, 0fBEFFFFFF, %p169;
	fma.rn.f32 	%f707, %f705, %f218, %f706;
	fma.rn.f32 	%f896, %f707, %f219, %f217;
	and.b32  	%r1137, %r1482, 2;
	setp.eq.s32	%p171, %r1137, 0;
	@%p171 bra 	BB6_218;

	mov.f32 	%f709, 0fBF800000;
	fma.rn.f32 	%f896, %f896, %f709, %f379;

BB6_218:
	and.b32  	%r1138, %r1, 63;
	and.b32  	%r1140, %r759, 1073741696;
	add.s32 	%r1141, %r1140, %r1138;
	mul.f32 	%f710, %f199, %f896;
	mul.f32 	%f711, %f198, %f893;
	sub.f32 	%f712, %f711, %f710;
	mul.f32 	%f713, %f199, %f893;
	fma.rn.f32 	%f714, %f198, %f896, %f713;
	add.f32 	%f715, %f196, %f712;
	shl.b32 	%r1142, %r1141, 2;
	add.s32 	%r1144, %r686, %r1142;
	st.shared.f32 	[%r1144], %f715;
	add.f32 	%f716, %f197, %f714;
	add.s32 	%r1146, %r688, %r1142;
	st.shared.f32 	[%r1146], %f716;
	sub.f32 	%f717, %f196, %f712;
	st.shared.f32 	[%r1144+256], %f717;
	sub.f32 	%f718, %f197, %f714;
	st.shared.f32 	[%r1146+256], %f718;
	bar.sync 	0;
	ld.shared.f32 	%f225, [%r692];
	ld.shared.f32 	%f226, [%r694];
	ld.shared.f32 	%f227, [%r692+2048];
	ld.shared.f32 	%f228, [%r694+2048];
	shr.u32 	%r1153, %r772, 25;
	add.s32 	%r1154, %r1, %r1153;
	and.b32  	%r1155, %r1154, 1073741696;
	sub.s32 	%r1156, %r1, %r1155;
	shl.b32 	%r1157, %r1156, 2;
	cvt.rn.f32.s32	%f719, %r1157;
	mul.f32 	%f720, %f719, 0f3A800000;
	cvt.f64.f32	%fd51, %f720;
	mul.f64 	%fd52, %fd51, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f229, %fd52;
	mul.f32 	%f721, %f229, 0f3F22F983;
	cvt.rni.s32.f32	%r1498, %f721;
	cvt.rn.f32.s32	%f722, %r1498;
	fma.rn.f32 	%f724, %f722, %f370, %f229;
	fma.rn.f32 	%f726, %f722, %f372, %f724;
	fma.rn.f32 	%f900, %f722, %f374, %f726;
	abs.f32 	%f231, %f229;
	setp.leu.f32	%p172, %f231, 0f47CE4780;
	mov.u32 	%r1490, %r1498;
	mov.f32 	%f897, %f900;
	@%p172 bra 	BB6_229;

	setp.eq.f32	%p173, %f231, 0f7F800000;
	@%p173 bra 	BB6_228;
	bra.uni 	BB6_220;

BB6_228:
	mul.rn.f32 	%f897, %f229, %f379;
	mov.u32 	%r1490, %r1498;
	bra.uni 	BB6_229;

BB6_220:
	mov.b32 	 %r396, %f229;
	shl.b32 	%r1160, %r396, 8;
	or.b32  	%r397, %r1160, -2147483648;
	cvta.to.local.u64 	%rd322, %rd133;
	mov.u32 	%r1484, 0;
	mov.u64 	%rd321, __cudart_i2opi_f;
	mov.u32 	%r1483, -6;

BB6_221:
	.pragma "nounroll";
	ld.const.u32 	%r1163, [%rd321];
	// inline asm
	{
	mad.lo.cc.u32   %r1161, %r1163, %r397, %r1484;
	madc.hi.u32     %r1484, %r1163, %r397,  0;
	}
	// inline asm
	st.local.u32 	[%rd322], %r1161;
	add.s64 	%rd322, %rd322, 4;
	add.s64 	%rd321, %rd321, 4;
	add.s32 	%r1483, %r1483, 1;
	setp.ne.s32	%p174, %r1483, 0;
	@%p174 bra 	BB6_221;

	bfe.u32 	%r1166, %r396, 23, 8;
	add.s32 	%r1167, %r1166, -128;
	shr.u32 	%r1168, %r1167, 5;
	and.b32  	%r402, %r396, -2147483648;
	cvta.to.local.u64 	%rd243, %rd133;
	st.local.u32 	[%rd243+24], %r1484;
	bfe.u32 	%r403, %r396, 23, 5;
	mov.u32 	%r1169, 6;
	sub.s32 	%r1170, %r1169, %r1168;
	mul.wide.s32 	%rd244, %r1170, 4;
	add.s64 	%rd90, %rd243, %rd244;
	ld.local.u32 	%r1486, [%rd90];
	ld.local.u32 	%r1485, [%rd90+-4];
	setp.eq.s32	%p175, %r403, 0;
	@%p175 bra 	BB6_224;

	mov.u32 	%r1171, 32;
	sub.s32 	%r1172, %r1171, %r403;
	shr.u32 	%r1173, %r1485, %r1172;
	shl.b32 	%r1174, %r1486, %r403;
	add.s32 	%r1486, %r1173, %r1174;
	ld.local.u32 	%r1175, [%rd90+-8];
	shr.u32 	%r1176, %r1175, %r1172;
	shl.b32 	%r1177, %r1485, %r403;
	add.s32 	%r1485, %r1176, %r1177;

BB6_224:
	shr.u32 	%r1178, %r1485, 30;
	shl.b32 	%r1179, %r1486, 2;
	add.s32 	%r1488, %r1179, %r1178;
	shl.b32 	%r411, %r1485, 2;
	shr.u32 	%r1180, %r1488, 31;
	shr.u32 	%r1181, %r1486, 30;
	add.s32 	%r412, %r1180, %r1181;
	setp.eq.s32	%p176, %r1180, 0;
	@%p176 bra 	BB6_225;

	not.b32 	%r1182, %r1488;
	neg.s32 	%r1487, %r411;
	setp.eq.s32	%p177, %r411, 0;
	selp.u32	%r1183, 1, 0, %p177;
	add.s32 	%r1488, %r1183, %r1182;
	xor.b32  	%r1489, %r402, -2147483648;
	bra.uni 	BB6_227;

BB6_225:
	mov.u32 	%r1487, %r411;
	mov.u32 	%r1489, %r402;

BB6_227:
	cvt.u64.u32	%rd245, %r1488;
	cvt.u64.u32	%rd246, %r1487;
	bfi.b64 	%rd247, %rd245, %rd246, 32, 32;
	cvt.rn.f64.s64	%fd53, %rd247;
	mul.f64 	%fd54, %fd53, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f728, %fd54;
	neg.f32 	%f729, %f728;
	setp.eq.s32	%p178, %r1489, 0;
	selp.f32	%f897, %f728, %f729, %p178;
	setp.eq.s32	%p179, %r402, 0;
	neg.s32 	%r1184, %r412;
	selp.b32	%r1490, %r412, %r1184, %p179;

BB6_229:
	add.s32 	%r421, %r1490, 1;
	and.b32  	%r422, %r421, 1;
	setp.eq.s32	%p180, %r422, 0;
	selp.f32	%f235, %f897, 0f3F800000, %p180;
	mul.rn.f32 	%f236, %f897, %f897;
	fma.rn.f32 	%f237, %f236, %f235, %f379;
	mov.f32 	%f898, 0fB94D4153;
	@%p180 bra 	BB6_231;

	mov.f32 	%f733, 0fBAB607ED;
	mov.f32 	%f734, 0f37CBAC00;
	fma.rn.f32 	%f898, %f734, %f236, %f733;

BB6_231:
	selp.f32	%f735, 0f3C0885E4, 0f3D2AAABB, %p180;
	fma.rn.f32 	%f736, %f898, %f236, %f735;
	selp.f32	%f737, 0fBE2AAAA8, 0fBEFFFFFF, %p180;
	fma.rn.f32 	%f738, %f736, %f236, %f737;
	fma.rn.f32 	%f899, %f738, %f237, %f235;
	and.b32  	%r1185, %r421, 2;
	setp.eq.s32	%p182, %r1185, 0;
	@%p182 bra 	BB6_233;

	mov.f32 	%f740, 0fBF800000;
	fma.rn.f32 	%f899, %f899, %f740, %f379;

BB6_233:
	@%p172 bra 	BB6_244;

	setp.eq.f32	%p184, %f231, 0f7F800000;
	@%p184 bra 	BB6_243;
	bra.uni 	BB6_235;

BB6_243:
	mul.rn.f32 	%f900, %f229, %f379;
	bra.uni 	BB6_244;

BB6_235:
	mov.b32 	 %r423, %f229;
	shl.b32 	%r1188, %r423, 8;
	or.b32  	%r424, %r1188, -2147483648;
	cvta.to.local.u64 	%rd324, %rd133;
	mov.u32 	%r1492, 0;
	mov.u64 	%rd323, __cudart_i2opi_f;
	mov.u32 	%r1491, -6;

BB6_236:
	.pragma "nounroll";
	ld.const.u32 	%r1191, [%rd323];
	// inline asm
	{
	mad.lo.cc.u32   %r1189, %r1191, %r424, %r1492;
	madc.hi.u32     %r1492, %r1191, %r424,  0;
	}
	// inline asm
	st.local.u32 	[%rd324], %r1189;
	add.s64 	%rd324, %rd324, 4;
	add.s64 	%rd323, %rd323, 4;
	add.s32 	%r1491, %r1491, 1;
	setp.ne.s32	%p185, %r1491, 0;
	@%p185 bra 	BB6_236;

	bfe.u32 	%r1194, %r423, 23, 8;
	add.s32 	%r1195, %r1194, -128;
	shr.u32 	%r1196, %r1195, 5;
	and.b32  	%r429, %r423, -2147483648;
	cvta.to.local.u64 	%rd251, %rd133;
	st.local.u32 	[%rd251+24], %r1492;
	bfe.u32 	%r430, %r423, 23, 5;
	mov.u32 	%r1197, 6;
	sub.s32 	%r1198, %r1197, %r1196;
	mul.wide.s32 	%rd252, %r1198, 4;
	add.s64 	%rd96, %rd251, %rd252;
	ld.local.u32 	%r1494, [%rd96];
	ld.local.u32 	%r1493, [%rd96+-4];
	setp.eq.s32	%p186, %r430, 0;
	@%p186 bra 	BB6_239;

	mov.u32 	%r1199, 32;
	sub.s32 	%r1200, %r1199, %r430;
	shr.u32 	%r1201, %r1493, %r1200;
	shl.b32 	%r1202, %r1494, %r430;
	add.s32 	%r1494, %r1201, %r1202;
	ld.local.u32 	%r1203, [%rd96+-8];
	shr.u32 	%r1204, %r1203, %r1200;
	shl.b32 	%r1205, %r1493, %r430;
	add.s32 	%r1493, %r1204, %r1205;

BB6_239:
	shr.u32 	%r1206, %r1493, 30;
	shl.b32 	%r1207, %r1494, 2;
	add.s32 	%r1496, %r1207, %r1206;
	shl.b32 	%r438, %r1493, 2;
	shr.u32 	%r1208, %r1496, 31;
	shr.u32 	%r1209, %r1494, 30;
	add.s32 	%r439, %r1208, %r1209;
	setp.eq.s32	%p187, %r1208, 0;
	@%p187 bra 	BB6_240;

	not.b32 	%r1210, %r1496;
	neg.s32 	%r1495, %r438;
	setp.eq.s32	%p188, %r438, 0;
	selp.u32	%r1211, 1, 0, %p188;
	add.s32 	%r1496, %r1211, %r1210;
	xor.b32  	%r1497, %r429, -2147483648;
	bra.uni 	BB6_242;

BB6_240:
	mov.u32 	%r1495, %r438;
	mov.u32 	%r1497, %r429;

BB6_242:
	cvt.u64.u32	%rd253, %r1496;
	cvt.u64.u32	%rd254, %r1495;
	bfi.b64 	%rd255, %rd253, %rd254, 32, 32;
	cvt.rn.f64.s64	%fd55, %rd255;
	mul.f64 	%fd56, %fd55, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f741, %fd56;
	neg.f32 	%f742, %f741;
	setp.eq.s32	%p189, %r1497, 0;
	selp.f32	%f900, %f741, %f742, %p189;
	setp.eq.s32	%p190, %r429, 0;
	neg.s32 	%r1212, %r439;
	selp.b32	%r1498, %r439, %r1212, %p190;

BB6_244:
	and.b32  	%r448, %r1498, 1;
	setp.eq.s32	%p191, %r448, 0;
	selp.f32	%f246, %f900, 0f3F800000, %p191;
	mul.rn.f32 	%f247, %f900, %f900;
	fma.rn.f32 	%f248, %f247, %f246, %f379;
	mov.f32 	%f901, 0fB94D4153;
	@%p191 bra 	BB6_246;

	mov.f32 	%f746, 0fBAB607ED;
	mov.f32 	%f747, 0f37CBAC00;
	fma.rn.f32 	%f901, %f747, %f247, %f746;

BB6_246:
	selp.f32	%f748, 0f3C0885E4, 0f3D2AAABB, %p191;
	fma.rn.f32 	%f749, %f901, %f247, %f748;
	selp.f32	%f750, 0fBE2AAAA8, 0fBEFFFFFF, %p191;
	fma.rn.f32 	%f751, %f749, %f247, %f750;
	fma.rn.f32 	%f902, %f751, %f248, %f246;
	and.b32  	%r1213, %r1498, 2;
	setp.eq.s32	%p193, %r1213, 0;
	@%p193 bra 	BB6_248;

	mov.f32 	%f753, 0fBF800000;
	fma.rn.f32 	%f902, %f902, %f753, %f379;

BB6_248:
	and.b32  	%r1214, %r1, 127;
	and.b32  	%r1216, %r759, 1073741568;
	add.s32 	%r1217, %r1216, %r1214;
	mul.f32 	%f754, %f228, %f902;
	mul.f32 	%f755, %f227, %f899;
	sub.f32 	%f756, %f755, %f754;
	mul.f32 	%f757, %f228, %f899;
	fma.rn.f32 	%f758, %f227, %f902, %f757;
	add.f32 	%f759, %f225, %f756;
	shl.b32 	%r1218, %r1217, 2;
	add.s32 	%r1220, %r566, %r1218;
	st.shared.f32 	[%r1220], %f759;
	add.f32 	%f760, %f226, %f758;
	add.s32 	%r1222, %r567, %r1218;
	st.shared.f32 	[%r1222], %f760;
	sub.f32 	%f761, %f225, %f756;
	st.shared.f32 	[%r1220+512], %f761;
	sub.f32 	%f762, %f226, %f758;
	st.shared.f32 	[%r1222+512], %f762;
	bar.sync 	0;
	ld.shared.f32 	%f254, [%r2];
	ld.shared.f32 	%f255, [%r3];
	ld.shared.f32 	%f256, [%r2+2048];
	ld.shared.f32 	%f257, [%r3+2048];
	shr.u32 	%r1229, %r772, 24;
	add.s32 	%r1230, %r1, %r1229;
	and.b32  	%r1231, %r1230, 2147483392;
	sub.s32 	%r1232, %r1, %r1231;
	shl.b32 	%r1233, %r1232, 1;
	cvt.rn.f32.s32	%f763, %r1233;
	mul.f32 	%f764, %f763, 0f3A800000;
	cvt.f64.f32	%fd57, %f764;
	mul.f64 	%fd58, %fd57, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f258, %fd58;
	mul.f32 	%f765, %f258, 0f3F22F983;
	cvt.rni.s32.f32	%r1514, %f765;
	cvt.rn.f32.s32	%f766, %r1514;
	fma.rn.f32 	%f768, %f766, %f370, %f258;
	fma.rn.f32 	%f770, %f766, %f372, %f768;
	fma.rn.f32 	%f906, %f766, %f374, %f770;
	abs.f32 	%f260, %f258;
	setp.leu.f32	%p194, %f260, 0f47CE4780;
	mov.u32 	%r1506, %r1514;
	mov.f32 	%f903, %f906;
	@%p194 bra 	BB6_259;

	setp.eq.f32	%p195, %f260, 0f7F800000;
	@%p195 bra 	BB6_258;
	bra.uni 	BB6_250;

BB6_258:
	mul.rn.f32 	%f903, %f258, %f379;
	mov.u32 	%r1506, %r1514;
	bra.uni 	BB6_259;

BB6_250:
	mov.b32 	 %r451, %f258;
	shl.b32 	%r1236, %r451, 8;
	or.b32  	%r452, %r1236, -2147483648;
	cvta.to.local.u64 	%rd326, %rd133;
	mov.u32 	%r1500, 0;
	mov.u64 	%rd325, __cudart_i2opi_f;
	mov.u32 	%r1499, -6;

BB6_251:
	.pragma "nounroll";
	ld.const.u32 	%r1239, [%rd325];
	// inline asm
	{
	mad.lo.cc.u32   %r1237, %r1239, %r452, %r1500;
	madc.hi.u32     %r1500, %r1239, %r452,  0;
	}
	// inline asm
	st.local.u32 	[%rd326], %r1237;
	add.s64 	%rd326, %rd326, 4;
	add.s64 	%rd325, %rd325, 4;
	add.s32 	%r1499, %r1499, 1;
	setp.ne.s32	%p196, %r1499, 0;
	@%p196 bra 	BB6_251;

	bfe.u32 	%r1242, %r451, 23, 8;
	add.s32 	%r1243, %r1242, -128;
	shr.u32 	%r1244, %r1243, 5;
	and.b32  	%r457, %r451, -2147483648;
	cvta.to.local.u64 	%rd259, %rd133;
	st.local.u32 	[%rd259+24], %r1500;
	bfe.u32 	%r458, %r451, 23, 5;
	mov.u32 	%r1245, 6;
	sub.s32 	%r1246, %r1245, %r1244;
	mul.wide.s32 	%rd260, %r1246, 4;
	add.s64 	%rd102, %rd259, %rd260;
	ld.local.u32 	%r1502, [%rd102];
	ld.local.u32 	%r1501, [%rd102+-4];
	setp.eq.s32	%p197, %r458, 0;
	@%p197 bra 	BB6_254;

	mov.u32 	%r1247, 32;
	sub.s32 	%r1248, %r1247, %r458;
	shr.u32 	%r1249, %r1501, %r1248;
	shl.b32 	%r1250, %r1502, %r458;
	add.s32 	%r1502, %r1249, %r1250;
	ld.local.u32 	%r1251, [%rd102+-8];
	shr.u32 	%r1252, %r1251, %r1248;
	shl.b32 	%r1253, %r1501, %r458;
	add.s32 	%r1501, %r1252, %r1253;

BB6_254:
	shr.u32 	%r1254, %r1501, 30;
	shl.b32 	%r1255, %r1502, 2;
	add.s32 	%r1504, %r1255, %r1254;
	shl.b32 	%r466, %r1501, 2;
	shr.u32 	%r1256, %r1504, 31;
	shr.u32 	%r1257, %r1502, 30;
	add.s32 	%r467, %r1256, %r1257;
	setp.eq.s32	%p198, %r1256, 0;
	@%p198 bra 	BB6_255;

	not.b32 	%r1258, %r1504;
	neg.s32 	%r1503, %r466;
	setp.eq.s32	%p199, %r466, 0;
	selp.u32	%r1259, 1, 0, %p199;
	add.s32 	%r1504, %r1259, %r1258;
	xor.b32  	%r1505, %r457, -2147483648;
	bra.uni 	BB6_257;

BB6_255:
	mov.u32 	%r1503, %r466;
	mov.u32 	%r1505, %r457;

BB6_257:
	cvt.u64.u32	%rd261, %r1504;
	cvt.u64.u32	%rd262, %r1503;
	bfi.b64 	%rd263, %rd261, %rd262, 32, 32;
	cvt.rn.f64.s64	%fd59, %rd263;
	mul.f64 	%fd60, %fd59, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f772, %fd60;
	neg.f32 	%f773, %f772;
	setp.eq.s32	%p200, %r1505, 0;
	selp.f32	%f903, %f772, %f773, %p200;
	setp.eq.s32	%p201, %r457, 0;
	neg.s32 	%r1260, %r467;
	selp.b32	%r1506, %r467, %r1260, %p201;

BB6_259:
	add.s32 	%r476, %r1506, 1;
	and.b32  	%r477, %r476, 1;
	setp.eq.s32	%p202, %r477, 0;
	selp.f32	%f264, %f903, 0f3F800000, %p202;
	mul.rn.f32 	%f265, %f903, %f903;
	fma.rn.f32 	%f266, %f265, %f264, %f379;
	mov.f32 	%f904, 0fB94D4153;
	@%p202 bra 	BB6_261;

	mov.f32 	%f777, 0fBAB607ED;
	mov.f32 	%f778, 0f37CBAC00;
	fma.rn.f32 	%f904, %f778, %f265, %f777;

BB6_261:
	selp.f32	%f779, 0f3C0885E4, 0f3D2AAABB, %p202;
	fma.rn.f32 	%f780, %f904, %f265, %f779;
	selp.f32	%f781, 0fBE2AAAA8, 0fBEFFFFFF, %p202;
	fma.rn.f32 	%f782, %f780, %f265, %f781;
	fma.rn.f32 	%f905, %f782, %f266, %f264;
	and.b32  	%r1261, %r476, 2;
	setp.eq.s32	%p204, %r1261, 0;
	@%p204 bra 	BB6_263;

	mov.f32 	%f784, 0fBF800000;
	fma.rn.f32 	%f905, %f905, %f784, %f379;

BB6_263:
	@%p194 bra 	BB6_274;

	setp.eq.f32	%p206, %f260, 0f7F800000;
	@%p206 bra 	BB6_273;
	bra.uni 	BB6_265;

BB6_273:
	mul.rn.f32 	%f906, %f258, %f379;
	bra.uni 	BB6_274;

BB6_265:
	mov.b32 	 %r478, %f258;
	shl.b32 	%r1264, %r478, 8;
	or.b32  	%r479, %r1264, -2147483648;
	cvta.to.local.u64 	%rd328, %rd133;
	mov.u32 	%r1508, 0;
	mov.u64 	%rd327, __cudart_i2opi_f;
	mov.u32 	%r1507, -6;

BB6_266:
	.pragma "nounroll";
	ld.const.u32 	%r1267, [%rd327];
	// inline asm
	{
	mad.lo.cc.u32   %r1265, %r1267, %r479, %r1508;
	madc.hi.u32     %r1508, %r1267, %r479,  0;
	}
	// inline asm
	st.local.u32 	[%rd328], %r1265;
	add.s64 	%rd328, %rd328, 4;
	add.s64 	%rd327, %rd327, 4;
	add.s32 	%r1507, %r1507, 1;
	setp.ne.s32	%p207, %r1507, 0;
	@%p207 bra 	BB6_266;

	bfe.u32 	%r1270, %r478, 23, 8;
	add.s32 	%r1271, %r1270, -128;
	shr.u32 	%r1272, %r1271, 5;
	and.b32  	%r484, %r478, -2147483648;
	cvta.to.local.u64 	%rd267, %rd133;
	st.local.u32 	[%rd267+24], %r1508;
	bfe.u32 	%r485, %r478, 23, 5;
	mov.u32 	%r1273, 6;
	sub.s32 	%r1274, %r1273, %r1272;
	mul.wide.s32 	%rd268, %r1274, 4;
	add.s64 	%rd108, %rd267, %rd268;
	ld.local.u32 	%r1510, [%rd108];
	ld.local.u32 	%r1509, [%rd108+-4];
	setp.eq.s32	%p208, %r485, 0;
	@%p208 bra 	BB6_269;

	mov.u32 	%r1275, 32;
	sub.s32 	%r1276, %r1275, %r485;
	shr.u32 	%r1277, %r1509, %r1276;
	shl.b32 	%r1278, %r1510, %r485;
	add.s32 	%r1510, %r1277, %r1278;
	ld.local.u32 	%r1279, [%rd108+-8];
	shr.u32 	%r1280, %r1279, %r1276;
	shl.b32 	%r1281, %r1509, %r485;
	add.s32 	%r1509, %r1280, %r1281;

BB6_269:
	shr.u32 	%r1282, %r1509, 30;
	shl.b32 	%r1283, %r1510, 2;
	add.s32 	%r1512, %r1283, %r1282;
	shl.b32 	%r493, %r1509, 2;
	shr.u32 	%r1284, %r1512, 31;
	shr.u32 	%r1285, %r1510, 30;
	add.s32 	%r494, %r1284, %r1285;
	setp.eq.s32	%p209, %r1284, 0;
	@%p209 bra 	BB6_270;

	not.b32 	%r1286, %r1512;
	neg.s32 	%r1511, %r493;
	setp.eq.s32	%p210, %r493, 0;
	selp.u32	%r1287, 1, 0, %p210;
	add.s32 	%r1512, %r1287, %r1286;
	xor.b32  	%r1513, %r484, -2147483648;
	bra.uni 	BB6_272;

BB6_270:
	mov.u32 	%r1511, %r493;
	mov.u32 	%r1513, %r484;

BB6_272:
	cvt.u64.u32	%rd269, %r1512;
	cvt.u64.u32	%rd270, %r1511;
	bfi.b64 	%rd271, %rd269, %rd270, 32, 32;
	cvt.rn.f64.s64	%fd61, %rd271;
	mul.f64 	%fd62, %fd61, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f785, %fd62;
	neg.f32 	%f786, %f785;
	setp.eq.s32	%p211, %r1513, 0;
	selp.f32	%f906, %f785, %f786, %p211;
	setp.eq.s32	%p212, %r484, 0;
	neg.s32 	%r1288, %r494;
	selp.b32	%r1514, %r494, %r1288, %p212;

BB6_274:
	and.b32  	%r503, %r1514, 1;
	setp.eq.s32	%p213, %r503, 0;
	selp.f32	%f275, %f906, 0f3F800000, %p213;
	mul.rn.f32 	%f276, %f906, %f906;
	fma.rn.f32 	%f277, %f276, %f275, %f379;
	mov.f32 	%f907, 0fB94D4153;
	@%p213 bra 	BB6_276;

	mov.f32 	%f790, 0fBAB607ED;
	mov.f32 	%f791, 0f37CBAC00;
	fma.rn.f32 	%f907, %f791, %f276, %f790;

BB6_276:
	selp.f32	%f792, 0f3C0885E4, 0f3D2AAABB, %p213;
	fma.rn.f32 	%f793, %f907, %f276, %f792;
	selp.f32	%f794, 0fBE2AAAA8, 0fBEFFFFFF, %p213;
	fma.rn.f32 	%f795, %f793, %f276, %f794;
	fma.rn.f32 	%f908, %f795, %f277, %f275;
	and.b32  	%r1289, %r1514, 2;
	setp.eq.s32	%p215, %r1289, 0;
	@%p215 bra 	BB6_278;

	mov.f32 	%f797, 0fBF800000;
	fma.rn.f32 	%f908, %f908, %f797, %f379;

BB6_278:
	and.b32  	%r1290, %r1, 255;
	and.b32  	%r1292, %r759, 1073741312;
	add.s32 	%r1293, %r1292, %r1290;
	mul.f32 	%f798, %f257, %f908;
	mul.f32 	%f799, %f256, %f905;
	sub.f32 	%f800, %f799, %f798;
	mul.f32 	%f801, %f257, %f905;
	fma.rn.f32 	%f802, %f256, %f908, %f801;
	add.f32 	%f803, %f254, %f800;
	shl.b32 	%r1294, %r1293, 2;
	add.s32 	%r1296, %r686, %r1294;
	st.shared.f32 	[%r1296], %f803;
	add.f32 	%f804, %f255, %f802;
	add.s32 	%r1298, %r688, %r1294;
	st.shared.f32 	[%r1298], %f804;
	sub.f32 	%f805, %f254, %f800;
	st.shared.f32 	[%r1296+1024], %f805;
	sub.f32 	%f806, %f255, %f802;
	st.shared.f32 	[%r1298+1024], %f806;
	bar.sync 	0;
	ld.shared.f32 	%f283, [%r692];
	ld.shared.f32 	%f284, [%r694];
	ld.shared.f32 	%f285, [%r692+2048];
	ld.shared.f32 	%f286, [%r694+2048];
	shr.u32 	%r1305, %r772, 23;
	add.s32 	%r1306, %r1, %r1305;
	and.b32  	%r1307, %r1306, -512;
	sub.s32 	%r1308, %r1, %r1307;
	cvt.rn.f32.s32	%f807, %r1308;
	mul.f32 	%f808, %f807, 0f3A800000;
	cvt.f64.f32	%fd63, %f808;
	mul.f64 	%fd64, %fd63, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f287, %fd64;
	mul.f32 	%f809, %f287, 0f3F22F983;
	cvt.rni.s32.f32	%r1530, %f809;
	cvt.rn.f32.s32	%f810, %r1530;
	fma.rn.f32 	%f812, %f810, %f370, %f287;
	fma.rn.f32 	%f814, %f810, %f372, %f812;
	fma.rn.f32 	%f912, %f810, %f374, %f814;
	abs.f32 	%f289, %f287;
	setp.leu.f32	%p216, %f289, 0f47CE4780;
	mov.u32 	%r1522, %r1530;
	mov.f32 	%f909, %f912;
	@%p216 bra 	BB6_289;

	setp.eq.f32	%p217, %f289, 0f7F800000;
	@%p217 bra 	BB6_288;
	bra.uni 	BB6_280;

BB6_288:
	mul.rn.f32 	%f909, %f287, %f379;
	mov.u32 	%r1522, %r1530;
	bra.uni 	BB6_289;

BB6_280:
	mov.b32 	 %r506, %f287;
	shl.b32 	%r1311, %r506, 8;
	or.b32  	%r507, %r1311, -2147483648;
	cvta.to.local.u64 	%rd330, %rd133;
	mov.u32 	%r1516, 0;
	mov.u64 	%rd329, __cudart_i2opi_f;
	mov.u32 	%r1515, -6;

BB6_281:
	.pragma "nounroll";
	ld.const.u32 	%r1314, [%rd329];
	// inline asm
	{
	mad.lo.cc.u32   %r1312, %r1314, %r507, %r1516;
	madc.hi.u32     %r1516, %r1314, %r507,  0;
	}
	// inline asm
	st.local.u32 	[%rd330], %r1312;
	add.s64 	%rd330, %rd330, 4;
	add.s64 	%rd329, %rd329, 4;
	add.s32 	%r1515, %r1515, 1;
	setp.ne.s32	%p218, %r1515, 0;
	@%p218 bra 	BB6_281;

	bfe.u32 	%r1317, %r506, 23, 8;
	add.s32 	%r1318, %r1317, -128;
	shr.u32 	%r1319, %r1318, 5;
	and.b32  	%r512, %r506, -2147483648;
	cvta.to.local.u64 	%rd275, %rd133;
	st.local.u32 	[%rd275+24], %r1516;
	bfe.u32 	%r513, %r506, 23, 5;
	mov.u32 	%r1320, 6;
	sub.s32 	%r1321, %r1320, %r1319;
	mul.wide.s32 	%rd276, %r1321, 4;
	add.s64 	%rd114, %rd275, %rd276;
	ld.local.u32 	%r1518, [%rd114];
	ld.local.u32 	%r1517, [%rd114+-4];
	setp.eq.s32	%p219, %r513, 0;
	@%p219 bra 	BB6_284;

	mov.u32 	%r1322, 32;
	sub.s32 	%r1323, %r1322, %r513;
	shr.u32 	%r1324, %r1517, %r1323;
	shl.b32 	%r1325, %r1518, %r513;
	add.s32 	%r1518, %r1324, %r1325;
	ld.local.u32 	%r1326, [%rd114+-8];
	shr.u32 	%r1327, %r1326, %r1323;
	shl.b32 	%r1328, %r1517, %r513;
	add.s32 	%r1517, %r1327, %r1328;

BB6_284:
	shr.u32 	%r1329, %r1517, 30;
	shl.b32 	%r1330, %r1518, 2;
	add.s32 	%r1520, %r1330, %r1329;
	shl.b32 	%r521, %r1517, 2;
	shr.u32 	%r1331, %r1520, 31;
	shr.u32 	%r1332, %r1518, 30;
	add.s32 	%r522, %r1331, %r1332;
	setp.eq.s32	%p220, %r1331, 0;
	@%p220 bra 	BB6_285;

	not.b32 	%r1333, %r1520;
	neg.s32 	%r1519, %r521;
	setp.eq.s32	%p221, %r521, 0;
	selp.u32	%r1334, 1, 0, %p221;
	add.s32 	%r1520, %r1334, %r1333;
	xor.b32  	%r1521, %r512, -2147483648;
	bra.uni 	BB6_287;

BB6_285:
	mov.u32 	%r1519, %r521;
	mov.u32 	%r1521, %r512;

BB6_287:
	cvt.u64.u32	%rd277, %r1520;
	cvt.u64.u32	%rd278, %r1519;
	bfi.b64 	%rd279, %rd277, %rd278, 32, 32;
	cvt.rn.f64.s64	%fd65, %rd279;
	mul.f64 	%fd66, %fd65, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f816, %fd66;
	neg.f32 	%f817, %f816;
	setp.eq.s32	%p222, %r1521, 0;
	selp.f32	%f909, %f816, %f817, %p222;
	setp.eq.s32	%p223, %r512, 0;
	neg.s32 	%r1335, %r522;
	selp.b32	%r1522, %r522, %r1335, %p223;

BB6_289:
	add.s32 	%r531, %r1522, 1;
	and.b32  	%r532, %r531, 1;
	setp.eq.s32	%p224, %r532, 0;
	selp.f32	%f293, %f909, 0f3F800000, %p224;
	mul.rn.f32 	%f294, %f909, %f909;
	fma.rn.f32 	%f295, %f294, %f293, %f379;
	mov.f32 	%f910, 0fB94D4153;
	@%p224 bra 	BB6_291;

	mov.f32 	%f821, 0fBAB607ED;
	mov.f32 	%f822, 0f37CBAC00;
	fma.rn.f32 	%f910, %f822, %f294, %f821;

BB6_291:
	selp.f32	%f823, 0f3C0885E4, 0f3D2AAABB, %p224;
	fma.rn.f32 	%f824, %f910, %f294, %f823;
	selp.f32	%f825, 0fBE2AAAA8, 0fBEFFFFFF, %p224;
	fma.rn.f32 	%f826, %f824, %f294, %f825;
	fma.rn.f32 	%f911, %f826, %f295, %f293;
	and.b32  	%r1336, %r531, 2;
	setp.eq.s32	%p226, %r1336, 0;
	@%p226 bra 	BB6_293;

	mov.f32 	%f828, 0fBF800000;
	fma.rn.f32 	%f911, %f911, %f828, %f379;

BB6_293:
	@%p216 bra 	BB6_304;

	setp.eq.f32	%p228, %f289, 0f7F800000;
	@%p228 bra 	BB6_303;
	bra.uni 	BB6_295;

BB6_303:
	mul.rn.f32 	%f912, %f287, %f379;
	bra.uni 	BB6_304;

BB6_295:
	mov.b32 	 %r533, %f287;
	shl.b32 	%r1339, %r533, 8;
	or.b32  	%r534, %r1339, -2147483648;
	cvta.to.local.u64 	%rd332, %rd133;
	mov.u64 	%rd331, __cudart_i2opi_f;
	mov.u32 	%r1523, -6;

BB6_296:
	.pragma "nounroll";
	ld.const.u32 	%r1342, [%rd331];
	// inline asm
	{
	mad.lo.cc.u32   %r1340, %r1342, %r534, %r1524;
	madc.hi.u32     %r1524, %r1342, %r534,  0;
	}
	// inline asm
	st.local.u32 	[%rd332], %r1340;
	add.s64 	%rd332, %rd332, 4;
	add.s64 	%rd331, %rd331, 4;
	add.s32 	%r1523, %r1523, 1;
	setp.ne.s32	%p229, %r1523, 0;
	@%p229 bra 	BB6_296;

	bfe.u32 	%r1345, %r533, 23, 8;
	add.s32 	%r1346, %r1345, -128;
	shr.u32 	%r1347, %r1346, 5;
	and.b32  	%r539, %r533, -2147483648;
	cvta.to.local.u64 	%rd283, %rd133;
	st.local.u32 	[%rd283+24], %r1524;
	bfe.u32 	%r540, %r533, 23, 5;
	mov.u32 	%r1348, 6;
	sub.s32 	%r1349, %r1348, %r1347;
	mul.wide.s32 	%rd284, %r1349, 4;
	add.s64 	%rd120, %rd283, %rd284;
	ld.local.u32 	%r1526, [%rd120];
	ld.local.u32 	%r1525, [%rd120+-4];
	setp.eq.s32	%p230, %r540, 0;
	@%p230 bra 	BB6_299;

	mov.u32 	%r1350, 32;
	sub.s32 	%r1351, %r1350, %r540;
	shr.u32 	%r1352, %r1525, %r1351;
	shl.b32 	%r1353, %r1526, %r540;
	add.s32 	%r1526, %r1352, %r1353;
	ld.local.u32 	%r1354, [%rd120+-8];
	shr.u32 	%r1355, %r1354, %r1351;
	shl.b32 	%r1356, %r1525, %r540;
	add.s32 	%r1525, %r1355, %r1356;

BB6_299:
	shr.u32 	%r1357, %r1525, 30;
	shl.b32 	%r1358, %r1526, 2;
	add.s32 	%r1528, %r1358, %r1357;
	shl.b32 	%r548, %r1525, 2;
	shr.u32 	%r1359, %r1528, 31;
	shr.u32 	%r1360, %r1526, 30;
	add.s32 	%r549, %r1359, %r1360;
	setp.eq.s32	%p231, %r1359, 0;
	@%p231 bra 	BB6_300;

	not.b32 	%r1361, %r1528;
	neg.s32 	%r1527, %r548;
	setp.eq.s32	%p232, %r548, 0;
	selp.u32	%r1362, 1, 0, %p232;
	add.s32 	%r1528, %r1362, %r1361;
	xor.b32  	%r1529, %r539, -2147483648;
	bra.uni 	BB6_302;

BB6_300:
	mov.u32 	%r1527, %r548;
	mov.u32 	%r1529, %r539;

BB6_302:
	cvt.u64.u32	%rd285, %r1528;
	cvt.u64.u32	%rd286, %r1527;
	bfi.b64 	%rd287, %rd285, %rd286, 32, 32;
	cvt.rn.f64.s64	%fd67, %rd287;
	mul.f64 	%fd68, %fd67, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f829, %fd68;
	neg.f32 	%f830, %f829;
	setp.eq.s32	%p233, %r1529, 0;
	selp.f32	%f912, %f829, %f830, %p233;
	setp.eq.s32	%p234, %r539, 0;
	neg.s32 	%r1363, %r549;
	selp.b32	%r1530, %r549, %r1363, %p234;

BB6_304:
	and.b32  	%r558, %r1530, 1;
	setp.eq.s32	%p235, %r558, 0;
	selp.f32	%f304, %f912, 0f3F800000, %p235;
	mul.rn.f32 	%f305, %f912, %f912;
	fma.rn.f32 	%f306, %f305, %f304, %f379;
	mov.f32 	%f913, 0fB94D4153;
	@%p235 bra 	BB6_306;

	mov.f32 	%f834, 0fBAB607ED;
	mov.f32 	%f835, 0f37CBAC00;
	fma.rn.f32 	%f913, %f835, %f305, %f834;

BB6_306:
	selp.f32	%f836, 0f3C0885E4, 0f3D2AAABB, %p235;
	fma.rn.f32 	%f837, %f913, %f305, %f836;
	selp.f32	%f838, 0fBE2AAAA8, 0fBEFFFFFF, %p235;
	fma.rn.f32 	%f839, %f837, %f305, %f838;
	fma.rn.f32 	%f914, %f839, %f306, %f304;
	and.b32  	%r1364, %r1530, 2;
	setp.eq.s32	%p237, %r1364, 0;
	@%p237 bra 	BB6_308;

	mov.f32 	%f841, 0fBF800000;
	fma.rn.f32 	%f914, %f914, %f841, %f379;

BB6_308:
	mul.f32 	%f842, %f286, %f914;
	mul.f32 	%f843, %f285, %f911;
	sub.f32 	%f844, %f843, %f842;
	mul.f32 	%f845, %f286, %f911;
	fma.rn.f32 	%f846, %f285, %f914, %f845;
	add.f32 	%f847, %f283, %f844;
	cvta.to.global.u64 	%rd288, %rd121;
	shl.b32 	%r1366, %r561, 9;
	add.s32 	%r1367, %r1366, %r1;
	shl.b32 	%r1368, %r1367, 1;
	and.b32  	%r1369, %r1368, -1024;
	add.s32 	%r1370, %r1369, %r1;
	mul.wide.u32 	%rd289, %r1370, 4;
	add.s64 	%rd290, %rd288, %rd289;
	st.global.f32 	[%rd290], %f847;
	add.f32 	%f848, %f284, %f846;
	cvta.to.global.u64 	%rd291, %rd122;
	add.s64 	%rd292, %rd291, %rd289;
	st.global.f32 	[%rd292], %f848;
	sub.f32 	%f849, %f283, %f844;
	st.global.f32 	[%rd290+2048], %f849;
	sub.f32 	%f850, %f284, %f846;
	st.global.f32 	[%rd292+2048], %f850;
	ret;
}

	// .globl	_occa_preprocesses_ODW_10_0
.visible .entry _occa_preprocesses_ODW_10_0(
	.param .u64 _occa_preprocesses_ODW_10_0_param_0,
	.param .u32 _occa_preprocesses_ODW_10_0_param_1,
	.param .u32 _occa_preprocesses_ODW_10_0_param_2,
	.param .u32 _occa_preprocesses_ODW_10_0_param_3,
	.param .u64 _occa_preprocesses_ODW_10_0_param_4
)
.maxntid 512, 1, 1
{
	.local .align 4 .b8 	__local_depot7[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<35>;
	.reg .b16 	%rs<10>;
	.reg .f32 	%f<148>;
	.reg .b32 	%r<204>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<42>;
	// demoted variable
	.shared .align 4 .b8 _ZZ27_occa_preprocesses_ODW_10_0E2wr[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ27_occa_preprocesses_ODW_10_0E11windowAdded[2048];

	mov.u64 	%SPL, __local_depot7;
	ld.param.u64 	%rd14, [_occa_preprocesses_ODW_10_0_param_0];
	ld.param.u32 	%r62, [_occa_preprocesses_ODW_10_0_param_2];
	ld.param.u32 	%r63, [_occa_preprocesses_ODW_10_0_param_3];
	ld.param.u64 	%rd13, [_occa_preprocesses_ODW_10_0_param_4];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r64, %r1, %r63, %r2;
	add.s32 	%r65, %r64, 512;
	setp.lt.u32	%p1, %r64, %r62;
	setp.lt.u32	%p2, %r65, %r62;
	cvt.u64.u32	%rd15, %r64;
	selp.b64	%rd16, %rd15, 0, %p1;
	cvta.to.global.u64 	%rd17, %rd14;
	shl.b64 	%rd18, %rd16, 2;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.f32 	%f31, [%rd19];
	selp.f32	%f32, %f31, 0f00000000, %p1;
	shl.b32 	%r66, %r2, 2;
	mov.u32 	%r67, _ZZ27_occa_preprocesses_ODW_10_0E2wr;
	add.s32 	%r3, %r67, %r66;
	st.shared.f32 	[%r3], %f32;
	cvt.u64.u32	%rd20, %r65;
	selp.b64	%rd21, %rd20, 0, %p2;
	shl.b64 	%rd22, %rd21, 2;
	add.s64 	%rd23, %rd17, %rd22;
	ld.global.f32 	%f33, [%rd23];
	selp.f32	%f34, %f33, 0f00000000, %p2;
	st.shared.f32 	[%r3+2048], %f34;
	bar.sync 	0;
	setp.lt.s32	%p3, %r2, 512;
	selp.u16	%rs1, 1, 0, %p3;
	mul.wide.u16 	%r68, %rs1, 512;
	add.s32 	%r69, %r68, %r2;
	shl.b32 	%r70, %r69, 2;
	add.s32 	%r72, %r67, %r70;
	ld.shared.f32 	%f35, [%r72];
	ld.shared.f32 	%f36, [%r3];
	add.f32 	%f37, %f36, %f35;
	selp.u32	%r73, 1, 0, %p3;
	cvt.rn.f32.u32	%f38, %r73;
	mul.f32 	%f39, %f38, %f37;
	mov.u32 	%r75, _ZZ27_occa_preprocesses_ODW_10_0E11windowAdded;
	add.s32 	%r4, %r75, %r66;
	st.shared.f32 	[%r4], %f39;
	bar.sync 	0;
	setp.lt.s32	%p4, %r2, 256;
	selp.u16	%rs2, 1, 0, %p4;
	mul.wide.u16 	%r76, %rs2, 256;
	add.s32 	%r77, %r76, %r2;
	shl.b32 	%r78, %r77, 2;
	add.s32 	%r80, %r75, %r78;
	ld.shared.f32 	%f40, [%r80];
	ld.shared.f32 	%f41, [%r4];
	add.f32 	%f42, %f41, %f40;
	selp.u32	%r81, 1, 0, %p4;
	cvt.rn.f32.u32	%f43, %r81;
	mul.f32 	%f44, %f43, %f42;
	st.shared.f32 	[%r4], %f44;
	bar.sync 	0;
	setp.lt.s32	%p5, %r2, 128;
	selp.u16	%rs3, 1, 0, %p5;
	mul.wide.u16 	%r82, %rs3, 128;
	add.s32 	%r83, %r82, %r2;
	shl.b32 	%r84, %r83, 2;
	add.s32 	%r86, %r75, %r84;
	ld.shared.f32 	%f45, [%r86];
	ld.shared.f32 	%f46, [%r4];
	add.f32 	%f47, %f46, %f45;
	selp.u32	%r87, 1, 0, %p5;
	cvt.rn.f32.u32	%f48, %r87;
	mul.f32 	%f49, %f48, %f47;
	st.shared.f32 	[%r4], %f49;
	bar.sync 	0;
	setp.lt.s32	%p6, %r2, 64;
	selp.u16	%rs4, 1, 0, %p6;
	mul.wide.u16 	%r88, %rs4, 64;
	add.s32 	%r89, %r88, %r2;
	shl.b32 	%r90, %r89, 2;
	add.s32 	%r92, %r75, %r90;
	ld.shared.f32 	%f50, [%r92];
	ld.shared.f32 	%f51, [%r4];
	add.f32 	%f52, %f51, %f50;
	selp.u32	%r93, 1, 0, %p6;
	cvt.rn.f32.u32	%f53, %r93;
	mul.f32 	%f54, %f53, %f52;
	st.shared.f32 	[%r4], %f54;
	bar.sync 	0;
	setp.lt.s32	%p7, %r2, 32;
	selp.u16	%rs5, 1, 0, %p7;
	mul.wide.u16 	%r94, %rs5, 32;
	add.s32 	%r95, %r94, %r2;
	shl.b32 	%r96, %r95, 2;
	add.s32 	%r98, %r75, %r96;
	ld.shared.f32 	%f55, [%r98];
	ld.shared.f32 	%f56, [%r4];
	add.f32 	%f57, %f56, %f55;
	selp.u32	%r99, 1, 0, %p7;
	cvt.rn.f32.u32	%f58, %r99;
	mul.f32 	%f59, %f58, %f57;
	st.shared.f32 	[%r4], %f59;
	bar.sync 	0;
	setp.lt.s32	%p8, %r2, 16;
	selp.u16	%rs6, 1, 0, %p8;
	mul.wide.u16 	%r100, %rs6, 16;
	add.s32 	%r101, %r100, %r2;
	shl.b32 	%r102, %r101, 2;
	add.s32 	%r104, %r75, %r102;
	ld.shared.f32 	%f60, [%r104];
	ld.shared.f32 	%f61, [%r4];
	add.f32 	%f62, %f61, %f60;
	selp.u32	%r105, 1, 0, %p8;
	cvt.rn.f32.u32	%f63, %r105;
	mul.f32 	%f64, %f63, %f62;
	st.shared.f32 	[%r4], %f64;
	bar.sync 	0;
	setp.lt.s32	%p9, %r2, 8;
	selp.u16	%rs7, 1, 0, %p9;
	mul.wide.u16 	%r106, %rs7, 8;
	add.s32 	%r107, %r106, %r2;
	shl.b32 	%r108, %r107, 2;
	add.s32 	%r110, %r75, %r108;
	ld.shared.f32 	%f65, [%r110];
	ld.shared.f32 	%f66, [%r4];
	add.f32 	%f67, %f66, %f65;
	selp.u32	%r111, 1, 0, %p9;
	cvt.rn.f32.u32	%f68, %r111;
	mul.f32 	%f69, %f68, %f67;
	st.shared.f32 	[%r4], %f69;
	bar.sync 	0;
	setp.lt.s32	%p10, %r2, 4;
	selp.u16	%rs8, 1, 0, %p10;
	mul.wide.u16 	%r112, %rs8, 4;
	add.s32 	%r113, %r112, %r2;
	shl.b32 	%r114, %r113, 2;
	add.s32 	%r116, %r75, %r114;
	ld.shared.f32 	%f70, [%r116];
	ld.shared.f32 	%f71, [%r4];
	add.f32 	%f72, %f71, %f70;
	selp.u32	%r117, 1, 0, %p10;
	cvt.rn.f32.u32	%f73, %r117;
	mul.f32 	%f74, %f73, %f72;
	st.shared.f32 	[%r4], %f74;
	bar.sync 	0;
	setp.lt.s32	%p11, %r2, 2;
	selp.u16	%rs9, 1, 0, %p11;
	mul.wide.u16 	%r118, %rs9, 2;
	add.s32 	%r119, %r118, %r2;
	shl.b32 	%r120, %r119, 2;
	add.s32 	%r122, %r75, %r120;
	ld.shared.f32 	%f75, [%r122];
	ld.shared.f32 	%f76, [%r4];
	add.f32 	%f77, %f76, %f75;
	selp.u32	%r123, 1, 0, %p11;
	cvt.rn.f32.u32	%f78, %r123;
	mul.f32 	%f79, %f78, %f77;
	st.shared.f32 	[%r4], %f79;
	bar.sync 	0;
	setp.lt.s32	%p12, %r2, 1;
	selp.u32	%r124, 1, 0, %p12;
	add.s32 	%r125, %r124, %r2;
	shl.b32 	%r126, %r125, 2;
	add.s32 	%r128, %r75, %r126;
	ld.shared.f32 	%f80, [%r128];
	ld.shared.f32 	%f81, [%r4];
	add.f32 	%f82, %f81, %f80;
	cvt.rn.f32.u32	%f83, %r124;
	mul.f32 	%f84, %f83, %f82;
	st.shared.f32 	[%r4], %f84;
	bar.sync 	0;
	ld.shared.f32 	%f85, [_ZZ27_occa_preprocesses_ODW_10_0E11windowAdded];
	cvt.f64.f32	%fd1, %f85;
	mul.f64 	%fd2, %fd1, 0d3F50000000000000;
	ld.shared.f32 	%f86, [%r3];
	cvt.f64.f32	%fd3, %f86;
	sub.f64 	%fd4, %fd3, %fd2;
	cvt.rn.f32.f64	%f1, %fd4;
	st.shared.f32 	[%r3], %f1;
	ld.shared.f32 	%f87, [%r3+2048];
	cvt.f64.f32	%fd5, %f87;
	sub.f64 	%fd6, %fd5, %fd2;
	cvt.rn.f32.f64	%f2, %fd6;
	st.shared.f32 	[%r3+2048], %f2;
	cvt.rn.f32.s32	%f88, %r2;
	div.rn.f32 	%f89, %f88, 0f447FC000;
	cvt.f64.f32	%fd7, %f89;
	mul.f64 	%fd8, %fd7, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f3, %fd8;
	add.u64 	%rd1, %SPL, 0;
	mul.f32 	%f90, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r195, %f90;
	cvt.rn.f32.s32	%f91, %r195;
	mov.f32 	%f92, 0fBFC90FDA;
	fma.rn.f32 	%f93, %f91, %f92, %f3;
	mov.f32 	%f94, 0fB3A22168;
	fma.rn.f32 	%f95, %f91, %f94, %f93;
	mov.f32 	%f96, 0fA7C234C5;
	fma.rn.f32 	%f142, %f91, %f96, %f95;
	abs.f32 	%f5, %f3;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p13, %f5, 0f47CE4780;
	@%p13 bra 	BB7_11;

	setp.eq.f32	%p14, %f5, 0f7F800000;
	@%p14 bra 	BB7_10;
	bra.uni 	BB7_2;

BB7_10:
	mov.f32 	%f99, 0f00000000;
	mul.rn.f32 	%f142, %f3, %f99;
	bra.uni 	BB7_11;

BB7_2:
	mov.b32 	 %r6, %f3;
	shl.b32 	%r131, %r6, 8;
	or.b32  	%r7, %r131, -2147483648;
	mov.u32 	%r189, 0;
	mov.u64 	%rd38, __cudart_i2opi_f;
	mov.u32 	%r188, -6;
	mov.u64 	%rd39, %rd1;

BB7_3:
	.pragma "nounroll";
	ld.const.u32 	%r134, [%rd38];
	// inline asm
	{
	mad.lo.cc.u32   %r132, %r134, %r7, %r189;
	madc.hi.u32     %r189, %r134, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd39], %r132;
	add.s64 	%rd39, %rd39, 4;
	add.s64 	%rd38, %rd38, 4;
	add.s32 	%r188, %r188, 1;
	setp.ne.s32	%p15, %r188, 0;
	@%p15 bra 	BB7_3;

	bfe.u32 	%r137, %r6, 23, 8;
	add.s32 	%r138, %r137, -128;
	shr.u32 	%r139, %r138, 5;
	and.b32  	%r12, %r6, -2147483648;
	st.local.u32 	[%rd2], %r189;
	bfe.u32 	%r13, %r6, 23, 5;
	mov.u32 	%r140, 6;
	sub.s32 	%r141, %r140, %r139;
	mul.wide.s32 	%rd26, %r141, 4;
	add.s64 	%rd7, %rd1, %rd26;
	ld.local.u32 	%r191, [%rd7];
	ld.local.u32 	%r190, [%rd7+-4];
	setp.eq.s32	%p16, %r13, 0;
	@%p16 bra 	BB7_6;

	mov.u32 	%r142, 32;
	sub.s32 	%r143, %r142, %r13;
	shr.u32 	%r144, %r190, %r143;
	shl.b32 	%r145, %r191, %r13;
	add.s32 	%r191, %r144, %r145;
	ld.local.u32 	%r146, [%rd7+-8];
	shr.u32 	%r147, %r146, %r143;
	shl.b32 	%r148, %r190, %r13;
	add.s32 	%r190, %r147, %r148;

BB7_6:
	shr.u32 	%r149, %r190, 30;
	shl.b32 	%r150, %r191, 2;
	add.s32 	%r193, %r150, %r149;
	shl.b32 	%r21, %r190, 2;
	shr.u32 	%r151, %r193, 31;
	shr.u32 	%r152, %r191, 30;
	add.s32 	%r22, %r151, %r152;
	setp.eq.s32	%p17, %r151, 0;
	@%p17 bra 	BB7_7;

	not.b32 	%r153, %r193;
	neg.s32 	%r192, %r21;
	setp.eq.s32	%p18, %r21, 0;
	selp.u32	%r154, 1, 0, %p18;
	add.s32 	%r193, %r154, %r153;
	xor.b32  	%r194, %r12, -2147483648;
	bra.uni 	BB7_9;

BB7_7:
	mov.u32 	%r192, %r21;
	mov.u32 	%r194, %r12;

BB7_9:
	cvt.u64.u32	%rd27, %r193;
	cvt.u64.u32	%rd28, %r192;
	bfi.b64 	%rd29, %rd27, %rd28, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd29;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f97, %fd10;
	neg.f32 	%f98, %f97;
	setp.eq.s32	%p19, %r194, 0;
	selp.f32	%f142, %f97, %f98, %p19;
	setp.eq.s32	%p20, %r12, 0;
	neg.s32 	%r155, %r22;
	selp.b32	%r195, %r22, %r155, %p20;

BB7_11:
	add.s32 	%r31, %r195, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p21, %r32, 0;
	selp.f32	%f9, %f142, 0f3F800000, %p21;
	mul.rn.f32 	%f10, %f142, %f142;
	mov.f32 	%f101, 0f00000000;
	fma.rn.f32 	%f11, %f10, %f9, %f101;
	mov.f32 	%f143, 0fB94D4153;
	@%p21 bra 	BB7_13;

	mov.f32 	%f102, 0fBAB607ED;
	mov.f32 	%f103, 0f37CBAC00;
	fma.rn.f32 	%f143, %f103, %f10, %f102;

BB7_13:
	selp.f32	%f104, 0f3C0885E4, 0f3D2AAABB, %p21;
	fma.rn.f32 	%f105, %f143, %f10, %f104;
	selp.f32	%f106, 0fBE2AAAA8, 0fBEFFFFFF, %p21;
	fma.rn.f32 	%f107, %f105, %f10, %f106;
	fma.rn.f32 	%f144, %f107, %f11, %f9;
	and.b32  	%r156, %r31, 2;
	setp.eq.s32	%p23, %r156, 0;
	@%p23 bra 	BB7_15;

	mov.f32 	%f109, 0fBF800000;
	fma.rn.f32 	%f144, %f144, %f109, %f101;

BB7_15:
	mov.f32 	%f110, 0f3F800000;
	sub.f32 	%f111, %f110, %f144;
	mul.f32 	%f112, %f111, 0f3F000000;
	mul.f32 	%f113, %f1, %f112;
	st.shared.f32 	[%r3], %f113;
	add.s32 	%r157, %r2, 512;
	cvt.rn.f32.s32	%f114, %r157;
	div.rn.f32 	%f115, %f114, 0f447FC000;
	cvt.f64.f32	%fd11, %f115;
	mul.f64 	%fd12, %fd11, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f17, %fd12;
	mul.f32 	%f116, %f17, 0f3F22F983;
	cvt.rni.s32.f32	%r203, %f116;
	cvt.rn.f32.s32	%f117, %r203;
	fma.rn.f32 	%f119, %f117, %f92, %f17;
	fma.rn.f32 	%f121, %f117, %f94, %f119;
	fma.rn.f32 	%f145, %f117, %f96, %f121;
	abs.f32 	%f19, %f17;
	setp.leu.f32	%p24, %f19, 0f47CE4780;
	@%p24 bra 	BB7_26;

	setp.eq.f32	%p25, %f19, 0f7F800000;
	@%p25 bra 	BB7_25;
	bra.uni 	BB7_17;

BB7_25:
	mul.rn.f32 	%f145, %f17, %f101;
	bra.uni 	BB7_26;

BB7_17:
	mov.b32 	 %r34, %f17;
	shl.b32 	%r160, %r34, 8;
	or.b32  	%r35, %r160, -2147483648;
	mov.u32 	%r197, 0;
	mov.u64 	%rd40, __cudart_i2opi_f;
	mov.u32 	%r196, -6;
	mov.u64 	%rd41, %rd1;

BB7_18:
	.pragma "nounroll";
	ld.const.u32 	%r163, [%rd40];
	// inline asm
	{
	mad.lo.cc.u32   %r161, %r163, %r35, %r197;
	madc.hi.u32     %r197, %r163, %r35,  0;
	}
	// inline asm
	st.local.u32 	[%rd41], %r161;
	add.s64 	%rd41, %rd41, 4;
	add.s64 	%rd40, %rd40, 4;
	add.s32 	%r196, %r196, 1;
	setp.ne.s32	%p26, %r196, 0;
	@%p26 bra 	BB7_18;

	bfe.u32 	%r166, %r34, 23, 8;
	add.s32 	%r167, %r166, -128;
	shr.u32 	%r168, %r167, 5;
	and.b32  	%r40, %r34, -2147483648;
	st.local.u32 	[%rd2], %r197;
	bfe.u32 	%r41, %r34, 23, 5;
	mov.u32 	%r169, 6;
	sub.s32 	%r170, %r169, %r168;
	mul.wide.s32 	%rd31, %r170, 4;
	add.s64 	%rd12, %rd1, %rd31;
	ld.local.u32 	%r199, [%rd12];
	ld.local.u32 	%r198, [%rd12+-4];
	setp.eq.s32	%p27, %r41, 0;
	@%p27 bra 	BB7_21;

	mov.u32 	%r171, 32;
	sub.s32 	%r172, %r171, %r41;
	shr.u32 	%r173, %r198, %r172;
	shl.b32 	%r174, %r199, %r41;
	add.s32 	%r199, %r173, %r174;
	ld.local.u32 	%r175, [%rd12+-8];
	shr.u32 	%r176, %r175, %r172;
	shl.b32 	%r177, %r198, %r41;
	add.s32 	%r198, %r176, %r177;

BB7_21:
	shr.u32 	%r178, %r198, 30;
	shl.b32 	%r179, %r199, 2;
	add.s32 	%r201, %r179, %r178;
	shl.b32 	%r49, %r198, 2;
	shr.u32 	%r180, %r201, 31;
	shr.u32 	%r181, %r199, 30;
	add.s32 	%r50, %r180, %r181;
	setp.eq.s32	%p28, %r180, 0;
	@%p28 bra 	BB7_22;

	not.b32 	%r182, %r201;
	neg.s32 	%r200, %r49;
	setp.eq.s32	%p29, %r49, 0;
	selp.u32	%r183, 1, 0, %p29;
	add.s32 	%r201, %r183, %r182;
	xor.b32  	%r202, %r40, -2147483648;
	bra.uni 	BB7_24;

BB7_22:
	mov.u32 	%r200, %r49;
	mov.u32 	%r202, %r40;

BB7_24:
	cvt.u64.u32	%rd32, %r201;
	cvt.u64.u32	%rd33, %r200;
	bfi.b64 	%rd34, %rd32, %rd33, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd34;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f123, %fd14;
	neg.f32 	%f124, %f123;
	setp.eq.s32	%p30, %r202, 0;
	selp.f32	%f145, %f123, %f124, %p30;
	setp.eq.s32	%p31, %r40, 0;
	neg.s32 	%r184, %r50;
	selp.b32	%r203, %r50, %r184, %p31;

BB7_26:
	add.s32 	%r59, %r203, 1;
	and.b32  	%r60, %r59, 1;
	setp.eq.s32	%p32, %r60, 0;
	selp.f32	%f23, %f145, 0f3F800000, %p32;
	mul.rn.f32 	%f24, %f145, %f145;
	fma.rn.f32 	%f25, %f24, %f23, %f101;
	mov.f32 	%f146, 0fB94D4153;
	@%p32 bra 	BB7_28;

	mov.f32 	%f128, 0fBAB607ED;
	mov.f32 	%f129, 0f37CBAC00;
	fma.rn.f32 	%f146, %f129, %f24, %f128;

BB7_28:
	selp.f32	%f130, 0f3C0885E4, 0f3D2AAABB, %p32;
	fma.rn.f32 	%f131, %f146, %f24, %f130;
	selp.f32	%f132, 0fBE2AAAA8, 0fBEFFFFFF, %p32;
	fma.rn.f32 	%f133, %f131, %f24, %f132;
	fma.rn.f32 	%f147, %f133, %f25, %f23;
	and.b32  	%r185, %r59, 2;
	setp.eq.s32	%p34, %r185, 0;
	@%p34 bra 	BB7_30;

	mov.f32 	%f135, 0fBF800000;
	fma.rn.f32 	%f147, %f147, %f135, %f101;

BB7_30:
	sub.f32 	%f137, %f110, %f147;
	mul.f32 	%f138, %f137, 0f3F000000;
	mul.f32 	%f139, %f2, %f138;
	st.shared.f32 	[%r3+2048], %f139;
	bar.sync 	0;
	ld.shared.f32 	%f140, [%r3];
	shl.b32 	%r186, %r1, 10;
	add.s32 	%r187, %r186, %r2;
	cvta.to.global.u64 	%rd35, %rd13;
	mul.wide.u32 	%rd36, %r187, 4;
	add.s64 	%rd37, %rd35, %rd36;
	st.global.f32 	[%rd37], %f140;
	ld.shared.f32 	%f141, [%r3+2048];
	st.global.f32 	[%rd37+2048], %f141;
	ret;
}

	// .globl	_occa_Stockhoptimized10_0
.visible .entry _occa_Stockhoptimized10_0(
	.param .u64 _occa_Stockhoptimized10_0_param_0,
	.param .u64 _occa_Stockhoptimized10_0_param_1,
	.param .u32 _occa_Stockhoptimized10_0_param_2
)
.maxntid 512, 1, 1
{
	.local .align 4 .b8 	__local_depot8[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<205>;
	.reg .f32 	%f<771>;
	.reg .b32 	%r<1338>;
	.reg .f64 	%fd<55>;
	.reg .b64 	%rd<299>;
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized10_0E6FRBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized10_0E6FIBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized10_0E6SRBank[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized10_0E6SIBank[4096];

	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd109, [_occa_Stockhoptimized10_0_param_0];
	ld.param.u64 	%rd110, [_occa_Stockhoptimized10_0_param_1];
	mov.u32 	%r499, %ctaid.x;
	shl.b32 	%r500, %r499, 9;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r501, %r500, %r1;
	and.b32  	%r502, %r501, 511;
	shl.b32 	%r503, %r501, 1;
	and.b32  	%r504, %r503, -1024;
	add.s32 	%r505, %r504, %r502;
	cvta.to.global.u64 	%rd111, %rd109;
	mul.wide.u32 	%rd112, %r505, 4;
	add.s64 	%rd113, %rd111, %rd112;
	ld.global.f32 	%f1, [%rd113];
	ld.global.f32 	%f2, [%rd113+2048];
	mov.f32 	%f281, 0f80000000;
	cvt.rni.s32.f32	%r2, %f281;
	cvt.rn.f32.s32	%f282, %r2;
	mov.f32 	%f283, 0fBFC90FDA;
	fma.rn.f32 	%f284, %f282, %f283, %f281;
	mov.f32 	%f285, 0fB3A22168;
	fma.rn.f32 	%f286, %f282, %f285, %f284;
	mov.f32 	%f287, 0fA7C234C5;
	fma.rn.f32 	%f3, %f282, %f287, %f286;
	add.s32 	%r3, %r2, 1;
	mul.rn.f32 	%f4, %f3, %f3;
	and.b32  	%r4, %r3, 1;
	setp.eq.s32	%p1, %r4, 0;
	selp.f32	%f5, %f3, 0f3F800000, %p1;
	mov.f32 	%f288, 0f00000000;
	fma.rn.f32 	%f6, %f4, %f5, %f288;
	mov.f32 	%f713, 0fB94D4153;
	@%p1 bra 	BB8_2;

	mov.f32 	%f289, 0fBAB607ED;
	mov.f32 	%f290, 0f37CBAC00;
	fma.rn.f32 	%f713, %f290, %f4, %f289;

BB8_2:
	selp.f32	%f291, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f292, %f713, %f4, %f291;
	selp.f32	%f293, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f294, %f292, %f4, %f293;
	fma.rn.f32 	%f714, %f294, %f6, %f5;
	and.b32  	%r506, %r3, 2;
	setp.eq.s32	%p3, %r506, 0;
	@%p3 bra 	BB8_4;

	mov.f32 	%f296, 0fBF800000;
	fma.rn.f32 	%f714, %f714, %f296, %f288;

BB8_4:
	and.b32  	%r5, %r2, 1;
	setp.eq.s32	%p4, %r5, 0;
	selp.f32	%f12, %f3, 0f3F800000, %p4;
	fma.rn.f32 	%f13, %f4, %f12, %f288;
	mov.f32 	%f715, 0fB94D4153;
	@%p4 bra 	BB8_6;

	mov.f32 	%f299, 0fBAB607ED;
	mov.f32 	%f300, 0f37CBAC00;
	fma.rn.f32 	%f715, %f300, %f4, %f299;

BB8_6:
	selp.f32	%f301, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f302, %f715, %f4, %f301;
	selp.f32	%f303, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f304, %f302, %f4, %f303;
	fma.rn.f32 	%f716, %f304, %f13, %f12;
	and.b32  	%r507, %r2, 2;
	setp.eq.s32	%p6, %r507, 0;
	@%p6 bra 	BB8_8;

	mov.f32 	%f306, 0fBF800000;
	fma.rn.f32 	%f716, %f716, %f306, %f288;

BB8_8:
	mul.f32 	%f307, %f716, 0f00000000;
	mul.f32 	%f308, %f2, %f714;
	sub.f32 	%f309, %f308, %f307;
	mul.f32 	%f310, %f714, 0f00000000;
	fma.rn.f32 	%f311, %f2, %f716, %f310;
	add.f32 	%f312, %f1, %f309;
	shl.b32 	%r508, %r1, 3;
	mov.u32 	%r509, _ZZ25_occa_Stockhoptimized10_0E6FRBank;
	add.s32 	%r510, %r509, %r508;
	st.shared.f32 	[%r510], %f312;
	add.f32 	%f313, %f311, 0f00000000;
	mov.u32 	%r511, _ZZ25_occa_Stockhoptimized10_0E6FIBank;
	add.s32 	%r512, %r511, %r508;
	st.shared.f32 	[%r512], %f313;
	sub.f32 	%f314, %f1, %f309;
	st.shared.f32 	[%r510+4], %f314;
	sub.f32 	%f316, %f288, %f311;
	st.shared.f32 	[%r512+4], %f316;
	bar.sync 	0;
	shl.b32 	%r513, %r1, 2;
	add.s32 	%r515, %r509, %r513;
	ld.shared.f32 	%f19, [%r515];
	add.s32 	%r517, %r511, %r513;
	ld.shared.f32 	%f20, [%r517];
	ld.shared.f32 	%f21, [%r515+2048];
	ld.shared.f32 	%f22, [%r517+2048];
	shr.u32 	%r518, %r1, 31;
	add.s32 	%r519, %r1, %r518;
	and.b32  	%r520, %r519, 16777214;
	sub.s32 	%r521, %r1, %r520;
	shl.b32 	%r522, %r521, 8;
	cvt.rn.f32.s32	%f317, %r522;
	mul.f32 	%f318, %f317, 0f3A800000;
	cvt.f64.f32	%fd1, %f318;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f23, %fd2;
	mul.f32 	%f319, %f23, 0f3F22F983;
	cvt.rni.s32.f32	%r1209, %f319;
	cvt.rn.f32.s32	%f320, %r1209;
	fma.rn.f32 	%f322, %f320, %f283, %f23;
	fma.rn.f32 	%f324, %f320, %f285, %f322;
	fma.rn.f32 	%f720, %f320, %f287, %f324;
	abs.f32 	%f25, %f23;
	setp.leu.f32	%p7, %f25, 0f47CE4780;
	mov.u32 	%r1201, %r1209;
	mov.f32 	%f717, %f720;
	@%p7 bra 	BB8_19;

	setp.eq.f32	%p8, %f25, 0f7F800000;
	@%p8 bra 	BB8_18;
	bra.uni 	BB8_10;

BB8_18:
	mul.rn.f32 	%f717, %f23, %f288;
	mov.u32 	%r1201, %r1209;
	bra.uni 	BB8_19;

BB8_10:
	mov.b32 	 %r525, %f23;
	shl.b32 	%r526, %r525, 8;
	or.b32  	%r7, %r526, -2147483648;
	add.u64 	%rd115, %SP, 0;
	add.u64 	%rd264, %SPL, 0;
	mov.u32 	%r1195, 0;
	mov.u64 	%rd263, __cudart_i2opi_f;
	mov.u32 	%r1194, -6;

BB8_11:
	.pragma "nounroll";
	ld.const.u32 	%r529, [%rd263];
	// inline asm
	{
	mad.lo.cc.u32   %r527, %r529, %r7, %r1195;
	madc.hi.u32     %r1195, %r529, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd264], %r527;
	add.s64 	%rd264, %rd264, 4;
	add.s64 	%rd263, %rd263, 4;
	add.s32 	%r1194, %r1194, 1;
	setp.ne.s32	%p9, %r1194, 0;
	@%p9 bra 	BB8_11;

	bfe.u32 	%r533, %r525, 23, 8;
	add.s32 	%r534, %r533, -128;
	shr.u32 	%r535, %r534, 5;
	and.b32  	%r12, %r525, -2147483648;
	cvta.to.local.u64 	%rd117, %rd115;
	st.local.u32 	[%rd117+24], %r1195;
	bfe.u32 	%r13, %r525, 23, 5;
	mov.u32 	%r536, 6;
	sub.s32 	%r537, %r536, %r535;
	mul.wide.s32 	%rd118, %r537, 4;
	add.s64 	%rd6, %rd117, %rd118;
	ld.local.u32 	%r1197, [%rd6];
	ld.local.u32 	%r1196, [%rd6+-4];
	setp.eq.s32	%p10, %r13, 0;
	@%p10 bra 	BB8_14;

	mov.u32 	%r538, 32;
	sub.s32 	%r539, %r538, %r13;
	shr.u32 	%r540, %r1196, %r539;
	shl.b32 	%r541, %r1197, %r13;
	add.s32 	%r1197, %r540, %r541;
	ld.local.u32 	%r542, [%rd6+-8];
	shr.u32 	%r543, %r542, %r539;
	shl.b32 	%r544, %r1196, %r13;
	add.s32 	%r1196, %r543, %r544;

BB8_14:
	shr.u32 	%r545, %r1196, 30;
	shl.b32 	%r546, %r1197, 2;
	add.s32 	%r1199, %r546, %r545;
	shl.b32 	%r21, %r1196, 2;
	shr.u32 	%r547, %r1199, 31;
	shr.u32 	%r548, %r1197, 30;
	add.s32 	%r22, %r547, %r548;
	setp.eq.s32	%p11, %r547, 0;
	@%p11 bra 	BB8_15;

	not.b32 	%r549, %r1199;
	neg.s32 	%r1198, %r21;
	setp.eq.s32	%p12, %r21, 0;
	selp.u32	%r550, 1, 0, %p12;
	add.s32 	%r1199, %r550, %r549;
	xor.b32  	%r1200, %r12, -2147483648;
	bra.uni 	BB8_17;

BB8_15:
	mov.u32 	%r1198, %r21;
	mov.u32 	%r1200, %r12;

BB8_17:
	cvt.u64.u32	%rd119, %r1199;
	cvt.u64.u32	%rd120, %r1198;
	bfi.b64 	%rd121, %rd119, %rd120, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd121;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f326, %fd4;
	neg.f32 	%f327, %f326;
	setp.eq.s32	%p13, %r1200, 0;
	selp.f32	%f717, %f326, %f327, %p13;
	setp.eq.s32	%p14, %r12, 0;
	neg.s32 	%r551, %r22;
	selp.b32	%r1201, %r22, %r551, %p14;

BB8_19:
	add.s32 	%r31, %r1201, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p15, %r32, 0;
	selp.f32	%f29, %f717, 0f3F800000, %p15;
	mul.rn.f32 	%f30, %f717, %f717;
	fma.rn.f32 	%f31, %f30, %f29, %f288;
	mov.f32 	%f718, 0fB94D4153;
	@%p15 bra 	BB8_21;

	mov.f32 	%f331, 0fBAB607ED;
	mov.f32 	%f332, 0f37CBAC00;
	fma.rn.f32 	%f718, %f332, %f30, %f331;

BB8_21:
	selp.f32	%f333, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f334, %f718, %f30, %f333;
	selp.f32	%f335, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f336, %f334, %f30, %f335;
	fma.rn.f32 	%f719, %f336, %f31, %f29;
	and.b32  	%r552, %r31, 2;
	setp.eq.s32	%p17, %r552, 0;
	@%p17 bra 	BB8_23;

	mov.f32 	%f338, 0fBF800000;
	fma.rn.f32 	%f719, %f719, %f338, %f288;

BB8_23:
	@%p7 bra 	BB8_34;

	setp.eq.f32	%p19, %f25, 0f7F800000;
	@%p19 bra 	BB8_33;
	bra.uni 	BB8_25;

BB8_33:
	mul.rn.f32 	%f720, %f23, %f288;
	bra.uni 	BB8_34;

BB8_25:
	mov.b32 	 %r33, %f23;
	shl.b32 	%r555, %r33, 8;
	or.b32  	%r34, %r555, -2147483648;
	add.u64 	%rd123, %SP, 0;
	add.u64 	%rd266, %SPL, 0;
	mov.u32 	%r1203, 0;
	mov.u64 	%rd265, __cudart_i2opi_f;
	mov.u32 	%r1202, -6;

BB8_26:
	.pragma "nounroll";
	ld.const.u32 	%r558, [%rd265];
	// inline asm
	{
	mad.lo.cc.u32   %r556, %r558, %r34, %r1203;
	madc.hi.u32     %r1203, %r558, %r34,  0;
	}
	// inline asm
	st.local.u32 	[%rd266], %r556;
	add.s64 	%rd266, %rd266, 4;
	add.s64 	%rd265, %rd265, 4;
	add.s32 	%r1202, %r1202, 1;
	setp.ne.s32	%p20, %r1202, 0;
	@%p20 bra 	BB8_26;

	bfe.u32 	%r561, %r33, 23, 8;
	add.s32 	%r562, %r561, -128;
	shr.u32 	%r563, %r562, 5;
	and.b32  	%r39, %r33, -2147483648;
	cvta.to.local.u64 	%rd125, %rd123;
	st.local.u32 	[%rd125+24], %r1203;
	bfe.u32 	%r40, %r33, 23, 5;
	mov.u32 	%r564, 6;
	sub.s32 	%r565, %r564, %r563;
	mul.wide.s32 	%rd126, %r565, 4;
	add.s64 	%rd12, %rd125, %rd126;
	ld.local.u32 	%r1205, [%rd12];
	ld.local.u32 	%r1204, [%rd12+-4];
	setp.eq.s32	%p21, %r40, 0;
	@%p21 bra 	BB8_29;

	mov.u32 	%r566, 32;
	sub.s32 	%r567, %r566, %r40;
	shr.u32 	%r568, %r1204, %r567;
	shl.b32 	%r569, %r1205, %r40;
	add.s32 	%r1205, %r568, %r569;
	ld.local.u32 	%r570, [%rd12+-8];
	shr.u32 	%r571, %r570, %r567;
	shl.b32 	%r572, %r1204, %r40;
	add.s32 	%r1204, %r571, %r572;

BB8_29:
	shr.u32 	%r573, %r1204, 30;
	shl.b32 	%r574, %r1205, 2;
	add.s32 	%r1207, %r574, %r573;
	shl.b32 	%r48, %r1204, 2;
	shr.u32 	%r575, %r1207, 31;
	shr.u32 	%r576, %r1205, 30;
	add.s32 	%r49, %r575, %r576;
	setp.eq.s32	%p22, %r575, 0;
	@%p22 bra 	BB8_30;

	not.b32 	%r577, %r1207;
	neg.s32 	%r1206, %r48;
	setp.eq.s32	%p23, %r48, 0;
	selp.u32	%r578, 1, 0, %p23;
	add.s32 	%r1207, %r578, %r577;
	xor.b32  	%r1208, %r39, -2147483648;
	bra.uni 	BB8_32;

BB8_30:
	mov.u32 	%r1206, %r48;
	mov.u32 	%r1208, %r39;

BB8_32:
	cvt.u64.u32	%rd127, %r1207;
	cvt.u64.u32	%rd128, %r1206;
	bfi.b64 	%rd129, %rd127, %rd128, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd129;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f339, %fd6;
	neg.f32 	%f340, %f339;
	setp.eq.s32	%p24, %r1208, 0;
	selp.f32	%f720, %f339, %f340, %p24;
	setp.eq.s32	%p25, %r39, 0;
	neg.s32 	%r579, %r49;
	selp.b32	%r1209, %r49, %r579, %p25;

BB8_34:
	and.b32  	%r58, %r1209, 1;
	setp.eq.s32	%p26, %r58, 0;
	selp.f32	%f40, %f720, 0f3F800000, %p26;
	mul.rn.f32 	%f41, %f720, %f720;
	fma.rn.f32 	%f42, %f41, %f40, %f288;
	mov.f32 	%f721, 0fB94D4153;
	@%p26 bra 	BB8_36;

	mov.f32 	%f344, 0fBAB607ED;
	mov.f32 	%f345, 0f37CBAC00;
	fma.rn.f32 	%f721, %f345, %f41, %f344;

BB8_36:
	selp.f32	%f346, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f347, %f721, %f41, %f346;
	selp.f32	%f348, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f349, %f347, %f41, %f348;
	fma.rn.f32 	%f722, %f349, %f42, %f40;
	and.b32  	%r580, %r1209, 2;
	setp.eq.s32	%p28, %r580, 0;
	@%p28 bra 	BB8_38;

	mov.f32 	%f351, 0fBF800000;
	fma.rn.f32 	%f722, %f722, %f351, %f288;

BB8_38:
	mul.f32 	%f352, %f22, %f722;
	mul.f32 	%f353, %f21, %f719;
	sub.f32 	%f354, %f353, %f352;
	mul.f32 	%f355, %f22, %f719;
	fma.rn.f32 	%f356, %f21, %f722, %f355;
	add.f32 	%f357, %f19, %f354;
	shl.b32 	%r581, %r1, 1;
	and.b32  	%r582, %r581, 1073741820;
	and.b32  	%r583, %r1, 1;
	add.s32 	%r584, %r582, %r583;
	shl.b32 	%r585, %r584, 2;
	mov.u32 	%r586, _ZZ25_occa_Stockhoptimized10_0E6SRBank;
	add.s32 	%r587, %r586, %r585;
	st.shared.f32 	[%r587], %f357;
	add.f32 	%f358, %f20, %f356;
	mov.u32 	%r588, _ZZ25_occa_Stockhoptimized10_0E6SIBank;
	add.s32 	%r589, %r588, %r585;
	st.shared.f32 	[%r589], %f358;
	sub.f32 	%f359, %f19, %f354;
	st.shared.f32 	[%r587+8], %f359;
	sub.f32 	%f360, %f20, %f356;
	st.shared.f32 	[%r589+8], %f360;
	bar.sync 	0;
	add.s32 	%r592, %r586, %r513;
	ld.shared.f32 	%f48, [%r592];
	add.s32 	%r594, %r588, %r513;
	ld.shared.f32 	%f49, [%r594];
	ld.shared.f32 	%f50, [%r592+2048];
	ld.shared.f32 	%f51, [%r594+2048];
	shr.s32 	%r595, %r1, 31;
	shr.u32 	%r596, %r595, 30;
	add.s32 	%r597, %r1, %r596;
	and.b32  	%r598, %r597, 33554428;
	sub.s32 	%r599, %r1, %r598;
	shl.b32 	%r600, %r599, 7;
	cvt.rn.f32.s32	%f361, %r600;
	mul.f32 	%f362, %f361, 0f3A800000;
	cvt.f64.f32	%fd7, %f362;
	mul.f64 	%fd8, %fd7, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f52, %fd8;
	mul.f32 	%f363, %f52, 0f3F22F983;
	cvt.rni.s32.f32	%r1225, %f363;
	cvt.rn.f32.s32	%f364, %r1225;
	fma.rn.f32 	%f366, %f364, %f283, %f52;
	fma.rn.f32 	%f368, %f364, %f285, %f366;
	fma.rn.f32 	%f726, %f364, %f287, %f368;
	abs.f32 	%f54, %f52;
	setp.leu.f32	%p29, %f54, 0f47CE4780;
	mov.u32 	%r1217, %r1225;
	mov.f32 	%f723, %f726;
	@%p29 bra 	BB8_49;

	setp.eq.f32	%p30, %f54, 0f7F800000;
	@%p30 bra 	BB8_48;
	bra.uni 	BB8_40;

BB8_48:
	mul.rn.f32 	%f723, %f52, %f288;
	mov.u32 	%r1217, %r1225;
	bra.uni 	BB8_49;

BB8_40:
	mov.b32 	 %r61, %f52;
	shl.b32 	%r603, %r61, 8;
	or.b32  	%r62, %r603, -2147483648;
	add.u64 	%rd131, %SP, 0;
	add.u64 	%rd268, %SPL, 0;
	mov.u32 	%r1211, 0;
	mov.u64 	%rd267, __cudart_i2opi_f;
	mov.u32 	%r1210, -6;

BB8_41:
	.pragma "nounroll";
	ld.const.u32 	%r606, [%rd267];
	// inline asm
	{
	mad.lo.cc.u32   %r604, %r606, %r62, %r1211;
	madc.hi.u32     %r1211, %r606, %r62,  0;
	}
	// inline asm
	st.local.u32 	[%rd268], %r604;
	add.s64 	%rd268, %rd268, 4;
	add.s64 	%rd267, %rd267, 4;
	add.s32 	%r1210, %r1210, 1;
	setp.ne.s32	%p31, %r1210, 0;
	@%p31 bra 	BB8_41;

	bfe.u32 	%r609, %r61, 23, 8;
	add.s32 	%r610, %r609, -128;
	shr.u32 	%r611, %r610, 5;
	and.b32  	%r67, %r61, -2147483648;
	cvta.to.local.u64 	%rd133, %rd131;
	st.local.u32 	[%rd133+24], %r1211;
	bfe.u32 	%r68, %r61, 23, 5;
	mov.u32 	%r612, 6;
	sub.s32 	%r613, %r612, %r611;
	mul.wide.s32 	%rd134, %r613, 4;
	add.s64 	%rd18, %rd133, %rd134;
	ld.local.u32 	%r1213, [%rd18];
	ld.local.u32 	%r1212, [%rd18+-4];
	setp.eq.s32	%p32, %r68, 0;
	@%p32 bra 	BB8_44;

	mov.u32 	%r614, 32;
	sub.s32 	%r615, %r614, %r68;
	shr.u32 	%r616, %r1212, %r615;
	shl.b32 	%r617, %r1213, %r68;
	add.s32 	%r1213, %r616, %r617;
	ld.local.u32 	%r618, [%rd18+-8];
	shr.u32 	%r619, %r618, %r615;
	shl.b32 	%r620, %r1212, %r68;
	add.s32 	%r1212, %r619, %r620;

BB8_44:
	shr.u32 	%r621, %r1212, 30;
	shl.b32 	%r622, %r1213, 2;
	add.s32 	%r1215, %r622, %r621;
	shl.b32 	%r76, %r1212, 2;
	shr.u32 	%r623, %r1215, 31;
	shr.u32 	%r624, %r1213, 30;
	add.s32 	%r77, %r623, %r624;
	setp.eq.s32	%p33, %r623, 0;
	@%p33 bra 	BB8_45;

	not.b32 	%r625, %r1215;
	neg.s32 	%r1214, %r76;
	setp.eq.s32	%p34, %r76, 0;
	selp.u32	%r626, 1, 0, %p34;
	add.s32 	%r1215, %r626, %r625;
	xor.b32  	%r1216, %r67, -2147483648;
	bra.uni 	BB8_47;

BB8_45:
	mov.u32 	%r1214, %r76;
	mov.u32 	%r1216, %r67;

BB8_47:
	cvt.u64.u32	%rd135, %r1215;
	cvt.u64.u32	%rd136, %r1214;
	bfi.b64 	%rd137, %rd135, %rd136, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd137;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f370, %fd10;
	neg.f32 	%f371, %f370;
	setp.eq.s32	%p35, %r1216, 0;
	selp.f32	%f723, %f370, %f371, %p35;
	setp.eq.s32	%p36, %r67, 0;
	neg.s32 	%r627, %r77;
	selp.b32	%r1217, %r77, %r627, %p36;

BB8_49:
	add.s32 	%r86, %r1217, 1;
	and.b32  	%r87, %r86, 1;
	setp.eq.s32	%p37, %r87, 0;
	selp.f32	%f58, %f723, 0f3F800000, %p37;
	mul.rn.f32 	%f59, %f723, %f723;
	fma.rn.f32 	%f60, %f59, %f58, %f288;
	mov.f32 	%f724, 0fB94D4153;
	@%p37 bra 	BB8_51;

	mov.f32 	%f375, 0fBAB607ED;
	mov.f32 	%f376, 0f37CBAC00;
	fma.rn.f32 	%f724, %f376, %f59, %f375;

BB8_51:
	selp.f32	%f377, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f378, %f724, %f59, %f377;
	selp.f32	%f379, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f380, %f378, %f59, %f379;
	fma.rn.f32 	%f725, %f380, %f60, %f58;
	and.b32  	%r628, %r86, 2;
	setp.eq.s32	%p39, %r628, 0;
	@%p39 bra 	BB8_53;

	mov.f32 	%f382, 0fBF800000;
	fma.rn.f32 	%f725, %f725, %f382, %f288;

BB8_53:
	@%p29 bra 	BB8_64;

	setp.eq.f32	%p41, %f54, 0f7F800000;
	@%p41 bra 	BB8_63;
	bra.uni 	BB8_55;

BB8_63:
	mul.rn.f32 	%f726, %f52, %f288;
	bra.uni 	BB8_64;

BB8_55:
	mov.b32 	 %r88, %f52;
	shl.b32 	%r631, %r88, 8;
	or.b32  	%r89, %r631, -2147483648;
	add.u64 	%rd139, %SP, 0;
	add.u64 	%rd270, %SPL, 0;
	mov.u32 	%r1219, 0;
	mov.u64 	%rd269, __cudart_i2opi_f;
	mov.u32 	%r1218, -6;

BB8_56:
	.pragma "nounroll";
	ld.const.u32 	%r634, [%rd269];
	// inline asm
	{
	mad.lo.cc.u32   %r632, %r634, %r89, %r1219;
	madc.hi.u32     %r1219, %r634, %r89,  0;
	}
	// inline asm
	st.local.u32 	[%rd270], %r632;
	add.s64 	%rd270, %rd270, 4;
	add.s64 	%rd269, %rd269, 4;
	add.s32 	%r1218, %r1218, 1;
	setp.ne.s32	%p42, %r1218, 0;
	@%p42 bra 	BB8_56;

	bfe.u32 	%r637, %r88, 23, 8;
	add.s32 	%r638, %r637, -128;
	shr.u32 	%r639, %r638, 5;
	and.b32  	%r94, %r88, -2147483648;
	cvta.to.local.u64 	%rd141, %rd139;
	st.local.u32 	[%rd141+24], %r1219;
	bfe.u32 	%r95, %r88, 23, 5;
	mov.u32 	%r640, 6;
	sub.s32 	%r641, %r640, %r639;
	mul.wide.s32 	%rd142, %r641, 4;
	add.s64 	%rd24, %rd141, %rd142;
	ld.local.u32 	%r1221, [%rd24];
	ld.local.u32 	%r1220, [%rd24+-4];
	setp.eq.s32	%p43, %r95, 0;
	@%p43 bra 	BB8_59;

	mov.u32 	%r642, 32;
	sub.s32 	%r643, %r642, %r95;
	shr.u32 	%r644, %r1220, %r643;
	shl.b32 	%r645, %r1221, %r95;
	add.s32 	%r1221, %r644, %r645;
	ld.local.u32 	%r646, [%rd24+-8];
	shr.u32 	%r647, %r646, %r643;
	shl.b32 	%r648, %r1220, %r95;
	add.s32 	%r1220, %r647, %r648;

BB8_59:
	shr.u32 	%r649, %r1220, 30;
	shl.b32 	%r650, %r1221, 2;
	add.s32 	%r1223, %r650, %r649;
	shl.b32 	%r103, %r1220, 2;
	shr.u32 	%r651, %r1223, 31;
	shr.u32 	%r652, %r1221, 30;
	add.s32 	%r104, %r651, %r652;
	setp.eq.s32	%p44, %r651, 0;
	@%p44 bra 	BB8_60;

	not.b32 	%r653, %r1223;
	neg.s32 	%r1222, %r103;
	setp.eq.s32	%p45, %r103, 0;
	selp.u32	%r654, 1, 0, %p45;
	add.s32 	%r1223, %r654, %r653;
	xor.b32  	%r1224, %r94, -2147483648;
	bra.uni 	BB8_62;

BB8_60:
	mov.u32 	%r1222, %r103;
	mov.u32 	%r1224, %r94;

BB8_62:
	cvt.u64.u32	%rd143, %r1223;
	cvt.u64.u32	%rd144, %r1222;
	bfi.b64 	%rd145, %rd143, %rd144, 32, 32;
	cvt.rn.f64.s64	%fd11, %rd145;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f383, %fd12;
	neg.f32 	%f384, %f383;
	setp.eq.s32	%p46, %r1224, 0;
	selp.f32	%f726, %f383, %f384, %p46;
	setp.eq.s32	%p47, %r94, 0;
	neg.s32 	%r655, %r104;
	selp.b32	%r1225, %r104, %r655, %p47;

BB8_64:
	and.b32  	%r113, %r1225, 1;
	setp.eq.s32	%p48, %r113, 0;
	selp.f32	%f69, %f726, 0f3F800000, %p48;
	mul.rn.f32 	%f70, %f726, %f726;
	fma.rn.f32 	%f71, %f70, %f69, %f288;
	mov.f32 	%f727, 0fB94D4153;
	@%p48 bra 	BB8_66;

	mov.f32 	%f388, 0fBAB607ED;
	mov.f32 	%f389, 0f37CBAC00;
	fma.rn.f32 	%f727, %f389, %f70, %f388;

BB8_66:
	selp.f32	%f390, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f391, %f727, %f70, %f390;
	selp.f32	%f392, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f393, %f391, %f70, %f392;
	fma.rn.f32 	%f728, %f393, %f71, %f69;
	and.b32  	%r656, %r1225, 2;
	setp.eq.s32	%p50, %r656, 0;
	@%p50 bra 	BB8_68;

	mov.f32 	%f395, 0fBF800000;
	fma.rn.f32 	%f728, %f728, %f395, %f288;

BB8_68:
	and.b32  	%r657, %r1, 3;
	and.b32  	%r659, %r581, 1073741816;
	add.s32 	%r660, %r659, %r657;
	mul.f32 	%f396, %f51, %f728;
	mul.f32 	%f397, %f50, %f725;
	sub.f32 	%f398, %f397, %f396;
	mul.f32 	%f399, %f51, %f725;
	fma.rn.f32 	%f400, %f50, %f728, %f399;
	add.f32 	%f401, %f48, %f398;
	shl.b32 	%r661, %r660, 2;
	add.s32 	%r663, %r509, %r661;
	st.shared.f32 	[%r663], %f401;
	add.f32 	%f402, %f49, %f400;
	add.s32 	%r665, %r511, %r661;
	st.shared.f32 	[%r665], %f402;
	sub.f32 	%f403, %f48, %f398;
	st.shared.f32 	[%r663+16], %f403;
	sub.f32 	%f404, %f49, %f400;
	st.shared.f32 	[%r665+16], %f404;
	bar.sync 	0;
	ld.shared.f32 	%f77, [%r515];
	ld.shared.f32 	%f78, [%r517];
	ld.shared.f32 	%f79, [%r515+2048];
	ld.shared.f32 	%f80, [%r517+2048];
	shr.u32 	%r672, %r595, 29;
	add.s32 	%r673, %r1, %r672;
	and.b32  	%r674, %r673, 67108856;
	sub.s32 	%r675, %r1, %r674;
	shl.b32 	%r676, %r675, 6;
	cvt.rn.f32.s32	%f405, %r676;
	mul.f32 	%f406, %f405, 0f3A800000;
	cvt.f64.f32	%fd13, %f406;
	mul.f64 	%fd14, %fd13, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f81, %fd14;
	mul.f32 	%f407, %f81, 0f3F22F983;
	cvt.rni.s32.f32	%r1241, %f407;
	cvt.rn.f32.s32	%f408, %r1241;
	fma.rn.f32 	%f410, %f408, %f283, %f81;
	fma.rn.f32 	%f412, %f408, %f285, %f410;
	fma.rn.f32 	%f732, %f408, %f287, %f412;
	abs.f32 	%f83, %f81;
	setp.leu.f32	%p51, %f83, 0f47CE4780;
	mov.u32 	%r1233, %r1241;
	mov.f32 	%f729, %f732;
	@%p51 bra 	BB8_79;

	setp.eq.f32	%p52, %f83, 0f7F800000;
	@%p52 bra 	BB8_78;
	bra.uni 	BB8_70;

BB8_78:
	mul.rn.f32 	%f729, %f81, %f288;
	mov.u32 	%r1233, %r1241;
	bra.uni 	BB8_79;

BB8_70:
	mov.b32 	 %r116, %f81;
	shl.b32 	%r679, %r116, 8;
	or.b32  	%r117, %r679, -2147483648;
	add.u64 	%rd147, %SP, 0;
	add.u64 	%rd272, %SPL, 0;
	mov.u32 	%r1227, 0;
	mov.u64 	%rd271, __cudart_i2opi_f;
	mov.u32 	%r1226, -6;

BB8_71:
	.pragma "nounroll";
	ld.const.u32 	%r682, [%rd271];
	// inline asm
	{
	mad.lo.cc.u32   %r680, %r682, %r117, %r1227;
	madc.hi.u32     %r1227, %r682, %r117,  0;
	}
	// inline asm
	st.local.u32 	[%rd272], %r680;
	add.s64 	%rd272, %rd272, 4;
	add.s64 	%rd271, %rd271, 4;
	add.s32 	%r1226, %r1226, 1;
	setp.ne.s32	%p53, %r1226, 0;
	@%p53 bra 	BB8_71;

	bfe.u32 	%r685, %r116, 23, 8;
	add.s32 	%r686, %r685, -128;
	shr.u32 	%r687, %r686, 5;
	and.b32  	%r122, %r116, -2147483648;
	cvta.to.local.u64 	%rd149, %rd147;
	st.local.u32 	[%rd149+24], %r1227;
	bfe.u32 	%r123, %r116, 23, 5;
	mov.u32 	%r688, 6;
	sub.s32 	%r689, %r688, %r687;
	mul.wide.s32 	%rd150, %r689, 4;
	add.s64 	%rd30, %rd149, %rd150;
	ld.local.u32 	%r1229, [%rd30];
	ld.local.u32 	%r1228, [%rd30+-4];
	setp.eq.s32	%p54, %r123, 0;
	@%p54 bra 	BB8_74;

	mov.u32 	%r690, 32;
	sub.s32 	%r691, %r690, %r123;
	shr.u32 	%r692, %r1228, %r691;
	shl.b32 	%r693, %r1229, %r123;
	add.s32 	%r1229, %r692, %r693;
	ld.local.u32 	%r694, [%rd30+-8];
	shr.u32 	%r695, %r694, %r691;
	shl.b32 	%r696, %r1228, %r123;
	add.s32 	%r1228, %r695, %r696;

BB8_74:
	shr.u32 	%r697, %r1228, 30;
	shl.b32 	%r698, %r1229, 2;
	add.s32 	%r1231, %r698, %r697;
	shl.b32 	%r131, %r1228, 2;
	shr.u32 	%r699, %r1231, 31;
	shr.u32 	%r700, %r1229, 30;
	add.s32 	%r132, %r699, %r700;
	setp.eq.s32	%p55, %r699, 0;
	@%p55 bra 	BB8_75;

	not.b32 	%r701, %r1231;
	neg.s32 	%r1230, %r131;
	setp.eq.s32	%p56, %r131, 0;
	selp.u32	%r702, 1, 0, %p56;
	add.s32 	%r1231, %r702, %r701;
	xor.b32  	%r1232, %r122, -2147483648;
	bra.uni 	BB8_77;

BB8_75:
	mov.u32 	%r1230, %r131;
	mov.u32 	%r1232, %r122;

BB8_77:
	cvt.u64.u32	%rd151, %r1231;
	cvt.u64.u32	%rd152, %r1230;
	bfi.b64 	%rd153, %rd151, %rd152, 32, 32;
	cvt.rn.f64.s64	%fd15, %rd153;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f414, %fd16;
	neg.f32 	%f415, %f414;
	setp.eq.s32	%p57, %r1232, 0;
	selp.f32	%f729, %f414, %f415, %p57;
	setp.eq.s32	%p58, %r122, 0;
	neg.s32 	%r703, %r132;
	selp.b32	%r1233, %r132, %r703, %p58;

BB8_79:
	add.s32 	%r141, %r1233, 1;
	and.b32  	%r142, %r141, 1;
	setp.eq.s32	%p59, %r142, 0;
	selp.f32	%f87, %f729, 0f3F800000, %p59;
	mul.rn.f32 	%f88, %f729, %f729;
	fma.rn.f32 	%f89, %f88, %f87, %f288;
	mov.f32 	%f730, 0fB94D4153;
	@%p59 bra 	BB8_81;

	mov.f32 	%f419, 0fBAB607ED;
	mov.f32 	%f420, 0f37CBAC00;
	fma.rn.f32 	%f730, %f420, %f88, %f419;

BB8_81:
	selp.f32	%f421, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f422, %f730, %f88, %f421;
	selp.f32	%f423, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f424, %f422, %f88, %f423;
	fma.rn.f32 	%f731, %f424, %f89, %f87;
	and.b32  	%r704, %r141, 2;
	setp.eq.s32	%p61, %r704, 0;
	@%p61 bra 	BB8_83;

	mov.f32 	%f426, 0fBF800000;
	fma.rn.f32 	%f731, %f731, %f426, %f288;

BB8_83:
	@%p51 bra 	BB8_94;

	setp.eq.f32	%p63, %f83, 0f7F800000;
	@%p63 bra 	BB8_93;
	bra.uni 	BB8_85;

BB8_93:
	mul.rn.f32 	%f732, %f81, %f288;
	bra.uni 	BB8_94;

BB8_85:
	mov.b32 	 %r143, %f81;
	shl.b32 	%r707, %r143, 8;
	or.b32  	%r144, %r707, -2147483648;
	add.u64 	%rd155, %SP, 0;
	add.u64 	%rd274, %SPL, 0;
	mov.u32 	%r1235, 0;
	mov.u64 	%rd273, __cudart_i2opi_f;
	mov.u32 	%r1234, -6;

BB8_86:
	.pragma "nounroll";
	ld.const.u32 	%r710, [%rd273];
	// inline asm
	{
	mad.lo.cc.u32   %r708, %r710, %r144, %r1235;
	madc.hi.u32     %r1235, %r710, %r144,  0;
	}
	// inline asm
	st.local.u32 	[%rd274], %r708;
	add.s64 	%rd274, %rd274, 4;
	add.s64 	%rd273, %rd273, 4;
	add.s32 	%r1234, %r1234, 1;
	setp.ne.s32	%p64, %r1234, 0;
	@%p64 bra 	BB8_86;

	bfe.u32 	%r713, %r143, 23, 8;
	add.s32 	%r714, %r713, -128;
	shr.u32 	%r715, %r714, 5;
	and.b32  	%r149, %r143, -2147483648;
	cvta.to.local.u64 	%rd157, %rd155;
	st.local.u32 	[%rd157+24], %r1235;
	bfe.u32 	%r150, %r143, 23, 5;
	mov.u32 	%r716, 6;
	sub.s32 	%r717, %r716, %r715;
	mul.wide.s32 	%rd158, %r717, 4;
	add.s64 	%rd36, %rd157, %rd158;
	ld.local.u32 	%r1237, [%rd36];
	ld.local.u32 	%r1236, [%rd36+-4];
	setp.eq.s32	%p65, %r150, 0;
	@%p65 bra 	BB8_89;

	mov.u32 	%r718, 32;
	sub.s32 	%r719, %r718, %r150;
	shr.u32 	%r720, %r1236, %r719;
	shl.b32 	%r721, %r1237, %r150;
	add.s32 	%r1237, %r720, %r721;
	ld.local.u32 	%r722, [%rd36+-8];
	shr.u32 	%r723, %r722, %r719;
	shl.b32 	%r724, %r1236, %r150;
	add.s32 	%r1236, %r723, %r724;

BB8_89:
	shr.u32 	%r725, %r1236, 30;
	shl.b32 	%r726, %r1237, 2;
	add.s32 	%r1239, %r726, %r725;
	shl.b32 	%r158, %r1236, 2;
	shr.u32 	%r727, %r1239, 31;
	shr.u32 	%r728, %r1237, 30;
	add.s32 	%r159, %r727, %r728;
	setp.eq.s32	%p66, %r727, 0;
	@%p66 bra 	BB8_90;

	not.b32 	%r729, %r1239;
	neg.s32 	%r1238, %r158;
	setp.eq.s32	%p67, %r158, 0;
	selp.u32	%r730, 1, 0, %p67;
	add.s32 	%r1239, %r730, %r729;
	xor.b32  	%r1240, %r149, -2147483648;
	bra.uni 	BB8_92;

BB8_90:
	mov.u32 	%r1238, %r158;
	mov.u32 	%r1240, %r149;

BB8_92:
	cvt.u64.u32	%rd159, %r1239;
	cvt.u64.u32	%rd160, %r1238;
	bfi.b64 	%rd161, %rd159, %rd160, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd161;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f427, %fd18;
	neg.f32 	%f428, %f427;
	setp.eq.s32	%p68, %r1240, 0;
	selp.f32	%f732, %f427, %f428, %p68;
	setp.eq.s32	%p69, %r149, 0;
	neg.s32 	%r731, %r159;
	selp.b32	%r1241, %r159, %r731, %p69;

BB8_94:
	and.b32  	%r168, %r1241, 1;
	setp.eq.s32	%p70, %r168, 0;
	selp.f32	%f98, %f732, 0f3F800000, %p70;
	mul.rn.f32 	%f99, %f732, %f732;
	fma.rn.f32 	%f100, %f99, %f98, %f288;
	mov.f32 	%f733, 0fB94D4153;
	@%p70 bra 	BB8_96;

	mov.f32 	%f432, 0fBAB607ED;
	mov.f32 	%f433, 0f37CBAC00;
	fma.rn.f32 	%f733, %f433, %f99, %f432;

BB8_96:
	selp.f32	%f434, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f435, %f733, %f99, %f434;
	selp.f32	%f436, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f437, %f435, %f99, %f436;
	fma.rn.f32 	%f734, %f437, %f100, %f98;
	and.b32  	%r732, %r1241, 2;
	setp.eq.s32	%p72, %r732, 0;
	@%p72 bra 	BB8_98;

	mov.f32 	%f439, 0fBF800000;
	fma.rn.f32 	%f734, %f734, %f439, %f288;

BB8_98:
	and.b32  	%r733, %r1, 7;
	and.b32  	%r735, %r581, 1073741808;
	add.s32 	%r736, %r735, %r733;
	mul.f32 	%f440, %f80, %f734;
	mul.f32 	%f441, %f79, %f731;
	sub.f32 	%f442, %f441, %f440;
	mul.f32 	%f443, %f80, %f731;
	fma.rn.f32 	%f444, %f79, %f734, %f443;
	add.f32 	%f445, %f77, %f442;
	shl.b32 	%r737, %r736, 2;
	add.s32 	%r739, %r586, %r737;
	st.shared.f32 	[%r739], %f445;
	add.f32 	%f446, %f78, %f444;
	add.s32 	%r741, %r588, %r737;
	st.shared.f32 	[%r741], %f446;
	sub.f32 	%f447, %f77, %f442;
	st.shared.f32 	[%r739+32], %f447;
	sub.f32 	%f448, %f78, %f444;
	st.shared.f32 	[%r741+32], %f448;
	bar.sync 	0;
	ld.shared.f32 	%f106, [%r592];
	ld.shared.f32 	%f107, [%r594];
	ld.shared.f32 	%f108, [%r592+2048];
	ld.shared.f32 	%f109, [%r594+2048];
	shr.u32 	%r748, %r595, 28;
	add.s32 	%r749, %r1, %r748;
	and.b32  	%r750, %r749, 134217712;
	sub.s32 	%r751, %r1, %r750;
	shl.b32 	%r752, %r751, 5;
	cvt.rn.f32.s32	%f449, %r752;
	mul.f32 	%f450, %f449, 0f3A800000;
	cvt.f64.f32	%fd19, %f450;
	mul.f64 	%fd20, %fd19, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f110, %fd20;
	mul.f32 	%f451, %f110, 0f3F22F983;
	cvt.rni.s32.f32	%r1257, %f451;
	cvt.rn.f32.s32	%f452, %r1257;
	fma.rn.f32 	%f454, %f452, %f283, %f110;
	fma.rn.f32 	%f456, %f452, %f285, %f454;
	fma.rn.f32 	%f738, %f452, %f287, %f456;
	abs.f32 	%f112, %f110;
	setp.leu.f32	%p73, %f112, 0f47CE4780;
	mov.u32 	%r1249, %r1257;
	mov.f32 	%f735, %f738;
	@%p73 bra 	BB8_109;

	setp.eq.f32	%p74, %f112, 0f7F800000;
	@%p74 bra 	BB8_108;
	bra.uni 	BB8_100;

BB8_108:
	mul.rn.f32 	%f735, %f110, %f288;
	mov.u32 	%r1249, %r1257;
	bra.uni 	BB8_109;

BB8_100:
	mov.b32 	 %r171, %f110;
	shl.b32 	%r755, %r171, 8;
	or.b32  	%r172, %r755, -2147483648;
	add.u64 	%rd163, %SP, 0;
	add.u64 	%rd276, %SPL, 0;
	mov.u32 	%r1243, 0;
	mov.u64 	%rd275, __cudart_i2opi_f;
	mov.u32 	%r1242, -6;

BB8_101:
	.pragma "nounroll";
	ld.const.u32 	%r758, [%rd275];
	// inline asm
	{
	mad.lo.cc.u32   %r756, %r758, %r172, %r1243;
	madc.hi.u32     %r1243, %r758, %r172,  0;
	}
	// inline asm
	st.local.u32 	[%rd276], %r756;
	add.s64 	%rd276, %rd276, 4;
	add.s64 	%rd275, %rd275, 4;
	add.s32 	%r1242, %r1242, 1;
	setp.ne.s32	%p75, %r1242, 0;
	@%p75 bra 	BB8_101;

	bfe.u32 	%r761, %r171, 23, 8;
	add.s32 	%r762, %r761, -128;
	shr.u32 	%r763, %r762, 5;
	and.b32  	%r177, %r171, -2147483648;
	cvta.to.local.u64 	%rd165, %rd163;
	st.local.u32 	[%rd165+24], %r1243;
	bfe.u32 	%r178, %r171, 23, 5;
	mov.u32 	%r764, 6;
	sub.s32 	%r765, %r764, %r763;
	mul.wide.s32 	%rd166, %r765, 4;
	add.s64 	%rd42, %rd165, %rd166;
	ld.local.u32 	%r1245, [%rd42];
	ld.local.u32 	%r1244, [%rd42+-4];
	setp.eq.s32	%p76, %r178, 0;
	@%p76 bra 	BB8_104;

	mov.u32 	%r766, 32;
	sub.s32 	%r767, %r766, %r178;
	shr.u32 	%r768, %r1244, %r767;
	shl.b32 	%r769, %r1245, %r178;
	add.s32 	%r1245, %r768, %r769;
	ld.local.u32 	%r770, [%rd42+-8];
	shr.u32 	%r771, %r770, %r767;
	shl.b32 	%r772, %r1244, %r178;
	add.s32 	%r1244, %r771, %r772;

BB8_104:
	shr.u32 	%r773, %r1244, 30;
	shl.b32 	%r774, %r1245, 2;
	add.s32 	%r1247, %r774, %r773;
	shl.b32 	%r186, %r1244, 2;
	shr.u32 	%r775, %r1247, 31;
	shr.u32 	%r776, %r1245, 30;
	add.s32 	%r187, %r775, %r776;
	setp.eq.s32	%p77, %r775, 0;
	@%p77 bra 	BB8_105;

	not.b32 	%r777, %r1247;
	neg.s32 	%r1246, %r186;
	setp.eq.s32	%p78, %r186, 0;
	selp.u32	%r778, 1, 0, %p78;
	add.s32 	%r1247, %r778, %r777;
	xor.b32  	%r1248, %r177, -2147483648;
	bra.uni 	BB8_107;

BB8_105:
	mov.u32 	%r1246, %r186;
	mov.u32 	%r1248, %r177;

BB8_107:
	cvt.u64.u32	%rd167, %r1247;
	cvt.u64.u32	%rd168, %r1246;
	bfi.b64 	%rd169, %rd167, %rd168, 32, 32;
	cvt.rn.f64.s64	%fd21, %rd169;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f458, %fd22;
	neg.f32 	%f459, %f458;
	setp.eq.s32	%p79, %r1248, 0;
	selp.f32	%f735, %f458, %f459, %p79;
	setp.eq.s32	%p80, %r177, 0;
	neg.s32 	%r779, %r187;
	selp.b32	%r1249, %r187, %r779, %p80;

BB8_109:
	add.s32 	%r196, %r1249, 1;
	and.b32  	%r197, %r196, 1;
	setp.eq.s32	%p81, %r197, 0;
	selp.f32	%f116, %f735, 0f3F800000, %p81;
	mul.rn.f32 	%f117, %f735, %f735;
	fma.rn.f32 	%f118, %f117, %f116, %f288;
	mov.f32 	%f736, 0fB94D4153;
	@%p81 bra 	BB8_111;

	mov.f32 	%f463, 0fBAB607ED;
	mov.f32 	%f464, 0f37CBAC00;
	fma.rn.f32 	%f736, %f464, %f117, %f463;

BB8_111:
	selp.f32	%f465, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f466, %f736, %f117, %f465;
	selp.f32	%f467, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f468, %f466, %f117, %f467;
	fma.rn.f32 	%f737, %f468, %f118, %f116;
	and.b32  	%r780, %r196, 2;
	setp.eq.s32	%p83, %r780, 0;
	@%p83 bra 	BB8_113;

	mov.f32 	%f470, 0fBF800000;
	fma.rn.f32 	%f737, %f737, %f470, %f288;

BB8_113:
	@%p73 bra 	BB8_124;

	setp.eq.f32	%p85, %f112, 0f7F800000;
	@%p85 bra 	BB8_123;
	bra.uni 	BB8_115;

BB8_123:
	mul.rn.f32 	%f738, %f110, %f288;
	bra.uni 	BB8_124;

BB8_115:
	mov.b32 	 %r198, %f110;
	shl.b32 	%r783, %r198, 8;
	or.b32  	%r199, %r783, -2147483648;
	add.u64 	%rd171, %SP, 0;
	add.u64 	%rd278, %SPL, 0;
	mov.u32 	%r1251, 0;
	mov.u64 	%rd277, __cudart_i2opi_f;
	mov.u32 	%r1250, -6;

BB8_116:
	.pragma "nounroll";
	ld.const.u32 	%r786, [%rd277];
	// inline asm
	{
	mad.lo.cc.u32   %r784, %r786, %r199, %r1251;
	madc.hi.u32     %r1251, %r786, %r199,  0;
	}
	// inline asm
	st.local.u32 	[%rd278], %r784;
	add.s64 	%rd278, %rd278, 4;
	add.s64 	%rd277, %rd277, 4;
	add.s32 	%r1250, %r1250, 1;
	setp.ne.s32	%p86, %r1250, 0;
	@%p86 bra 	BB8_116;

	bfe.u32 	%r789, %r198, 23, 8;
	add.s32 	%r790, %r789, -128;
	shr.u32 	%r791, %r790, 5;
	and.b32  	%r204, %r198, -2147483648;
	cvta.to.local.u64 	%rd173, %rd171;
	st.local.u32 	[%rd173+24], %r1251;
	bfe.u32 	%r205, %r198, 23, 5;
	mov.u32 	%r792, 6;
	sub.s32 	%r793, %r792, %r791;
	mul.wide.s32 	%rd174, %r793, 4;
	add.s64 	%rd48, %rd173, %rd174;
	ld.local.u32 	%r1253, [%rd48];
	ld.local.u32 	%r1252, [%rd48+-4];
	setp.eq.s32	%p87, %r205, 0;
	@%p87 bra 	BB8_119;

	mov.u32 	%r794, 32;
	sub.s32 	%r795, %r794, %r205;
	shr.u32 	%r796, %r1252, %r795;
	shl.b32 	%r797, %r1253, %r205;
	add.s32 	%r1253, %r796, %r797;
	ld.local.u32 	%r798, [%rd48+-8];
	shr.u32 	%r799, %r798, %r795;
	shl.b32 	%r800, %r1252, %r205;
	add.s32 	%r1252, %r799, %r800;

BB8_119:
	shr.u32 	%r801, %r1252, 30;
	shl.b32 	%r802, %r1253, 2;
	add.s32 	%r1255, %r802, %r801;
	shl.b32 	%r213, %r1252, 2;
	shr.u32 	%r803, %r1255, 31;
	shr.u32 	%r804, %r1253, 30;
	add.s32 	%r214, %r803, %r804;
	setp.eq.s32	%p88, %r803, 0;
	@%p88 bra 	BB8_120;

	not.b32 	%r805, %r1255;
	neg.s32 	%r1254, %r213;
	setp.eq.s32	%p89, %r213, 0;
	selp.u32	%r806, 1, 0, %p89;
	add.s32 	%r1255, %r806, %r805;
	xor.b32  	%r1256, %r204, -2147483648;
	bra.uni 	BB8_122;

BB8_120:
	mov.u32 	%r1254, %r213;
	mov.u32 	%r1256, %r204;

BB8_122:
	cvt.u64.u32	%rd175, %r1255;
	cvt.u64.u32	%rd176, %r1254;
	bfi.b64 	%rd177, %rd175, %rd176, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd177;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f471, %fd24;
	neg.f32 	%f472, %f471;
	setp.eq.s32	%p90, %r1256, 0;
	selp.f32	%f738, %f471, %f472, %p90;
	setp.eq.s32	%p91, %r204, 0;
	neg.s32 	%r807, %r214;
	selp.b32	%r1257, %r214, %r807, %p91;

BB8_124:
	and.b32  	%r223, %r1257, 1;
	setp.eq.s32	%p92, %r223, 0;
	selp.f32	%f127, %f738, 0f3F800000, %p92;
	mul.rn.f32 	%f128, %f738, %f738;
	fma.rn.f32 	%f129, %f128, %f127, %f288;
	mov.f32 	%f739, 0fB94D4153;
	@%p92 bra 	BB8_126;

	mov.f32 	%f476, 0fBAB607ED;
	mov.f32 	%f477, 0f37CBAC00;
	fma.rn.f32 	%f739, %f477, %f128, %f476;

BB8_126:
	selp.f32	%f478, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f479, %f739, %f128, %f478;
	selp.f32	%f480, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f481, %f479, %f128, %f480;
	fma.rn.f32 	%f740, %f481, %f129, %f127;
	and.b32  	%r808, %r1257, 2;
	setp.eq.s32	%p94, %r808, 0;
	@%p94 bra 	BB8_128;

	mov.f32 	%f483, 0fBF800000;
	fma.rn.f32 	%f740, %f740, %f483, %f288;

BB8_128:
	and.b32  	%r809, %r1, 15;
	and.b32  	%r811, %r581, 1073741792;
	add.s32 	%r812, %r811, %r809;
	mul.f32 	%f484, %f109, %f740;
	mul.f32 	%f485, %f108, %f737;
	sub.f32 	%f486, %f485, %f484;
	mul.f32 	%f487, %f109, %f737;
	fma.rn.f32 	%f488, %f108, %f740, %f487;
	add.f32 	%f489, %f106, %f486;
	shl.b32 	%r813, %r812, 2;
	add.s32 	%r815, %r509, %r813;
	st.shared.f32 	[%r815], %f489;
	add.f32 	%f490, %f107, %f488;
	add.s32 	%r817, %r511, %r813;
	st.shared.f32 	[%r817], %f490;
	sub.f32 	%f491, %f106, %f486;
	st.shared.f32 	[%r815+64], %f491;
	sub.f32 	%f492, %f107, %f488;
	st.shared.f32 	[%r817+64], %f492;
	bar.sync 	0;
	ld.shared.f32 	%f135, [%r515];
	ld.shared.f32 	%f136, [%r517];
	ld.shared.f32 	%f137, [%r515+2048];
	ld.shared.f32 	%f138, [%r517+2048];
	shr.u32 	%r824, %r595, 27;
	add.s32 	%r825, %r1, %r824;
	and.b32  	%r826, %r825, 268435424;
	sub.s32 	%r827, %r1, %r826;
	shl.b32 	%r828, %r827, 4;
	cvt.rn.f32.s32	%f493, %r828;
	mul.f32 	%f494, %f493, 0f3A800000;
	cvt.f64.f32	%fd25, %f494;
	mul.f64 	%fd26, %fd25, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f139, %fd26;
	mul.f32 	%f495, %f139, 0f3F22F983;
	cvt.rni.s32.f32	%r1273, %f495;
	cvt.rn.f32.s32	%f496, %r1273;
	fma.rn.f32 	%f498, %f496, %f283, %f139;
	fma.rn.f32 	%f500, %f496, %f285, %f498;
	fma.rn.f32 	%f744, %f496, %f287, %f500;
	abs.f32 	%f141, %f139;
	setp.leu.f32	%p95, %f141, 0f47CE4780;
	mov.u32 	%r1265, %r1273;
	mov.f32 	%f741, %f744;
	@%p95 bra 	BB8_139;

	setp.eq.f32	%p96, %f141, 0f7F800000;
	@%p96 bra 	BB8_138;
	bra.uni 	BB8_130;

BB8_138:
	mul.rn.f32 	%f741, %f139, %f288;
	mov.u32 	%r1265, %r1273;
	bra.uni 	BB8_139;

BB8_130:
	mov.b32 	 %r226, %f139;
	shl.b32 	%r831, %r226, 8;
	or.b32  	%r227, %r831, -2147483648;
	add.u64 	%rd179, %SP, 0;
	add.u64 	%rd280, %SPL, 0;
	mov.u32 	%r1259, 0;
	mov.u64 	%rd279, __cudart_i2opi_f;
	mov.u32 	%r1258, -6;

BB8_131:
	.pragma "nounroll";
	ld.const.u32 	%r834, [%rd279];
	// inline asm
	{
	mad.lo.cc.u32   %r832, %r834, %r227, %r1259;
	madc.hi.u32     %r1259, %r834, %r227,  0;
	}
	// inline asm
	st.local.u32 	[%rd280], %r832;
	add.s64 	%rd280, %rd280, 4;
	add.s64 	%rd279, %rd279, 4;
	add.s32 	%r1258, %r1258, 1;
	setp.ne.s32	%p97, %r1258, 0;
	@%p97 bra 	BB8_131;

	bfe.u32 	%r837, %r226, 23, 8;
	add.s32 	%r838, %r837, -128;
	shr.u32 	%r839, %r838, 5;
	and.b32  	%r232, %r226, -2147483648;
	cvta.to.local.u64 	%rd181, %rd179;
	st.local.u32 	[%rd181+24], %r1259;
	bfe.u32 	%r233, %r226, 23, 5;
	mov.u32 	%r840, 6;
	sub.s32 	%r841, %r840, %r839;
	mul.wide.s32 	%rd182, %r841, 4;
	add.s64 	%rd54, %rd181, %rd182;
	ld.local.u32 	%r1261, [%rd54];
	ld.local.u32 	%r1260, [%rd54+-4];
	setp.eq.s32	%p98, %r233, 0;
	@%p98 bra 	BB8_134;

	mov.u32 	%r842, 32;
	sub.s32 	%r843, %r842, %r233;
	shr.u32 	%r844, %r1260, %r843;
	shl.b32 	%r845, %r1261, %r233;
	add.s32 	%r1261, %r844, %r845;
	ld.local.u32 	%r846, [%rd54+-8];
	shr.u32 	%r847, %r846, %r843;
	shl.b32 	%r848, %r1260, %r233;
	add.s32 	%r1260, %r847, %r848;

BB8_134:
	shr.u32 	%r849, %r1260, 30;
	shl.b32 	%r850, %r1261, 2;
	add.s32 	%r1263, %r850, %r849;
	shl.b32 	%r241, %r1260, 2;
	shr.u32 	%r851, %r1263, 31;
	shr.u32 	%r852, %r1261, 30;
	add.s32 	%r242, %r851, %r852;
	setp.eq.s32	%p99, %r851, 0;
	@%p99 bra 	BB8_135;

	not.b32 	%r853, %r1263;
	neg.s32 	%r1262, %r241;
	setp.eq.s32	%p100, %r241, 0;
	selp.u32	%r854, 1, 0, %p100;
	add.s32 	%r1263, %r854, %r853;
	xor.b32  	%r1264, %r232, -2147483648;
	bra.uni 	BB8_137;

BB8_135:
	mov.u32 	%r1262, %r241;
	mov.u32 	%r1264, %r232;

BB8_137:
	cvt.u64.u32	%rd183, %r1263;
	cvt.u64.u32	%rd184, %r1262;
	bfi.b64 	%rd185, %rd183, %rd184, 32, 32;
	cvt.rn.f64.s64	%fd27, %rd185;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f502, %fd28;
	neg.f32 	%f503, %f502;
	setp.eq.s32	%p101, %r1264, 0;
	selp.f32	%f741, %f502, %f503, %p101;
	setp.eq.s32	%p102, %r232, 0;
	neg.s32 	%r855, %r242;
	selp.b32	%r1265, %r242, %r855, %p102;

BB8_139:
	add.s32 	%r251, %r1265, 1;
	and.b32  	%r252, %r251, 1;
	setp.eq.s32	%p103, %r252, 0;
	selp.f32	%f145, %f741, 0f3F800000, %p103;
	mul.rn.f32 	%f146, %f741, %f741;
	fma.rn.f32 	%f147, %f146, %f145, %f288;
	mov.f32 	%f742, 0fB94D4153;
	@%p103 bra 	BB8_141;

	mov.f32 	%f507, 0fBAB607ED;
	mov.f32 	%f508, 0f37CBAC00;
	fma.rn.f32 	%f742, %f508, %f146, %f507;

BB8_141:
	selp.f32	%f509, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f510, %f742, %f146, %f509;
	selp.f32	%f511, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f512, %f510, %f146, %f511;
	fma.rn.f32 	%f743, %f512, %f147, %f145;
	and.b32  	%r856, %r251, 2;
	setp.eq.s32	%p105, %r856, 0;
	@%p105 bra 	BB8_143;

	mov.f32 	%f514, 0fBF800000;
	fma.rn.f32 	%f743, %f743, %f514, %f288;

BB8_143:
	@%p95 bra 	BB8_154;

	setp.eq.f32	%p107, %f141, 0f7F800000;
	@%p107 bra 	BB8_153;
	bra.uni 	BB8_145;

BB8_153:
	mul.rn.f32 	%f744, %f139, %f288;
	bra.uni 	BB8_154;

BB8_145:
	mov.b32 	 %r253, %f139;
	shl.b32 	%r859, %r253, 8;
	or.b32  	%r254, %r859, -2147483648;
	add.u64 	%rd187, %SP, 0;
	add.u64 	%rd282, %SPL, 0;
	mov.u32 	%r1267, 0;
	mov.u64 	%rd281, __cudart_i2opi_f;
	mov.u32 	%r1266, -6;

BB8_146:
	.pragma "nounroll";
	ld.const.u32 	%r862, [%rd281];
	// inline asm
	{
	mad.lo.cc.u32   %r860, %r862, %r254, %r1267;
	madc.hi.u32     %r1267, %r862, %r254,  0;
	}
	// inline asm
	st.local.u32 	[%rd282], %r860;
	add.s64 	%rd282, %rd282, 4;
	add.s64 	%rd281, %rd281, 4;
	add.s32 	%r1266, %r1266, 1;
	setp.ne.s32	%p108, %r1266, 0;
	@%p108 bra 	BB8_146;

	bfe.u32 	%r865, %r253, 23, 8;
	add.s32 	%r866, %r865, -128;
	shr.u32 	%r867, %r866, 5;
	and.b32  	%r259, %r253, -2147483648;
	cvta.to.local.u64 	%rd189, %rd187;
	st.local.u32 	[%rd189+24], %r1267;
	bfe.u32 	%r260, %r253, 23, 5;
	mov.u32 	%r868, 6;
	sub.s32 	%r869, %r868, %r867;
	mul.wide.s32 	%rd190, %r869, 4;
	add.s64 	%rd60, %rd189, %rd190;
	ld.local.u32 	%r1269, [%rd60];
	ld.local.u32 	%r1268, [%rd60+-4];
	setp.eq.s32	%p109, %r260, 0;
	@%p109 bra 	BB8_149;

	mov.u32 	%r870, 32;
	sub.s32 	%r871, %r870, %r260;
	shr.u32 	%r872, %r1268, %r871;
	shl.b32 	%r873, %r1269, %r260;
	add.s32 	%r1269, %r872, %r873;
	ld.local.u32 	%r874, [%rd60+-8];
	shr.u32 	%r875, %r874, %r871;
	shl.b32 	%r876, %r1268, %r260;
	add.s32 	%r1268, %r875, %r876;

BB8_149:
	shr.u32 	%r877, %r1268, 30;
	shl.b32 	%r878, %r1269, 2;
	add.s32 	%r1271, %r878, %r877;
	shl.b32 	%r268, %r1268, 2;
	shr.u32 	%r879, %r1271, 31;
	shr.u32 	%r880, %r1269, 30;
	add.s32 	%r269, %r879, %r880;
	setp.eq.s32	%p110, %r879, 0;
	@%p110 bra 	BB8_150;

	not.b32 	%r881, %r1271;
	neg.s32 	%r1270, %r268;
	setp.eq.s32	%p111, %r268, 0;
	selp.u32	%r882, 1, 0, %p111;
	add.s32 	%r1271, %r882, %r881;
	xor.b32  	%r1272, %r259, -2147483648;
	bra.uni 	BB8_152;

BB8_150:
	mov.u32 	%r1270, %r268;
	mov.u32 	%r1272, %r259;

BB8_152:
	cvt.u64.u32	%rd191, %r1271;
	cvt.u64.u32	%rd192, %r1270;
	bfi.b64 	%rd193, %rd191, %rd192, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd193;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f515, %fd30;
	neg.f32 	%f516, %f515;
	setp.eq.s32	%p112, %r1272, 0;
	selp.f32	%f744, %f515, %f516, %p112;
	setp.eq.s32	%p113, %r259, 0;
	neg.s32 	%r883, %r269;
	selp.b32	%r1273, %r269, %r883, %p113;

BB8_154:
	and.b32  	%r278, %r1273, 1;
	setp.eq.s32	%p114, %r278, 0;
	selp.f32	%f156, %f744, 0f3F800000, %p114;
	mul.rn.f32 	%f157, %f744, %f744;
	fma.rn.f32 	%f158, %f157, %f156, %f288;
	mov.f32 	%f745, 0fB94D4153;
	@%p114 bra 	BB8_156;

	mov.f32 	%f520, 0fBAB607ED;
	mov.f32 	%f521, 0f37CBAC00;
	fma.rn.f32 	%f745, %f521, %f157, %f520;

BB8_156:
	selp.f32	%f522, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f523, %f745, %f157, %f522;
	selp.f32	%f524, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f525, %f523, %f157, %f524;
	fma.rn.f32 	%f746, %f525, %f158, %f156;
	and.b32  	%r884, %r1273, 2;
	setp.eq.s32	%p116, %r884, 0;
	@%p116 bra 	BB8_158;

	mov.f32 	%f527, 0fBF800000;
	fma.rn.f32 	%f746, %f746, %f527, %f288;

BB8_158:
	and.b32  	%r885, %r1, 31;
	and.b32  	%r887, %r581, 1073741760;
	add.s32 	%r888, %r887, %r885;
	mul.f32 	%f528, %f138, %f746;
	mul.f32 	%f529, %f137, %f743;
	sub.f32 	%f530, %f529, %f528;
	mul.f32 	%f531, %f138, %f743;
	fma.rn.f32 	%f532, %f137, %f746, %f531;
	add.f32 	%f533, %f135, %f530;
	shl.b32 	%r889, %r888, 2;
	add.s32 	%r891, %r586, %r889;
	st.shared.f32 	[%r891], %f533;
	add.f32 	%f534, %f136, %f532;
	add.s32 	%r893, %r588, %r889;
	st.shared.f32 	[%r893], %f534;
	sub.f32 	%f535, %f135, %f530;
	st.shared.f32 	[%r891+128], %f535;
	sub.f32 	%f536, %f136, %f532;
	st.shared.f32 	[%r893+128], %f536;
	bar.sync 	0;
	ld.shared.f32 	%f164, [%r592];
	ld.shared.f32 	%f165, [%r594];
	ld.shared.f32 	%f166, [%r592+2048];
	ld.shared.f32 	%f167, [%r594+2048];
	shr.u32 	%r900, %r595, 26;
	add.s32 	%r901, %r1, %r900;
	and.b32  	%r902, %r901, 536870848;
	sub.s32 	%r903, %r1, %r902;
	shl.b32 	%r904, %r903, 3;
	cvt.rn.f32.s32	%f537, %r904;
	mul.f32 	%f538, %f537, 0f3A800000;
	cvt.f64.f32	%fd31, %f538;
	mul.f64 	%fd32, %fd31, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f168, %fd32;
	mul.f32 	%f539, %f168, 0f3F22F983;
	cvt.rni.s32.f32	%r1289, %f539;
	cvt.rn.f32.s32	%f540, %r1289;
	fma.rn.f32 	%f542, %f540, %f283, %f168;
	fma.rn.f32 	%f544, %f540, %f285, %f542;
	fma.rn.f32 	%f750, %f540, %f287, %f544;
	abs.f32 	%f170, %f168;
	setp.leu.f32	%p117, %f170, 0f47CE4780;
	mov.u32 	%r1281, %r1289;
	mov.f32 	%f747, %f750;
	@%p117 bra 	BB8_169;

	setp.eq.f32	%p118, %f170, 0f7F800000;
	@%p118 bra 	BB8_168;
	bra.uni 	BB8_160;

BB8_168:
	mul.rn.f32 	%f747, %f168, %f288;
	mov.u32 	%r1281, %r1289;
	bra.uni 	BB8_169;

BB8_160:
	mov.b32 	 %r281, %f168;
	shl.b32 	%r907, %r281, 8;
	or.b32  	%r282, %r907, -2147483648;
	add.u64 	%rd195, %SP, 0;
	add.u64 	%rd284, %SPL, 0;
	mov.u32 	%r1275, 0;
	mov.u64 	%rd283, __cudart_i2opi_f;
	mov.u32 	%r1274, -6;

BB8_161:
	.pragma "nounroll";
	ld.const.u32 	%r910, [%rd283];
	// inline asm
	{
	mad.lo.cc.u32   %r908, %r910, %r282, %r1275;
	madc.hi.u32     %r1275, %r910, %r282,  0;
	}
	// inline asm
	st.local.u32 	[%rd284], %r908;
	add.s64 	%rd284, %rd284, 4;
	add.s64 	%rd283, %rd283, 4;
	add.s32 	%r1274, %r1274, 1;
	setp.ne.s32	%p119, %r1274, 0;
	@%p119 bra 	BB8_161;

	bfe.u32 	%r913, %r281, 23, 8;
	add.s32 	%r914, %r913, -128;
	shr.u32 	%r915, %r914, 5;
	and.b32  	%r287, %r281, -2147483648;
	cvta.to.local.u64 	%rd197, %rd195;
	st.local.u32 	[%rd197+24], %r1275;
	bfe.u32 	%r288, %r281, 23, 5;
	mov.u32 	%r916, 6;
	sub.s32 	%r917, %r916, %r915;
	mul.wide.s32 	%rd198, %r917, 4;
	add.s64 	%rd66, %rd197, %rd198;
	ld.local.u32 	%r1277, [%rd66];
	ld.local.u32 	%r1276, [%rd66+-4];
	setp.eq.s32	%p120, %r288, 0;
	@%p120 bra 	BB8_164;

	mov.u32 	%r918, 32;
	sub.s32 	%r919, %r918, %r288;
	shr.u32 	%r920, %r1276, %r919;
	shl.b32 	%r921, %r1277, %r288;
	add.s32 	%r1277, %r920, %r921;
	ld.local.u32 	%r922, [%rd66+-8];
	shr.u32 	%r923, %r922, %r919;
	shl.b32 	%r924, %r1276, %r288;
	add.s32 	%r1276, %r923, %r924;

BB8_164:
	shr.u32 	%r925, %r1276, 30;
	shl.b32 	%r926, %r1277, 2;
	add.s32 	%r1279, %r926, %r925;
	shl.b32 	%r296, %r1276, 2;
	shr.u32 	%r927, %r1279, 31;
	shr.u32 	%r928, %r1277, 30;
	add.s32 	%r297, %r927, %r928;
	setp.eq.s32	%p121, %r927, 0;
	@%p121 bra 	BB8_165;

	not.b32 	%r929, %r1279;
	neg.s32 	%r1278, %r296;
	setp.eq.s32	%p122, %r296, 0;
	selp.u32	%r930, 1, 0, %p122;
	add.s32 	%r1279, %r930, %r929;
	xor.b32  	%r1280, %r287, -2147483648;
	bra.uni 	BB8_167;

BB8_165:
	mov.u32 	%r1278, %r296;
	mov.u32 	%r1280, %r287;

BB8_167:
	cvt.u64.u32	%rd199, %r1279;
	cvt.u64.u32	%rd200, %r1278;
	bfi.b64 	%rd201, %rd199, %rd200, 32, 32;
	cvt.rn.f64.s64	%fd33, %rd201;
	mul.f64 	%fd34, %fd33, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f546, %fd34;
	neg.f32 	%f547, %f546;
	setp.eq.s32	%p123, %r1280, 0;
	selp.f32	%f747, %f546, %f547, %p123;
	setp.eq.s32	%p124, %r287, 0;
	neg.s32 	%r931, %r297;
	selp.b32	%r1281, %r297, %r931, %p124;

BB8_169:
	add.s32 	%r306, %r1281, 1;
	and.b32  	%r307, %r306, 1;
	setp.eq.s32	%p125, %r307, 0;
	selp.f32	%f174, %f747, 0f3F800000, %p125;
	mul.rn.f32 	%f175, %f747, %f747;
	fma.rn.f32 	%f176, %f175, %f174, %f288;
	mov.f32 	%f748, 0fB94D4153;
	@%p125 bra 	BB8_171;

	mov.f32 	%f551, 0fBAB607ED;
	mov.f32 	%f552, 0f37CBAC00;
	fma.rn.f32 	%f748, %f552, %f175, %f551;

BB8_171:
	selp.f32	%f553, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f554, %f748, %f175, %f553;
	selp.f32	%f555, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f556, %f554, %f175, %f555;
	fma.rn.f32 	%f749, %f556, %f176, %f174;
	and.b32  	%r932, %r306, 2;
	setp.eq.s32	%p127, %r932, 0;
	@%p127 bra 	BB8_173;

	mov.f32 	%f558, 0fBF800000;
	fma.rn.f32 	%f749, %f749, %f558, %f288;

BB8_173:
	@%p117 bra 	BB8_184;

	setp.eq.f32	%p129, %f170, 0f7F800000;
	@%p129 bra 	BB8_183;
	bra.uni 	BB8_175;

BB8_183:
	mul.rn.f32 	%f750, %f168, %f288;
	bra.uni 	BB8_184;

BB8_175:
	mov.b32 	 %r308, %f168;
	shl.b32 	%r935, %r308, 8;
	or.b32  	%r309, %r935, -2147483648;
	add.u64 	%rd203, %SP, 0;
	add.u64 	%rd286, %SPL, 0;
	mov.u32 	%r1283, 0;
	mov.u64 	%rd285, __cudart_i2opi_f;
	mov.u32 	%r1282, -6;

BB8_176:
	.pragma "nounroll";
	ld.const.u32 	%r938, [%rd285];
	// inline asm
	{
	mad.lo.cc.u32   %r936, %r938, %r309, %r1283;
	madc.hi.u32     %r1283, %r938, %r309,  0;
	}
	// inline asm
	st.local.u32 	[%rd286], %r936;
	add.s64 	%rd286, %rd286, 4;
	add.s64 	%rd285, %rd285, 4;
	add.s32 	%r1282, %r1282, 1;
	setp.ne.s32	%p130, %r1282, 0;
	@%p130 bra 	BB8_176;

	bfe.u32 	%r941, %r308, 23, 8;
	add.s32 	%r942, %r941, -128;
	shr.u32 	%r943, %r942, 5;
	and.b32  	%r314, %r308, -2147483648;
	cvta.to.local.u64 	%rd205, %rd203;
	st.local.u32 	[%rd205+24], %r1283;
	bfe.u32 	%r315, %r308, 23, 5;
	mov.u32 	%r944, 6;
	sub.s32 	%r945, %r944, %r943;
	mul.wide.s32 	%rd206, %r945, 4;
	add.s64 	%rd72, %rd205, %rd206;
	ld.local.u32 	%r1285, [%rd72];
	ld.local.u32 	%r1284, [%rd72+-4];
	setp.eq.s32	%p131, %r315, 0;
	@%p131 bra 	BB8_179;

	mov.u32 	%r946, 32;
	sub.s32 	%r947, %r946, %r315;
	shr.u32 	%r948, %r1284, %r947;
	shl.b32 	%r949, %r1285, %r315;
	add.s32 	%r1285, %r948, %r949;
	ld.local.u32 	%r950, [%rd72+-8];
	shr.u32 	%r951, %r950, %r947;
	shl.b32 	%r952, %r1284, %r315;
	add.s32 	%r1284, %r951, %r952;

BB8_179:
	shr.u32 	%r953, %r1284, 30;
	shl.b32 	%r954, %r1285, 2;
	add.s32 	%r1287, %r954, %r953;
	shl.b32 	%r323, %r1284, 2;
	shr.u32 	%r955, %r1287, 31;
	shr.u32 	%r956, %r1285, 30;
	add.s32 	%r324, %r955, %r956;
	setp.eq.s32	%p132, %r955, 0;
	@%p132 bra 	BB8_180;

	not.b32 	%r957, %r1287;
	neg.s32 	%r1286, %r323;
	setp.eq.s32	%p133, %r323, 0;
	selp.u32	%r958, 1, 0, %p133;
	add.s32 	%r1287, %r958, %r957;
	xor.b32  	%r1288, %r314, -2147483648;
	bra.uni 	BB8_182;

BB8_180:
	mov.u32 	%r1286, %r323;
	mov.u32 	%r1288, %r314;

BB8_182:
	cvt.u64.u32	%rd207, %r1287;
	cvt.u64.u32	%rd208, %r1286;
	bfi.b64 	%rd209, %rd207, %rd208, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd209;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f559, %fd36;
	neg.f32 	%f560, %f559;
	setp.eq.s32	%p134, %r1288, 0;
	selp.f32	%f750, %f559, %f560, %p134;
	setp.eq.s32	%p135, %r314, 0;
	neg.s32 	%r959, %r324;
	selp.b32	%r1289, %r324, %r959, %p135;

BB8_184:
	and.b32  	%r333, %r1289, 1;
	setp.eq.s32	%p136, %r333, 0;
	selp.f32	%f185, %f750, 0f3F800000, %p136;
	mul.rn.f32 	%f186, %f750, %f750;
	fma.rn.f32 	%f187, %f186, %f185, %f288;
	mov.f32 	%f751, 0fB94D4153;
	@%p136 bra 	BB8_186;

	mov.f32 	%f564, 0fBAB607ED;
	mov.f32 	%f565, 0f37CBAC00;
	fma.rn.f32 	%f751, %f565, %f186, %f564;

BB8_186:
	selp.f32	%f566, 0f3C0885E4, 0f3D2AAABB, %p136;
	fma.rn.f32 	%f567, %f751, %f186, %f566;
	selp.f32	%f568, 0fBE2AAAA8, 0fBEFFFFFF, %p136;
	fma.rn.f32 	%f569, %f567, %f186, %f568;
	fma.rn.f32 	%f752, %f569, %f187, %f185;
	and.b32  	%r960, %r1289, 2;
	setp.eq.s32	%p138, %r960, 0;
	@%p138 bra 	BB8_188;

	mov.f32 	%f571, 0fBF800000;
	fma.rn.f32 	%f752, %f752, %f571, %f288;

BB8_188:
	and.b32  	%r961, %r1, 63;
	and.b32  	%r963, %r581, 1073741696;
	add.s32 	%r964, %r963, %r961;
	mul.f32 	%f572, %f167, %f752;
	mul.f32 	%f573, %f166, %f749;
	sub.f32 	%f574, %f573, %f572;
	mul.f32 	%f575, %f167, %f749;
	fma.rn.f32 	%f576, %f166, %f752, %f575;
	add.f32 	%f577, %f164, %f574;
	shl.b32 	%r965, %r964, 2;
	add.s32 	%r967, %r509, %r965;
	st.shared.f32 	[%r967], %f577;
	add.f32 	%f578, %f165, %f576;
	add.s32 	%r969, %r511, %r965;
	st.shared.f32 	[%r969], %f578;
	sub.f32 	%f579, %f164, %f574;
	st.shared.f32 	[%r967+256], %f579;
	sub.f32 	%f580, %f165, %f576;
	st.shared.f32 	[%r969+256], %f580;
	bar.sync 	0;
	ld.shared.f32 	%f193, [%r515];
	ld.shared.f32 	%f194, [%r517];
	ld.shared.f32 	%f195, [%r515+2048];
	ld.shared.f32 	%f196, [%r517+2048];
	shr.u32 	%r976, %r595, 25;
	add.s32 	%r977, %r1, %r976;
	and.b32  	%r978, %r977, 1073741696;
	sub.s32 	%r979, %r1, %r978;
	shl.b32 	%r980, %r979, 2;
	cvt.rn.f32.s32	%f581, %r980;
	mul.f32 	%f582, %f581, 0f3A800000;
	cvt.f64.f32	%fd37, %f582;
	mul.f64 	%fd38, %fd37, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f197, %fd38;
	mul.f32 	%f583, %f197, 0f3F22F983;
	cvt.rni.s32.f32	%r1305, %f583;
	cvt.rn.f32.s32	%f584, %r1305;
	fma.rn.f32 	%f586, %f584, %f283, %f197;
	fma.rn.f32 	%f588, %f584, %f285, %f586;
	fma.rn.f32 	%f756, %f584, %f287, %f588;
	abs.f32 	%f199, %f197;
	setp.leu.f32	%p139, %f199, 0f47CE4780;
	mov.u32 	%r1297, %r1305;
	mov.f32 	%f753, %f756;
	@%p139 bra 	BB8_199;

	setp.eq.f32	%p140, %f199, 0f7F800000;
	@%p140 bra 	BB8_198;
	bra.uni 	BB8_190;

BB8_198:
	mul.rn.f32 	%f753, %f197, %f288;
	mov.u32 	%r1297, %r1305;
	bra.uni 	BB8_199;

BB8_190:
	mov.b32 	 %r336, %f197;
	shl.b32 	%r983, %r336, 8;
	or.b32  	%r337, %r983, -2147483648;
	add.u64 	%rd211, %SP, 0;
	add.u64 	%rd288, %SPL, 0;
	mov.u32 	%r1291, 0;
	mov.u64 	%rd287, __cudart_i2opi_f;
	mov.u32 	%r1290, -6;

BB8_191:
	.pragma "nounroll";
	ld.const.u32 	%r986, [%rd287];
	// inline asm
	{
	mad.lo.cc.u32   %r984, %r986, %r337, %r1291;
	madc.hi.u32     %r1291, %r986, %r337,  0;
	}
	// inline asm
	st.local.u32 	[%rd288], %r984;
	add.s64 	%rd288, %rd288, 4;
	add.s64 	%rd287, %rd287, 4;
	add.s32 	%r1290, %r1290, 1;
	setp.ne.s32	%p141, %r1290, 0;
	@%p141 bra 	BB8_191;

	bfe.u32 	%r989, %r336, 23, 8;
	add.s32 	%r990, %r989, -128;
	shr.u32 	%r991, %r990, 5;
	and.b32  	%r342, %r336, -2147483648;
	cvta.to.local.u64 	%rd213, %rd211;
	st.local.u32 	[%rd213+24], %r1291;
	bfe.u32 	%r343, %r336, 23, 5;
	mov.u32 	%r992, 6;
	sub.s32 	%r993, %r992, %r991;
	mul.wide.s32 	%rd214, %r993, 4;
	add.s64 	%rd78, %rd213, %rd214;
	ld.local.u32 	%r1293, [%rd78];
	ld.local.u32 	%r1292, [%rd78+-4];
	setp.eq.s32	%p142, %r343, 0;
	@%p142 bra 	BB8_194;

	mov.u32 	%r994, 32;
	sub.s32 	%r995, %r994, %r343;
	shr.u32 	%r996, %r1292, %r995;
	shl.b32 	%r997, %r1293, %r343;
	add.s32 	%r1293, %r996, %r997;
	ld.local.u32 	%r998, [%rd78+-8];
	shr.u32 	%r999, %r998, %r995;
	shl.b32 	%r1000, %r1292, %r343;
	add.s32 	%r1292, %r999, %r1000;

BB8_194:
	shr.u32 	%r1001, %r1292, 30;
	shl.b32 	%r1002, %r1293, 2;
	add.s32 	%r1295, %r1002, %r1001;
	shl.b32 	%r351, %r1292, 2;
	shr.u32 	%r1003, %r1295, 31;
	shr.u32 	%r1004, %r1293, 30;
	add.s32 	%r352, %r1003, %r1004;
	setp.eq.s32	%p143, %r1003, 0;
	@%p143 bra 	BB8_195;

	not.b32 	%r1005, %r1295;
	neg.s32 	%r1294, %r351;
	setp.eq.s32	%p144, %r351, 0;
	selp.u32	%r1006, 1, 0, %p144;
	add.s32 	%r1295, %r1006, %r1005;
	xor.b32  	%r1296, %r342, -2147483648;
	bra.uni 	BB8_197;

BB8_195:
	mov.u32 	%r1294, %r351;
	mov.u32 	%r1296, %r342;

BB8_197:
	cvt.u64.u32	%rd215, %r1295;
	cvt.u64.u32	%rd216, %r1294;
	bfi.b64 	%rd217, %rd215, %rd216, 32, 32;
	cvt.rn.f64.s64	%fd39, %rd217;
	mul.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f590, %fd40;
	neg.f32 	%f591, %f590;
	setp.eq.s32	%p145, %r1296, 0;
	selp.f32	%f753, %f590, %f591, %p145;
	setp.eq.s32	%p146, %r342, 0;
	neg.s32 	%r1007, %r352;
	selp.b32	%r1297, %r352, %r1007, %p146;

BB8_199:
	add.s32 	%r361, %r1297, 1;
	and.b32  	%r362, %r361, 1;
	setp.eq.s32	%p147, %r362, 0;
	selp.f32	%f203, %f753, 0f3F800000, %p147;
	mul.rn.f32 	%f204, %f753, %f753;
	fma.rn.f32 	%f205, %f204, %f203, %f288;
	mov.f32 	%f754, 0fB94D4153;
	@%p147 bra 	BB8_201;

	mov.f32 	%f595, 0fBAB607ED;
	mov.f32 	%f596, 0f37CBAC00;
	fma.rn.f32 	%f754, %f596, %f204, %f595;

BB8_201:
	selp.f32	%f597, 0f3C0885E4, 0f3D2AAABB, %p147;
	fma.rn.f32 	%f598, %f754, %f204, %f597;
	selp.f32	%f599, 0fBE2AAAA8, 0fBEFFFFFF, %p147;
	fma.rn.f32 	%f600, %f598, %f204, %f599;
	fma.rn.f32 	%f755, %f600, %f205, %f203;
	and.b32  	%r1008, %r361, 2;
	setp.eq.s32	%p149, %r1008, 0;
	@%p149 bra 	BB8_203;

	mov.f32 	%f602, 0fBF800000;
	fma.rn.f32 	%f755, %f755, %f602, %f288;

BB8_203:
	@%p139 bra 	BB8_214;

	setp.eq.f32	%p151, %f199, 0f7F800000;
	@%p151 bra 	BB8_213;
	bra.uni 	BB8_205;

BB8_213:
	mul.rn.f32 	%f756, %f197, %f288;
	bra.uni 	BB8_214;

BB8_205:
	mov.b32 	 %r363, %f197;
	shl.b32 	%r1011, %r363, 8;
	or.b32  	%r364, %r1011, -2147483648;
	add.u64 	%rd219, %SP, 0;
	add.u64 	%rd290, %SPL, 0;
	mov.u32 	%r1299, 0;
	mov.u64 	%rd289, __cudart_i2opi_f;
	mov.u32 	%r1298, -6;

BB8_206:
	.pragma "nounroll";
	ld.const.u32 	%r1014, [%rd289];
	// inline asm
	{
	mad.lo.cc.u32   %r1012, %r1014, %r364, %r1299;
	madc.hi.u32     %r1299, %r1014, %r364,  0;
	}
	// inline asm
	st.local.u32 	[%rd290], %r1012;
	add.s64 	%rd290, %rd290, 4;
	add.s64 	%rd289, %rd289, 4;
	add.s32 	%r1298, %r1298, 1;
	setp.ne.s32	%p152, %r1298, 0;
	@%p152 bra 	BB8_206;

	bfe.u32 	%r1017, %r363, 23, 8;
	add.s32 	%r1018, %r1017, -128;
	shr.u32 	%r1019, %r1018, 5;
	and.b32  	%r369, %r363, -2147483648;
	cvta.to.local.u64 	%rd221, %rd219;
	st.local.u32 	[%rd221+24], %r1299;
	bfe.u32 	%r370, %r363, 23, 5;
	mov.u32 	%r1020, 6;
	sub.s32 	%r1021, %r1020, %r1019;
	mul.wide.s32 	%rd222, %r1021, 4;
	add.s64 	%rd84, %rd221, %rd222;
	ld.local.u32 	%r1301, [%rd84];
	ld.local.u32 	%r1300, [%rd84+-4];
	setp.eq.s32	%p153, %r370, 0;
	@%p153 bra 	BB8_209;

	mov.u32 	%r1022, 32;
	sub.s32 	%r1023, %r1022, %r370;
	shr.u32 	%r1024, %r1300, %r1023;
	shl.b32 	%r1025, %r1301, %r370;
	add.s32 	%r1301, %r1024, %r1025;
	ld.local.u32 	%r1026, [%rd84+-8];
	shr.u32 	%r1027, %r1026, %r1023;
	shl.b32 	%r1028, %r1300, %r370;
	add.s32 	%r1300, %r1027, %r1028;

BB8_209:
	shr.u32 	%r1029, %r1300, 30;
	shl.b32 	%r1030, %r1301, 2;
	add.s32 	%r1303, %r1030, %r1029;
	shl.b32 	%r378, %r1300, 2;
	shr.u32 	%r1031, %r1303, 31;
	shr.u32 	%r1032, %r1301, 30;
	add.s32 	%r379, %r1031, %r1032;
	setp.eq.s32	%p154, %r1031, 0;
	@%p154 bra 	BB8_210;

	not.b32 	%r1033, %r1303;
	neg.s32 	%r1302, %r378;
	setp.eq.s32	%p155, %r378, 0;
	selp.u32	%r1034, 1, 0, %p155;
	add.s32 	%r1303, %r1034, %r1033;
	xor.b32  	%r1304, %r369, -2147483648;
	bra.uni 	BB8_212;

BB8_210:
	mov.u32 	%r1302, %r378;
	mov.u32 	%r1304, %r369;

BB8_212:
	cvt.u64.u32	%rd223, %r1303;
	cvt.u64.u32	%rd224, %r1302;
	bfi.b64 	%rd225, %rd223, %rd224, 32, 32;
	cvt.rn.f64.s64	%fd41, %rd225;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f603, %fd42;
	neg.f32 	%f604, %f603;
	setp.eq.s32	%p156, %r1304, 0;
	selp.f32	%f756, %f603, %f604, %p156;
	setp.eq.s32	%p157, %r369, 0;
	neg.s32 	%r1035, %r379;
	selp.b32	%r1305, %r379, %r1035, %p157;

BB8_214:
	and.b32  	%r388, %r1305, 1;
	setp.eq.s32	%p158, %r388, 0;
	selp.f32	%f214, %f756, 0f3F800000, %p158;
	mul.rn.f32 	%f215, %f756, %f756;
	fma.rn.f32 	%f216, %f215, %f214, %f288;
	mov.f32 	%f757, 0fB94D4153;
	@%p158 bra 	BB8_216;

	mov.f32 	%f608, 0fBAB607ED;
	mov.f32 	%f609, 0f37CBAC00;
	fma.rn.f32 	%f757, %f609, %f215, %f608;

BB8_216:
	selp.f32	%f610, 0f3C0885E4, 0f3D2AAABB, %p158;
	fma.rn.f32 	%f611, %f757, %f215, %f610;
	selp.f32	%f612, 0fBE2AAAA8, 0fBEFFFFFF, %p158;
	fma.rn.f32 	%f613, %f611, %f215, %f612;
	fma.rn.f32 	%f758, %f613, %f216, %f214;
	and.b32  	%r1036, %r1305, 2;
	setp.eq.s32	%p160, %r1036, 0;
	@%p160 bra 	BB8_218;

	mov.f32 	%f615, 0fBF800000;
	fma.rn.f32 	%f758, %f758, %f615, %f288;

BB8_218:
	and.b32  	%r1037, %r1, 127;
	and.b32  	%r1039, %r581, 1073741568;
	add.s32 	%r1040, %r1039, %r1037;
	mul.f32 	%f616, %f196, %f758;
	mul.f32 	%f617, %f195, %f755;
	sub.f32 	%f618, %f617, %f616;
	mul.f32 	%f619, %f196, %f755;
	fma.rn.f32 	%f620, %f195, %f758, %f619;
	add.f32 	%f621, %f193, %f618;
	shl.b32 	%r1041, %r1040, 2;
	add.s32 	%r1043, %r586, %r1041;
	st.shared.f32 	[%r1043], %f621;
	add.f32 	%f622, %f194, %f620;
	add.s32 	%r1045, %r588, %r1041;
	st.shared.f32 	[%r1045], %f622;
	sub.f32 	%f623, %f193, %f618;
	st.shared.f32 	[%r1043+512], %f623;
	sub.f32 	%f624, %f194, %f620;
	st.shared.f32 	[%r1045+512], %f624;
	bar.sync 	0;
	ld.shared.f32 	%f222, [%r592];
	ld.shared.f32 	%f223, [%r594];
	ld.shared.f32 	%f224, [%r592+2048];
	ld.shared.f32 	%f225, [%r594+2048];
	shr.u32 	%r1052, %r595, 24;
	add.s32 	%r1053, %r1, %r1052;
	and.b32  	%r1054, %r1053, 2147483392;
	sub.s32 	%r1055, %r1, %r1054;
	shl.b32 	%r1056, %r1055, 1;
	cvt.rn.f32.s32	%f625, %r1056;
	mul.f32 	%f626, %f625, 0f3A800000;
	cvt.f64.f32	%fd43, %f626;
	mul.f64 	%fd44, %fd43, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f226, %fd44;
	mul.f32 	%f627, %f226, 0f3F22F983;
	cvt.rni.s32.f32	%r1321, %f627;
	cvt.rn.f32.s32	%f628, %r1321;
	fma.rn.f32 	%f630, %f628, %f283, %f226;
	fma.rn.f32 	%f632, %f628, %f285, %f630;
	fma.rn.f32 	%f762, %f628, %f287, %f632;
	abs.f32 	%f228, %f226;
	setp.leu.f32	%p161, %f228, 0f47CE4780;
	mov.u32 	%r1313, %r1321;
	mov.f32 	%f759, %f762;
	@%p161 bra 	BB8_229;

	setp.eq.f32	%p162, %f228, 0f7F800000;
	@%p162 bra 	BB8_228;
	bra.uni 	BB8_220;

BB8_228:
	mul.rn.f32 	%f759, %f226, %f288;
	mov.u32 	%r1313, %r1321;
	bra.uni 	BB8_229;

BB8_220:
	mov.b32 	 %r391, %f226;
	shl.b32 	%r1059, %r391, 8;
	or.b32  	%r392, %r1059, -2147483648;
	add.u64 	%rd227, %SP, 0;
	add.u64 	%rd292, %SPL, 0;
	mov.u32 	%r1307, 0;
	mov.u64 	%rd291, __cudart_i2opi_f;
	mov.u32 	%r1306, -6;

BB8_221:
	.pragma "nounroll";
	ld.const.u32 	%r1062, [%rd291];
	// inline asm
	{
	mad.lo.cc.u32   %r1060, %r1062, %r392, %r1307;
	madc.hi.u32     %r1307, %r1062, %r392,  0;
	}
	// inline asm
	st.local.u32 	[%rd292], %r1060;
	add.s64 	%rd292, %rd292, 4;
	add.s64 	%rd291, %rd291, 4;
	add.s32 	%r1306, %r1306, 1;
	setp.ne.s32	%p163, %r1306, 0;
	@%p163 bra 	BB8_221;

	bfe.u32 	%r1065, %r391, 23, 8;
	add.s32 	%r1066, %r1065, -128;
	shr.u32 	%r1067, %r1066, 5;
	and.b32  	%r397, %r391, -2147483648;
	cvta.to.local.u64 	%rd229, %rd227;
	st.local.u32 	[%rd229+24], %r1307;
	bfe.u32 	%r398, %r391, 23, 5;
	mov.u32 	%r1068, 6;
	sub.s32 	%r1069, %r1068, %r1067;
	mul.wide.s32 	%rd230, %r1069, 4;
	add.s64 	%rd90, %rd229, %rd230;
	ld.local.u32 	%r1309, [%rd90];
	ld.local.u32 	%r1308, [%rd90+-4];
	setp.eq.s32	%p164, %r398, 0;
	@%p164 bra 	BB8_224;

	mov.u32 	%r1070, 32;
	sub.s32 	%r1071, %r1070, %r398;
	shr.u32 	%r1072, %r1308, %r1071;
	shl.b32 	%r1073, %r1309, %r398;
	add.s32 	%r1309, %r1072, %r1073;
	ld.local.u32 	%r1074, [%rd90+-8];
	shr.u32 	%r1075, %r1074, %r1071;
	shl.b32 	%r1076, %r1308, %r398;
	add.s32 	%r1308, %r1075, %r1076;

BB8_224:
	shr.u32 	%r1077, %r1308, 30;
	shl.b32 	%r1078, %r1309, 2;
	add.s32 	%r1311, %r1078, %r1077;
	shl.b32 	%r406, %r1308, 2;
	shr.u32 	%r1079, %r1311, 31;
	shr.u32 	%r1080, %r1309, 30;
	add.s32 	%r407, %r1079, %r1080;
	setp.eq.s32	%p165, %r1079, 0;
	@%p165 bra 	BB8_225;

	not.b32 	%r1081, %r1311;
	neg.s32 	%r1310, %r406;
	setp.eq.s32	%p166, %r406, 0;
	selp.u32	%r1082, 1, 0, %p166;
	add.s32 	%r1311, %r1082, %r1081;
	xor.b32  	%r1312, %r397, -2147483648;
	bra.uni 	BB8_227;

BB8_225:
	mov.u32 	%r1310, %r406;
	mov.u32 	%r1312, %r397;

BB8_227:
	cvt.u64.u32	%rd231, %r1311;
	cvt.u64.u32	%rd232, %r1310;
	bfi.b64 	%rd233, %rd231, %rd232, 32, 32;
	cvt.rn.f64.s64	%fd45, %rd233;
	mul.f64 	%fd46, %fd45, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f634, %fd46;
	neg.f32 	%f635, %f634;
	setp.eq.s32	%p167, %r1312, 0;
	selp.f32	%f759, %f634, %f635, %p167;
	setp.eq.s32	%p168, %r397, 0;
	neg.s32 	%r1083, %r407;
	selp.b32	%r1313, %r407, %r1083, %p168;

BB8_229:
	add.s32 	%r416, %r1313, 1;
	and.b32  	%r417, %r416, 1;
	setp.eq.s32	%p169, %r417, 0;
	selp.f32	%f232, %f759, 0f3F800000, %p169;
	mul.rn.f32 	%f233, %f759, %f759;
	fma.rn.f32 	%f234, %f233, %f232, %f288;
	mov.f32 	%f760, 0fB94D4153;
	@%p169 bra 	BB8_231;

	mov.f32 	%f639, 0fBAB607ED;
	mov.f32 	%f640, 0f37CBAC00;
	fma.rn.f32 	%f760, %f640, %f233, %f639;

BB8_231:
	selp.f32	%f641, 0f3C0885E4, 0f3D2AAABB, %p169;
	fma.rn.f32 	%f642, %f760, %f233, %f641;
	selp.f32	%f643, 0fBE2AAAA8, 0fBEFFFFFF, %p169;
	fma.rn.f32 	%f644, %f642, %f233, %f643;
	fma.rn.f32 	%f761, %f644, %f234, %f232;
	and.b32  	%r1084, %r416, 2;
	setp.eq.s32	%p171, %r1084, 0;
	@%p171 bra 	BB8_233;

	mov.f32 	%f646, 0fBF800000;
	fma.rn.f32 	%f761, %f761, %f646, %f288;

BB8_233:
	@%p161 bra 	BB8_244;

	setp.eq.f32	%p173, %f228, 0f7F800000;
	@%p173 bra 	BB8_243;
	bra.uni 	BB8_235;

BB8_243:
	mul.rn.f32 	%f762, %f226, %f288;
	bra.uni 	BB8_244;

BB8_235:
	mov.b32 	 %r418, %f226;
	shl.b32 	%r1087, %r418, 8;
	or.b32  	%r419, %r1087, -2147483648;
	add.u64 	%rd235, %SP, 0;
	add.u64 	%rd294, %SPL, 0;
	mov.u32 	%r1315, 0;
	mov.u64 	%rd293, __cudart_i2opi_f;
	mov.u32 	%r1314, -6;

BB8_236:
	.pragma "nounroll";
	ld.const.u32 	%r1090, [%rd293];
	// inline asm
	{
	mad.lo.cc.u32   %r1088, %r1090, %r419, %r1315;
	madc.hi.u32     %r1315, %r1090, %r419,  0;
	}
	// inline asm
	st.local.u32 	[%rd294], %r1088;
	add.s64 	%rd294, %rd294, 4;
	add.s64 	%rd293, %rd293, 4;
	add.s32 	%r1314, %r1314, 1;
	setp.ne.s32	%p174, %r1314, 0;
	@%p174 bra 	BB8_236;

	bfe.u32 	%r1093, %r418, 23, 8;
	add.s32 	%r1094, %r1093, -128;
	shr.u32 	%r1095, %r1094, 5;
	and.b32  	%r424, %r418, -2147483648;
	cvta.to.local.u64 	%rd237, %rd235;
	st.local.u32 	[%rd237+24], %r1315;
	bfe.u32 	%r425, %r418, 23, 5;
	mov.u32 	%r1096, 6;
	sub.s32 	%r1097, %r1096, %r1095;
	mul.wide.s32 	%rd238, %r1097, 4;
	add.s64 	%rd96, %rd237, %rd238;
	ld.local.u32 	%r1317, [%rd96];
	ld.local.u32 	%r1316, [%rd96+-4];
	setp.eq.s32	%p175, %r425, 0;
	@%p175 bra 	BB8_239;

	mov.u32 	%r1098, 32;
	sub.s32 	%r1099, %r1098, %r425;
	shr.u32 	%r1100, %r1316, %r1099;
	shl.b32 	%r1101, %r1317, %r425;
	add.s32 	%r1317, %r1100, %r1101;
	ld.local.u32 	%r1102, [%rd96+-8];
	shr.u32 	%r1103, %r1102, %r1099;
	shl.b32 	%r1104, %r1316, %r425;
	add.s32 	%r1316, %r1103, %r1104;

BB8_239:
	shr.u32 	%r1105, %r1316, 30;
	shl.b32 	%r1106, %r1317, 2;
	add.s32 	%r1319, %r1106, %r1105;
	shl.b32 	%r433, %r1316, 2;
	shr.u32 	%r1107, %r1319, 31;
	shr.u32 	%r1108, %r1317, 30;
	add.s32 	%r434, %r1107, %r1108;
	setp.eq.s32	%p176, %r1107, 0;
	@%p176 bra 	BB8_240;

	not.b32 	%r1109, %r1319;
	neg.s32 	%r1318, %r433;
	setp.eq.s32	%p177, %r433, 0;
	selp.u32	%r1110, 1, 0, %p177;
	add.s32 	%r1319, %r1110, %r1109;
	xor.b32  	%r1320, %r424, -2147483648;
	bra.uni 	BB8_242;

BB8_240:
	mov.u32 	%r1318, %r433;
	mov.u32 	%r1320, %r424;

BB8_242:
	cvt.u64.u32	%rd239, %r1319;
	cvt.u64.u32	%rd240, %r1318;
	bfi.b64 	%rd241, %rd239, %rd240, 32, 32;
	cvt.rn.f64.s64	%fd47, %rd241;
	mul.f64 	%fd48, %fd47, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f647, %fd48;
	neg.f32 	%f648, %f647;
	setp.eq.s32	%p178, %r1320, 0;
	selp.f32	%f762, %f647, %f648, %p178;
	setp.eq.s32	%p179, %r424, 0;
	neg.s32 	%r1111, %r434;
	selp.b32	%r1321, %r434, %r1111, %p179;

BB8_244:
	and.b32  	%r443, %r1321, 1;
	setp.eq.s32	%p180, %r443, 0;
	selp.f32	%f243, %f762, 0f3F800000, %p180;
	mul.rn.f32 	%f244, %f762, %f762;
	fma.rn.f32 	%f245, %f244, %f243, %f288;
	mov.f32 	%f763, 0fB94D4153;
	@%p180 bra 	BB8_246;

	mov.f32 	%f652, 0fBAB607ED;
	mov.f32 	%f653, 0f37CBAC00;
	fma.rn.f32 	%f763, %f653, %f244, %f652;

BB8_246:
	selp.f32	%f654, 0f3C0885E4, 0f3D2AAABB, %p180;
	fma.rn.f32 	%f655, %f763, %f244, %f654;
	selp.f32	%f656, 0fBE2AAAA8, 0fBEFFFFFF, %p180;
	fma.rn.f32 	%f657, %f655, %f244, %f656;
	fma.rn.f32 	%f764, %f657, %f245, %f243;
	and.b32  	%r1112, %r1321, 2;
	setp.eq.s32	%p182, %r1112, 0;
	@%p182 bra 	BB8_248;

	mov.f32 	%f659, 0fBF800000;
	fma.rn.f32 	%f764, %f764, %f659, %f288;

BB8_248:
	and.b32  	%r1113, %r1, 255;
	and.b32  	%r1115, %r581, 1073741312;
	add.s32 	%r1116, %r1115, %r1113;
	mul.f32 	%f660, %f225, %f764;
	mul.f32 	%f661, %f224, %f761;
	sub.f32 	%f662, %f661, %f660;
	mul.f32 	%f663, %f225, %f761;
	fma.rn.f32 	%f664, %f224, %f764, %f663;
	add.f32 	%f665, %f222, %f662;
	shl.b32 	%r1117, %r1116, 2;
	add.s32 	%r1119, %r509, %r1117;
	st.shared.f32 	[%r1119], %f665;
	add.f32 	%f666, %f223, %f664;
	add.s32 	%r1121, %r511, %r1117;
	st.shared.f32 	[%r1121], %f666;
	sub.f32 	%f667, %f222, %f662;
	st.shared.f32 	[%r1119+1024], %f667;
	sub.f32 	%f668, %f223, %f664;
	st.shared.f32 	[%r1121+1024], %f668;
	bar.sync 	0;
	ld.shared.f32 	%f251, [%r515];
	ld.shared.f32 	%f252, [%r517];
	ld.shared.f32 	%f253, [%r515+2048];
	ld.shared.f32 	%f254, [%r517+2048];
	shr.u32 	%r1128, %r595, 23;
	add.s32 	%r1129, %r1, %r1128;
	and.b32  	%r1130, %r1129, -512;
	sub.s32 	%r1131, %r1, %r1130;
	cvt.rn.f32.s32	%f669, %r1131;
	mul.f32 	%f670, %f669, 0f3A800000;
	cvt.f64.f32	%fd49, %f670;
	mul.f64 	%fd50, %fd49, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f255, %fd50;
	mul.f32 	%f671, %f255, 0f3F22F983;
	cvt.rni.s32.f32	%r1337, %f671;
	cvt.rn.f32.s32	%f672, %r1337;
	fma.rn.f32 	%f674, %f672, %f283, %f255;
	fma.rn.f32 	%f676, %f672, %f285, %f674;
	fma.rn.f32 	%f768, %f672, %f287, %f676;
	abs.f32 	%f257, %f255;
	setp.leu.f32	%p183, %f257, 0f47CE4780;
	mov.u32 	%r1329, %r1337;
	mov.f32 	%f765, %f768;
	@%p183 bra 	BB8_259;

	setp.eq.f32	%p184, %f257, 0f7F800000;
	@%p184 bra 	BB8_258;
	bra.uni 	BB8_250;

BB8_258:
	mul.rn.f32 	%f765, %f255, %f288;
	mov.u32 	%r1329, %r1337;
	bra.uni 	BB8_259;

BB8_250:
	mov.b32 	 %r446, %f255;
	shl.b32 	%r1134, %r446, 8;
	or.b32  	%r447, %r1134, -2147483648;
	add.u64 	%rd243, %SP, 0;
	add.u64 	%rd296, %SPL, 0;
	mov.u32 	%r1323, 0;
	mov.u64 	%rd295, __cudart_i2opi_f;
	mov.u32 	%r1322, -6;

BB8_251:
	.pragma "nounroll";
	ld.const.u32 	%r1137, [%rd295];
	// inline asm
	{
	mad.lo.cc.u32   %r1135, %r1137, %r447, %r1323;
	madc.hi.u32     %r1323, %r1137, %r447,  0;
	}
	// inline asm
	st.local.u32 	[%rd296], %r1135;
	add.s64 	%rd296, %rd296, 4;
	add.s64 	%rd295, %rd295, 4;
	add.s32 	%r1322, %r1322, 1;
	setp.ne.s32	%p185, %r1322, 0;
	@%p185 bra 	BB8_251;

	bfe.u32 	%r1140, %r446, 23, 8;
	add.s32 	%r1141, %r1140, -128;
	shr.u32 	%r1142, %r1141, 5;
	and.b32  	%r452, %r446, -2147483648;
	cvta.to.local.u64 	%rd245, %rd243;
	st.local.u32 	[%rd245+24], %r1323;
	bfe.u32 	%r453, %r446, 23, 5;
	mov.u32 	%r1143, 6;
	sub.s32 	%r1144, %r1143, %r1142;
	mul.wide.s32 	%rd246, %r1144, 4;
	add.s64 	%rd102, %rd245, %rd246;
	ld.local.u32 	%r1325, [%rd102];
	ld.local.u32 	%r1324, [%rd102+-4];
	setp.eq.s32	%p186, %r453, 0;
	@%p186 bra 	BB8_254;

	mov.u32 	%r1145, 32;
	sub.s32 	%r1146, %r1145, %r453;
	shr.u32 	%r1147, %r1324, %r1146;
	shl.b32 	%r1148, %r1325, %r453;
	add.s32 	%r1325, %r1147, %r1148;
	ld.local.u32 	%r1149, [%rd102+-8];
	shr.u32 	%r1150, %r1149, %r1146;
	shl.b32 	%r1151, %r1324, %r453;
	add.s32 	%r1324, %r1150, %r1151;

BB8_254:
	shr.u32 	%r1152, %r1324, 30;
	shl.b32 	%r1153, %r1325, 2;
	add.s32 	%r1327, %r1153, %r1152;
	shl.b32 	%r461, %r1324, 2;
	shr.u32 	%r1154, %r1327, 31;
	shr.u32 	%r1155, %r1325, 30;
	add.s32 	%r462, %r1154, %r1155;
	setp.eq.s32	%p187, %r1154, 0;
	@%p187 bra 	BB8_255;

	not.b32 	%r1156, %r1327;
	neg.s32 	%r1326, %r461;
	setp.eq.s32	%p188, %r461, 0;
	selp.u32	%r1157, 1, 0, %p188;
	add.s32 	%r1327, %r1157, %r1156;
	xor.b32  	%r1328, %r452, -2147483648;
	bra.uni 	BB8_257;

BB8_255:
	mov.u32 	%r1326, %r461;
	mov.u32 	%r1328, %r452;

BB8_257:
	cvt.u64.u32	%rd247, %r1327;
	cvt.u64.u32	%rd248, %r1326;
	bfi.b64 	%rd249, %rd247, %rd248, 32, 32;
	cvt.rn.f64.s64	%fd51, %rd249;
	mul.f64 	%fd52, %fd51, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f678, %fd52;
	neg.f32 	%f679, %f678;
	setp.eq.s32	%p189, %r1328, 0;
	selp.f32	%f765, %f678, %f679, %p189;
	setp.eq.s32	%p190, %r452, 0;
	neg.s32 	%r1158, %r462;
	selp.b32	%r1329, %r462, %r1158, %p190;

BB8_259:
	add.s32 	%r471, %r1329, 1;
	and.b32  	%r472, %r471, 1;
	setp.eq.s32	%p191, %r472, 0;
	selp.f32	%f261, %f765, 0f3F800000, %p191;
	mul.rn.f32 	%f262, %f765, %f765;
	fma.rn.f32 	%f263, %f262, %f261, %f288;
	mov.f32 	%f766, 0fB94D4153;
	@%p191 bra 	BB8_261;

	mov.f32 	%f683, 0fBAB607ED;
	mov.f32 	%f684, 0f37CBAC00;
	fma.rn.f32 	%f766, %f684, %f262, %f683;

BB8_261:
	selp.f32	%f685, 0f3C0885E4, 0f3D2AAABB, %p191;
	fma.rn.f32 	%f686, %f766, %f262, %f685;
	selp.f32	%f687, 0fBE2AAAA8, 0fBEFFFFFF, %p191;
	fma.rn.f32 	%f688, %f686, %f262, %f687;
	fma.rn.f32 	%f767, %f688, %f263, %f261;
	and.b32  	%r1159, %r471, 2;
	setp.eq.s32	%p193, %r1159, 0;
	@%p193 bra 	BB8_263;

	mov.f32 	%f690, 0fBF800000;
	fma.rn.f32 	%f767, %f767, %f690, %f288;

BB8_263:
	@%p183 bra 	BB8_274;

	setp.eq.f32	%p195, %f257, 0f7F800000;
	@%p195 bra 	BB8_273;
	bra.uni 	BB8_265;

BB8_273:
	mul.rn.f32 	%f768, %f255, %f288;
	bra.uni 	BB8_274;

BB8_265:
	mov.b32 	 %r473, %f255;
	shl.b32 	%r1162, %r473, 8;
	or.b32  	%r474, %r1162, -2147483648;
	add.u64 	%rd251, %SP, 0;
	add.u64 	%rd298, %SPL, 0;
	mov.u32 	%r1331, 0;
	mov.u64 	%rd297, __cudart_i2opi_f;
	mov.u32 	%r1330, -6;

BB8_266:
	.pragma "nounroll";
	ld.const.u32 	%r1165, [%rd297];
	// inline asm
	{
	mad.lo.cc.u32   %r1163, %r1165, %r474, %r1331;
	madc.hi.u32     %r1331, %r1165, %r474,  0;
	}
	// inline asm
	st.local.u32 	[%rd298], %r1163;
	add.s64 	%rd298, %rd298, 4;
	add.s64 	%rd297, %rd297, 4;
	add.s32 	%r1330, %r1330, 1;
	setp.ne.s32	%p196, %r1330, 0;
	@%p196 bra 	BB8_266;

	bfe.u32 	%r1168, %r473, 23, 8;
	add.s32 	%r1169, %r1168, -128;
	shr.u32 	%r1170, %r1169, 5;
	and.b32  	%r479, %r473, -2147483648;
	cvta.to.local.u64 	%rd253, %rd251;
	st.local.u32 	[%rd253+24], %r1331;
	bfe.u32 	%r480, %r473, 23, 5;
	mov.u32 	%r1171, 6;
	sub.s32 	%r1172, %r1171, %r1170;
	mul.wide.s32 	%rd254, %r1172, 4;
	add.s64 	%rd108, %rd253, %rd254;
	ld.local.u32 	%r1333, [%rd108];
	ld.local.u32 	%r1332, [%rd108+-4];
	setp.eq.s32	%p197, %r480, 0;
	@%p197 bra 	BB8_269;

	mov.u32 	%r1173, 32;
	sub.s32 	%r1174, %r1173, %r480;
	shr.u32 	%r1175, %r1332, %r1174;
	shl.b32 	%r1176, %r1333, %r480;
	add.s32 	%r1333, %r1175, %r1176;
	ld.local.u32 	%r1177, [%rd108+-8];
	shr.u32 	%r1178, %r1177, %r1174;
	shl.b32 	%r1179, %r1332, %r480;
	add.s32 	%r1332, %r1178, %r1179;

BB8_269:
	shr.u32 	%r1180, %r1332, 30;
	shl.b32 	%r1181, %r1333, 2;
	add.s32 	%r1335, %r1181, %r1180;
	shl.b32 	%r488, %r1332, 2;
	shr.u32 	%r1182, %r1335, 31;
	shr.u32 	%r1183, %r1333, 30;
	add.s32 	%r489, %r1182, %r1183;
	setp.eq.s32	%p198, %r1182, 0;
	@%p198 bra 	BB8_270;

	not.b32 	%r1184, %r1335;
	neg.s32 	%r1334, %r488;
	setp.eq.s32	%p199, %r488, 0;
	selp.u32	%r1185, 1, 0, %p199;
	add.s32 	%r1335, %r1185, %r1184;
	xor.b32  	%r1336, %r479, -2147483648;
	bra.uni 	BB8_272;

BB8_270:
	mov.u32 	%r1334, %r488;
	mov.u32 	%r1336, %r479;

BB8_272:
	cvt.u64.u32	%rd255, %r1335;
	cvt.u64.u32	%rd256, %r1334;
	bfi.b64 	%rd257, %rd255, %rd256, 32, 32;
	cvt.rn.f64.s64	%fd53, %rd257;
	mul.f64 	%fd54, %fd53, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f691, %fd54;
	neg.f32 	%f692, %f691;
	setp.eq.s32	%p200, %r1336, 0;
	selp.f32	%f768, %f691, %f692, %p200;
	setp.eq.s32	%p201, %r479, 0;
	neg.s32 	%r1186, %r489;
	selp.b32	%r1337, %r489, %r1186, %p201;

BB8_274:
	and.b32  	%r498, %r1337, 1;
	setp.eq.s32	%p202, %r498, 0;
	selp.f32	%f272, %f768, 0f3F800000, %p202;
	mul.rn.f32 	%f273, %f768, %f768;
	fma.rn.f32 	%f274, %f273, %f272, %f288;
	mov.f32 	%f769, 0fB94D4153;
	@%p202 bra 	BB8_276;

	mov.f32 	%f696, 0fBAB607ED;
	mov.f32 	%f697, 0f37CBAC00;
	fma.rn.f32 	%f769, %f697, %f273, %f696;

BB8_276:
	selp.f32	%f698, 0f3C0885E4, 0f3D2AAABB, %p202;
	fma.rn.f32 	%f699, %f769, %f273, %f698;
	selp.f32	%f700, 0fBE2AAAA8, 0fBEFFFFFF, %p202;
	fma.rn.f32 	%f701, %f699, %f273, %f700;
	fma.rn.f32 	%f770, %f701, %f274, %f272;
	and.b32  	%r1187, %r1337, 2;
	setp.eq.s32	%p204, %r1187, 0;
	@%p204 bra 	BB8_278;

	mov.f32 	%f703, 0fBF800000;
	fma.rn.f32 	%f770, %f770, %f703, %f288;

BB8_278:
	mul.f32 	%f704, %f254, %f770;
	mul.f32 	%f705, %f253, %f767;
	sub.f32 	%f706, %f705, %f704;
	mul.f32 	%f707, %f254, %f767;
	fma.rn.f32 	%f708, %f253, %f770, %f707;
	add.f32 	%f709, %f251, %f706;
	add.s32 	%r1193, %r504, %r1;
	mul.wide.u32 	%rd259, %r1193, 4;
	add.s64 	%rd260, %rd111, %rd259;
	st.global.f32 	[%rd260], %f709;
	add.f32 	%f710, %f252, %f708;
	cvta.to.global.u64 	%rd261, %rd110;
	add.s64 	%rd262, %rd261, %rd259;
	st.global.f32 	[%rd262], %f710;
	sub.f32 	%f711, %f251, %f706;
	st.global.f32 	[%rd260+2048], %f711;
	sub.f32 	%f712, %f252, %f708;
	st.global.f32 	[%rd262+2048], %f712;
	ret;
}

	// .globl	_occa_preprocesses_ODW_11_0
.visible .entry _occa_preprocesses_ODW_11_0(
	.param .u64 _occa_preprocesses_ODW_11_0_param_0,
	.param .u32 _occa_preprocesses_ODW_11_0_param_1,
	.param .u32 _occa_preprocesses_ODW_11_0_param_2,
	.param .u32 _occa_preprocesses_ODW_11_0_param_3,
	.param .u64 _occa_preprocesses_ODW_11_0_param_4
)
.maxntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot9[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<10>;
	.reg .f32 	%f<147>;
	.reg .b32 	%r<203>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<37>;
	// demoted variable
	.shared .align 4 .b8 _ZZ27_occa_preprocesses_ODW_11_0E2wr[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ27_occa_preprocesses_ODW_11_0E11windowAdded[4096];

	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd13, [_occa_preprocesses_ODW_11_0_param_4];
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r61, %r1, 2;
	mov.u32 	%r62, _ZZ27_occa_preprocesses_ODW_11_0E2wr;
	add.s32 	%r2, %r62, %r61;
	mov.u32 	%r196, 0;
	st.shared.u32 	[%r2], %r196;
	st.shared.u32 	[%r2+4096], %r196;
	bar.sync 	0;
	ld.shared.f32 	%f31, [%r2+4096];
	ld.shared.f32 	%f32, [%r2];
	add.f32 	%f33, %f32, %f31;
	mov.u32 	%r65, _ZZ27_occa_preprocesses_ODW_11_0E11windowAdded;
	add.s32 	%r3, %r65, %r61;
	st.shared.f32 	[%r3], %f33;
	bar.sync 	0;
	setp.lt.s32	%p1, %r1, 512;
	selp.u16	%rs1, 1, 0, %p1;
	mul.wide.u16 	%r66, %rs1, 512;
	add.s32 	%r67, %r66, %r1;
	shl.b32 	%r68, %r67, 2;
	add.s32 	%r70, %r65, %r68;
	ld.shared.f32 	%f34, [%r70];
	ld.shared.f32 	%f35, [%r3];
	add.f32 	%f36, %f35, %f34;
	selp.u32	%r71, 1, 0, %p1;
	cvt.rn.f32.u32	%f37, %r71;
	mul.f32 	%f38, %f37, %f36;
	st.shared.f32 	[%r3], %f38;
	bar.sync 	0;
	setp.lt.s32	%p2, %r1, 256;
	selp.u16	%rs2, 1, 0, %p2;
	mul.wide.u16 	%r72, %rs2, 256;
	add.s32 	%r73, %r72, %r1;
	shl.b32 	%r74, %r73, 2;
	add.s32 	%r76, %r65, %r74;
	ld.shared.f32 	%f39, [%r76];
	ld.shared.f32 	%f40, [%r3];
	add.f32 	%f41, %f40, %f39;
	selp.u32	%r77, 1, 0, %p2;
	cvt.rn.f32.u32	%f42, %r77;
	mul.f32 	%f43, %f42, %f41;
	st.shared.f32 	[%r3], %f43;
	bar.sync 	0;
	setp.lt.s32	%p3, %r1, 128;
	selp.u16	%rs3, 1, 0, %p3;
	mul.wide.u16 	%r78, %rs3, 128;
	add.s32 	%r79, %r78, %r1;
	shl.b32 	%r80, %r79, 2;
	add.s32 	%r82, %r65, %r80;
	ld.shared.f32 	%f44, [%r82];
	ld.shared.f32 	%f45, [%r3];
	add.f32 	%f46, %f45, %f44;
	selp.u32	%r83, 1, 0, %p3;
	cvt.rn.f32.u32	%f47, %r83;
	mul.f32 	%f48, %f47, %f46;
	st.shared.f32 	[%r3], %f48;
	bar.sync 	0;
	setp.lt.s32	%p4, %r1, 64;
	selp.u16	%rs4, 1, 0, %p4;
	mul.wide.u16 	%r84, %rs4, 64;
	add.s32 	%r85, %r84, %r1;
	shl.b32 	%r86, %r85, 2;
	add.s32 	%r88, %r65, %r86;
	ld.shared.f32 	%f49, [%r88];
	ld.shared.f32 	%f50, [%r3];
	add.f32 	%f51, %f50, %f49;
	selp.u32	%r89, 1, 0, %p4;
	cvt.rn.f32.u32	%f52, %r89;
	mul.f32 	%f53, %f52, %f51;
	st.shared.f32 	[%r3], %f53;
	bar.sync 	0;
	setp.lt.s32	%p5, %r1, 32;
	selp.u16	%rs5, 1, 0, %p5;
	mul.wide.u16 	%r90, %rs5, 32;
	add.s32 	%r91, %r90, %r1;
	shl.b32 	%r92, %r91, 2;
	add.s32 	%r94, %r65, %r92;
	ld.shared.f32 	%f54, [%r94];
	ld.shared.f32 	%f55, [%r3];
	add.f32 	%f56, %f55, %f54;
	selp.u32	%r95, 1, 0, %p5;
	cvt.rn.f32.u32	%f57, %r95;
	mul.f32 	%f58, %f57, %f56;
	st.shared.f32 	[%r3], %f58;
	bar.sync 	0;
	setp.lt.s32	%p6, %r1, 16;
	selp.u16	%rs6, 1, 0, %p6;
	mul.wide.u16 	%r96, %rs6, 16;
	add.s32 	%r97, %r96, %r1;
	shl.b32 	%r98, %r97, 2;
	add.s32 	%r100, %r65, %r98;
	ld.shared.f32 	%f59, [%r100];
	ld.shared.f32 	%f60, [%r3];
	add.f32 	%f61, %f60, %f59;
	selp.u32	%r101, 1, 0, %p6;
	cvt.rn.f32.u32	%f62, %r101;
	mul.f32 	%f63, %f62, %f61;
	st.shared.f32 	[%r3], %f63;
	bar.sync 	0;
	setp.lt.s32	%p7, %r1, 8;
	selp.u16	%rs7, 1, 0, %p7;
	mul.wide.u16 	%r102, %rs7, 8;
	add.s32 	%r103, %r102, %r1;
	shl.b32 	%r104, %r103, 2;
	add.s32 	%r106, %r65, %r104;
	ld.shared.f32 	%f64, [%r106];
	ld.shared.f32 	%f65, [%r3];
	add.f32 	%f66, %f65, %f64;
	selp.u32	%r107, 1, 0, %p7;
	cvt.rn.f32.u32	%f67, %r107;
	mul.f32 	%f68, %f67, %f66;
	st.shared.f32 	[%r3], %f68;
	bar.sync 	0;
	setp.lt.s32	%p8, %r1, 4;
	selp.u16	%rs8, 1, 0, %p8;
	mul.wide.u16 	%r108, %rs8, 4;
	add.s32 	%r109, %r108, %r1;
	shl.b32 	%r110, %r109, 2;
	add.s32 	%r112, %r65, %r110;
	ld.shared.f32 	%f69, [%r112];
	ld.shared.f32 	%f70, [%r3];
	add.f32 	%f71, %f70, %f69;
	selp.u32	%r113, 1, 0, %p8;
	cvt.rn.f32.u32	%f72, %r113;
	mul.f32 	%f73, %f72, %f71;
	st.shared.f32 	[%r3], %f73;
	bar.sync 	0;
	setp.lt.s32	%p9, %r1, 2;
	selp.u16	%rs9, 1, 0, %p9;
	mul.wide.u16 	%r114, %rs9, 2;
	add.s32 	%r115, %r114, %r1;
	shl.b32 	%r116, %r115, 2;
	add.s32 	%r118, %r65, %r116;
	ld.shared.f32 	%f74, [%r118];
	ld.shared.f32 	%f75, [%r3];
	add.f32 	%f76, %f75, %f74;
	selp.u32	%r119, 1, 0, %p9;
	cvt.rn.f32.u32	%f77, %r119;
	mul.f32 	%f78, %f77, %f76;
	st.shared.f32 	[%r3], %f78;
	bar.sync 	0;
	setp.lt.s32	%p10, %r1, 1;
	selp.u32	%r120, 1, 0, %p10;
	add.s32 	%r121, %r120, %r1;
	shl.b32 	%r122, %r121, 2;
	add.s32 	%r124, %r65, %r122;
	ld.shared.f32 	%f79, [%r124];
	ld.shared.f32 	%f80, [%r3];
	add.f32 	%f81, %f80, %f79;
	cvt.rn.f32.u32	%f82, %r120;
	mul.f32 	%f83, %f82, %f81;
	st.shared.f32 	[%r3], %f83;
	bar.sync 	0;
	ld.shared.f32 	%f84, [_ZZ27_occa_preprocesses_ODW_11_0E11windowAdded];
	cvt.f64.f32	%fd1, %f84;
	mul.f64 	%fd2, %fd1, 0d3F40000000000000;
	ld.shared.f32 	%f85, [%r2];
	cvt.f64.f32	%fd3, %f85;
	sub.f64 	%fd4, %fd3, %fd2;
	cvt.rn.f32.f64	%f1, %fd4;
	st.shared.f32 	[%r2], %f1;
	ld.shared.f32 	%f86, [%r2+4096];
	cvt.f64.f32	%fd5, %f86;
	sub.f64 	%fd6, %fd5, %fd2;
	cvt.rn.f32.f64	%f2, %fd6;
	st.shared.f32 	[%r2+4096], %f2;
	cvt.rn.f32.s32	%f87, %r1;
	div.rn.f32 	%f88, %f87, 0f44FFE000;
	cvt.f64.f32	%fd7, %f88;
	mul.f64 	%fd8, %fd7, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f3, %fd8;
	mul.f32 	%f89, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r194, %f89;
	cvt.rn.f32.s32	%f90, %r194;
	mov.f32 	%f91, 0fBFC90FDA;
	fma.rn.f32 	%f92, %f90, %f91, %f3;
	mov.f32 	%f93, 0fB3A22168;
	fma.rn.f32 	%f94, %f90, %f93, %f92;
	mov.f32 	%f95, 0fA7C234C5;
	fma.rn.f32 	%f141, %f90, %f95, %f94;
	abs.f32 	%f5, %f3;
	setp.leu.f32	%p11, %f5, 0f47CE4780;
	@%p11 bra 	BB9_11;

	setp.eq.f32	%p12, %f5, 0f7F800000;
	@%p12 bra 	BB9_10;
	bra.uni 	BB9_2;

BB9_10:
	mov.f32 	%f98, 0f00000000;
	mul.rn.f32 	%f141, %f3, %f98;
	bra.uni 	BB9_11;

BB9_2:
	mov.b32 	 %r5, %f3;
	shl.b32 	%r127, %r5, 8;
	or.b32  	%r6, %r127, -2147483648;
	add.u64 	%rd15, %SP, 0;
	add.u64 	%rd34, %SPL, 0;
	mov.u32 	%r188, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
	mov.u32 	%r187, -6;

BB9_3:
	.pragma "nounroll";
	ld.const.u32 	%r130, [%rd33];
	// inline asm
	{
	mad.lo.cc.u32   %r128, %r130, %r6, %r188;
	madc.hi.u32     %r188, %r130, %r6,  0;
	}
	// inline asm
	st.local.u32 	[%rd34], %r128;
	add.s64 	%rd34, %rd34, 4;
	add.s64 	%rd33, %rd33, 4;
	add.s32 	%r187, %r187, 1;
	setp.ne.s32	%p13, %r187, 0;
	@%p13 bra 	BB9_3;

	bfe.u32 	%r133, %r5, 23, 8;
	add.s32 	%r134, %r133, -128;
	shr.u32 	%r135, %r134, 5;
	and.b32  	%r11, %r5, -2147483648;
	cvta.to.local.u64 	%rd17, %rd15;
	st.local.u32 	[%rd17+24], %r188;
	bfe.u32 	%r12, %r5, 23, 5;
	mov.u32 	%r136, 6;
	sub.s32 	%r137, %r136, %r135;
	mul.wide.s32 	%rd18, %r137, 4;
	add.s64 	%rd6, %rd17, %rd18;
	ld.local.u32 	%r190, [%rd6];
	ld.local.u32 	%r189, [%rd6+-4];
	setp.eq.s32	%p14, %r12, 0;
	@%p14 bra 	BB9_6;

	mov.u32 	%r138, 32;
	sub.s32 	%r139, %r138, %r12;
	shr.u32 	%r140, %r189, %r139;
	shl.b32 	%r141, %r190, %r12;
	add.s32 	%r190, %r140, %r141;
	ld.local.u32 	%r142, [%rd6+-8];
	shr.u32 	%r143, %r142, %r139;
	shl.b32 	%r144, %r189, %r12;
	add.s32 	%r189, %r143, %r144;

BB9_6:
	shr.u32 	%r145, %r189, 30;
	shl.b32 	%r146, %r190, 2;
	add.s32 	%r192, %r146, %r145;
	shl.b32 	%r20, %r189, 2;
	shr.u32 	%r147, %r192, 31;
	shr.u32 	%r148, %r190, 30;
	add.s32 	%r21, %r147, %r148;
	setp.eq.s32	%p15, %r147, 0;
	@%p15 bra 	BB9_7;

	not.b32 	%r149, %r192;
	neg.s32 	%r191, %r20;
	setp.eq.s32	%p16, %r20, 0;
	selp.u32	%r150, 1, 0, %p16;
	add.s32 	%r192, %r150, %r149;
	xor.b32  	%r193, %r11, -2147483648;
	bra.uni 	BB9_9;

BB9_7:
	mov.u32 	%r191, %r20;
	mov.u32 	%r193, %r11;

BB9_9:
	cvt.u64.u32	%rd19, %r192;
	cvt.u64.u32	%rd20, %r191;
	bfi.b64 	%rd21, %rd19, %rd20, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd21;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f96, %fd10;
	neg.f32 	%f97, %f96;
	setp.eq.s32	%p17, %r193, 0;
	selp.f32	%f141, %f96, %f97, %p17;
	setp.eq.s32	%p18, %r11, 0;
	neg.s32 	%r151, %r21;
	selp.b32	%r194, %r21, %r151, %p18;

BB9_11:
	add.s32 	%r30, %r194, 1;
	and.b32  	%r31, %r30, 1;
	setp.eq.s32	%p19, %r31, 0;
	selp.f32	%f9, %f141, 0f3F800000, %p19;
	mul.rn.f32 	%f10, %f141, %f141;
	mov.f32 	%f100, 0f00000000;
	fma.rn.f32 	%f11, %f10, %f9, %f100;
	mov.f32 	%f142, 0fB94D4153;
	@%p19 bra 	BB9_13;

	mov.f32 	%f101, 0fBAB607ED;
	mov.f32 	%f102, 0f37CBAC00;
	fma.rn.f32 	%f142, %f102, %f10, %f101;

BB9_13:
	selp.f32	%f103, 0f3C0885E4, 0f3D2AAABB, %p19;
	fma.rn.f32 	%f104, %f142, %f10, %f103;
	selp.f32	%f105, 0fBE2AAAA8, 0fBEFFFFFF, %p19;
	fma.rn.f32 	%f106, %f104, %f10, %f105;
	fma.rn.f32 	%f143, %f106, %f11, %f9;
	and.b32  	%r152, %r30, 2;
	setp.eq.s32	%p21, %r152, 0;
	@%p21 bra 	BB9_15;

	mov.f32 	%f108, 0fBF800000;
	fma.rn.f32 	%f143, %f143, %f108, %f100;

BB9_15:
	mov.f32 	%f109, 0f3F800000;
	sub.f32 	%f110, %f109, %f143;
	mul.f32 	%f111, %f110, 0f3F000000;
	mul.f32 	%f112, %f1, %f111;
	st.shared.f32 	[%r2], %f112;
	add.s32 	%r154, %r1, 1024;
	cvt.rn.f32.s32	%f113, %r154;
	div.rn.f32 	%f114, %f113, 0f44FFE000;
	cvt.f64.f32	%fd11, %f114;
	mul.f64 	%fd12, %fd11, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f17, %fd12;
	mul.f32 	%f115, %f17, 0f3F22F983;
	cvt.rni.s32.f32	%r202, %f115;
	cvt.rn.f32.s32	%f116, %r202;
	fma.rn.f32 	%f118, %f116, %f91, %f17;
	fma.rn.f32 	%f120, %f116, %f93, %f118;
	fma.rn.f32 	%f144, %f116, %f95, %f120;
	abs.f32 	%f19, %f17;
	setp.leu.f32	%p22, %f19, 0f47CE4780;
	@%p22 bra 	BB9_26;

	setp.eq.f32	%p23, %f19, 0f7F800000;
	@%p23 bra 	BB9_25;
	bra.uni 	BB9_17;

BB9_25:
	mul.rn.f32 	%f144, %f17, %f100;
	bra.uni 	BB9_26;

BB9_17:
	mov.b32 	 %r33, %f17;
	shl.b32 	%r157, %r33, 8;
	or.b32  	%r34, %r157, -2147483648;
	add.u64 	%rd23, %SP, 0;
	add.u64 	%rd36, %SPL, 0;
	mov.u64 	%rd35, __cudart_i2opi_f;
	mov.u32 	%r195, -6;

BB9_18:
	.pragma "nounroll";
	ld.const.u32 	%r160, [%rd35];
	// inline asm
	{
	mad.lo.cc.u32   %r158, %r160, %r34, %r196;
	madc.hi.u32     %r196, %r160, %r34,  0;
	}
	// inline asm
	st.local.u32 	[%rd36], %r158;
	add.s64 	%rd36, %rd36, 4;
	add.s64 	%rd35, %rd35, 4;
	add.s32 	%r195, %r195, 1;
	setp.ne.s32	%p24, %r195, 0;
	@%p24 bra 	BB9_18;

	bfe.u32 	%r163, %r33, 23, 8;
	add.s32 	%r164, %r163, -128;
	shr.u32 	%r165, %r164, 5;
	and.b32  	%r39, %r33, -2147483648;
	cvta.to.local.u64 	%rd25, %rd23;
	st.local.u32 	[%rd25+24], %r196;
	bfe.u32 	%r40, %r33, 23, 5;
	mov.u32 	%r166, 6;
	sub.s32 	%r167, %r166, %r165;
	mul.wide.s32 	%rd26, %r167, 4;
	add.s64 	%rd12, %rd25, %rd26;
	ld.local.u32 	%r198, [%rd12];
	ld.local.u32 	%r197, [%rd12+-4];
	setp.eq.s32	%p25, %r40, 0;
	@%p25 bra 	BB9_21;

	mov.u32 	%r168, 32;
	sub.s32 	%r169, %r168, %r40;
	shr.u32 	%r170, %r197, %r169;
	shl.b32 	%r171, %r198, %r40;
	add.s32 	%r198, %r170, %r171;
	ld.local.u32 	%r172, [%rd12+-8];
	shr.u32 	%r173, %r172, %r169;
	shl.b32 	%r174, %r197, %r40;
	add.s32 	%r197, %r173, %r174;

BB9_21:
	shr.u32 	%r175, %r197, 30;
	shl.b32 	%r176, %r198, 2;
	add.s32 	%r200, %r176, %r175;
	shl.b32 	%r48, %r197, 2;
	shr.u32 	%r177, %r200, 31;
	shr.u32 	%r178, %r198, 30;
	add.s32 	%r49, %r177, %r178;
	setp.eq.s32	%p26, %r177, 0;
	@%p26 bra 	BB9_22;

	not.b32 	%r179, %r200;
	neg.s32 	%r199, %r48;
	setp.eq.s32	%p27, %r48, 0;
	selp.u32	%r180, 1, 0, %p27;
	add.s32 	%r200, %r180, %r179;
	xor.b32  	%r201, %r39, -2147483648;
	bra.uni 	BB9_24;

BB9_22:
	mov.u32 	%r199, %r48;
	mov.u32 	%r201, %r39;

BB9_24:
	cvt.u64.u32	%rd27, %r200;
	cvt.u64.u32	%rd28, %r199;
	bfi.b64 	%rd29, %rd27, %rd28, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd29;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f122, %fd14;
	neg.f32 	%f123, %f122;
	setp.eq.s32	%p28, %r201, 0;
	selp.f32	%f144, %f122, %f123, %p28;
	setp.eq.s32	%p29, %r39, 0;
	neg.s32 	%r181, %r49;
	selp.b32	%r202, %r49, %r181, %p29;

BB9_26:
	add.s32 	%r58, %r202, 1;
	and.b32  	%r59, %r58, 1;
	setp.eq.s32	%p30, %r59, 0;
	selp.f32	%f23, %f144, 0f3F800000, %p30;
	mul.rn.f32 	%f24, %f144, %f144;
	fma.rn.f32 	%f25, %f24, %f23, %f100;
	mov.f32 	%f145, 0fB94D4153;
	@%p30 bra 	BB9_28;

	mov.f32 	%f127, 0fBAB607ED;
	mov.f32 	%f128, 0f37CBAC00;
	fma.rn.f32 	%f145, %f128, %f24, %f127;

BB9_28:
	selp.f32	%f129, 0f3C0885E4, 0f3D2AAABB, %p30;
	fma.rn.f32 	%f130, %f145, %f24, %f129;
	selp.f32	%f131, 0fBE2AAAA8, 0fBEFFFFFF, %p30;
	fma.rn.f32 	%f132, %f130, %f24, %f131;
	fma.rn.f32 	%f146, %f132, %f25, %f23;
	and.b32  	%r182, %r58, 2;
	setp.eq.s32	%p32, %r182, 0;
	@%p32 bra 	BB9_30;

	mov.f32 	%f134, 0fBF800000;
	fma.rn.f32 	%f146, %f146, %f134, %f100;

BB9_30:
	sub.f32 	%f136, %f109, %f146;
	mul.f32 	%f137, %f136, 0f3F000000;
	mul.f32 	%f138, %f2, %f137;
	st.shared.f32 	[%r2+4096], %f138;
	bar.sync 	0;
	ld.shared.f32 	%f139, [%r2];
	mov.u32 	%r183, %ctaid.x;
	shl.b32 	%r184, %r183, 11;
	add.s32 	%r186, %r184, %r1;
	cvta.to.global.u64 	%rd30, %rd13;
	mul.wide.u32 	%rd31, %r186, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.global.f32 	[%rd32], %f139;
	ld.shared.f32 	%f140, [%r2+4096];
	st.global.f32 	[%rd32+4096], %f140;
	ret;
}

	// .globl	_occa_Stockhoptimized11_0
.visible .entry _occa_Stockhoptimized11_0(
	.param .u64 _occa_Stockhoptimized11_0_param_0,
	.param .u64 _occa_Stockhoptimized11_0_param_1,
	.param .u32 _occa_Stockhoptimized11_0_param_2
)
.maxntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot10[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<227>;
	.reg .f32 	%f<850>;
	.reg .b32 	%r<1485>;
	.reg .f64 	%fd<61>;
	.reg .b64 	%rd<331>;
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized11_0E6FRBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized11_0E6FIBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized11_0E6SRBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ25_occa_Stockhoptimized11_0E6SIBank[8192];

	mov.u64 	%SPL, __local_depot10;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd121, [_occa_Stockhoptimized11_0_param_0];
	ld.param.u64 	%rd122, [_occa_Stockhoptimized11_0_param_1];
	mov.u32 	%r554, %ctaid.x;
	shl.b32 	%r555, %r554, 10;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r556, %r555, %r1;
	and.b32  	%r557, %r556, 1023;
	shl.b32 	%r558, %r556, 1;
	and.b32  	%r559, %r558, -2048;
	add.s32 	%r560, %r559, %r557;
	cvta.to.global.u64 	%rd123, %rd121;
	mul.wide.u32 	%rd124, %r560, 4;
	add.s64 	%rd125, %rd123, %rd124;
	ld.global.f32 	%f1, [%rd125];
	ld.global.f32 	%f2, [%rd125+4096];
	mov.f32 	%f310, 0f80000000;
	cvt.rni.s32.f32	%r2, %f310;
	cvt.rn.f32.s32	%f311, %r2;
	mov.f32 	%f312, 0fBFC90FDA;
	fma.rn.f32 	%f313, %f311, %f312, %f310;
	mov.f32 	%f314, 0fB3A22168;
	fma.rn.f32 	%f315, %f311, %f314, %f313;
	mov.f32 	%f316, 0fA7C234C5;
	fma.rn.f32 	%f3, %f311, %f316, %f315;
	add.s32 	%r3, %r2, 1;
	mul.rn.f32 	%f4, %f3, %f3;
	and.b32  	%r4, %r3, 1;
	setp.eq.s32	%p1, %r4, 0;
	selp.f32	%f5, %f3, 0f3F800000, %p1;
	mov.f32 	%f317, 0f00000000;
	fma.rn.f32 	%f6, %f4, %f5, %f317;
	mov.f32 	%f786, 0fB94D4153;
	@%p1 bra 	BB10_2;

	mov.f32 	%f318, 0fBAB607ED;
	mov.f32 	%f319, 0f37CBAC00;
	fma.rn.f32 	%f786, %f319, %f4, %f318;

BB10_2:
	selp.f32	%f320, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f321, %f786, %f4, %f320;
	selp.f32	%f322, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f323, %f321, %f4, %f322;
	fma.rn.f32 	%f787, %f323, %f6, %f5;
	and.b32  	%r561, %r3, 2;
	setp.eq.s32	%p3, %r561, 0;
	@%p3 bra 	BB10_4;

	mov.f32 	%f325, 0fBF800000;
	fma.rn.f32 	%f787, %f787, %f325, %f317;

BB10_4:
	and.b32  	%r5, %r2, 1;
	setp.eq.s32	%p4, %r5, 0;
	selp.f32	%f12, %f3, 0f3F800000, %p4;
	fma.rn.f32 	%f13, %f4, %f12, %f317;
	mov.f32 	%f788, 0fB94D4153;
	@%p4 bra 	BB10_6;

	mov.f32 	%f328, 0fBAB607ED;
	mov.f32 	%f329, 0f37CBAC00;
	fma.rn.f32 	%f788, %f329, %f4, %f328;

BB10_6:
	selp.f32	%f330, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f331, %f788, %f4, %f330;
	selp.f32	%f332, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f333, %f331, %f4, %f332;
	fma.rn.f32 	%f789, %f333, %f13, %f12;
	and.b32  	%r562, %r2, 2;
	setp.eq.s32	%p6, %r562, 0;
	@%p6 bra 	BB10_8;

	mov.f32 	%f335, 0fBF800000;
	fma.rn.f32 	%f789, %f789, %f335, %f317;

BB10_8:
	mul.f32 	%f336, %f789, 0f00000000;
	mul.f32 	%f337, %f2, %f787;
	sub.f32 	%f338, %f337, %f336;
	mul.f32 	%f339, %f787, 0f00000000;
	fma.rn.f32 	%f340, %f2, %f789, %f339;
	add.f32 	%f341, %f1, %f338;
	shl.b32 	%r563, %r1, 3;
	mov.u32 	%r564, _ZZ25_occa_Stockhoptimized11_0E6FRBank;
	add.s32 	%r565, %r564, %r563;
	st.shared.f32 	[%r565], %f341;
	add.f32 	%f342, %f340, 0f00000000;
	mov.u32 	%r566, _ZZ25_occa_Stockhoptimized11_0E6FIBank;
	add.s32 	%r567, %r566, %r563;
	st.shared.f32 	[%r567], %f342;
	sub.f32 	%f343, %f1, %f338;
	st.shared.f32 	[%r565+4], %f343;
	sub.f32 	%f345, %f317, %f340;
	st.shared.f32 	[%r567+4], %f345;
	bar.sync 	0;
	shl.b32 	%r568, %r1, 2;
	add.s32 	%r570, %r564, %r568;
	ld.shared.f32 	%f19, [%r570];
	add.s32 	%r572, %r566, %r568;
	ld.shared.f32 	%f20, [%r572];
	ld.shared.f32 	%f21, [%r570+4096];
	ld.shared.f32 	%f22, [%r572+4096];
	shr.u32 	%r573, %r1, 31;
	add.s32 	%r574, %r1, %r573;
	and.b32  	%r575, %r574, 8388606;
	sub.s32 	%r576, %r1, %r575;
	shl.b32 	%r577, %r576, 9;
	cvt.rn.f32.s32	%f346, %r577;
	mul.f32 	%f347, %f346, 0f3A000000;
	cvt.f64.f32	%fd1, %f347;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f23, %fd2;
	mul.f32 	%f348, %f23, 0f3F22F983;
	cvt.rni.s32.f32	%r1340, %f348;
	cvt.rn.f32.s32	%f349, %r1340;
	fma.rn.f32 	%f351, %f349, %f312, %f23;
	fma.rn.f32 	%f353, %f349, %f314, %f351;
	fma.rn.f32 	%f793, %f349, %f316, %f353;
	abs.f32 	%f25, %f23;
	setp.leu.f32	%p7, %f25, 0f47CE4780;
	mov.u32 	%r1332, %r1340;
	mov.f32 	%f790, %f793;
	@%p7 bra 	BB10_19;

	setp.eq.f32	%p8, %f25, 0f7F800000;
	@%p8 bra 	BB10_18;
	bra.uni 	BB10_10;

BB10_18:
	mul.rn.f32 	%f790, %f23, %f317;
	mov.u32 	%r1332, %r1340;
	bra.uni 	BB10_19;

BB10_10:
	mov.b32 	 %r580, %f23;
	shl.b32 	%r581, %r580, 8;
	or.b32  	%r7, %r581, -2147483648;
	add.u64 	%rd127, %SP, 0;
	add.u64 	%rd292, %SPL, 0;
	mov.u32 	%r1326, 0;
	mov.u64 	%rd291, __cudart_i2opi_f;
	mov.u32 	%r1325, -6;

BB10_11:
	.pragma "nounroll";
	ld.const.u32 	%r584, [%rd291];
	// inline asm
	{
	mad.lo.cc.u32   %r582, %r584, %r7, %r1326;
	madc.hi.u32     %r1326, %r584, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd292], %r582;
	add.s64 	%rd292, %rd292, 4;
	add.s64 	%rd291, %rd291, 4;
	add.s32 	%r1325, %r1325, 1;
	setp.ne.s32	%p9, %r1325, 0;
	@%p9 bra 	BB10_11;

	bfe.u32 	%r588, %r580, 23, 8;
	add.s32 	%r589, %r588, -128;
	shr.u32 	%r590, %r589, 5;
	and.b32  	%r12, %r580, -2147483648;
	cvta.to.local.u64 	%rd129, %rd127;
	st.local.u32 	[%rd129+24], %r1326;
	bfe.u32 	%r13, %r580, 23, 5;
	mov.u32 	%r591, 6;
	sub.s32 	%r592, %r591, %r590;
	mul.wide.s32 	%rd130, %r592, 4;
	add.s64 	%rd6, %rd129, %rd130;
	ld.local.u32 	%r1328, [%rd6];
	ld.local.u32 	%r1327, [%rd6+-4];
	setp.eq.s32	%p10, %r13, 0;
	@%p10 bra 	BB10_14;

	mov.u32 	%r593, 32;
	sub.s32 	%r594, %r593, %r13;
	shr.u32 	%r595, %r1327, %r594;
	shl.b32 	%r596, %r1328, %r13;
	add.s32 	%r1328, %r595, %r596;
	ld.local.u32 	%r597, [%rd6+-8];
	shr.u32 	%r598, %r597, %r594;
	shl.b32 	%r599, %r1327, %r13;
	add.s32 	%r1327, %r598, %r599;

BB10_14:
	shr.u32 	%r600, %r1327, 30;
	shl.b32 	%r601, %r1328, 2;
	add.s32 	%r1330, %r601, %r600;
	shl.b32 	%r21, %r1327, 2;
	shr.u32 	%r602, %r1330, 31;
	shr.u32 	%r603, %r1328, 30;
	add.s32 	%r22, %r602, %r603;
	setp.eq.s32	%p11, %r602, 0;
	@%p11 bra 	BB10_15;

	not.b32 	%r604, %r1330;
	neg.s32 	%r1329, %r21;
	setp.eq.s32	%p12, %r21, 0;
	selp.u32	%r605, 1, 0, %p12;
	add.s32 	%r1330, %r605, %r604;
	xor.b32  	%r1331, %r12, -2147483648;
	bra.uni 	BB10_17;

BB10_15:
	mov.u32 	%r1329, %r21;
	mov.u32 	%r1331, %r12;

BB10_17:
	cvt.u64.u32	%rd131, %r1330;
	cvt.u64.u32	%rd132, %r1329;
	bfi.b64 	%rd133, %rd131, %rd132, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd133;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f355, %fd4;
	neg.f32 	%f356, %f355;
	setp.eq.s32	%p13, %r1331, 0;
	selp.f32	%f790, %f355, %f356, %p13;
	setp.eq.s32	%p14, %r12, 0;
	neg.s32 	%r606, %r22;
	selp.b32	%r1332, %r22, %r606, %p14;

BB10_19:
	add.s32 	%r31, %r1332, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p15, %r32, 0;
	selp.f32	%f29, %f790, 0f3F800000, %p15;
	mul.rn.f32 	%f30, %f790, %f790;
	fma.rn.f32 	%f31, %f30, %f29, %f317;
	mov.f32 	%f791, 0fB94D4153;
	@%p15 bra 	BB10_21;

	mov.f32 	%f360, 0fBAB607ED;
	mov.f32 	%f361, 0f37CBAC00;
	fma.rn.f32 	%f791, %f361, %f30, %f360;

BB10_21:
	selp.f32	%f362, 0f3C0885E4, 0f3D2AAABB, %p15;
	fma.rn.f32 	%f363, %f791, %f30, %f362;
	selp.f32	%f364, 0fBE2AAAA8, 0fBEFFFFFF, %p15;
	fma.rn.f32 	%f365, %f363, %f30, %f364;
	fma.rn.f32 	%f792, %f365, %f31, %f29;
	and.b32  	%r607, %r31, 2;
	setp.eq.s32	%p17, %r607, 0;
	@%p17 bra 	BB10_23;

	mov.f32 	%f367, 0fBF800000;
	fma.rn.f32 	%f792, %f792, %f367, %f317;

BB10_23:
	@%p7 bra 	BB10_34;

	setp.eq.f32	%p19, %f25, 0f7F800000;
	@%p19 bra 	BB10_33;
	bra.uni 	BB10_25;

BB10_33:
	mul.rn.f32 	%f793, %f23, %f317;
	bra.uni 	BB10_34;

BB10_25:
	mov.b32 	 %r33, %f23;
	shl.b32 	%r610, %r33, 8;
	or.b32  	%r34, %r610, -2147483648;
	add.u64 	%rd135, %SP, 0;
	add.u64 	%rd294, %SPL, 0;
	mov.u32 	%r1334, 0;
	mov.u64 	%rd293, __cudart_i2opi_f;
	mov.u32 	%r1333, -6;

BB10_26:
	.pragma "nounroll";
	ld.const.u32 	%r613, [%rd293];
	// inline asm
	{
	mad.lo.cc.u32   %r611, %r613, %r34, %r1334;
	madc.hi.u32     %r1334, %r613, %r34,  0;
	}
	// inline asm
	st.local.u32 	[%rd294], %r611;
	add.s64 	%rd294, %rd294, 4;
	add.s64 	%rd293, %rd293, 4;
	add.s32 	%r1333, %r1333, 1;
	setp.ne.s32	%p20, %r1333, 0;
	@%p20 bra 	BB10_26;

	bfe.u32 	%r616, %r33, 23, 8;
	add.s32 	%r617, %r616, -128;
	shr.u32 	%r618, %r617, 5;
	and.b32  	%r39, %r33, -2147483648;
	cvta.to.local.u64 	%rd137, %rd135;
	st.local.u32 	[%rd137+24], %r1334;
	bfe.u32 	%r40, %r33, 23, 5;
	mov.u32 	%r619, 6;
	sub.s32 	%r620, %r619, %r618;
	mul.wide.s32 	%rd138, %r620, 4;
	add.s64 	%rd12, %rd137, %rd138;
	ld.local.u32 	%r1336, [%rd12];
	ld.local.u32 	%r1335, [%rd12+-4];
	setp.eq.s32	%p21, %r40, 0;
	@%p21 bra 	BB10_29;

	mov.u32 	%r621, 32;
	sub.s32 	%r622, %r621, %r40;
	shr.u32 	%r623, %r1335, %r622;
	shl.b32 	%r624, %r1336, %r40;
	add.s32 	%r1336, %r623, %r624;
	ld.local.u32 	%r625, [%rd12+-8];
	shr.u32 	%r626, %r625, %r622;
	shl.b32 	%r627, %r1335, %r40;
	add.s32 	%r1335, %r626, %r627;

BB10_29:
	shr.u32 	%r628, %r1335, 30;
	shl.b32 	%r629, %r1336, 2;
	add.s32 	%r1338, %r629, %r628;
	shl.b32 	%r48, %r1335, 2;
	shr.u32 	%r630, %r1338, 31;
	shr.u32 	%r631, %r1336, 30;
	add.s32 	%r49, %r630, %r631;
	setp.eq.s32	%p22, %r630, 0;
	@%p22 bra 	BB10_30;

	not.b32 	%r632, %r1338;
	neg.s32 	%r1337, %r48;
	setp.eq.s32	%p23, %r48, 0;
	selp.u32	%r633, 1, 0, %p23;
	add.s32 	%r1338, %r633, %r632;
	xor.b32  	%r1339, %r39, -2147483648;
	bra.uni 	BB10_32;

BB10_30:
	mov.u32 	%r1337, %r48;
	mov.u32 	%r1339, %r39;

BB10_32:
	cvt.u64.u32	%rd139, %r1338;
	cvt.u64.u32	%rd140, %r1337;
	bfi.b64 	%rd141, %rd139, %rd140, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd141;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f368, %fd6;
	neg.f32 	%f369, %f368;
	setp.eq.s32	%p24, %r1339, 0;
	selp.f32	%f793, %f368, %f369, %p24;
	setp.eq.s32	%p25, %r39, 0;
	neg.s32 	%r634, %r49;
	selp.b32	%r1340, %r49, %r634, %p25;

BB10_34:
	and.b32  	%r58, %r1340, 1;
	setp.eq.s32	%p26, %r58, 0;
	selp.f32	%f40, %f793, 0f3F800000, %p26;
	mul.rn.f32 	%f41, %f793, %f793;
	fma.rn.f32 	%f42, %f41, %f40, %f317;
	mov.f32 	%f794, 0fB94D4153;
	@%p26 bra 	BB10_36;

	mov.f32 	%f373, 0fBAB607ED;
	mov.f32 	%f374, 0f37CBAC00;
	fma.rn.f32 	%f794, %f374, %f41, %f373;

BB10_36:
	selp.f32	%f375, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f376, %f794, %f41, %f375;
	selp.f32	%f377, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f378, %f376, %f41, %f377;
	fma.rn.f32 	%f795, %f378, %f42, %f40;
	and.b32  	%r635, %r1340, 2;
	setp.eq.s32	%p28, %r635, 0;
	@%p28 bra 	BB10_38;

	mov.f32 	%f380, 0fBF800000;
	fma.rn.f32 	%f795, %f795, %f380, %f317;

BB10_38:
	mul.f32 	%f381, %f22, %f795;
	mul.f32 	%f382, %f21, %f792;
	sub.f32 	%f383, %f382, %f381;
	mul.f32 	%f384, %f22, %f792;
	fma.rn.f32 	%f385, %f21, %f795, %f384;
	add.f32 	%f386, %f19, %f383;
	shl.b32 	%r636, %r1, 1;
	and.b32  	%r637, %r636, 1073741820;
	and.b32  	%r638, %r1, 1;
	add.s32 	%r639, %r637, %r638;
	shl.b32 	%r640, %r639, 2;
	mov.u32 	%r641, _ZZ25_occa_Stockhoptimized11_0E6SRBank;
	add.s32 	%r642, %r641, %r640;
	st.shared.f32 	[%r642], %f386;
	add.f32 	%f387, %f20, %f385;
	mov.u32 	%r643, _ZZ25_occa_Stockhoptimized11_0E6SIBank;
	add.s32 	%r644, %r643, %r640;
	st.shared.f32 	[%r644], %f387;
	sub.f32 	%f388, %f19, %f383;
	st.shared.f32 	[%r642+8], %f388;
	sub.f32 	%f389, %f20, %f385;
	st.shared.f32 	[%r644+8], %f389;
	bar.sync 	0;
	add.s32 	%r647, %r641, %r568;
	ld.shared.f32 	%f48, [%r647];
	add.s32 	%r649, %r643, %r568;
	ld.shared.f32 	%f49, [%r649];
	ld.shared.f32 	%f50, [%r647+4096];
	ld.shared.f32 	%f51, [%r649+4096];
	shr.s32 	%r650, %r1, 31;
	shr.u32 	%r651, %r650, 30;
	add.s32 	%r652, %r1, %r651;
	and.b32  	%r653, %r652, 16777212;
	sub.s32 	%r654, %r1, %r653;
	shl.b32 	%r655, %r654, 8;
	cvt.rn.f32.s32	%f390, %r655;
	mul.f32 	%f391, %f390, 0f3A000000;
	cvt.f64.f32	%fd7, %f391;
	mul.f64 	%fd8, %fd7, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f52, %fd8;
	mul.f32 	%f392, %f52, 0f3F22F983;
	cvt.rni.s32.f32	%r1356, %f392;
	cvt.rn.f32.s32	%f393, %r1356;
	fma.rn.f32 	%f395, %f393, %f312, %f52;
	fma.rn.f32 	%f397, %f393, %f314, %f395;
	fma.rn.f32 	%f799, %f393, %f316, %f397;
	abs.f32 	%f54, %f52;
	setp.leu.f32	%p29, %f54, 0f47CE4780;
	mov.u32 	%r1348, %r1356;
	mov.f32 	%f796, %f799;
	@%p29 bra 	BB10_49;

	setp.eq.f32	%p30, %f54, 0f7F800000;
	@%p30 bra 	BB10_48;
	bra.uni 	BB10_40;

BB10_48:
	mul.rn.f32 	%f796, %f52, %f317;
	mov.u32 	%r1348, %r1356;
	bra.uni 	BB10_49;

BB10_40:
	mov.b32 	 %r61, %f52;
	shl.b32 	%r658, %r61, 8;
	or.b32  	%r62, %r658, -2147483648;
	add.u64 	%rd143, %SP, 0;
	add.u64 	%rd296, %SPL, 0;
	mov.u32 	%r1342, 0;
	mov.u64 	%rd295, __cudart_i2opi_f;
	mov.u32 	%r1341, -6;

BB10_41:
	.pragma "nounroll";
	ld.const.u32 	%r661, [%rd295];
	// inline asm
	{
	mad.lo.cc.u32   %r659, %r661, %r62, %r1342;
	madc.hi.u32     %r1342, %r661, %r62,  0;
	}
	// inline asm
	st.local.u32 	[%rd296], %r659;
	add.s64 	%rd296, %rd296, 4;
	add.s64 	%rd295, %rd295, 4;
	add.s32 	%r1341, %r1341, 1;
	setp.ne.s32	%p31, %r1341, 0;
	@%p31 bra 	BB10_41;

	bfe.u32 	%r664, %r61, 23, 8;
	add.s32 	%r665, %r664, -128;
	shr.u32 	%r666, %r665, 5;
	and.b32  	%r67, %r61, -2147483648;
	cvta.to.local.u64 	%rd145, %rd143;
	st.local.u32 	[%rd145+24], %r1342;
	bfe.u32 	%r68, %r61, 23, 5;
	mov.u32 	%r667, 6;
	sub.s32 	%r668, %r667, %r666;
	mul.wide.s32 	%rd146, %r668, 4;
	add.s64 	%rd18, %rd145, %rd146;
	ld.local.u32 	%r1344, [%rd18];
	ld.local.u32 	%r1343, [%rd18+-4];
	setp.eq.s32	%p32, %r68, 0;
	@%p32 bra 	BB10_44;

	mov.u32 	%r669, 32;
	sub.s32 	%r670, %r669, %r68;
	shr.u32 	%r671, %r1343, %r670;
	shl.b32 	%r672, %r1344, %r68;
	add.s32 	%r1344, %r671, %r672;
	ld.local.u32 	%r673, [%rd18+-8];
	shr.u32 	%r674, %r673, %r670;
	shl.b32 	%r675, %r1343, %r68;
	add.s32 	%r1343, %r674, %r675;

BB10_44:
	shr.u32 	%r676, %r1343, 30;
	shl.b32 	%r677, %r1344, 2;
	add.s32 	%r1346, %r677, %r676;
	shl.b32 	%r76, %r1343, 2;
	shr.u32 	%r678, %r1346, 31;
	shr.u32 	%r679, %r1344, 30;
	add.s32 	%r77, %r678, %r679;
	setp.eq.s32	%p33, %r678, 0;
	@%p33 bra 	BB10_45;

	not.b32 	%r680, %r1346;
	neg.s32 	%r1345, %r76;
	setp.eq.s32	%p34, %r76, 0;
	selp.u32	%r681, 1, 0, %p34;
	add.s32 	%r1346, %r681, %r680;
	xor.b32  	%r1347, %r67, -2147483648;
	bra.uni 	BB10_47;

BB10_45:
	mov.u32 	%r1345, %r76;
	mov.u32 	%r1347, %r67;

BB10_47:
	cvt.u64.u32	%rd147, %r1346;
	cvt.u64.u32	%rd148, %r1345;
	bfi.b64 	%rd149, %rd147, %rd148, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd149;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f399, %fd10;
	neg.f32 	%f400, %f399;
	setp.eq.s32	%p35, %r1347, 0;
	selp.f32	%f796, %f399, %f400, %p35;
	setp.eq.s32	%p36, %r67, 0;
	neg.s32 	%r682, %r77;
	selp.b32	%r1348, %r77, %r682, %p36;

BB10_49:
	add.s32 	%r86, %r1348, 1;
	and.b32  	%r87, %r86, 1;
	setp.eq.s32	%p37, %r87, 0;
	selp.f32	%f58, %f796, 0f3F800000, %p37;
	mul.rn.f32 	%f59, %f796, %f796;
	fma.rn.f32 	%f60, %f59, %f58, %f317;
	mov.f32 	%f797, 0fB94D4153;
	@%p37 bra 	BB10_51;

	mov.f32 	%f404, 0fBAB607ED;
	mov.f32 	%f405, 0f37CBAC00;
	fma.rn.f32 	%f797, %f405, %f59, %f404;

BB10_51:
	selp.f32	%f406, 0f3C0885E4, 0f3D2AAABB, %p37;
	fma.rn.f32 	%f407, %f797, %f59, %f406;
	selp.f32	%f408, 0fBE2AAAA8, 0fBEFFFFFF, %p37;
	fma.rn.f32 	%f409, %f407, %f59, %f408;
	fma.rn.f32 	%f798, %f409, %f60, %f58;
	and.b32  	%r683, %r86, 2;
	setp.eq.s32	%p39, %r683, 0;
	@%p39 bra 	BB10_53;

	mov.f32 	%f411, 0fBF800000;
	fma.rn.f32 	%f798, %f798, %f411, %f317;

BB10_53:
	@%p29 bra 	BB10_64;

	setp.eq.f32	%p41, %f54, 0f7F800000;
	@%p41 bra 	BB10_63;
	bra.uni 	BB10_55;

BB10_63:
	mul.rn.f32 	%f799, %f52, %f317;
	bra.uni 	BB10_64;

BB10_55:
	mov.b32 	 %r88, %f52;
	shl.b32 	%r686, %r88, 8;
	or.b32  	%r89, %r686, -2147483648;
	add.u64 	%rd151, %SP, 0;
	add.u64 	%rd298, %SPL, 0;
	mov.u32 	%r1350, 0;
	mov.u64 	%rd297, __cudart_i2opi_f;
	mov.u32 	%r1349, -6;

BB10_56:
	.pragma "nounroll";
	ld.const.u32 	%r689, [%rd297];
	// inline asm
	{
	mad.lo.cc.u32   %r687, %r689, %r89, %r1350;
	madc.hi.u32     %r1350, %r689, %r89,  0;
	}
	// inline asm
	st.local.u32 	[%rd298], %r687;
	add.s64 	%rd298, %rd298, 4;
	add.s64 	%rd297, %rd297, 4;
	add.s32 	%r1349, %r1349, 1;
	setp.ne.s32	%p42, %r1349, 0;
	@%p42 bra 	BB10_56;

	bfe.u32 	%r692, %r88, 23, 8;
	add.s32 	%r693, %r692, -128;
	shr.u32 	%r694, %r693, 5;
	and.b32  	%r94, %r88, -2147483648;
	cvta.to.local.u64 	%rd153, %rd151;
	st.local.u32 	[%rd153+24], %r1350;
	bfe.u32 	%r95, %r88, 23, 5;
	mov.u32 	%r695, 6;
	sub.s32 	%r696, %r695, %r694;
	mul.wide.s32 	%rd154, %r696, 4;
	add.s64 	%rd24, %rd153, %rd154;
	ld.local.u32 	%r1352, [%rd24];
	ld.local.u32 	%r1351, [%rd24+-4];
	setp.eq.s32	%p43, %r95, 0;
	@%p43 bra 	BB10_59;

	mov.u32 	%r697, 32;
	sub.s32 	%r698, %r697, %r95;
	shr.u32 	%r699, %r1351, %r698;
	shl.b32 	%r700, %r1352, %r95;
	add.s32 	%r1352, %r699, %r700;
	ld.local.u32 	%r701, [%rd24+-8];
	shr.u32 	%r702, %r701, %r698;
	shl.b32 	%r703, %r1351, %r95;
	add.s32 	%r1351, %r702, %r703;

BB10_59:
	shr.u32 	%r704, %r1351, 30;
	shl.b32 	%r705, %r1352, 2;
	add.s32 	%r1354, %r705, %r704;
	shl.b32 	%r103, %r1351, 2;
	shr.u32 	%r706, %r1354, 31;
	shr.u32 	%r707, %r1352, 30;
	add.s32 	%r104, %r706, %r707;
	setp.eq.s32	%p44, %r706, 0;
	@%p44 bra 	BB10_60;

	not.b32 	%r708, %r1354;
	neg.s32 	%r1353, %r103;
	setp.eq.s32	%p45, %r103, 0;
	selp.u32	%r709, 1, 0, %p45;
	add.s32 	%r1354, %r709, %r708;
	xor.b32  	%r1355, %r94, -2147483648;
	bra.uni 	BB10_62;

BB10_60:
	mov.u32 	%r1353, %r103;
	mov.u32 	%r1355, %r94;

BB10_62:
	cvt.u64.u32	%rd155, %r1354;
	cvt.u64.u32	%rd156, %r1353;
	bfi.b64 	%rd157, %rd155, %rd156, 32, 32;
	cvt.rn.f64.s64	%fd11, %rd157;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f412, %fd12;
	neg.f32 	%f413, %f412;
	setp.eq.s32	%p46, %r1355, 0;
	selp.f32	%f799, %f412, %f413, %p46;
	setp.eq.s32	%p47, %r94, 0;
	neg.s32 	%r710, %r104;
	selp.b32	%r1356, %r104, %r710, %p47;

BB10_64:
	and.b32  	%r113, %r1356, 1;
	setp.eq.s32	%p48, %r113, 0;
	selp.f32	%f69, %f799, 0f3F800000, %p48;
	mul.rn.f32 	%f70, %f799, %f799;
	fma.rn.f32 	%f71, %f70, %f69, %f317;
	mov.f32 	%f800, 0fB94D4153;
	@%p48 bra 	BB10_66;

	mov.f32 	%f417, 0fBAB607ED;
	mov.f32 	%f418, 0f37CBAC00;
	fma.rn.f32 	%f800, %f418, %f70, %f417;

BB10_66:
	selp.f32	%f419, 0f3C0885E4, 0f3D2AAABB, %p48;
	fma.rn.f32 	%f420, %f800, %f70, %f419;
	selp.f32	%f421, 0fBE2AAAA8, 0fBEFFFFFF, %p48;
	fma.rn.f32 	%f422, %f420, %f70, %f421;
	fma.rn.f32 	%f801, %f422, %f71, %f69;
	and.b32  	%r711, %r1356, 2;
	setp.eq.s32	%p50, %r711, 0;
	@%p50 bra 	BB10_68;

	mov.f32 	%f424, 0fBF800000;
	fma.rn.f32 	%f801, %f801, %f424, %f317;

BB10_68:
	and.b32  	%r712, %r1, 3;
	and.b32  	%r714, %r636, 1073741816;
	add.s32 	%r715, %r714, %r712;
	mul.f32 	%f425, %f51, %f801;
	mul.f32 	%f426, %f50, %f798;
	sub.f32 	%f427, %f426, %f425;
	mul.f32 	%f428, %f51, %f798;
	fma.rn.f32 	%f429, %f50, %f801, %f428;
	add.f32 	%f430, %f48, %f427;
	shl.b32 	%r716, %r715, 2;
	add.s32 	%r718, %r564, %r716;
	st.shared.f32 	[%r718], %f430;
	add.f32 	%f431, %f49, %f429;
	add.s32 	%r720, %r566, %r716;
	st.shared.f32 	[%r720], %f431;
	sub.f32 	%f432, %f48, %f427;
	st.shared.f32 	[%r718+16], %f432;
	sub.f32 	%f433, %f49, %f429;
	st.shared.f32 	[%r720+16], %f433;
	bar.sync 	0;
	ld.shared.f32 	%f77, [%r570];
	ld.shared.f32 	%f78, [%r572];
	ld.shared.f32 	%f79, [%r570+4096];
	ld.shared.f32 	%f80, [%r572+4096];
	shr.u32 	%r727, %r650, 29;
	add.s32 	%r728, %r1, %r727;
	and.b32  	%r729, %r728, 33554424;
	sub.s32 	%r730, %r1, %r729;
	shl.b32 	%r731, %r730, 7;
	cvt.rn.f32.s32	%f434, %r731;
	mul.f32 	%f435, %f434, 0f3A000000;
	cvt.f64.f32	%fd13, %f435;
	mul.f64 	%fd14, %fd13, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f81, %fd14;
	mul.f32 	%f436, %f81, 0f3F22F983;
	cvt.rni.s32.f32	%r1372, %f436;
	cvt.rn.f32.s32	%f437, %r1372;
	fma.rn.f32 	%f439, %f437, %f312, %f81;
	fma.rn.f32 	%f441, %f437, %f314, %f439;
	fma.rn.f32 	%f805, %f437, %f316, %f441;
	abs.f32 	%f83, %f81;
	setp.leu.f32	%p51, %f83, 0f47CE4780;
	mov.u32 	%r1364, %r1372;
	mov.f32 	%f802, %f805;
	@%p51 bra 	BB10_79;

	setp.eq.f32	%p52, %f83, 0f7F800000;
	@%p52 bra 	BB10_78;
	bra.uni 	BB10_70;

BB10_78:
	mul.rn.f32 	%f802, %f81, %f317;
	mov.u32 	%r1364, %r1372;
	bra.uni 	BB10_79;

BB10_70:
	mov.b32 	 %r116, %f81;
	shl.b32 	%r734, %r116, 8;
	or.b32  	%r117, %r734, -2147483648;
	add.u64 	%rd159, %SP, 0;
	add.u64 	%rd300, %SPL, 0;
	mov.u32 	%r1358, 0;
	mov.u64 	%rd299, __cudart_i2opi_f;
	mov.u32 	%r1357, -6;

BB10_71:
	.pragma "nounroll";
	ld.const.u32 	%r737, [%rd299];
	// inline asm
	{
	mad.lo.cc.u32   %r735, %r737, %r117, %r1358;
	madc.hi.u32     %r1358, %r737, %r117,  0;
	}
	// inline asm
	st.local.u32 	[%rd300], %r735;
	add.s64 	%rd300, %rd300, 4;
	add.s64 	%rd299, %rd299, 4;
	add.s32 	%r1357, %r1357, 1;
	setp.ne.s32	%p53, %r1357, 0;
	@%p53 bra 	BB10_71;

	bfe.u32 	%r740, %r116, 23, 8;
	add.s32 	%r741, %r740, -128;
	shr.u32 	%r742, %r741, 5;
	and.b32  	%r122, %r116, -2147483648;
	cvta.to.local.u64 	%rd161, %rd159;
	st.local.u32 	[%rd161+24], %r1358;
	bfe.u32 	%r123, %r116, 23, 5;
	mov.u32 	%r743, 6;
	sub.s32 	%r744, %r743, %r742;
	mul.wide.s32 	%rd162, %r744, 4;
	add.s64 	%rd30, %rd161, %rd162;
	ld.local.u32 	%r1360, [%rd30];
	ld.local.u32 	%r1359, [%rd30+-4];
	setp.eq.s32	%p54, %r123, 0;
	@%p54 bra 	BB10_74;

	mov.u32 	%r745, 32;
	sub.s32 	%r746, %r745, %r123;
	shr.u32 	%r747, %r1359, %r746;
	shl.b32 	%r748, %r1360, %r123;
	add.s32 	%r1360, %r747, %r748;
	ld.local.u32 	%r749, [%rd30+-8];
	shr.u32 	%r750, %r749, %r746;
	shl.b32 	%r751, %r1359, %r123;
	add.s32 	%r1359, %r750, %r751;

BB10_74:
	shr.u32 	%r752, %r1359, 30;
	shl.b32 	%r753, %r1360, 2;
	add.s32 	%r1362, %r753, %r752;
	shl.b32 	%r131, %r1359, 2;
	shr.u32 	%r754, %r1362, 31;
	shr.u32 	%r755, %r1360, 30;
	add.s32 	%r132, %r754, %r755;
	setp.eq.s32	%p55, %r754, 0;
	@%p55 bra 	BB10_75;

	not.b32 	%r756, %r1362;
	neg.s32 	%r1361, %r131;
	setp.eq.s32	%p56, %r131, 0;
	selp.u32	%r757, 1, 0, %p56;
	add.s32 	%r1362, %r757, %r756;
	xor.b32  	%r1363, %r122, -2147483648;
	bra.uni 	BB10_77;

BB10_75:
	mov.u32 	%r1361, %r131;
	mov.u32 	%r1363, %r122;

BB10_77:
	cvt.u64.u32	%rd163, %r1362;
	cvt.u64.u32	%rd164, %r1361;
	bfi.b64 	%rd165, %rd163, %rd164, 32, 32;
	cvt.rn.f64.s64	%fd15, %rd165;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f443, %fd16;
	neg.f32 	%f444, %f443;
	setp.eq.s32	%p57, %r1363, 0;
	selp.f32	%f802, %f443, %f444, %p57;
	setp.eq.s32	%p58, %r122, 0;
	neg.s32 	%r758, %r132;
	selp.b32	%r1364, %r132, %r758, %p58;

BB10_79:
	add.s32 	%r141, %r1364, 1;
	and.b32  	%r142, %r141, 1;
	setp.eq.s32	%p59, %r142, 0;
	selp.f32	%f87, %f802, 0f3F800000, %p59;
	mul.rn.f32 	%f88, %f802, %f802;
	fma.rn.f32 	%f89, %f88, %f87, %f317;
	mov.f32 	%f803, 0fB94D4153;
	@%p59 bra 	BB10_81;

	mov.f32 	%f448, 0fBAB607ED;
	mov.f32 	%f449, 0f37CBAC00;
	fma.rn.f32 	%f803, %f449, %f88, %f448;

BB10_81:
	selp.f32	%f450, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f451, %f803, %f88, %f450;
	selp.f32	%f452, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f453, %f451, %f88, %f452;
	fma.rn.f32 	%f804, %f453, %f89, %f87;
	and.b32  	%r759, %r141, 2;
	setp.eq.s32	%p61, %r759, 0;
	@%p61 bra 	BB10_83;

	mov.f32 	%f455, 0fBF800000;
	fma.rn.f32 	%f804, %f804, %f455, %f317;

BB10_83:
	@%p51 bra 	BB10_94;

	setp.eq.f32	%p63, %f83, 0f7F800000;
	@%p63 bra 	BB10_93;
	bra.uni 	BB10_85;

BB10_93:
	mul.rn.f32 	%f805, %f81, %f317;
	bra.uni 	BB10_94;

BB10_85:
	mov.b32 	 %r143, %f81;
	shl.b32 	%r762, %r143, 8;
	or.b32  	%r144, %r762, -2147483648;
	add.u64 	%rd167, %SP, 0;
	add.u64 	%rd302, %SPL, 0;
	mov.u32 	%r1366, 0;
	mov.u64 	%rd301, __cudart_i2opi_f;
	mov.u32 	%r1365, -6;

BB10_86:
	.pragma "nounroll";
	ld.const.u32 	%r765, [%rd301];
	// inline asm
	{
	mad.lo.cc.u32   %r763, %r765, %r144, %r1366;
	madc.hi.u32     %r1366, %r765, %r144,  0;
	}
	// inline asm
	st.local.u32 	[%rd302], %r763;
	add.s64 	%rd302, %rd302, 4;
	add.s64 	%rd301, %rd301, 4;
	add.s32 	%r1365, %r1365, 1;
	setp.ne.s32	%p64, %r1365, 0;
	@%p64 bra 	BB10_86;

	bfe.u32 	%r768, %r143, 23, 8;
	add.s32 	%r769, %r768, -128;
	shr.u32 	%r770, %r769, 5;
	and.b32  	%r149, %r143, -2147483648;
	cvta.to.local.u64 	%rd169, %rd167;
	st.local.u32 	[%rd169+24], %r1366;
	bfe.u32 	%r150, %r143, 23, 5;
	mov.u32 	%r771, 6;
	sub.s32 	%r772, %r771, %r770;
	mul.wide.s32 	%rd170, %r772, 4;
	add.s64 	%rd36, %rd169, %rd170;
	ld.local.u32 	%r1368, [%rd36];
	ld.local.u32 	%r1367, [%rd36+-4];
	setp.eq.s32	%p65, %r150, 0;
	@%p65 bra 	BB10_89;

	mov.u32 	%r773, 32;
	sub.s32 	%r774, %r773, %r150;
	shr.u32 	%r775, %r1367, %r774;
	shl.b32 	%r776, %r1368, %r150;
	add.s32 	%r1368, %r775, %r776;
	ld.local.u32 	%r777, [%rd36+-8];
	shr.u32 	%r778, %r777, %r774;
	shl.b32 	%r779, %r1367, %r150;
	add.s32 	%r1367, %r778, %r779;

BB10_89:
	shr.u32 	%r780, %r1367, 30;
	shl.b32 	%r781, %r1368, 2;
	add.s32 	%r1370, %r781, %r780;
	shl.b32 	%r158, %r1367, 2;
	shr.u32 	%r782, %r1370, 31;
	shr.u32 	%r783, %r1368, 30;
	add.s32 	%r159, %r782, %r783;
	setp.eq.s32	%p66, %r782, 0;
	@%p66 bra 	BB10_90;

	not.b32 	%r784, %r1370;
	neg.s32 	%r1369, %r158;
	setp.eq.s32	%p67, %r158, 0;
	selp.u32	%r785, 1, 0, %p67;
	add.s32 	%r1370, %r785, %r784;
	xor.b32  	%r1371, %r149, -2147483648;
	bra.uni 	BB10_92;

BB10_90:
	mov.u32 	%r1369, %r158;
	mov.u32 	%r1371, %r149;

BB10_92:
	cvt.u64.u32	%rd171, %r1370;
	cvt.u64.u32	%rd172, %r1369;
	bfi.b64 	%rd173, %rd171, %rd172, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd173;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f456, %fd18;
	neg.f32 	%f457, %f456;
	setp.eq.s32	%p68, %r1371, 0;
	selp.f32	%f805, %f456, %f457, %p68;
	setp.eq.s32	%p69, %r149, 0;
	neg.s32 	%r786, %r159;
	selp.b32	%r1372, %r159, %r786, %p69;

BB10_94:
	and.b32  	%r168, %r1372, 1;
	setp.eq.s32	%p70, %r168, 0;
	selp.f32	%f98, %f805, 0f3F800000, %p70;
	mul.rn.f32 	%f99, %f805, %f805;
	fma.rn.f32 	%f100, %f99, %f98, %f317;
	mov.f32 	%f806, 0fB94D4153;
	@%p70 bra 	BB10_96;

	mov.f32 	%f461, 0fBAB607ED;
	mov.f32 	%f462, 0f37CBAC00;
	fma.rn.f32 	%f806, %f462, %f99, %f461;

BB10_96:
	selp.f32	%f463, 0f3C0885E4, 0f3D2AAABB, %p70;
	fma.rn.f32 	%f464, %f806, %f99, %f463;
	selp.f32	%f465, 0fBE2AAAA8, 0fBEFFFFFF, %p70;
	fma.rn.f32 	%f466, %f464, %f99, %f465;
	fma.rn.f32 	%f807, %f466, %f100, %f98;
	and.b32  	%r787, %r1372, 2;
	setp.eq.s32	%p72, %r787, 0;
	@%p72 bra 	BB10_98;

	mov.f32 	%f468, 0fBF800000;
	fma.rn.f32 	%f807, %f807, %f468, %f317;

BB10_98:
	and.b32  	%r788, %r1, 7;
	and.b32  	%r790, %r636, 1073741808;
	add.s32 	%r791, %r790, %r788;
	mul.f32 	%f469, %f80, %f807;
	mul.f32 	%f470, %f79, %f804;
	sub.f32 	%f471, %f470, %f469;
	mul.f32 	%f472, %f80, %f804;
	fma.rn.f32 	%f473, %f79, %f807, %f472;
	add.f32 	%f474, %f77, %f471;
	shl.b32 	%r792, %r791, 2;
	add.s32 	%r794, %r641, %r792;
	st.shared.f32 	[%r794], %f474;
	add.f32 	%f475, %f78, %f473;
	add.s32 	%r796, %r643, %r792;
	st.shared.f32 	[%r796], %f475;
	sub.f32 	%f476, %f77, %f471;
	st.shared.f32 	[%r794+32], %f476;
	sub.f32 	%f477, %f78, %f473;
	st.shared.f32 	[%r796+32], %f477;
	bar.sync 	0;
	ld.shared.f32 	%f106, [%r647];
	ld.shared.f32 	%f107, [%r649];
	ld.shared.f32 	%f108, [%r647+4096];
	ld.shared.f32 	%f109, [%r649+4096];
	shr.u32 	%r803, %r650, 28;
	add.s32 	%r804, %r1, %r803;
	and.b32  	%r805, %r804, 67108848;
	sub.s32 	%r806, %r1, %r805;
	shl.b32 	%r807, %r806, 6;
	cvt.rn.f32.s32	%f478, %r807;
	mul.f32 	%f479, %f478, 0f3A000000;
	cvt.f64.f32	%fd19, %f479;
	mul.f64 	%fd20, %fd19, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f110, %fd20;
	mul.f32 	%f480, %f110, 0f3F22F983;
	cvt.rni.s32.f32	%r1388, %f480;
	cvt.rn.f32.s32	%f481, %r1388;
	fma.rn.f32 	%f483, %f481, %f312, %f110;
	fma.rn.f32 	%f485, %f481, %f314, %f483;
	fma.rn.f32 	%f811, %f481, %f316, %f485;
	abs.f32 	%f112, %f110;
	setp.leu.f32	%p73, %f112, 0f47CE4780;
	mov.u32 	%r1380, %r1388;
	mov.f32 	%f808, %f811;
	@%p73 bra 	BB10_109;

	setp.eq.f32	%p74, %f112, 0f7F800000;
	@%p74 bra 	BB10_108;
	bra.uni 	BB10_100;

BB10_108:
	mul.rn.f32 	%f808, %f110, %f317;
	mov.u32 	%r1380, %r1388;
	bra.uni 	BB10_109;

BB10_100:
	mov.b32 	 %r171, %f110;
	shl.b32 	%r810, %r171, 8;
	or.b32  	%r172, %r810, -2147483648;
	add.u64 	%rd175, %SP, 0;
	add.u64 	%rd304, %SPL, 0;
	mov.u32 	%r1374, 0;
	mov.u64 	%rd303, __cudart_i2opi_f;
	mov.u32 	%r1373, -6;

BB10_101:
	.pragma "nounroll";
	ld.const.u32 	%r813, [%rd303];
	// inline asm
	{
	mad.lo.cc.u32   %r811, %r813, %r172, %r1374;
	madc.hi.u32     %r1374, %r813, %r172,  0;
	}
	// inline asm
	st.local.u32 	[%rd304], %r811;
	add.s64 	%rd304, %rd304, 4;
	add.s64 	%rd303, %rd303, 4;
	add.s32 	%r1373, %r1373, 1;
	setp.ne.s32	%p75, %r1373, 0;
	@%p75 bra 	BB10_101;

	bfe.u32 	%r816, %r171, 23, 8;
	add.s32 	%r817, %r816, -128;
	shr.u32 	%r818, %r817, 5;
	and.b32  	%r177, %r171, -2147483648;
	cvta.to.local.u64 	%rd177, %rd175;
	st.local.u32 	[%rd177+24], %r1374;
	bfe.u32 	%r178, %r171, 23, 5;
	mov.u32 	%r819, 6;
	sub.s32 	%r820, %r819, %r818;
	mul.wide.s32 	%rd178, %r820, 4;
	add.s64 	%rd42, %rd177, %rd178;
	ld.local.u32 	%r1376, [%rd42];
	ld.local.u32 	%r1375, [%rd42+-4];
	setp.eq.s32	%p76, %r178, 0;
	@%p76 bra 	BB10_104;

	mov.u32 	%r821, 32;
	sub.s32 	%r822, %r821, %r178;
	shr.u32 	%r823, %r1375, %r822;
	shl.b32 	%r824, %r1376, %r178;
	add.s32 	%r1376, %r823, %r824;
	ld.local.u32 	%r825, [%rd42+-8];
	shr.u32 	%r826, %r825, %r822;
	shl.b32 	%r827, %r1375, %r178;
	add.s32 	%r1375, %r826, %r827;

BB10_104:
	shr.u32 	%r828, %r1375, 30;
	shl.b32 	%r829, %r1376, 2;
	add.s32 	%r1378, %r829, %r828;
	shl.b32 	%r186, %r1375, 2;
	shr.u32 	%r830, %r1378, 31;
	shr.u32 	%r831, %r1376, 30;
	add.s32 	%r187, %r830, %r831;
	setp.eq.s32	%p77, %r830, 0;
	@%p77 bra 	BB10_105;

	not.b32 	%r832, %r1378;
	neg.s32 	%r1377, %r186;
	setp.eq.s32	%p78, %r186, 0;
	selp.u32	%r833, 1, 0, %p78;
	add.s32 	%r1378, %r833, %r832;
	xor.b32  	%r1379, %r177, -2147483648;
	bra.uni 	BB10_107;

BB10_105:
	mov.u32 	%r1377, %r186;
	mov.u32 	%r1379, %r177;

BB10_107:
	cvt.u64.u32	%rd179, %r1378;
	cvt.u64.u32	%rd180, %r1377;
	bfi.b64 	%rd181, %rd179, %rd180, 32, 32;
	cvt.rn.f64.s64	%fd21, %rd181;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f487, %fd22;
	neg.f32 	%f488, %f487;
	setp.eq.s32	%p79, %r1379, 0;
	selp.f32	%f808, %f487, %f488, %p79;
	setp.eq.s32	%p80, %r177, 0;
	neg.s32 	%r834, %r187;
	selp.b32	%r1380, %r187, %r834, %p80;

BB10_109:
	add.s32 	%r196, %r1380, 1;
	and.b32  	%r197, %r196, 1;
	setp.eq.s32	%p81, %r197, 0;
	selp.f32	%f116, %f808, 0f3F800000, %p81;
	mul.rn.f32 	%f117, %f808, %f808;
	fma.rn.f32 	%f118, %f117, %f116, %f317;
	mov.f32 	%f809, 0fB94D4153;
	@%p81 bra 	BB10_111;

	mov.f32 	%f492, 0fBAB607ED;
	mov.f32 	%f493, 0f37CBAC00;
	fma.rn.f32 	%f809, %f493, %f117, %f492;

BB10_111:
	selp.f32	%f494, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f495, %f809, %f117, %f494;
	selp.f32	%f496, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f497, %f495, %f117, %f496;
	fma.rn.f32 	%f810, %f497, %f118, %f116;
	and.b32  	%r835, %r196, 2;
	setp.eq.s32	%p83, %r835, 0;
	@%p83 bra 	BB10_113;

	mov.f32 	%f499, 0fBF800000;
	fma.rn.f32 	%f810, %f810, %f499, %f317;

BB10_113:
	@%p73 bra 	BB10_124;

	setp.eq.f32	%p85, %f112, 0f7F800000;
	@%p85 bra 	BB10_123;
	bra.uni 	BB10_115;

BB10_123:
	mul.rn.f32 	%f811, %f110, %f317;
	bra.uni 	BB10_124;

BB10_115:
	mov.b32 	 %r198, %f110;
	shl.b32 	%r838, %r198, 8;
	or.b32  	%r199, %r838, -2147483648;
	add.u64 	%rd183, %SP, 0;
	add.u64 	%rd306, %SPL, 0;
	mov.u32 	%r1382, 0;
	mov.u64 	%rd305, __cudart_i2opi_f;
	mov.u32 	%r1381, -6;

BB10_116:
	.pragma "nounroll";
	ld.const.u32 	%r841, [%rd305];
	// inline asm
	{
	mad.lo.cc.u32   %r839, %r841, %r199, %r1382;
	madc.hi.u32     %r1382, %r841, %r199,  0;
	}
	// inline asm
	st.local.u32 	[%rd306], %r839;
	add.s64 	%rd306, %rd306, 4;
	add.s64 	%rd305, %rd305, 4;
	add.s32 	%r1381, %r1381, 1;
	setp.ne.s32	%p86, %r1381, 0;
	@%p86 bra 	BB10_116;

	bfe.u32 	%r844, %r198, 23, 8;
	add.s32 	%r845, %r844, -128;
	shr.u32 	%r846, %r845, 5;
	and.b32  	%r204, %r198, -2147483648;
	cvta.to.local.u64 	%rd185, %rd183;
	st.local.u32 	[%rd185+24], %r1382;
	bfe.u32 	%r205, %r198, 23, 5;
	mov.u32 	%r847, 6;
	sub.s32 	%r848, %r847, %r846;
	mul.wide.s32 	%rd186, %r848, 4;
	add.s64 	%rd48, %rd185, %rd186;
	ld.local.u32 	%r1384, [%rd48];
	ld.local.u32 	%r1383, [%rd48+-4];
	setp.eq.s32	%p87, %r205, 0;
	@%p87 bra 	BB10_119;

	mov.u32 	%r849, 32;
	sub.s32 	%r850, %r849, %r205;
	shr.u32 	%r851, %r1383, %r850;
	shl.b32 	%r852, %r1384, %r205;
	add.s32 	%r1384, %r851, %r852;
	ld.local.u32 	%r853, [%rd48+-8];
	shr.u32 	%r854, %r853, %r850;
	shl.b32 	%r855, %r1383, %r205;
	add.s32 	%r1383, %r854, %r855;

BB10_119:
	shr.u32 	%r856, %r1383, 30;
	shl.b32 	%r857, %r1384, 2;
	add.s32 	%r1386, %r857, %r856;
	shl.b32 	%r213, %r1383, 2;
	shr.u32 	%r858, %r1386, 31;
	shr.u32 	%r859, %r1384, 30;
	add.s32 	%r214, %r858, %r859;
	setp.eq.s32	%p88, %r858, 0;
	@%p88 bra 	BB10_120;

	not.b32 	%r860, %r1386;
	neg.s32 	%r1385, %r213;
	setp.eq.s32	%p89, %r213, 0;
	selp.u32	%r861, 1, 0, %p89;
	add.s32 	%r1386, %r861, %r860;
	xor.b32  	%r1387, %r204, -2147483648;
	bra.uni 	BB10_122;

BB10_120:
	mov.u32 	%r1385, %r213;
	mov.u32 	%r1387, %r204;

BB10_122:
	cvt.u64.u32	%rd187, %r1386;
	cvt.u64.u32	%rd188, %r1385;
	bfi.b64 	%rd189, %rd187, %rd188, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd189;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f500, %fd24;
	neg.f32 	%f501, %f500;
	setp.eq.s32	%p90, %r1387, 0;
	selp.f32	%f811, %f500, %f501, %p90;
	setp.eq.s32	%p91, %r204, 0;
	neg.s32 	%r862, %r214;
	selp.b32	%r1388, %r214, %r862, %p91;

BB10_124:
	and.b32  	%r223, %r1388, 1;
	setp.eq.s32	%p92, %r223, 0;
	selp.f32	%f127, %f811, 0f3F800000, %p92;
	mul.rn.f32 	%f128, %f811, %f811;
	fma.rn.f32 	%f129, %f128, %f127, %f317;
	mov.f32 	%f812, 0fB94D4153;
	@%p92 bra 	BB10_126;

	mov.f32 	%f505, 0fBAB607ED;
	mov.f32 	%f506, 0f37CBAC00;
	fma.rn.f32 	%f812, %f506, %f128, %f505;

BB10_126:
	selp.f32	%f507, 0f3C0885E4, 0f3D2AAABB, %p92;
	fma.rn.f32 	%f508, %f812, %f128, %f507;
	selp.f32	%f509, 0fBE2AAAA8, 0fBEFFFFFF, %p92;
	fma.rn.f32 	%f510, %f508, %f128, %f509;
	fma.rn.f32 	%f813, %f510, %f129, %f127;
	and.b32  	%r863, %r1388, 2;
	setp.eq.s32	%p94, %r863, 0;
	@%p94 bra 	BB10_128;

	mov.f32 	%f512, 0fBF800000;
	fma.rn.f32 	%f813, %f813, %f512, %f317;

BB10_128:
	and.b32  	%r864, %r1, 15;
	and.b32  	%r866, %r636, 1073741792;
	add.s32 	%r867, %r866, %r864;
	mul.f32 	%f513, %f109, %f813;
	mul.f32 	%f514, %f108, %f810;
	sub.f32 	%f515, %f514, %f513;
	mul.f32 	%f516, %f109, %f810;
	fma.rn.f32 	%f517, %f108, %f813, %f516;
	add.f32 	%f518, %f106, %f515;
	shl.b32 	%r868, %r867, 2;
	add.s32 	%r870, %r564, %r868;
	st.shared.f32 	[%r870], %f518;
	add.f32 	%f519, %f107, %f517;
	add.s32 	%r872, %r566, %r868;
	st.shared.f32 	[%r872], %f519;
	sub.f32 	%f520, %f106, %f515;
	st.shared.f32 	[%r870+64], %f520;
	sub.f32 	%f521, %f107, %f517;
	st.shared.f32 	[%r872+64], %f521;
	bar.sync 	0;
	ld.shared.f32 	%f135, [%r570];
	ld.shared.f32 	%f136, [%r572];
	ld.shared.f32 	%f137, [%r570+4096];
	ld.shared.f32 	%f138, [%r572+4096];
	shr.u32 	%r879, %r650, 27;
	add.s32 	%r880, %r1, %r879;
	and.b32  	%r881, %r880, 134217696;
	sub.s32 	%r882, %r1, %r881;
	shl.b32 	%r883, %r882, 5;
	cvt.rn.f32.s32	%f522, %r883;
	mul.f32 	%f523, %f522, 0f3A000000;
	cvt.f64.f32	%fd25, %f523;
	mul.f64 	%fd26, %fd25, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f139, %fd26;
	mul.f32 	%f524, %f139, 0f3F22F983;
	cvt.rni.s32.f32	%r1404, %f524;
	cvt.rn.f32.s32	%f525, %r1404;
	fma.rn.f32 	%f527, %f525, %f312, %f139;
	fma.rn.f32 	%f529, %f525, %f314, %f527;
	fma.rn.f32 	%f817, %f525, %f316, %f529;
	abs.f32 	%f141, %f139;
	setp.leu.f32	%p95, %f141, 0f47CE4780;
	mov.u32 	%r1396, %r1404;
	mov.f32 	%f814, %f817;
	@%p95 bra 	BB10_139;

	setp.eq.f32	%p96, %f141, 0f7F800000;
	@%p96 bra 	BB10_138;
	bra.uni 	BB10_130;

BB10_138:
	mul.rn.f32 	%f814, %f139, %f317;
	mov.u32 	%r1396, %r1404;
	bra.uni 	BB10_139;

BB10_130:
	mov.b32 	 %r226, %f139;
	shl.b32 	%r886, %r226, 8;
	or.b32  	%r227, %r886, -2147483648;
	add.u64 	%rd191, %SP, 0;
	add.u64 	%rd308, %SPL, 0;
	mov.u32 	%r1390, 0;
	mov.u64 	%rd307, __cudart_i2opi_f;
	mov.u32 	%r1389, -6;

BB10_131:
	.pragma "nounroll";
	ld.const.u32 	%r889, [%rd307];
	// inline asm
	{
	mad.lo.cc.u32   %r887, %r889, %r227, %r1390;
	madc.hi.u32     %r1390, %r889, %r227,  0;
	}
	// inline asm
	st.local.u32 	[%rd308], %r887;
	add.s64 	%rd308, %rd308, 4;
	add.s64 	%rd307, %rd307, 4;
	add.s32 	%r1389, %r1389, 1;
	setp.ne.s32	%p97, %r1389, 0;
	@%p97 bra 	BB10_131;

	bfe.u32 	%r892, %r226, 23, 8;
	add.s32 	%r893, %r892, -128;
	shr.u32 	%r894, %r893, 5;
	and.b32  	%r232, %r226, -2147483648;
	cvta.to.local.u64 	%rd193, %rd191;
	st.local.u32 	[%rd193+24], %r1390;
	bfe.u32 	%r233, %r226, 23, 5;
	mov.u32 	%r895, 6;
	sub.s32 	%r896, %r895, %r894;
	mul.wide.s32 	%rd194, %r896, 4;
	add.s64 	%rd54, %rd193, %rd194;
	ld.local.u32 	%r1392, [%rd54];
	ld.local.u32 	%r1391, [%rd54+-4];
	setp.eq.s32	%p98, %r233, 0;
	@%p98 bra 	BB10_134;

	mov.u32 	%r897, 32;
	sub.s32 	%r898, %r897, %r233;
	shr.u32 	%r899, %r1391, %r898;
	shl.b32 	%r900, %r1392, %r233;
	add.s32 	%r1392, %r899, %r900;
	ld.local.u32 	%r901, [%rd54+-8];
	shr.u32 	%r902, %r901, %r898;
	shl.b32 	%r903, %r1391, %r233;
	add.s32 	%r1391, %r902, %r903;

BB10_134:
	shr.u32 	%r904, %r1391, 30;
	shl.b32 	%r905, %r1392, 2;
	add.s32 	%r1394, %r905, %r904;
	shl.b32 	%r241, %r1391, 2;
	shr.u32 	%r906, %r1394, 31;
	shr.u32 	%r907, %r1392, 30;
	add.s32 	%r242, %r906, %r907;
	setp.eq.s32	%p99, %r906, 0;
	@%p99 bra 	BB10_135;

	not.b32 	%r908, %r1394;
	neg.s32 	%r1393, %r241;
	setp.eq.s32	%p100, %r241, 0;
	selp.u32	%r909, 1, 0, %p100;
	add.s32 	%r1394, %r909, %r908;
	xor.b32  	%r1395, %r232, -2147483648;
	bra.uni 	BB10_137;

BB10_135:
	mov.u32 	%r1393, %r241;
	mov.u32 	%r1395, %r232;

BB10_137:
	cvt.u64.u32	%rd195, %r1394;
	cvt.u64.u32	%rd196, %r1393;
	bfi.b64 	%rd197, %rd195, %rd196, 32, 32;
	cvt.rn.f64.s64	%fd27, %rd197;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f531, %fd28;
	neg.f32 	%f532, %f531;
	setp.eq.s32	%p101, %r1395, 0;
	selp.f32	%f814, %f531, %f532, %p101;
	setp.eq.s32	%p102, %r232, 0;
	neg.s32 	%r910, %r242;
	selp.b32	%r1396, %r242, %r910, %p102;

BB10_139:
	add.s32 	%r251, %r1396, 1;
	and.b32  	%r252, %r251, 1;
	setp.eq.s32	%p103, %r252, 0;
	selp.f32	%f145, %f814, 0f3F800000, %p103;
	mul.rn.f32 	%f146, %f814, %f814;
	fma.rn.f32 	%f147, %f146, %f145, %f317;
	mov.f32 	%f815, 0fB94D4153;
	@%p103 bra 	BB10_141;

	mov.f32 	%f536, 0fBAB607ED;
	mov.f32 	%f537, 0f37CBAC00;
	fma.rn.f32 	%f815, %f537, %f146, %f536;

BB10_141:
	selp.f32	%f538, 0f3C0885E4, 0f3D2AAABB, %p103;
	fma.rn.f32 	%f539, %f815, %f146, %f538;
	selp.f32	%f540, 0fBE2AAAA8, 0fBEFFFFFF, %p103;
	fma.rn.f32 	%f541, %f539, %f146, %f540;
	fma.rn.f32 	%f816, %f541, %f147, %f145;
	and.b32  	%r911, %r251, 2;
	setp.eq.s32	%p105, %r911, 0;
	@%p105 bra 	BB10_143;

	mov.f32 	%f543, 0fBF800000;
	fma.rn.f32 	%f816, %f816, %f543, %f317;

BB10_143:
	@%p95 bra 	BB10_154;

	setp.eq.f32	%p107, %f141, 0f7F800000;
	@%p107 bra 	BB10_153;
	bra.uni 	BB10_145;

BB10_153:
	mul.rn.f32 	%f817, %f139, %f317;
	bra.uni 	BB10_154;

BB10_145:
	mov.b32 	 %r253, %f139;
	shl.b32 	%r914, %r253, 8;
	or.b32  	%r254, %r914, -2147483648;
	add.u64 	%rd199, %SP, 0;
	add.u64 	%rd310, %SPL, 0;
	mov.u32 	%r1398, 0;
	mov.u64 	%rd309, __cudart_i2opi_f;
	mov.u32 	%r1397, -6;

BB10_146:
	.pragma "nounroll";
	ld.const.u32 	%r917, [%rd309];
	// inline asm
	{
	mad.lo.cc.u32   %r915, %r917, %r254, %r1398;
	madc.hi.u32     %r1398, %r917, %r254,  0;
	}
	// inline asm
	st.local.u32 	[%rd310], %r915;
	add.s64 	%rd310, %rd310, 4;
	add.s64 	%rd309, %rd309, 4;
	add.s32 	%r1397, %r1397, 1;
	setp.ne.s32	%p108, %r1397, 0;
	@%p108 bra 	BB10_146;

	bfe.u32 	%r920, %r253, 23, 8;
	add.s32 	%r921, %r920, -128;
	shr.u32 	%r922, %r921, 5;
	and.b32  	%r259, %r253, -2147483648;
	cvta.to.local.u64 	%rd201, %rd199;
	st.local.u32 	[%rd201+24], %r1398;
	bfe.u32 	%r260, %r253, 23, 5;
	mov.u32 	%r923, 6;
	sub.s32 	%r924, %r923, %r922;
	mul.wide.s32 	%rd202, %r924, 4;
	add.s64 	%rd60, %rd201, %rd202;
	ld.local.u32 	%r1400, [%rd60];
	ld.local.u32 	%r1399, [%rd60+-4];
	setp.eq.s32	%p109, %r260, 0;
	@%p109 bra 	BB10_149;

	mov.u32 	%r925, 32;
	sub.s32 	%r926, %r925, %r260;
	shr.u32 	%r927, %r1399, %r926;
	shl.b32 	%r928, %r1400, %r260;
	add.s32 	%r1400, %r927, %r928;
	ld.local.u32 	%r929, [%rd60+-8];
	shr.u32 	%r930, %r929, %r926;
	shl.b32 	%r931, %r1399, %r260;
	add.s32 	%r1399, %r930, %r931;

BB10_149:
	shr.u32 	%r932, %r1399, 30;
	shl.b32 	%r933, %r1400, 2;
	add.s32 	%r1402, %r933, %r932;
	shl.b32 	%r268, %r1399, 2;
	shr.u32 	%r934, %r1402, 31;
	shr.u32 	%r935, %r1400, 30;
	add.s32 	%r269, %r934, %r935;
	setp.eq.s32	%p110, %r934, 0;
	@%p110 bra 	BB10_150;

	not.b32 	%r936, %r1402;
	neg.s32 	%r1401, %r268;
	setp.eq.s32	%p111, %r268, 0;
	selp.u32	%r937, 1, 0, %p111;
	add.s32 	%r1402, %r937, %r936;
	xor.b32  	%r1403, %r259, -2147483648;
	bra.uni 	BB10_152;

BB10_150:
	mov.u32 	%r1401, %r268;
	mov.u32 	%r1403, %r259;

BB10_152:
	cvt.u64.u32	%rd203, %r1402;
	cvt.u64.u32	%rd204, %r1401;
	bfi.b64 	%rd205, %rd203, %rd204, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd205;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f544, %fd30;
	neg.f32 	%f545, %f544;
	setp.eq.s32	%p112, %r1403, 0;
	selp.f32	%f817, %f544, %f545, %p112;
	setp.eq.s32	%p113, %r259, 0;
	neg.s32 	%r938, %r269;
	selp.b32	%r1404, %r269, %r938, %p113;

BB10_154:
	and.b32  	%r278, %r1404, 1;
	setp.eq.s32	%p114, %r278, 0;
	selp.f32	%f156, %f817, 0f3F800000, %p114;
	mul.rn.f32 	%f157, %f817, %f817;
	fma.rn.f32 	%f158, %f157, %f156, %f317;
	mov.f32 	%f818, 0fB94D4153;
	@%p114 bra 	BB10_156;

	mov.f32 	%f549, 0fBAB607ED;
	mov.f32 	%f550, 0f37CBAC00;
	fma.rn.f32 	%f818, %f550, %f157, %f549;

BB10_156:
	selp.f32	%f551, 0f3C0885E4, 0f3D2AAABB, %p114;
	fma.rn.f32 	%f552, %f818, %f157, %f551;
	selp.f32	%f553, 0fBE2AAAA8, 0fBEFFFFFF, %p114;
	fma.rn.f32 	%f554, %f552, %f157, %f553;
	fma.rn.f32 	%f819, %f554, %f158, %f156;
	and.b32  	%r939, %r1404, 2;
	setp.eq.s32	%p116, %r939, 0;
	@%p116 bra 	BB10_158;

	mov.f32 	%f556, 0fBF800000;
	fma.rn.f32 	%f819, %f819, %f556, %f317;

BB10_158:
	and.b32  	%r940, %r1, 31;
	and.b32  	%r942, %r636, 1073741760;
	add.s32 	%r943, %r942, %r940;
	mul.f32 	%f557, %f138, %f819;
	mul.f32 	%f558, %f137, %f816;
	sub.f32 	%f559, %f558, %f557;
	mul.f32 	%f560, %f138, %f816;
	fma.rn.f32 	%f561, %f137, %f819, %f560;
	add.f32 	%f562, %f135, %f559;
	shl.b32 	%r944, %r943, 2;
	add.s32 	%r946, %r641, %r944;
	st.shared.f32 	[%r946], %f562;
	add.f32 	%f563, %f136, %f561;
	add.s32 	%r948, %r643, %r944;
	st.shared.f32 	[%r948], %f563;
	sub.f32 	%f564, %f135, %f559;
	st.shared.f32 	[%r946+128], %f564;
	sub.f32 	%f565, %f136, %f561;
	st.shared.f32 	[%r948+128], %f565;
	bar.sync 	0;
	ld.shared.f32 	%f164, [%r647];
	ld.shared.f32 	%f165, [%r649];
	ld.shared.f32 	%f166, [%r647+4096];
	ld.shared.f32 	%f167, [%r649+4096];
	shr.u32 	%r955, %r650, 26;
	add.s32 	%r956, %r1, %r955;
	and.b32  	%r957, %r956, 268435392;
	sub.s32 	%r958, %r1, %r957;
	shl.b32 	%r959, %r958, 4;
	cvt.rn.f32.s32	%f566, %r959;
	mul.f32 	%f567, %f566, 0f3A000000;
	cvt.f64.f32	%fd31, %f567;
	mul.f64 	%fd32, %fd31, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f168, %fd32;
	mul.f32 	%f568, %f168, 0f3F22F983;
	cvt.rni.s32.f32	%r1420, %f568;
	cvt.rn.f32.s32	%f569, %r1420;
	fma.rn.f32 	%f571, %f569, %f312, %f168;
	fma.rn.f32 	%f573, %f569, %f314, %f571;
	fma.rn.f32 	%f823, %f569, %f316, %f573;
	abs.f32 	%f170, %f168;
	setp.leu.f32	%p117, %f170, 0f47CE4780;
	mov.u32 	%r1412, %r1420;
	mov.f32 	%f820, %f823;
	@%p117 bra 	BB10_169;

	setp.eq.f32	%p118, %f170, 0f7F800000;
	@%p118 bra 	BB10_168;
	bra.uni 	BB10_160;

BB10_168:
	mul.rn.f32 	%f820, %f168, %f317;
	mov.u32 	%r1412, %r1420;
	bra.uni 	BB10_169;

BB10_160:
	mov.b32 	 %r281, %f168;
	shl.b32 	%r962, %r281, 8;
	or.b32  	%r282, %r962, -2147483648;
	add.u64 	%rd207, %SP, 0;
	add.u64 	%rd312, %SPL, 0;
	mov.u32 	%r1406, 0;
	mov.u64 	%rd311, __cudart_i2opi_f;
	mov.u32 	%r1405, -6;

BB10_161:
	.pragma "nounroll";
	ld.const.u32 	%r965, [%rd311];
	// inline asm
	{
	mad.lo.cc.u32   %r963, %r965, %r282, %r1406;
	madc.hi.u32     %r1406, %r965, %r282,  0;
	}
	// inline asm
	st.local.u32 	[%rd312], %r963;
	add.s64 	%rd312, %rd312, 4;
	add.s64 	%rd311, %rd311, 4;
	add.s32 	%r1405, %r1405, 1;
	setp.ne.s32	%p119, %r1405, 0;
	@%p119 bra 	BB10_161;

	bfe.u32 	%r968, %r281, 23, 8;
	add.s32 	%r969, %r968, -128;
	shr.u32 	%r970, %r969, 5;
	and.b32  	%r287, %r281, -2147483648;
	cvta.to.local.u64 	%rd209, %rd207;
	st.local.u32 	[%rd209+24], %r1406;
	bfe.u32 	%r288, %r281, 23, 5;
	mov.u32 	%r971, 6;
	sub.s32 	%r972, %r971, %r970;
	mul.wide.s32 	%rd210, %r972, 4;
	add.s64 	%rd66, %rd209, %rd210;
	ld.local.u32 	%r1408, [%rd66];
	ld.local.u32 	%r1407, [%rd66+-4];
	setp.eq.s32	%p120, %r288, 0;
	@%p120 bra 	BB10_164;

	mov.u32 	%r973, 32;
	sub.s32 	%r974, %r973, %r288;
	shr.u32 	%r975, %r1407, %r974;
	shl.b32 	%r976, %r1408, %r288;
	add.s32 	%r1408, %r975, %r976;
	ld.local.u32 	%r977, [%rd66+-8];
	shr.u32 	%r978, %r977, %r974;
	shl.b32 	%r979, %r1407, %r288;
	add.s32 	%r1407, %r978, %r979;

BB10_164:
	shr.u32 	%r980, %r1407, 30;
	shl.b32 	%r981, %r1408, 2;
	add.s32 	%r1410, %r981, %r980;
	shl.b32 	%r296, %r1407, 2;
	shr.u32 	%r982, %r1410, 31;
	shr.u32 	%r983, %r1408, 30;
	add.s32 	%r297, %r982, %r983;
	setp.eq.s32	%p121, %r982, 0;
	@%p121 bra 	BB10_165;

	not.b32 	%r984, %r1410;
	neg.s32 	%r1409, %r296;
	setp.eq.s32	%p122, %r296, 0;
	selp.u32	%r985, 1, 0, %p122;
	add.s32 	%r1410, %r985, %r984;
	xor.b32  	%r1411, %r287, -2147483648;
	bra.uni 	BB10_167;

BB10_165:
	mov.u32 	%r1409, %r296;
	mov.u32 	%r1411, %r287;

BB10_167:
	cvt.u64.u32	%rd211, %r1410;
	cvt.u64.u32	%rd212, %r1409;
	bfi.b64 	%rd213, %rd211, %rd212, 32, 32;
	cvt.rn.f64.s64	%fd33, %rd213;
	mul.f64 	%fd34, %fd33, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f575, %fd34;
	neg.f32 	%f576, %f575;
	setp.eq.s32	%p123, %r1411, 0;
	selp.f32	%f820, %f575, %f576, %p123;
	setp.eq.s32	%p124, %r287, 0;
	neg.s32 	%r986, %r297;
	selp.b32	%r1412, %r297, %r986, %p124;

BB10_169:
	add.s32 	%r306, %r1412, 1;
	and.b32  	%r307, %r306, 1;
	setp.eq.s32	%p125, %r307, 0;
	selp.f32	%f174, %f820, 0f3F800000, %p125;
	mul.rn.f32 	%f175, %f820, %f820;
	fma.rn.f32 	%f176, %f175, %f174, %f317;
	mov.f32 	%f821, 0fB94D4153;
	@%p125 bra 	BB10_171;

	mov.f32 	%f580, 0fBAB607ED;
	mov.f32 	%f581, 0f37CBAC00;
	fma.rn.f32 	%f821, %f581, %f175, %f580;

BB10_171:
	selp.f32	%f582, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f583, %f821, %f175, %f582;
	selp.f32	%f584, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f585, %f583, %f175, %f584;
	fma.rn.f32 	%f822, %f585, %f176, %f174;
	and.b32  	%r987, %r306, 2;
	setp.eq.s32	%p127, %r987, 0;
	@%p127 bra 	BB10_173;

	mov.f32 	%f587, 0fBF800000;
	fma.rn.f32 	%f822, %f822, %f587, %f317;

BB10_173:
	@%p117 bra 	BB10_184;

	setp.eq.f32	%p129, %f170, 0f7F800000;
	@%p129 bra 	BB10_183;
	bra.uni 	BB10_175;

BB10_183:
	mul.rn.f32 	%f823, %f168, %f317;
	bra.uni 	BB10_184;

BB10_175:
	mov.b32 	 %r308, %f168;
	shl.b32 	%r990, %r308, 8;
	or.b32  	%r309, %r990, -2147483648;
	add.u64 	%rd215, %SP, 0;
	add.u64 	%rd314, %SPL, 0;
	mov.u32 	%r1414, 0;
	mov.u64 	%rd313, __cudart_i2opi_f;
	mov.u32 	%r1413, -6;

BB10_176:
	.pragma "nounroll";
	ld.const.u32 	%r993, [%rd313];
	// inline asm
	{
	mad.lo.cc.u32   %r991, %r993, %r309, %r1414;
	madc.hi.u32     %r1414, %r993, %r309,  0;
	}
	// inline asm
	st.local.u32 	[%rd314], %r991;
	add.s64 	%rd314, %rd314, 4;
	add.s64 	%rd313, %rd313, 4;
	add.s32 	%r1413, %r1413, 1;
	setp.ne.s32	%p130, %r1413, 0;
	@%p130 bra 	BB10_176;

	bfe.u32 	%r996, %r308, 23, 8;
	add.s32 	%r997, %r996, -128;
	shr.u32 	%r998, %r997, 5;
	and.b32  	%r314, %r308, -2147483648;
	cvta.to.local.u64 	%rd217, %rd215;
	st.local.u32 	[%rd217+24], %r1414;
	bfe.u32 	%r315, %r308, 23, 5;
	mov.u32 	%r999, 6;
	sub.s32 	%r1000, %r999, %r998;
	mul.wide.s32 	%rd218, %r1000, 4;
	add.s64 	%rd72, %rd217, %rd218;
	ld.local.u32 	%r1416, [%rd72];
	ld.local.u32 	%r1415, [%rd72+-4];
	setp.eq.s32	%p131, %r315, 0;
	@%p131 bra 	BB10_179;

	mov.u32 	%r1001, 32;
	sub.s32 	%r1002, %r1001, %r315;
	shr.u32 	%r1003, %r1415, %r1002;
	shl.b32 	%r1004, %r1416, %r315;
	add.s32 	%r1416, %r1003, %r1004;
	ld.local.u32 	%r1005, [%rd72+-8];
	shr.u32 	%r1006, %r1005, %r1002;
	shl.b32 	%r1007, %r1415, %r315;
	add.s32 	%r1415, %r1006, %r1007;

BB10_179:
	shr.u32 	%r1008, %r1415, 30;
	shl.b32 	%r1009, %r1416, 2;
	add.s32 	%r1418, %r1009, %r1008;
	shl.b32 	%r323, %r1415, 2;
	shr.u32 	%r1010, %r1418, 31;
	shr.u32 	%r1011, %r1416, 30;
	add.s32 	%r324, %r1010, %r1011;
	setp.eq.s32	%p132, %r1010, 0;
	@%p132 bra 	BB10_180;

	not.b32 	%r1012, %r1418;
	neg.s32 	%r1417, %r323;
	setp.eq.s32	%p133, %r323, 0;
	selp.u32	%r1013, 1, 0, %p133;
	add.s32 	%r1418, %r1013, %r1012;
	xor.b32  	%r1419, %r314, -2147483648;
	bra.uni 	BB10_182;

BB10_180:
	mov.u32 	%r1417, %r323;
	mov.u32 	%r1419, %r314;

BB10_182:
	cvt.u64.u32	%rd219, %r1418;
	cvt.u64.u32	%rd220, %r1417;
	bfi.b64 	%rd221, %rd219, %rd220, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd221;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f588, %fd36;
	neg.f32 	%f589, %f588;
	setp.eq.s32	%p134, %r1419, 0;
	selp.f32	%f823, %f588, %f589, %p134;
	setp.eq.s32	%p135, %r314, 0;
	neg.s32 	%r1014, %r324;
	selp.b32	%r1420, %r324, %r1014, %p135;

BB10_184:
	and.b32  	%r333, %r1420, 1;
	setp.eq.s32	%p136, %r333, 0;
	selp.f32	%f185, %f823, 0f3F800000, %p136;
	mul.rn.f32 	%f186, %f823, %f823;
	fma.rn.f32 	%f187, %f186, %f185, %f317;
	mov.f32 	%f824, 0fB94D4153;
	@%p136 bra 	BB10_186;

	mov.f32 	%f593, 0fBAB607ED;
	mov.f32 	%f594, 0f37CBAC00;
	fma.rn.f32 	%f824, %f594, %f186, %f593;

BB10_186:
	selp.f32	%f595, 0f3C0885E4, 0f3D2AAABB, %p136;
	fma.rn.f32 	%f596, %f824, %f186, %f595;
	selp.f32	%f597, 0fBE2AAAA8, 0fBEFFFFFF, %p136;
	fma.rn.f32 	%f598, %f596, %f186, %f597;
	fma.rn.f32 	%f825, %f598, %f187, %f185;
	and.b32  	%r1015, %r1420, 2;
	setp.eq.s32	%p138, %r1015, 0;
	@%p138 bra 	BB10_188;

	mov.f32 	%f600, 0fBF800000;
	fma.rn.f32 	%f825, %f825, %f600, %f317;

BB10_188:
	and.b32  	%r1016, %r1, 63;
	and.b32  	%r1018, %r636, 1073741696;
	add.s32 	%r1019, %r1018, %r1016;
	mul.f32 	%f601, %f167, %f825;
	mul.f32 	%f602, %f166, %f822;
	sub.f32 	%f603, %f602, %f601;
	mul.f32 	%f604, %f167, %f822;
	fma.rn.f32 	%f605, %f166, %f825, %f604;
	add.f32 	%f606, %f164, %f603;
	shl.b32 	%r1020, %r1019, 2;
	add.s32 	%r1022, %r564, %r1020;
	st.shared.f32 	[%r1022], %f606;
	add.f32 	%f607, %f165, %f605;
	add.s32 	%r1024, %r566, %r1020;
	st.shared.f32 	[%r1024], %f607;
	sub.f32 	%f608, %f164, %f603;
	st.shared.f32 	[%r1022+256], %f608;
	sub.f32 	%f609, %f165, %f605;
	st.shared.f32 	[%r1024+256], %f609;
	bar.sync 	0;
	ld.shared.f32 	%f193, [%r570];
	ld.shared.f32 	%f194, [%r572];
	ld.shared.f32 	%f195, [%r570+4096];
	ld.shared.f32 	%f196, [%r572+4096];
	shr.u32 	%r1031, %r650, 25;
	add.s32 	%r1032, %r1, %r1031;
	and.b32  	%r1033, %r1032, 536870784;
	sub.s32 	%r1034, %r1, %r1033;
	shl.b32 	%r1035, %r1034, 3;
	cvt.rn.f32.s32	%f610, %r1035;
	mul.f32 	%f611, %f610, 0f3A000000;
	cvt.f64.f32	%fd37, %f611;
	mul.f64 	%fd38, %fd37, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f197, %fd38;
	mul.f32 	%f612, %f197, 0f3F22F983;
	cvt.rni.s32.f32	%r1436, %f612;
	cvt.rn.f32.s32	%f613, %r1436;
	fma.rn.f32 	%f615, %f613, %f312, %f197;
	fma.rn.f32 	%f617, %f613, %f314, %f615;
	fma.rn.f32 	%f829, %f613, %f316, %f617;
	abs.f32 	%f199, %f197;
	setp.leu.f32	%p139, %f199, 0f47CE4780;
	mov.u32 	%r1428, %r1436;
	mov.f32 	%f826, %f829;
	@%p139 bra 	BB10_199;

	setp.eq.f32	%p140, %f199, 0f7F800000;
	@%p140 bra 	BB10_198;
	bra.uni 	BB10_190;

BB10_198:
	mul.rn.f32 	%f826, %f197, %f317;
	mov.u32 	%r1428, %r1436;
	bra.uni 	BB10_199;

BB10_190:
	mov.b32 	 %r336, %f197;
	shl.b32 	%r1038, %r336, 8;
	or.b32  	%r337, %r1038, -2147483648;
	add.u64 	%rd223, %SP, 0;
	add.u64 	%rd316, %SPL, 0;
	mov.u32 	%r1422, 0;
	mov.u64 	%rd315, __cudart_i2opi_f;
	mov.u32 	%r1421, -6;

BB10_191:
	.pragma "nounroll";
	ld.const.u32 	%r1041, [%rd315];
	// inline asm
	{
	mad.lo.cc.u32   %r1039, %r1041, %r337, %r1422;
	madc.hi.u32     %r1422, %r1041, %r337,  0;
	}
	// inline asm
	st.local.u32 	[%rd316], %r1039;
	add.s64 	%rd316, %rd316, 4;
	add.s64 	%rd315, %rd315, 4;
	add.s32 	%r1421, %r1421, 1;
	setp.ne.s32	%p141, %r1421, 0;
	@%p141 bra 	BB10_191;

	bfe.u32 	%r1044, %r336, 23, 8;
	add.s32 	%r1045, %r1044, -128;
	shr.u32 	%r1046, %r1045, 5;
	and.b32  	%r342, %r336, -2147483648;
	cvta.to.local.u64 	%rd225, %rd223;
	st.local.u32 	[%rd225+24], %r1422;
	bfe.u32 	%r343, %r336, 23, 5;
	mov.u32 	%r1047, 6;
	sub.s32 	%r1048, %r1047, %r1046;
	mul.wide.s32 	%rd226, %r1048, 4;
	add.s64 	%rd78, %rd225, %rd226;
	ld.local.u32 	%r1424, [%rd78];
	ld.local.u32 	%r1423, [%rd78+-4];
	setp.eq.s32	%p142, %r343, 0;
	@%p142 bra 	BB10_194;

	mov.u32 	%r1049, 32;
	sub.s32 	%r1050, %r1049, %r343;
	shr.u32 	%r1051, %r1423, %r1050;
	shl.b32 	%r1052, %r1424, %r343;
	add.s32 	%r1424, %r1051, %r1052;
	ld.local.u32 	%r1053, [%rd78+-8];
	shr.u32 	%r1054, %r1053, %r1050;
	shl.b32 	%r1055, %r1423, %r343;
	add.s32 	%r1423, %r1054, %r1055;

BB10_194:
	shr.u32 	%r1056, %r1423, 30;
	shl.b32 	%r1057, %r1424, 2;
	add.s32 	%r1426, %r1057, %r1056;
	shl.b32 	%r351, %r1423, 2;
	shr.u32 	%r1058, %r1426, 31;
	shr.u32 	%r1059, %r1424, 30;
	add.s32 	%r352, %r1058, %r1059;
	setp.eq.s32	%p143, %r1058, 0;
	@%p143 bra 	BB10_195;

	not.b32 	%r1060, %r1426;
	neg.s32 	%r1425, %r351;
	setp.eq.s32	%p144, %r351, 0;
	selp.u32	%r1061, 1, 0, %p144;
	add.s32 	%r1426, %r1061, %r1060;
	xor.b32  	%r1427, %r342, -2147483648;
	bra.uni 	BB10_197;

BB10_195:
	mov.u32 	%r1425, %r351;
	mov.u32 	%r1427, %r342;

BB10_197:
	cvt.u64.u32	%rd227, %r1426;
	cvt.u64.u32	%rd228, %r1425;
	bfi.b64 	%rd229, %rd227, %rd228, 32, 32;
	cvt.rn.f64.s64	%fd39, %rd229;
	mul.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f619, %fd40;
	neg.f32 	%f620, %f619;
	setp.eq.s32	%p145, %r1427, 0;
	selp.f32	%f826, %f619, %f620, %p145;
	setp.eq.s32	%p146, %r342, 0;
	neg.s32 	%r1062, %r352;
	selp.b32	%r1428, %r352, %r1062, %p146;

BB10_199:
	add.s32 	%r361, %r1428, 1;
	and.b32  	%r362, %r361, 1;
	setp.eq.s32	%p147, %r362, 0;
	selp.f32	%f203, %f826, 0f3F800000, %p147;
	mul.rn.f32 	%f204, %f826, %f826;
	fma.rn.f32 	%f205, %f204, %f203, %f317;
	mov.f32 	%f827, 0fB94D4153;
	@%p147 bra 	BB10_201;

	mov.f32 	%f624, 0fBAB607ED;
	mov.f32 	%f625, 0f37CBAC00;
	fma.rn.f32 	%f827, %f625, %f204, %f624;

BB10_201:
	selp.f32	%f626, 0f3C0885E4, 0f3D2AAABB, %p147;
	fma.rn.f32 	%f627, %f827, %f204, %f626;
	selp.f32	%f628, 0fBE2AAAA8, 0fBEFFFFFF, %p147;
	fma.rn.f32 	%f629, %f627, %f204, %f628;
	fma.rn.f32 	%f828, %f629, %f205, %f203;
	and.b32  	%r1063, %r361, 2;
	setp.eq.s32	%p149, %r1063, 0;
	@%p149 bra 	BB10_203;

	mov.f32 	%f631, 0fBF800000;
	fma.rn.f32 	%f828, %f828, %f631, %f317;

BB10_203:
	@%p139 bra 	BB10_214;

	setp.eq.f32	%p151, %f199, 0f7F800000;
	@%p151 bra 	BB10_213;
	bra.uni 	BB10_205;

BB10_213:
	mul.rn.f32 	%f829, %f197, %f317;
	bra.uni 	BB10_214;

BB10_205:
	mov.b32 	 %r363, %f197;
	shl.b32 	%r1066, %r363, 8;
	or.b32  	%r364, %r1066, -2147483648;
	add.u64 	%rd231, %SP, 0;
	add.u64 	%rd318, %SPL, 0;
	mov.u32 	%r1430, 0;
	mov.u64 	%rd317, __cudart_i2opi_f;
	mov.u32 	%r1429, -6;

BB10_206:
	.pragma "nounroll";
	ld.const.u32 	%r1069, [%rd317];
	// inline asm
	{
	mad.lo.cc.u32   %r1067, %r1069, %r364, %r1430;
	madc.hi.u32     %r1430, %r1069, %r364,  0;
	}
	// inline asm
	st.local.u32 	[%rd318], %r1067;
	add.s64 	%rd318, %rd318, 4;
	add.s64 	%rd317, %rd317, 4;
	add.s32 	%r1429, %r1429, 1;
	setp.ne.s32	%p152, %r1429, 0;
	@%p152 bra 	BB10_206;

	bfe.u32 	%r1072, %r363, 23, 8;
	add.s32 	%r1073, %r1072, -128;
	shr.u32 	%r1074, %r1073, 5;
	and.b32  	%r369, %r363, -2147483648;
	cvta.to.local.u64 	%rd233, %rd231;
	st.local.u32 	[%rd233+24], %r1430;
	bfe.u32 	%r370, %r363, 23, 5;
	mov.u32 	%r1075, 6;
	sub.s32 	%r1076, %r1075, %r1074;
	mul.wide.s32 	%rd234, %r1076, 4;
	add.s64 	%rd84, %rd233, %rd234;
	ld.local.u32 	%r1432, [%rd84];
	ld.local.u32 	%r1431, [%rd84+-4];
	setp.eq.s32	%p153, %r370, 0;
	@%p153 bra 	BB10_209;

	mov.u32 	%r1077, 32;
	sub.s32 	%r1078, %r1077, %r370;
	shr.u32 	%r1079, %r1431, %r1078;
	shl.b32 	%r1080, %r1432, %r370;
	add.s32 	%r1432, %r1079, %r1080;
	ld.local.u32 	%r1081, [%rd84+-8];
	shr.u32 	%r1082, %r1081, %r1078;
	shl.b32 	%r1083, %r1431, %r370;
	add.s32 	%r1431, %r1082, %r1083;

BB10_209:
	shr.u32 	%r1084, %r1431, 30;
	shl.b32 	%r1085, %r1432, 2;
	add.s32 	%r1434, %r1085, %r1084;
	shl.b32 	%r378, %r1431, 2;
	shr.u32 	%r1086, %r1434, 31;
	shr.u32 	%r1087, %r1432, 30;
	add.s32 	%r379, %r1086, %r1087;
	setp.eq.s32	%p154, %r1086, 0;
	@%p154 bra 	BB10_210;

	not.b32 	%r1088, %r1434;
	neg.s32 	%r1433, %r378;
	setp.eq.s32	%p155, %r378, 0;
	selp.u32	%r1089, 1, 0, %p155;
	add.s32 	%r1434, %r1089, %r1088;
	xor.b32  	%r1435, %r369, -2147483648;
	bra.uni 	BB10_212;

BB10_210:
	mov.u32 	%r1433, %r378;
	mov.u32 	%r1435, %r369;

BB10_212:
	cvt.u64.u32	%rd235, %r1434;
	cvt.u64.u32	%rd236, %r1433;
	bfi.b64 	%rd237, %rd235, %rd236, 32, 32;
	cvt.rn.f64.s64	%fd41, %rd237;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f632, %fd42;
	neg.f32 	%f633, %f632;
	setp.eq.s32	%p156, %r1435, 0;
	selp.f32	%f829, %f632, %f633, %p156;
	setp.eq.s32	%p157, %r369, 0;
	neg.s32 	%r1090, %r379;
	selp.b32	%r1436, %r379, %r1090, %p157;

BB10_214:
	and.b32  	%r388, %r1436, 1;
	setp.eq.s32	%p158, %r388, 0;
	selp.f32	%f214, %f829, 0f3F800000, %p158;
	mul.rn.f32 	%f215, %f829, %f829;
	fma.rn.f32 	%f216, %f215, %f214, %f317;
	mov.f32 	%f830, 0fB94D4153;
	@%p158 bra 	BB10_216;

	mov.f32 	%f637, 0fBAB607ED;
	mov.f32 	%f638, 0f37CBAC00;
	fma.rn.f32 	%f830, %f638, %f215, %f637;

BB10_216:
	selp.f32	%f639, 0f3C0885E4, 0f3D2AAABB, %p158;
	fma.rn.f32 	%f640, %f830, %f215, %f639;
	selp.f32	%f641, 0fBE2AAAA8, 0fBEFFFFFF, %p158;
	fma.rn.f32 	%f642, %f640, %f215, %f641;
	fma.rn.f32 	%f831, %f642, %f216, %f214;
	and.b32  	%r1091, %r1436, 2;
	setp.eq.s32	%p160, %r1091, 0;
	@%p160 bra 	BB10_218;

	mov.f32 	%f644, 0fBF800000;
	fma.rn.f32 	%f831, %f831, %f644, %f317;

BB10_218:
	and.b32  	%r1092, %r1, 127;
	and.b32  	%r1094, %r636, 1073741568;
	add.s32 	%r1095, %r1094, %r1092;
	mul.f32 	%f645, %f196, %f831;
	mul.f32 	%f646, %f195, %f828;
	sub.f32 	%f647, %f646, %f645;
	mul.f32 	%f648, %f196, %f828;
	fma.rn.f32 	%f649, %f195, %f831, %f648;
	add.f32 	%f650, %f193, %f647;
	shl.b32 	%r1096, %r1095, 2;
	add.s32 	%r1098, %r641, %r1096;
	st.shared.f32 	[%r1098], %f650;
	add.f32 	%f651, %f194, %f649;
	add.s32 	%r1100, %r643, %r1096;
	st.shared.f32 	[%r1100], %f651;
	sub.f32 	%f652, %f193, %f647;
	st.shared.f32 	[%r1098+512], %f652;
	sub.f32 	%f653, %f194, %f649;
	st.shared.f32 	[%r1100+512], %f653;
	bar.sync 	0;
	ld.shared.f32 	%f222, [%r647];
	ld.shared.f32 	%f223, [%r649];
	ld.shared.f32 	%f224, [%r647+4096];
	ld.shared.f32 	%f225, [%r649+4096];
	shr.u32 	%r1107, %r650, 24;
	add.s32 	%r1108, %r1, %r1107;
	and.b32  	%r1109, %r1108, 1073741568;
	sub.s32 	%r1110, %r1, %r1109;
	shl.b32 	%r1111, %r1110, 2;
	cvt.rn.f32.s32	%f654, %r1111;
	mul.f32 	%f655, %f654, 0f3A000000;
	cvt.f64.f32	%fd43, %f655;
	mul.f64 	%fd44, %fd43, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f226, %fd44;
	mul.f32 	%f656, %f226, 0f3F22F983;
	cvt.rni.s32.f32	%r1452, %f656;
	cvt.rn.f32.s32	%f657, %r1452;
	fma.rn.f32 	%f659, %f657, %f312, %f226;
	fma.rn.f32 	%f661, %f657, %f314, %f659;
	fma.rn.f32 	%f835, %f657, %f316, %f661;
	abs.f32 	%f228, %f226;
	setp.leu.f32	%p161, %f228, 0f47CE4780;
	mov.u32 	%r1444, %r1452;
	mov.f32 	%f832, %f835;
	@%p161 bra 	BB10_229;

	setp.eq.f32	%p162, %f228, 0f7F800000;
	@%p162 bra 	BB10_228;
	bra.uni 	BB10_220;

BB10_228:
	mul.rn.f32 	%f832, %f226, %f317;
	mov.u32 	%r1444, %r1452;
	bra.uni 	BB10_229;

BB10_220:
	mov.b32 	 %r391, %f226;
	shl.b32 	%r1114, %r391, 8;
	or.b32  	%r392, %r1114, -2147483648;
	add.u64 	%rd239, %SP, 0;
	add.u64 	%rd320, %SPL, 0;
	mov.u32 	%r1438, 0;
	mov.u64 	%rd319, __cudart_i2opi_f;
	mov.u32 	%r1437, -6;

BB10_221:
	.pragma "nounroll";
	ld.const.u32 	%r1117, [%rd319];
	// inline asm
	{
	mad.lo.cc.u32   %r1115, %r1117, %r392, %r1438;
	madc.hi.u32     %r1438, %r1117, %r392,  0;
	}
	// inline asm
	st.local.u32 	[%rd320], %r1115;
	add.s64 	%rd320, %rd320, 4;
	add.s64 	%rd319, %rd319, 4;
	add.s32 	%r1437, %r1437, 1;
	setp.ne.s32	%p163, %r1437, 0;
	@%p163 bra 	BB10_221;

	bfe.u32 	%r1120, %r391, 23, 8;
	add.s32 	%r1121, %r1120, -128;
	shr.u32 	%r1122, %r1121, 5;
	and.b32  	%r397, %r391, -2147483648;
	cvta.to.local.u64 	%rd241, %rd239;
	st.local.u32 	[%rd241+24], %r1438;
	bfe.u32 	%r398, %r391, 23, 5;
	mov.u32 	%r1123, 6;
	sub.s32 	%r1124, %r1123, %r1122;
	mul.wide.s32 	%rd242, %r1124, 4;
	add.s64 	%rd90, %rd241, %rd242;
	ld.local.u32 	%r1440, [%rd90];
	ld.local.u32 	%r1439, [%rd90+-4];
	setp.eq.s32	%p164, %r398, 0;
	@%p164 bra 	BB10_224;

	mov.u32 	%r1125, 32;
	sub.s32 	%r1126, %r1125, %r398;
	shr.u32 	%r1127, %r1439, %r1126;
	shl.b32 	%r1128, %r1440, %r398;
	add.s32 	%r1440, %r1127, %r1128;
	ld.local.u32 	%r1129, [%rd90+-8];
	shr.u32 	%r1130, %r1129, %r1126;
	shl.b32 	%r1131, %r1439, %r398;
	add.s32 	%r1439, %r1130, %r1131;

BB10_224:
	shr.u32 	%r1132, %r1439, 30;
	shl.b32 	%r1133, %r1440, 2;
	add.s32 	%r1442, %r1133, %r1132;
	shl.b32 	%r406, %r1439, 2;
	shr.u32 	%r1134, %r1442, 31;
	shr.u32 	%r1135, %r1440, 30;
	add.s32 	%r407, %r1134, %r1135;
	setp.eq.s32	%p165, %r1134, 0;
	@%p165 bra 	BB10_225;

	not.b32 	%r1136, %r1442;
	neg.s32 	%r1441, %r406;
	setp.eq.s32	%p166, %r406, 0;
	selp.u32	%r1137, 1, 0, %p166;
	add.s32 	%r1442, %r1137, %r1136;
	xor.b32  	%r1443, %r397, -2147483648;
	bra.uni 	BB10_227;

BB10_225:
	mov.u32 	%r1441, %r406;
	mov.u32 	%r1443, %r397;

BB10_227:
	cvt.u64.u32	%rd243, %r1442;
	cvt.u64.u32	%rd244, %r1441;
	bfi.b64 	%rd245, %rd243, %rd244, 32, 32;
	cvt.rn.f64.s64	%fd45, %rd245;
	mul.f64 	%fd46, %fd45, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f663, %fd46;
	neg.f32 	%f664, %f663;
	setp.eq.s32	%p167, %r1443, 0;
	selp.f32	%f832, %f663, %f664, %p167;
	setp.eq.s32	%p168, %r397, 0;
	neg.s32 	%r1138, %r407;
	selp.b32	%r1444, %r407, %r1138, %p168;

BB10_229:
	add.s32 	%r416, %r1444, 1;
	and.b32  	%r417, %r416, 1;
	setp.eq.s32	%p169, %r417, 0;
	selp.f32	%f232, %f832, 0f3F800000, %p169;
	mul.rn.f32 	%f233, %f832, %f832;
	fma.rn.f32 	%f234, %f233, %f232, %f317;
	mov.f32 	%f833, 0fB94D4153;
	@%p169 bra 	BB10_231;

	mov.f32 	%f668, 0fBAB607ED;
	mov.f32 	%f669, 0f37CBAC00;
	fma.rn.f32 	%f833, %f669, %f233, %f668;

BB10_231:
	selp.f32	%f670, 0f3C0885E4, 0f3D2AAABB, %p169;
	fma.rn.f32 	%f671, %f833, %f233, %f670;
	selp.f32	%f672, 0fBE2AAAA8, 0fBEFFFFFF, %p169;
	fma.rn.f32 	%f673, %f671, %f233, %f672;
	fma.rn.f32 	%f834, %f673, %f234, %f232;
	and.b32  	%r1139, %r416, 2;
	setp.eq.s32	%p171, %r1139, 0;
	@%p171 bra 	BB10_233;

	mov.f32 	%f675, 0fBF800000;
	fma.rn.f32 	%f834, %f834, %f675, %f317;

BB10_233:
	@%p161 bra 	BB10_244;

	setp.eq.f32	%p173, %f228, 0f7F800000;
	@%p173 bra 	BB10_243;
	bra.uni 	BB10_235;

BB10_243:
	mul.rn.f32 	%f835, %f226, %f317;
	bra.uni 	BB10_244;

BB10_235:
	mov.b32 	 %r418, %f226;
	shl.b32 	%r1142, %r418, 8;
	or.b32  	%r419, %r1142, -2147483648;
	add.u64 	%rd247, %SP, 0;
	add.u64 	%rd322, %SPL, 0;
	mov.u32 	%r1446, 0;
	mov.u64 	%rd321, __cudart_i2opi_f;
	mov.u32 	%r1445, -6;

BB10_236:
	.pragma "nounroll";
	ld.const.u32 	%r1145, [%rd321];
	// inline asm
	{
	mad.lo.cc.u32   %r1143, %r1145, %r419, %r1446;
	madc.hi.u32     %r1446, %r1145, %r419,  0;
	}
	// inline asm
	st.local.u32 	[%rd322], %r1143;
	add.s64 	%rd322, %rd322, 4;
	add.s64 	%rd321, %rd321, 4;
	add.s32 	%r1445, %r1445, 1;
	setp.ne.s32	%p174, %r1445, 0;
	@%p174 bra 	BB10_236;

	bfe.u32 	%r1148, %r418, 23, 8;
	add.s32 	%r1149, %r1148, -128;
	shr.u32 	%r1150, %r1149, 5;
	and.b32  	%r424, %r418, -2147483648;
	cvta.to.local.u64 	%rd249, %rd247;
	st.local.u32 	[%rd249+24], %r1446;
	bfe.u32 	%r425, %r418, 23, 5;
	mov.u32 	%r1151, 6;
	sub.s32 	%r1152, %r1151, %r1150;
	mul.wide.s32 	%rd250, %r1152, 4;
	add.s64 	%rd96, %rd249, %rd250;
	ld.local.u32 	%r1448, [%rd96];
	ld.local.u32 	%r1447, [%rd96+-4];
	setp.eq.s32	%p175, %r425, 0;
	@%p175 bra 	BB10_239;

	mov.u32 	%r1153, 32;
	sub.s32 	%r1154, %r1153, %r425;
	shr.u32 	%r1155, %r1447, %r1154;
	shl.b32 	%r1156, %r1448, %r425;
	add.s32 	%r1448, %r1155, %r1156;
	ld.local.u32 	%r1157, [%rd96+-8];
	shr.u32 	%r1158, %r1157, %r1154;
	shl.b32 	%r1159, %r1447, %r425;
	add.s32 	%r1447, %r1158, %r1159;

BB10_239:
	shr.u32 	%r1160, %r1447, 30;
	shl.b32 	%r1161, %r1448, 2;
	add.s32 	%r1450, %r1161, %r1160;
	shl.b32 	%r433, %r1447, 2;
	shr.u32 	%r1162, %r1450, 31;
	shr.u32 	%r1163, %r1448, 30;
	add.s32 	%r434, %r1162, %r1163;
	setp.eq.s32	%p176, %r1162, 0;
	@%p176 bra 	BB10_240;

	not.b32 	%r1164, %r1450;
	neg.s32 	%r1449, %r433;
	setp.eq.s32	%p177, %r433, 0;
	selp.u32	%r1165, 1, 0, %p177;
	add.s32 	%r1450, %r1165, %r1164;
	xor.b32  	%r1451, %r424, -2147483648;
	bra.uni 	BB10_242;

BB10_240:
	mov.u32 	%r1449, %r433;
	mov.u32 	%r1451, %r424;

BB10_242:
	cvt.u64.u32	%rd251, %r1450;
	cvt.u64.u32	%rd252, %r1449;
	bfi.b64 	%rd253, %rd251, %rd252, 32, 32;
	cvt.rn.f64.s64	%fd47, %rd253;
	mul.f64 	%fd48, %fd47, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f676, %fd48;
	neg.f32 	%f677, %f676;
	setp.eq.s32	%p178, %r1451, 0;
	selp.f32	%f835, %f676, %f677, %p178;
	setp.eq.s32	%p179, %r424, 0;
	neg.s32 	%r1166, %r434;
	selp.b32	%r1452, %r434, %r1166, %p179;

BB10_244:
	and.b32  	%r443, %r1452, 1;
	setp.eq.s32	%p180, %r443, 0;
	selp.f32	%f243, %f835, 0f3F800000, %p180;
	mul.rn.f32 	%f244, %f835, %f835;
	fma.rn.f32 	%f245, %f244, %f243, %f317;
	mov.f32 	%f836, 0fB94D4153;
	@%p180 bra 	BB10_246;

	mov.f32 	%f681, 0fBAB607ED;
	mov.f32 	%f682, 0f37CBAC00;
	fma.rn.f32 	%f836, %f682, %f244, %f681;

BB10_246:
	selp.f32	%f683, 0f3C0885E4, 0f3D2AAABB, %p180;
	fma.rn.f32 	%f684, %f836, %f244, %f683;
	selp.f32	%f685, 0fBE2AAAA8, 0fBEFFFFFF, %p180;
	fma.rn.f32 	%f686, %f684, %f244, %f685;
	fma.rn.f32 	%f837, %f686, %f245, %f243;
	and.b32  	%r1167, %r1452, 2;
	setp.eq.s32	%p182, %r1167, 0;
	@%p182 bra 	BB10_248;

	mov.f32 	%f688, 0fBF800000;
	fma.rn.f32 	%f837, %f837, %f688, %f317;

BB10_248:
	and.b32  	%r1168, %r1, 255;
	and.b32  	%r1170, %r636, 1073741312;
	add.s32 	%r1171, %r1170, %r1168;
	mul.f32 	%f689, %f225, %f837;
	mul.f32 	%f690, %f224, %f834;
	sub.f32 	%f691, %f690, %f689;
	mul.f32 	%f692, %f225, %f834;
	fma.rn.f32 	%f693, %f224, %f837, %f692;
	add.f32 	%f694, %f222, %f691;
	shl.b32 	%r1172, %r1171, 2;
	add.s32 	%r1174, %r564, %r1172;
	st.shared.f32 	[%r1174], %f694;
	add.f32 	%f695, %f223, %f693;
	add.s32 	%r1176, %r566, %r1172;
	st.shared.f32 	[%r1176], %f695;
	sub.f32 	%f696, %f222, %f691;
	st.shared.f32 	[%r1174+1024], %f696;
	sub.f32 	%f697, %f223, %f693;
	st.shared.f32 	[%r1176+1024], %f697;
	bar.sync 	0;
	ld.shared.f32 	%f251, [%r570];
	ld.shared.f32 	%f252, [%r572];
	ld.shared.f32 	%f253, [%r570+4096];
	ld.shared.f32 	%f254, [%r572+4096];
	shr.u32 	%r1183, %r650, 23;
	add.s32 	%r1184, %r1, %r1183;
	and.b32  	%r1185, %r1184, 2147483136;
	sub.s32 	%r1186, %r1, %r1185;
	shl.b32 	%r1187, %r1186, 1;
	cvt.rn.f32.s32	%f698, %r1187;
	mul.f32 	%f699, %f698, 0f3A000000;
	cvt.f64.f32	%fd49, %f699;
	mul.f64 	%fd50, %fd49, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f255, %fd50;
	mul.f32 	%f700, %f255, 0f3F22F983;
	cvt.rni.s32.f32	%r1468, %f700;
	cvt.rn.f32.s32	%f701, %r1468;
	fma.rn.f32 	%f703, %f701, %f312, %f255;
	fma.rn.f32 	%f705, %f701, %f314, %f703;
	fma.rn.f32 	%f841, %f701, %f316, %f705;
	abs.f32 	%f257, %f255;
	setp.leu.f32	%p183, %f257, 0f47CE4780;
	mov.u32 	%r1460, %r1468;
	mov.f32 	%f838, %f841;
	@%p183 bra 	BB10_259;

	setp.eq.f32	%p184, %f257, 0f7F800000;
	@%p184 bra 	BB10_258;
	bra.uni 	BB10_250;

BB10_258:
	mul.rn.f32 	%f838, %f255, %f317;
	mov.u32 	%r1460, %r1468;
	bra.uni 	BB10_259;

BB10_250:
	mov.b32 	 %r446, %f255;
	shl.b32 	%r1190, %r446, 8;
	or.b32  	%r447, %r1190, -2147483648;
	add.u64 	%rd255, %SP, 0;
	add.u64 	%rd324, %SPL, 0;
	mov.u32 	%r1454, 0;
	mov.u64 	%rd323, __cudart_i2opi_f;
	mov.u32 	%r1453, -6;

BB10_251:
	.pragma "nounroll";
	ld.const.u32 	%r1193, [%rd323];
	// inline asm
	{
	mad.lo.cc.u32   %r1191, %r1193, %r447, %r1454;
	madc.hi.u32     %r1454, %r1193, %r447,  0;
	}
	// inline asm
	st.local.u32 	[%rd324], %r1191;
	add.s64 	%rd324, %rd324, 4;
	add.s64 	%rd323, %rd323, 4;
	add.s32 	%r1453, %r1453, 1;
	setp.ne.s32	%p185, %r1453, 0;
	@%p185 bra 	BB10_251;

	bfe.u32 	%r1196, %r446, 23, 8;
	add.s32 	%r1197, %r1196, -128;
	shr.u32 	%r1198, %r1197, 5;
	and.b32  	%r452, %r446, -2147483648;
	cvta.to.local.u64 	%rd257, %rd255;
	st.local.u32 	[%rd257+24], %r1454;
	bfe.u32 	%r453, %r446, 23, 5;
	mov.u32 	%r1199, 6;
	sub.s32 	%r1200, %r1199, %r1198;
	mul.wide.s32 	%rd258, %r1200, 4;
	add.s64 	%rd102, %rd257, %rd258;
	ld.local.u32 	%r1456, [%rd102];
	ld.local.u32 	%r1455, [%rd102+-4];
	setp.eq.s32	%p186, %r453, 0;
	@%p186 bra 	BB10_254;

	mov.u32 	%r1201, 32;
	sub.s32 	%r1202, %r1201, %r453;
	shr.u32 	%r1203, %r1455, %r1202;
	shl.b32 	%r1204, %r1456, %r453;
	add.s32 	%r1456, %r1203, %r1204;
	ld.local.u32 	%r1205, [%rd102+-8];
	shr.u32 	%r1206, %r1205, %r1202;
	shl.b32 	%r1207, %r1455, %r453;
	add.s32 	%r1455, %r1206, %r1207;

BB10_254:
	shr.u32 	%r1208, %r1455, 30;
	shl.b32 	%r1209, %r1456, 2;
	add.s32 	%r1458, %r1209, %r1208;
	shl.b32 	%r461, %r1455, 2;
	shr.u32 	%r1210, %r1458, 31;
	shr.u32 	%r1211, %r1456, 30;
	add.s32 	%r462, %r1210, %r1211;
	setp.eq.s32	%p187, %r1210, 0;
	@%p187 bra 	BB10_255;

	not.b32 	%r1212, %r1458;
	neg.s32 	%r1457, %r461;
	setp.eq.s32	%p188, %r461, 0;
	selp.u32	%r1213, 1, 0, %p188;
	add.s32 	%r1458, %r1213, %r1212;
	xor.b32  	%r1459, %r452, -2147483648;
	bra.uni 	BB10_257;

BB10_255:
	mov.u32 	%r1457, %r461;
	mov.u32 	%r1459, %r452;

BB10_257:
	cvt.u64.u32	%rd259, %r1458;
	cvt.u64.u32	%rd260, %r1457;
	bfi.b64 	%rd261, %rd259, %rd260, 32, 32;
	cvt.rn.f64.s64	%fd51, %rd261;
	mul.f64 	%fd52, %fd51, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f707, %fd52;
	neg.f32 	%f708, %f707;
	setp.eq.s32	%p189, %r1459, 0;
	selp.f32	%f838, %f707, %f708, %p189;
	setp.eq.s32	%p190, %r452, 0;
	neg.s32 	%r1214, %r462;
	selp.b32	%r1460, %r462, %r1214, %p190;

BB10_259:
	add.s32 	%r471, %r1460, 1;
	and.b32  	%r472, %r471, 1;
	setp.eq.s32	%p191, %r472, 0;
	selp.f32	%f261, %f838, 0f3F800000, %p191;
	mul.rn.f32 	%f262, %f838, %f838;
	fma.rn.f32 	%f263, %f262, %f261, %f317;
	mov.f32 	%f839, 0fB94D4153;
	@%p191 bra 	BB10_261;

	mov.f32 	%f712, 0fBAB607ED;
	mov.f32 	%f713, 0f37CBAC00;
	fma.rn.f32 	%f839, %f713, %f262, %f712;

BB10_261:
	selp.f32	%f714, 0f3C0885E4, 0f3D2AAABB, %p191;
	fma.rn.f32 	%f715, %f839, %f262, %f714;
	selp.f32	%f716, 0fBE2AAAA8, 0fBEFFFFFF, %p191;
	fma.rn.f32 	%f717, %f715, %f262, %f716;
	fma.rn.f32 	%f840, %f717, %f263, %f261;
	and.b32  	%r1215, %r471, 2;
	setp.eq.s32	%p193, %r1215, 0;
	@%p193 bra 	BB10_263;

	mov.f32 	%f719, 0fBF800000;
	fma.rn.f32 	%f840, %f840, %f719, %f317;

BB10_263:
	@%p183 bra 	BB10_274;

	setp.eq.f32	%p195, %f257, 0f7F800000;
	@%p195 bra 	BB10_273;
	bra.uni 	BB10_265;

BB10_273:
	mul.rn.f32 	%f841, %f255, %f317;
	bra.uni 	BB10_274;

BB10_265:
	mov.b32 	 %r473, %f255;
	shl.b32 	%r1218, %r473, 8;
	or.b32  	%r474, %r1218, -2147483648;
	add.u64 	%rd263, %SP, 0;
	add.u64 	%rd326, %SPL, 0;
	mov.u32 	%r1462, 0;
	mov.u64 	%rd325, __cudart_i2opi_f;
	mov.u32 	%r1461, -6;

BB10_266:
	.pragma "nounroll";
	ld.const.u32 	%r1221, [%rd325];
	// inline asm
	{
	mad.lo.cc.u32   %r1219, %r1221, %r474, %r1462;
	madc.hi.u32     %r1462, %r1221, %r474,  0;
	}
	// inline asm
	st.local.u32 	[%rd326], %r1219;
	add.s64 	%rd326, %rd326, 4;
	add.s64 	%rd325, %rd325, 4;
	add.s32 	%r1461, %r1461, 1;
	setp.ne.s32	%p196, %r1461, 0;
	@%p196 bra 	BB10_266;

	bfe.u32 	%r1224, %r473, 23, 8;
	add.s32 	%r1225, %r1224, -128;
	shr.u32 	%r1226, %r1225, 5;
	and.b32  	%r479, %r473, -2147483648;
	cvta.to.local.u64 	%rd265, %rd263;
	st.local.u32 	[%rd265+24], %r1462;
	bfe.u32 	%r480, %r473, 23, 5;
	mov.u32 	%r1227, 6;
	sub.s32 	%r1228, %r1227, %r1226;
	mul.wide.s32 	%rd266, %r1228, 4;
	add.s64 	%rd108, %rd265, %rd266;
	ld.local.u32 	%r1464, [%rd108];
	ld.local.u32 	%r1463, [%rd108+-4];
	setp.eq.s32	%p197, %r480, 0;
	@%p197 bra 	BB10_269;

	mov.u32 	%r1229, 32;
	sub.s32 	%r1230, %r1229, %r480;
	shr.u32 	%r1231, %r1463, %r1230;
	shl.b32 	%r1232, %r1464, %r480;
	add.s32 	%r1464, %r1231, %r1232;
	ld.local.u32 	%r1233, [%rd108+-8];
	shr.u32 	%r1234, %r1233, %r1230;
	shl.b32 	%r1235, %r1463, %r480;
	add.s32 	%r1463, %r1234, %r1235;

BB10_269:
	shr.u32 	%r1236, %r1463, 30;
	shl.b32 	%r1237, %r1464, 2;
	add.s32 	%r1466, %r1237, %r1236;
	shl.b32 	%r488, %r1463, 2;
	shr.u32 	%r1238, %r1466, 31;
	shr.u32 	%r1239, %r1464, 30;
	add.s32 	%r489, %r1238, %r1239;
	setp.eq.s32	%p198, %r1238, 0;
	@%p198 bra 	BB10_270;

	not.b32 	%r1240, %r1466;
	neg.s32 	%r1465, %r488;
	setp.eq.s32	%p199, %r488, 0;
	selp.u32	%r1241, 1, 0, %p199;
	add.s32 	%r1466, %r1241, %r1240;
	xor.b32  	%r1467, %r479, -2147483648;
	bra.uni 	BB10_272;

BB10_270:
	mov.u32 	%r1465, %r488;
	mov.u32 	%r1467, %r479;

BB10_272:
	cvt.u64.u32	%rd267, %r1466;
	cvt.u64.u32	%rd268, %r1465;
	bfi.b64 	%rd269, %rd267, %rd268, 32, 32;
	cvt.rn.f64.s64	%fd53, %rd269;
	mul.f64 	%fd54, %fd53, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f720, %fd54;
	neg.f32 	%f721, %f720;
	setp.eq.s32	%p200, %r1467, 0;
	selp.f32	%f841, %f720, %f721, %p200;
	setp.eq.s32	%p201, %r479, 0;
	neg.s32 	%r1242, %r489;
	selp.b32	%r1468, %r489, %r1242, %p201;

BB10_274:
	and.b32  	%r498, %r1468, 1;
	setp.eq.s32	%p202, %r498, 0;
	selp.f32	%f272, %f841, 0f3F800000, %p202;
	mul.rn.f32 	%f273, %f841, %f841;
	fma.rn.f32 	%f274, %f273, %f272, %f317;
	mov.f32 	%f842, 0fB94D4153;
	@%p202 bra 	BB10_276;

	mov.f32 	%f725, 0fBAB607ED;
	mov.f32 	%f726, 0f37CBAC00;
	fma.rn.f32 	%f842, %f726, %f273, %f725;

BB10_276:
	selp.f32	%f727, 0f3C0885E4, 0f3D2AAABB, %p202;
	fma.rn.f32 	%f728, %f842, %f273, %f727;
	selp.f32	%f729, 0fBE2AAAA8, 0fBEFFFFFF, %p202;
	fma.rn.f32 	%f730, %f728, %f273, %f729;
	fma.rn.f32 	%f843, %f730, %f274, %f272;
	and.b32  	%r1243, %r1468, 2;
	setp.eq.s32	%p204, %r1243, 0;
	@%p204 bra 	BB10_278;

	mov.f32 	%f732, 0fBF800000;
	fma.rn.f32 	%f843, %f843, %f732, %f317;

BB10_278:
	and.b32  	%r1244, %r1, 511;
	and.b32  	%r1246, %r636, 1073740800;
	add.s32 	%r1247, %r1246, %r1244;
	mul.f32 	%f733, %f254, %f843;
	mul.f32 	%f734, %f253, %f840;
	sub.f32 	%f735, %f734, %f733;
	mul.f32 	%f736, %f254, %f840;
	fma.rn.f32 	%f737, %f253, %f843, %f736;
	add.f32 	%f738, %f251, %f735;
	shl.b32 	%r1248, %r1247, 2;
	add.s32 	%r1250, %r641, %r1248;
	st.shared.f32 	[%r1250], %f738;
	add.f32 	%f739, %f252, %f737;
	add.s32 	%r1252, %r643, %r1248;
	st.shared.f32 	[%r1252], %f739;
	sub.f32 	%f740, %f251, %f735;
	st.shared.f32 	[%r1250+2048], %f740;
	sub.f32 	%f741, %f252, %f737;
	st.shared.f32 	[%r1252+2048], %f741;
	bar.sync 	0;
	ld.shared.f32 	%f280, [%r647];
	ld.shared.f32 	%f281, [%r649];
	ld.shared.f32 	%f282, [%r647+4096];
	ld.shared.f32 	%f283, [%r649+4096];
	shr.u32 	%r1259, %r650, 22;
	add.s32 	%r1260, %r1, %r1259;
	and.b32  	%r1261, %r1260, -1024;
	sub.s32 	%r1262, %r1, %r1261;
	cvt.rn.f32.s32	%f742, %r1262;
	mul.f32 	%f743, %f742, 0f3A000000;
	cvt.f64.f32	%fd55, %f743;
	mul.f64 	%fd56, %fd55, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f284, %fd56;
	mul.f32 	%f744, %f284, 0f3F22F983;
	cvt.rni.s32.f32	%r1484, %f744;
	cvt.rn.f32.s32	%f745, %r1484;
	fma.rn.f32 	%f747, %f745, %f312, %f284;
	fma.rn.f32 	%f749, %f745, %f314, %f747;
	fma.rn.f32 	%f847, %f745, %f316, %f749;
	abs.f32 	%f286, %f284;
	setp.leu.f32	%p205, %f286, 0f47CE4780;
	mov.u32 	%r1476, %r1484;
	mov.f32 	%f844, %f847;
	@%p205 bra 	BB10_289;

	setp.eq.f32	%p206, %f286, 0f7F800000;
	@%p206 bra 	BB10_288;
	bra.uni 	BB10_280;

BB10_288:
	mul.rn.f32 	%f844, %f284, %f317;
	mov.u32 	%r1476, %r1484;
	bra.uni 	BB10_289;

BB10_280:
	mov.b32 	 %r501, %f284;
	shl.b32 	%r1265, %r501, 8;
	or.b32  	%r502, %r1265, -2147483648;
	add.u64 	%rd271, %SP, 0;
	add.u64 	%rd328, %SPL, 0;
	mov.u32 	%r1470, 0;
	mov.u64 	%rd327, __cudart_i2opi_f;
	mov.u32 	%r1469, -6;

BB10_281:
	.pragma "nounroll";
	ld.const.u32 	%r1268, [%rd327];
	// inline asm
	{
	mad.lo.cc.u32   %r1266, %r1268, %r502, %r1470;
	madc.hi.u32     %r1470, %r1268, %r502,  0;
	}
	// inline asm
	st.local.u32 	[%rd328], %r1266;
	add.s64 	%rd328, %rd328, 4;
	add.s64 	%rd327, %rd327, 4;
	add.s32 	%r1469, %r1469, 1;
	setp.ne.s32	%p207, %r1469, 0;
	@%p207 bra 	BB10_281;

	bfe.u32 	%r1271, %r501, 23, 8;
	add.s32 	%r1272, %r1271, -128;
	shr.u32 	%r1273, %r1272, 5;
	and.b32  	%r507, %r501, -2147483648;
	cvta.to.local.u64 	%rd273, %rd271;
	st.local.u32 	[%rd273+24], %r1470;
	bfe.u32 	%r508, %r501, 23, 5;
	mov.u32 	%r1274, 6;
	sub.s32 	%r1275, %r1274, %r1273;
	mul.wide.s32 	%rd274, %r1275, 4;
	add.s64 	%rd114, %rd273, %rd274;
	ld.local.u32 	%r1472, [%rd114];
	ld.local.u32 	%r1471, [%rd114+-4];
	setp.eq.s32	%p208, %r508, 0;
	@%p208 bra 	BB10_284;

	mov.u32 	%r1276, 32;
	sub.s32 	%r1277, %r1276, %r508;
	shr.u32 	%r1278, %r1471, %r1277;
	shl.b32 	%r1279, %r1472, %r508;
	add.s32 	%r1472, %r1278, %r1279;
	ld.local.u32 	%r1280, [%rd114+-8];
	shr.u32 	%r1281, %r1280, %r1277;
	shl.b32 	%r1282, %r1471, %r508;
	add.s32 	%r1471, %r1281, %r1282;

BB10_284:
	shr.u32 	%r1283, %r1471, 30;
	shl.b32 	%r1284, %r1472, 2;
	add.s32 	%r1474, %r1284, %r1283;
	shl.b32 	%r516, %r1471, 2;
	shr.u32 	%r1285, %r1474, 31;
	shr.u32 	%r1286, %r1472, 30;
	add.s32 	%r517, %r1285, %r1286;
	setp.eq.s32	%p209, %r1285, 0;
	@%p209 bra 	BB10_285;

	not.b32 	%r1287, %r1474;
	neg.s32 	%r1473, %r516;
	setp.eq.s32	%p210, %r516, 0;
	selp.u32	%r1288, 1, 0, %p210;
	add.s32 	%r1474, %r1288, %r1287;
	xor.b32  	%r1475, %r507, -2147483648;
	bra.uni 	BB10_287;

BB10_285:
	mov.u32 	%r1473, %r516;
	mov.u32 	%r1475, %r507;

BB10_287:
	cvt.u64.u32	%rd275, %r1474;
	cvt.u64.u32	%rd276, %r1473;
	bfi.b64 	%rd277, %rd275, %rd276, 32, 32;
	cvt.rn.f64.s64	%fd57, %rd277;
	mul.f64 	%fd58, %fd57, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f751, %fd58;
	neg.f32 	%f752, %f751;
	setp.eq.s32	%p211, %r1475, 0;
	selp.f32	%f844, %f751, %f752, %p211;
	setp.eq.s32	%p212, %r507, 0;
	neg.s32 	%r1289, %r517;
	selp.b32	%r1476, %r517, %r1289, %p212;

BB10_289:
	add.s32 	%r526, %r1476, 1;
	and.b32  	%r527, %r526, 1;
	setp.eq.s32	%p213, %r527, 0;
	selp.f32	%f290, %f844, 0f3F800000, %p213;
	mul.rn.f32 	%f291, %f844, %f844;
	fma.rn.f32 	%f292, %f291, %f290, %f317;
	mov.f32 	%f845, 0fB94D4153;
	@%p213 bra 	BB10_291;

	mov.f32 	%f756, 0fBAB607ED;
	mov.f32 	%f757, 0f37CBAC00;
	fma.rn.f32 	%f845, %f757, %f291, %f756;

BB10_291:
	selp.f32	%f758, 0f3C0885E4, 0f3D2AAABB, %p213;
	fma.rn.f32 	%f759, %f845, %f291, %f758;
	selp.f32	%f760, 0fBE2AAAA8, 0fBEFFFFFF, %p213;
	fma.rn.f32 	%f761, %f759, %f291, %f760;
	fma.rn.f32 	%f846, %f761, %f292, %f290;
	and.b32  	%r1290, %r526, 2;
	setp.eq.s32	%p215, %r1290, 0;
	@%p215 bra 	BB10_293;

	mov.f32 	%f763, 0fBF800000;
	fma.rn.f32 	%f846, %f846, %f763, %f317;

BB10_293:
	@%p205 bra 	BB10_304;

	setp.eq.f32	%p217, %f286, 0f7F800000;
	@%p217 bra 	BB10_303;
	bra.uni 	BB10_295;

BB10_303:
	mul.rn.f32 	%f847, %f284, %f317;
	bra.uni 	BB10_304;

BB10_295:
	mov.b32 	 %r528, %f284;
	shl.b32 	%r1293, %r528, 8;
	or.b32  	%r529, %r1293, -2147483648;
	add.u64 	%rd279, %SP, 0;
	add.u64 	%rd330, %SPL, 0;
	mov.u32 	%r1478, 0;
	mov.u64 	%rd329, __cudart_i2opi_f;
	mov.u32 	%r1477, -6;

BB10_296:
	.pragma "nounroll";
	ld.const.u32 	%r1296, [%rd329];
	// inline asm
	{
	mad.lo.cc.u32   %r1294, %r1296, %r529, %r1478;
	madc.hi.u32     %r1478, %r1296, %r529,  0;
	}
	// inline asm
	st.local.u32 	[%rd330], %r1294;
	add.s64 	%rd330, %rd330, 4;
	add.s64 	%rd329, %rd329, 4;
	add.s32 	%r1477, %r1477, 1;
	setp.ne.s32	%p218, %r1477, 0;
	@%p218 bra 	BB10_296;

	bfe.u32 	%r1299, %r528, 23, 8;
	add.s32 	%r1300, %r1299, -128;
	shr.u32 	%r1301, %r1300, 5;
	and.b32  	%r534, %r528, -2147483648;
	cvta.to.local.u64 	%rd281, %rd279;
	st.local.u32 	[%rd281+24], %r1478;
	bfe.u32 	%r535, %r528, 23, 5;
	mov.u32 	%r1302, 6;
	sub.s32 	%r1303, %r1302, %r1301;
	mul.wide.s32 	%rd282, %r1303, 4;
	add.s64 	%rd120, %rd281, %rd282;
	ld.local.u32 	%r1480, [%rd120];
	ld.local.u32 	%r1479, [%rd120+-4];
	setp.eq.s32	%p219, %r535, 0;
	@%p219 bra 	BB10_299;

	mov.u32 	%r1304, 32;
	sub.s32 	%r1305, %r1304, %r535;
	shr.u32 	%r1306, %r1479, %r1305;
	shl.b32 	%r1307, %r1480, %r535;
	add.s32 	%r1480, %r1306, %r1307;
	ld.local.u32 	%r1308, [%rd120+-8];
	shr.u32 	%r1309, %r1308, %r1305;
	shl.b32 	%r1310, %r1479, %r535;
	add.s32 	%r1479, %r1309, %r1310;

BB10_299:
	shr.u32 	%r1311, %r1479, 30;
	shl.b32 	%r1312, %r1480, 2;
	add.s32 	%r1482, %r1312, %r1311;
	shl.b32 	%r543, %r1479, 2;
	shr.u32 	%r1313, %r1482, 31;
	shr.u32 	%r1314, %r1480, 30;
	add.s32 	%r544, %r1313, %r1314;
	setp.eq.s32	%p220, %r1313, 0;
	@%p220 bra 	BB10_300;

	not.b32 	%r1315, %r1482;
	neg.s32 	%r1481, %r543;
	setp.eq.s32	%p221, %r543, 0;
	selp.u32	%r1316, 1, 0, %p221;
	add.s32 	%r1482, %r1316, %r1315;
	xor.b32  	%r1483, %r534, -2147483648;
	bra.uni 	BB10_302;

BB10_300:
	mov.u32 	%r1481, %r543;
	mov.u32 	%r1483, %r534;

BB10_302:
	cvt.u64.u32	%rd283, %r1482;
	cvt.u64.u32	%rd284, %r1481;
	bfi.b64 	%rd285, %rd283, %rd284, 32, 32;
	cvt.rn.f64.s64	%fd59, %rd285;
	mul.f64 	%fd60, %fd59, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f764, %fd60;
	neg.f32 	%f765, %f764;
	setp.eq.s32	%p222, %r1483, 0;
	selp.f32	%f847, %f764, %f765, %p222;
	setp.eq.s32	%p223, %r534, 0;
	neg.s32 	%r1317, %r544;
	selp.b32	%r1484, %r544, %r1317, %p223;

BB10_304:
	and.b32  	%r553, %r1484, 1;
	setp.eq.s32	%p224, %r553, 0;
	selp.f32	%f301, %f847, 0f3F800000, %p224;
	mul.rn.f32 	%f302, %f847, %f847;
	fma.rn.f32 	%f303, %f302, %f301, %f317;
	mov.f32 	%f848, 0fB94D4153;
	@%p224 bra 	BB10_306;

	mov.f32 	%f769, 0fBAB607ED;
	mov.f32 	%f770, 0f37CBAC00;
	fma.rn.f32 	%f848, %f770, %f302, %f769;

BB10_306:
	selp.f32	%f771, 0f3C0885E4, 0f3D2AAABB, %p224;
	fma.rn.f32 	%f772, %f848, %f302, %f771;
	selp.f32	%f773, 0fBE2AAAA8, 0fBEFFFFFF, %p224;
	fma.rn.f32 	%f774, %f772, %f302, %f773;
	fma.rn.f32 	%f849, %f774, %f303, %f301;
	and.b32  	%r1318, %r1484, 2;
	setp.eq.s32	%p226, %r1318, 0;
	@%p226 bra 	BB10_308;

	mov.f32 	%f776, 0fBF800000;
	fma.rn.f32 	%f849, %f849, %f776, %f317;

BB10_308:
	mul.f32 	%f777, %f283, %f849;
	mul.f32 	%f778, %f282, %f846;
	sub.f32 	%f779, %f778, %f777;
	mul.f32 	%f780, %f283, %f846;
	fma.rn.f32 	%f781, %f282, %f849, %f780;
	add.f32 	%f782, %f280, %f779;
	add.s32 	%r1324, %r559, %r1;
	mul.wide.u32 	%rd287, %r1324, 4;
	add.s64 	%rd288, %rd123, %rd287;
	st.global.f32 	[%rd288], %f782;
	add.f32 	%f783, %f281, %f781;
	cvta.to.global.u64 	%rd289, %rd122;
	add.s64 	%rd290, %rd289, %rd287;
	st.global.f32 	[%rd290], %f783;
	sub.f32 	%f784, %f280, %f779;
	st.global.f32 	[%rd288+4096], %f784;
	sub.f32 	%f785, %f281, %f781;
	st.global.f32 	[%rd290+4096], %f785;
	ret;
}

	// .globl	_occa_preprocessed_ODW11_STH_STFT_0
.visible .entry _occa_preprocessed_ODW11_STH_STFT_0(
	.param .u64 _occa_preprocessed_ODW11_STH_STFT_0_param_0,
	.param .u32 _occa_preprocessed_ODW11_STH_STFT_0_param_1,
	.param .u32 _occa_preprocessed_ODW11_STH_STFT_0_param_2,
	.param .u32 _occa_preprocessed_ODW11_STH_STFT_0_param_3,
	.param .u32 _occa_preprocessed_ODW11_STH_STFT_0_param_4,
	.param .u64 _occa_preprocessed_ODW11_STH_STFT_0_param_5,
	.param .u64 _occa_preprocessed_ODW11_STH_STFT_0_param_6
)
.maxntid 1024, 1, 1
{
	.local .align 4 .b8 	__local_depot11[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<261>;
	.reg .b16 	%rs<10>;
	.reg .f32 	%f<999>;
	.reg .b32 	%r<1684>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<365>;
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6FRBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6FIBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6SRBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6SIBank[8192];
	// demoted variable
	.shared .align 4 .b8 _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E11windowAdded[4096];

	mov.u64 	%SPL, __local_depot11;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd135, [_occa_preprocessed_ODW11_STH_STFT_0_param_0];
	ld.param.u32 	%r614, [_occa_preprocessed_ODW11_STH_STFT_0_param_2];
	ld.param.u32 	%r615, [_occa_preprocessed_ODW11_STH_STFT_0_param_3];
	ld.param.u64 	%rd133, [_occa_preprocessed_ODW11_STH_STFT_0_param_5];
	ld.param.u64 	%rd134, [_occa_preprocessed_ODW11_STH_STFT_0_param_6];
	mov.u32 	%r616, %ctaid.x;
	and.b32  	%r617, %r616, 4194303;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r618, %r617, %r615, %r1;
	add.s32 	%r619, %r618, 1024;
	setp.lt.u32	%p1, %r618, %r614;
	setp.lt.u32	%p2, %r619, %r614;
	cvt.u64.u32	%rd136, %r618;
	selp.b64	%rd137, %rd136, 0, %p1;
	cvta.to.global.u64 	%rd138, %rd135;
	shl.b64 	%rd139, %rd137, 2;
	add.s64 	%rd140, %rd138, %rd139;
	ld.global.f32 	%f341, [%rd140];
	selp.f32	%f342, %f341, 0f00000000, %p1;
	shl.b32 	%r620, %r1, 2;
	mov.u32 	%r621, _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6FRBank;
	add.s32 	%r2, %r621, %r620;
	st.shared.f32 	[%r2], %f342;
	mov.u32 	%r622, _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6FIBank;
	add.s32 	%r3, %r622, %r620;
	mov.u32 	%r1677, 0;
	st.shared.u32 	[%r3], %r1677;
	cvt.u64.u32	%rd141, %r619;
	selp.b64	%rd142, %rd141, 0, %p2;
	shl.b64 	%rd143, %rd142, 2;
	add.s64 	%rd144, %rd138, %rd143;
	ld.global.f32 	%f343, [%rd144];
	selp.f32	%f344, %f343, 0f00000000, %p2;
	st.shared.f32 	[%r2+4096], %f344;
	st.shared.u32 	[%r3+4096], %r1677;
	bar.sync 	0;
	ld.shared.f32 	%f345, [%r2+4096];
	ld.shared.f32 	%f346, [%r2];
	add.f32 	%f347, %f346, %f345;
	mov.u32 	%r625, _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E11windowAdded;
	add.s32 	%r4, %r625, %r620;
	st.shared.f32 	[%r4], %f347;
	bar.sync 	0;
	setp.lt.s32	%p3, %r1, 512;
	selp.u16	%rs1, 1, 0, %p3;
	mul.wide.u16 	%r626, %rs1, 512;
	add.s32 	%r627, %r626, %r1;
	shl.b32 	%r628, %r627, 2;
	add.s32 	%r630, %r625, %r628;
	ld.shared.f32 	%f348, [%r630];
	ld.shared.f32 	%f349, [%r4];
	add.f32 	%f350, %f349, %f348;
	selp.u32	%r631, 1, 0, %p3;
	cvt.rn.f32.u32	%f351, %r631;
	mul.f32 	%f352, %f351, %f350;
	st.shared.f32 	[%r4], %f352;
	bar.sync 	0;
	setp.lt.s32	%p4, %r1, 256;
	selp.u16	%rs2, 1, 0, %p4;
	mul.wide.u16 	%r632, %rs2, 256;
	add.s32 	%r633, %r632, %r1;
	shl.b32 	%r634, %r633, 2;
	add.s32 	%r636, %r625, %r634;
	ld.shared.f32 	%f353, [%r636];
	ld.shared.f32 	%f354, [%r4];
	add.f32 	%f355, %f354, %f353;
	selp.u32	%r637, 1, 0, %p4;
	cvt.rn.f32.u32	%f356, %r637;
	mul.f32 	%f357, %f356, %f355;
	st.shared.f32 	[%r4], %f357;
	bar.sync 	0;
	setp.lt.s32	%p5, %r1, 128;
	selp.u16	%rs3, 1, 0, %p5;
	mul.wide.u16 	%r638, %rs3, 128;
	add.s32 	%r639, %r638, %r1;
	shl.b32 	%r640, %r639, 2;
	add.s32 	%r642, %r625, %r640;
	ld.shared.f32 	%f358, [%r642];
	ld.shared.f32 	%f359, [%r4];
	add.f32 	%f360, %f359, %f358;
	selp.u32	%r643, 1, 0, %p5;
	cvt.rn.f32.u32	%f361, %r643;
	mul.f32 	%f362, %f361, %f360;
	st.shared.f32 	[%r4], %f362;
	bar.sync 	0;
	setp.lt.s32	%p6, %r1, 64;
	selp.u16	%rs4, 1, 0, %p6;
	mul.wide.u16 	%r644, %rs4, 64;
	add.s32 	%r645, %r644, %r1;
	shl.b32 	%r646, %r645, 2;
	add.s32 	%r648, %r625, %r646;
	ld.shared.f32 	%f363, [%r648];
	ld.shared.f32 	%f364, [%r4];
	add.f32 	%f365, %f364, %f363;
	selp.u32	%r649, 1, 0, %p6;
	cvt.rn.f32.u32	%f366, %r649;
	mul.f32 	%f367, %f366, %f365;
	st.shared.f32 	[%r4], %f367;
	bar.sync 	0;
	setp.lt.s32	%p7, %r1, 32;
	selp.u16	%rs5, 1, 0, %p7;
	mul.wide.u16 	%r650, %rs5, 32;
	add.s32 	%r651, %r650, %r1;
	shl.b32 	%r652, %r651, 2;
	add.s32 	%r654, %r625, %r652;
	ld.shared.f32 	%f368, [%r654];
	ld.shared.f32 	%f369, [%r4];
	add.f32 	%f370, %f369, %f368;
	selp.u32	%r655, 1, 0, %p7;
	cvt.rn.f32.u32	%f371, %r655;
	mul.f32 	%f372, %f371, %f370;
	st.shared.f32 	[%r4], %f372;
	bar.sync 	0;
	setp.lt.s32	%p8, %r1, 16;
	selp.u16	%rs6, 1, 0, %p8;
	mul.wide.u16 	%r656, %rs6, 16;
	add.s32 	%r657, %r656, %r1;
	shl.b32 	%r658, %r657, 2;
	add.s32 	%r660, %r625, %r658;
	ld.shared.f32 	%f373, [%r660];
	ld.shared.f32 	%f374, [%r4];
	add.f32 	%f375, %f374, %f373;
	selp.u32	%r661, 1, 0, %p8;
	cvt.rn.f32.u32	%f376, %r661;
	mul.f32 	%f377, %f376, %f375;
	st.shared.f32 	[%r4], %f377;
	bar.sync 	0;
	setp.lt.s32	%p9, %r1, 8;
	selp.u16	%rs7, 1, 0, %p9;
	mul.wide.u16 	%r662, %rs7, 8;
	add.s32 	%r663, %r662, %r1;
	shl.b32 	%r664, %r663, 2;
	add.s32 	%r666, %r625, %r664;
	ld.shared.f32 	%f378, [%r666];
	ld.shared.f32 	%f379, [%r4];
	add.f32 	%f380, %f379, %f378;
	selp.u32	%r667, 1, 0, %p9;
	cvt.rn.f32.u32	%f381, %r667;
	mul.f32 	%f382, %f381, %f380;
	st.shared.f32 	[%r4], %f382;
	bar.sync 	0;
	setp.lt.s32	%p10, %r1, 4;
	selp.u16	%rs8, 1, 0, %p10;
	mul.wide.u16 	%r668, %rs8, 4;
	add.s32 	%r669, %r668, %r1;
	shl.b32 	%r670, %r669, 2;
	add.s32 	%r672, %r625, %r670;
	ld.shared.f32 	%f383, [%r672];
	ld.shared.f32 	%f384, [%r4];
	add.f32 	%f385, %f384, %f383;
	selp.u32	%r673, 1, 0, %p10;
	cvt.rn.f32.u32	%f386, %r673;
	mul.f32 	%f387, %f386, %f385;
	st.shared.f32 	[%r4], %f387;
	bar.sync 	0;
	setp.lt.s32	%p11, %r1, 2;
	selp.u16	%rs9, 1, 0, %p11;
	mul.wide.u16 	%r674, %rs9, 2;
	add.s32 	%r675, %r674, %r1;
	shl.b32 	%r676, %r675, 2;
	add.s32 	%r678, %r625, %r676;
	ld.shared.f32 	%f388, [%r678];
	ld.shared.f32 	%f389, [%r4];
	add.f32 	%f390, %f389, %f388;
	selp.u32	%r679, 1, 0, %p11;
	cvt.rn.f32.u32	%f391, %r679;
	mul.f32 	%f392, %f391, %f390;
	st.shared.f32 	[%r4], %f392;
	bar.sync 	0;
	setp.lt.s32	%p12, %r1, 1;
	selp.u32	%r680, 1, 0, %p12;
	add.s32 	%r681, %r680, %r1;
	shl.b32 	%r682, %r681, 2;
	add.s32 	%r684, %r625, %r682;
	ld.shared.f32 	%f393, [%r684];
	ld.shared.f32 	%f394, [%r4];
	add.f32 	%f395, %f394, %f393;
	cvt.rn.f32.u32	%f396, %r680;
	mul.f32 	%f397, %f396, %f395;
	st.shared.f32 	[%r4], %f397;
	bar.sync 	0;
	ld.shared.f32 	%f398, [_ZZ35_occa_preprocessed_ODW11_STH_STFT_0E11windowAdded];
	cvt.f64.f32	%fd2, %f398;
	mul.f64 	%fd1, %fd2, 0d3F40000000000000;
	ld.shared.f32 	%f399, [%r2];
	cvt.f64.f32	%fd3, %f399;
	sub.f64 	%fd4, %fd3, %fd1;
	cvt.rn.f32.f64	%f1, %fd4;
	st.shared.f32 	[%r2], %f1;
	cvt.rn.f32.s32	%f400, %r1;
	div.rn.f32 	%f401, %f400, 0f44FFE000;
	cvt.f64.f32	%fd5, %f401;
	mul.f64 	%fd6, %fd5, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f2, %fd6;
	add.u64 	%rd145, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mul.f32 	%f402, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r1515, %f402;
	cvt.rn.f32.s32	%f403, %r1515;
	mov.f32 	%f404, 0fBFC90FDA;
	fma.rn.f32 	%f405, %f403, %f404, %f2;
	mov.f32 	%f406, 0fB3A22168;
	fma.rn.f32 	%f407, %f403, %f406, %f405;
	mov.f32 	%f408, 0fA7C234C5;
	fma.rn.f32 	%f929, %f403, %f408, %f407;
	abs.f32 	%f4, %f2;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p13, %f4, 0f47CE4780;
	@%p13 bra 	BB11_11;

	setp.eq.f32	%p14, %f4, 0f7F800000;
	@%p14 bra 	BB11_10;
	bra.uni 	BB11_2;

BB11_10:
	mov.f32 	%f411, 0f00000000;
	mul.rn.f32 	%f929, %f2, %f411;
	bra.uni 	BB11_11;

BB11_2:
	mov.b32 	 %r6, %f2;
	shl.b32 	%r687, %r6, 8;
	or.b32  	%r7, %r687, -2147483648;
	mov.u32 	%r1509, 0;
	mov.u64 	%rd321, __cudart_i2opi_f;
	mov.u32 	%r1508, -6;
	mov.u64 	%rd322, %rd1;

BB11_3:
	.pragma "nounroll";
	ld.const.u32 	%r690, [%rd321];
	// inline asm
	{
	mad.lo.cc.u32   %r688, %r690, %r7, %r1509;
	madc.hi.u32     %r1509, %r690, %r7,  0;
	}
	// inline asm
	st.local.u32 	[%rd322], %r688;
	add.s64 	%rd322, %rd322, 4;
	add.s64 	%rd321, %rd321, 4;
	add.s32 	%r1508, %r1508, 1;
	setp.ne.s32	%p15, %r1508, 0;
	@%p15 bra 	BB11_3;

	bfe.u32 	%r693, %r6, 23, 8;
	add.s32 	%r694, %r693, -128;
	shr.u32 	%r695, %r694, 5;
	and.b32  	%r12, %r6, -2147483648;
	st.local.u32 	[%rd2], %r1509;
	bfe.u32 	%r13, %r6, 23, 5;
	mov.u32 	%r696, 6;
	sub.s32 	%r697, %r696, %r695;
	mul.wide.s32 	%rd147, %r697, 4;
	add.s64 	%rd7, %rd1, %rd147;
	ld.local.u32 	%r1511, [%rd7];
	ld.local.u32 	%r1510, [%rd7+-4];
	setp.eq.s32	%p16, %r13, 0;
	@%p16 bra 	BB11_6;

	mov.u32 	%r698, 32;
	sub.s32 	%r699, %r698, %r13;
	shr.u32 	%r700, %r1510, %r699;
	shl.b32 	%r701, %r1511, %r13;
	add.s32 	%r1511, %r700, %r701;
	ld.local.u32 	%r702, [%rd7+-8];
	shr.u32 	%r703, %r702, %r699;
	shl.b32 	%r704, %r1510, %r13;
	add.s32 	%r1510, %r703, %r704;

BB11_6:
	shr.u32 	%r705, %r1510, 30;
	shl.b32 	%r706, %r1511, 2;
	add.s32 	%r1513, %r706, %r705;
	shl.b32 	%r21, %r1510, 2;
	shr.u32 	%r707, %r1513, 31;
	shr.u32 	%r708, %r1511, 30;
	add.s32 	%r22, %r707, %r708;
	setp.eq.s32	%p17, %r707, 0;
	@%p17 bra 	BB11_7;

	not.b32 	%r709, %r1513;
	neg.s32 	%r1512, %r21;
	setp.eq.s32	%p18, %r21, 0;
	selp.u32	%r710, 1, 0, %p18;
	add.s32 	%r1513, %r710, %r709;
	xor.b32  	%r1514, %r12, -2147483648;
	bra.uni 	BB11_9;

BB11_7:
	mov.u32 	%r1512, %r21;
	mov.u32 	%r1514, %r12;

BB11_9:
	cvt.u64.u32	%rd148, %r1513;
	cvt.u64.u32	%rd149, %r1512;
	bfi.b64 	%rd150, %rd148, %rd149, 32, 32;
	cvt.rn.f64.s64	%fd7, %rd150;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f409, %fd8;
	neg.f32 	%f410, %f409;
	setp.eq.s32	%p19, %r1514, 0;
	selp.f32	%f929, %f409, %f410, %p19;
	setp.eq.s32	%p20, %r12, 0;
	neg.s32 	%r711, %r22;
	selp.b32	%r1515, %r22, %r711, %p20;

BB11_11:
	add.s32 	%r31, %r1515, 1;
	and.b32  	%r32, %r31, 1;
	setp.eq.s32	%p21, %r32, 0;
	selp.f32	%f8, %f929, 0f3F800000, %p21;
	mul.rn.f32 	%f9, %f929, %f929;
	mov.f32 	%f413, 0f00000000;
	fma.rn.f32 	%f10, %f9, %f8, %f413;
	mov.f32 	%f930, 0fB94D4153;
	@%p21 bra 	BB11_13;

	mov.f32 	%f414, 0fBAB607ED;
	mov.f32 	%f415, 0f37CBAC00;
	fma.rn.f32 	%f930, %f415, %f9, %f414;

BB11_13:
	selp.f32	%f416, 0f3C0885E4, 0f3D2AAABB, %p21;
	fma.rn.f32 	%f417, %f930, %f9, %f416;
	selp.f32	%f418, 0fBE2AAAA8, 0fBEFFFFFF, %p21;
	fma.rn.f32 	%f419, %f417, %f9, %f418;
	fma.rn.f32 	%f931, %f419, %f10, %f8;
	and.b32  	%r712, %r31, 2;
	setp.eq.s32	%p23, %r712, 0;
	@%p23 bra 	BB11_15;

	mov.f32 	%f421, 0fBF800000;
	fma.rn.f32 	%f931, %f931, %f421, %f413;

BB11_15:
	mov.f32 	%f422, 0f3F800000;
	sub.f32 	%f423, %f422, %f931;
	mul.f32 	%f424, %f423, 0f3F000000;
	mul.f32 	%f425, %f1, %f424;
	st.shared.f32 	[%r2], %f425;
	ld.shared.f32 	%f426, [%r2+4096];
	cvt.f64.f32	%fd9, %f426;
	sub.f64 	%fd10, %fd9, %fd1;
	cvt.rn.f32.f64	%f16, %fd10;
	st.shared.f32 	[%r2+4096], %f16;
	add.s32 	%r713, %r1, 1024;
	cvt.rn.f32.s32	%f427, %r713;
	div.rn.f32 	%f428, %f427, 0f44FFE000;
	cvt.f64.f32	%fd11, %f428;
	mul.f64 	%fd12, %fd11, 0d401921FB54442D18;
	cvt.rn.f32.f64	%f17, %fd12;
	mul.f32 	%f429, %f17, 0f3F22F983;
	cvt.rni.s32.f32	%r1523, %f429;
	cvt.rn.f32.s32	%f430, %r1523;
	fma.rn.f32 	%f432, %f430, %f404, %f17;
	fma.rn.f32 	%f434, %f430, %f406, %f432;
	fma.rn.f32 	%f932, %f430, %f408, %f434;
	abs.f32 	%f19, %f17;
	setp.leu.f32	%p24, %f19, 0f47CE4780;
	@%p24 bra 	BB11_26;

	setp.eq.f32	%p25, %f19, 0f7F800000;
	@%p25 bra 	BB11_25;
	bra.uni 	BB11_17;

BB11_25:
	mul.rn.f32 	%f932, %f17, %f413;
	bra.uni 	BB11_26;

BB11_17:
	mov.b32 	 %r34, %f17;
	shl.b32 	%r716, %r34, 8;
	or.b32  	%r35, %r716, -2147483648;
	mov.u32 	%r1517, 0;
	mov.u64 	%rd323, __cudart_i2opi_f;
	mov.u32 	%r1516, -6;
	mov.u64 	%rd324, %rd1;

BB11_18:
	.pragma "nounroll";
	ld.const.u32 	%r719, [%rd323];
	// inline asm
	{
	mad.lo.cc.u32   %r717, %r719, %r35, %r1517;
	madc.hi.u32     %r1517, %r719, %r35,  0;
	}
	// inline asm
	st.local.u32 	[%rd324], %r717;
	add.s64 	%rd324, %rd324, 4;
	add.s64 	%rd323, %rd323, 4;
	add.s32 	%r1516, %r1516, 1;
	setp.ne.s32	%p26, %r1516, 0;
	@%p26 bra 	BB11_18;

	bfe.u32 	%r722, %r34, 23, 8;
	add.s32 	%r723, %r722, -128;
	shr.u32 	%r724, %r723, 5;
	and.b32  	%r40, %r34, -2147483648;
	st.local.u32 	[%rd2], %r1517;
	bfe.u32 	%r41, %r34, 23, 5;
	mov.u32 	%r725, 6;
	sub.s32 	%r726, %r725, %r724;
	mul.wide.s32 	%rd152, %r726, 4;
	add.s64 	%rd12, %rd1, %rd152;
	ld.local.u32 	%r1519, [%rd12];
	ld.local.u32 	%r1518, [%rd12+-4];
	setp.eq.s32	%p27, %r41, 0;
	@%p27 bra 	BB11_21;

	mov.u32 	%r727, 32;
	sub.s32 	%r728, %r727, %r41;
	shr.u32 	%r729, %r1518, %r728;
	shl.b32 	%r730, %r1519, %r41;
	add.s32 	%r1519, %r729, %r730;
	ld.local.u32 	%r731, [%rd12+-8];
	shr.u32 	%r732, %r731, %r728;
	shl.b32 	%r733, %r1518, %r41;
	add.s32 	%r1518, %r732, %r733;

BB11_21:
	shr.u32 	%r734, %r1518, 30;
	shl.b32 	%r735, %r1519, 2;
	add.s32 	%r1521, %r735, %r734;
	shl.b32 	%r49, %r1518, 2;
	shr.u32 	%r736, %r1521, 31;
	shr.u32 	%r737, %r1519, 30;
	add.s32 	%r50, %r736, %r737;
	setp.eq.s32	%p28, %r736, 0;
	@%p28 bra 	BB11_22;

	not.b32 	%r738, %r1521;
	neg.s32 	%r1520, %r49;
	setp.eq.s32	%p29, %r49, 0;
	selp.u32	%r739, 1, 0, %p29;
	add.s32 	%r1521, %r739, %r738;
	xor.b32  	%r1522, %r40, -2147483648;
	bra.uni 	BB11_24;

BB11_22:
	mov.u32 	%r1520, %r49;
	mov.u32 	%r1522, %r40;

BB11_24:
	cvt.u64.u32	%rd153, %r1521;
	cvt.u64.u32	%rd154, %r1520;
	bfi.b64 	%rd155, %rd153, %rd154, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd155;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f436, %fd14;
	neg.f32 	%f437, %f436;
	setp.eq.s32	%p30, %r1522, 0;
	selp.f32	%f932, %f436, %f437, %p30;
	setp.eq.s32	%p31, %r40, 0;
	neg.s32 	%r740, %r50;
	selp.b32	%r1523, %r50, %r740, %p31;

BB11_26:
	add.s32 	%r59, %r1523, 1;
	and.b32  	%r60, %r59, 1;
	setp.eq.s32	%p32, %r60, 0;
	selp.f32	%f23, %f932, 0f3F800000, %p32;
	mul.rn.f32 	%f24, %f932, %f932;
	fma.rn.f32 	%f25, %f24, %f23, %f413;
	mov.f32 	%f933, 0fB94D4153;
	@%p32 bra 	BB11_28;

	mov.f32 	%f441, 0fBAB607ED;
	mov.f32 	%f442, 0f37CBAC00;
	fma.rn.f32 	%f933, %f442, %f24, %f441;

BB11_28:
	selp.f32	%f443, 0f3C0885E4, 0f3D2AAABB, %p32;
	fma.rn.f32 	%f444, %f933, %f24, %f443;
	selp.f32	%f445, 0fBE2AAAA8, 0fBEFFFFFF, %p32;
	fma.rn.f32 	%f446, %f444, %f24, %f445;
	fma.rn.f32 	%f934, %f446, %f25, %f23;
	and.b32  	%r741, %r59, 2;
	setp.eq.s32	%p34, %r741, 0;
	@%p34 bra 	BB11_30;

	mov.f32 	%f448, 0fBF800000;
	fma.rn.f32 	%f934, %f934, %f448, %f413;

BB11_30:
	sub.f32 	%f450, %f422, %f934;
	mul.f32 	%f451, %f450, 0f3F000000;
	mul.f32 	%f452, %f16, %f451;
	st.shared.f32 	[%r2+4096], %f452;
	bar.sync 	0;
	ld.shared.f32 	%f31, [%r2];
	ld.shared.f32 	%f32, [%r3];
	ld.shared.f32 	%f33, [%r2+4096];
	ld.shared.f32 	%f34, [%r3+4096];
	mov.f32 	%f454, 0f80000000;
	cvt.rni.s32.f32	%r62, %f454;
	cvt.rn.f32.s32	%f455, %r62;
	fma.rn.f32 	%f457, %f455, %f404, %f454;
	fma.rn.f32 	%f459, %f455, %f406, %f457;
	fma.rn.f32 	%f35, %f455, %f408, %f459;
	mul.rn.f32 	%f36, %f35, %f35;
	add.s32 	%r742, %r62, 1;
	and.b32  	%r63, %r742, 1;
	setp.eq.s32	%p35, %r63, 0;
	selp.f32	%f37, %f35, 0f3F800000, %p35;
	fma.rn.f32 	%f38, %f36, %f37, %f413;
	mov.f32 	%f935, 0fB94D4153;
	@%p35 bra 	BB11_32;

	mov.f32 	%f462, 0fBAB607ED;
	mov.f32 	%f463, 0f37CBAC00;
	fma.rn.f32 	%f935, %f463, %f36, %f462;

BB11_32:
	selp.f32	%f464, 0f3C0885E4, 0f3D2AAABB, %p35;
	fma.rn.f32 	%f465, %f935, %f36, %f464;
	selp.f32	%f466, 0fBE2AAAA8, 0fBEFFFFFF, %p35;
	fma.rn.f32 	%f467, %f465, %f36, %f466;
	fma.rn.f32 	%f936, %f467, %f38, %f37;
	and.b32  	%r744, %r742, 2;
	setp.eq.s32	%p37, %r744, 0;
	@%p37 bra 	BB11_34;

	mov.f32 	%f469, 0fBF800000;
	fma.rn.f32 	%f936, %f936, %f469, %f413;

BB11_34:
	and.b32  	%r64, %r62, 1;
	setp.eq.s32	%p38, %r64, 0;
	selp.f32	%f44, %f35, 0f3F800000, %p38;
	fma.rn.f32 	%f45, %f36, %f44, %f413;
	mov.f32 	%f937, 0fB94D4153;
	@%p38 bra 	BB11_36;

	mov.f32 	%f472, 0fBAB607ED;
	mov.f32 	%f473, 0f37CBAC00;
	fma.rn.f32 	%f937, %f473, %f36, %f472;

BB11_36:
	selp.f32	%f474, 0f3C0885E4, 0f3D2AAABB, %p38;
	fma.rn.f32 	%f475, %f937, %f36, %f474;
	selp.f32	%f476, 0fBE2AAAA8, 0fBEFFFFFF, %p38;
	fma.rn.f32 	%f477, %f475, %f36, %f476;
	fma.rn.f32 	%f938, %f477, %f45, %f44;
	and.b32  	%r745, %r62, 2;
	setp.eq.s32	%p40, %r745, 0;
	@%p40 bra 	BB11_38;

	mov.f32 	%f479, 0fBF800000;
	fma.rn.f32 	%f938, %f938, %f479, %f413;

BB11_38:
	mul.f32 	%f480, %f34, %f938;
	mul.f32 	%f481, %f33, %f936;
	sub.f32 	%f482, %f481, %f480;
	mul.f32 	%f483, %f34, %f936;
	fma.rn.f32 	%f484, %f33, %f938, %f483;
	add.f32 	%f485, %f31, %f482;
	shl.b32 	%r746, %r1, 3;
	mov.u32 	%r747, _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6SRBank;
	add.s32 	%r748, %r747, %r746;
	st.shared.f32 	[%r748], %f485;
	add.f32 	%f486, %f32, %f484;
	mov.u32 	%r749, _ZZ35_occa_preprocessed_ODW11_STH_STFT_0E6SIBank;
	add.s32 	%r750, %r749, %r746;
	st.shared.f32 	[%r750], %f486;
	sub.f32 	%f487, %f31, %f482;
	st.shared.f32 	[%r748+4], %f487;
	sub.f32 	%f488, %f32, %f484;
	st.shared.f32 	[%r750+4], %f488;
	bar.sync 	0;
	add.s32 	%r753, %r747, %r620;
	ld.shared.f32 	%f51, [%r753];
	add.s32 	%r755, %r749, %r620;
	ld.shared.f32 	%f52, [%r755];
	ld.shared.f32 	%f53, [%r753+4096];
	ld.shared.f32 	%f54, [%r755+4096];
	shr.u32 	%r756, %r1, 31;
	add.s32 	%r757, %r1, %r756;
	and.b32  	%r758, %r757, 8388606;
	sub.s32 	%r759, %r1, %r758;
	shl.b32 	%r760, %r759, 9;
	cvt.rn.f32.s32	%f489, %r760;
	mul.f32 	%f490, %f489, 0f3A000000;
	cvt.f64.f32	%fd15, %f490;
	mul.f64 	%fd16, %fd15, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f55, %fd16;
	mul.f32 	%f491, %f55, 0f3F22F983;
	cvt.rni.s32.f32	%r1539, %f491;
	cvt.rn.f32.s32	%f492, %r1539;
	fma.rn.f32 	%f494, %f492, %f404, %f55;
	fma.rn.f32 	%f496, %f492, %f406, %f494;
	fma.rn.f32 	%f942, %f492, %f408, %f496;
	abs.f32 	%f57, %f55;
	setp.leu.f32	%p41, %f57, 0f47CE4780;
	mov.u32 	%r1531, %r1539;
	mov.f32 	%f939, %f942;
	@%p41 bra 	BB11_49;

	setp.eq.f32	%p42, %f57, 0f7F800000;
	@%p42 bra 	BB11_48;
	bra.uni 	BB11_40;

BB11_48:
	mul.rn.f32 	%f939, %f55, %f413;
	mov.u32 	%r1531, %r1539;
	bra.uni 	BB11_49;

BB11_40:
	mov.b32 	 %r763, %f55;
	shl.b32 	%r764, %r763, 8;
	or.b32  	%r67, %r764, -2147483648;
	cvta.to.local.u64 	%rd326, %rd145;
	mov.u32 	%r1525, 0;
	mov.u64 	%rd325, __cudart_i2opi_f;
	mov.u32 	%r1524, -6;

BB11_41:
	.pragma "nounroll";
	ld.const.u32 	%r767, [%rd325];
	// inline asm
	{
	mad.lo.cc.u32   %r765, %r767, %r67, %r1525;
	madc.hi.u32     %r1525, %r767, %r67,  0;
	}
	// inline asm
	st.local.u32 	[%rd326], %r765;
	add.s64 	%rd326, %rd326, 4;
	add.s64 	%rd325, %rd325, 4;
	add.s32 	%r1524, %r1524, 1;
	setp.ne.s32	%p43, %r1524, 0;
	@%p43 bra 	BB11_41;

	bfe.u32 	%r771, %r763, 23, 8;
	add.s32 	%r772, %r771, -128;
	shr.u32 	%r773, %r772, 5;
	and.b32  	%r72, %r763, -2147483648;
	cvta.to.local.u64 	%rd159, %rd145;
	st.local.u32 	[%rd159+24], %r1525;
	bfe.u32 	%r73, %r763, 23, 5;
	mov.u32 	%r774, 6;
	sub.s32 	%r775, %r774, %r773;
	mul.wide.s32 	%rd160, %r775, 4;
	add.s64 	%rd18, %rd159, %rd160;
	ld.local.u32 	%r1527, [%rd18];
	ld.local.u32 	%r1526, [%rd18+-4];
	setp.eq.s32	%p44, %r73, 0;
	@%p44 bra 	BB11_44;

	mov.u32 	%r776, 32;
	sub.s32 	%r777, %r776, %r73;
	shr.u32 	%r778, %r1526, %r777;
	shl.b32 	%r779, %r1527, %r73;
	add.s32 	%r1527, %r778, %r779;
	ld.local.u32 	%r780, [%rd18+-8];
	shr.u32 	%r781, %r780, %r777;
	shl.b32 	%r782, %r1526, %r73;
	add.s32 	%r1526, %r781, %r782;

BB11_44:
	shr.u32 	%r783, %r1526, 30;
	shl.b32 	%r784, %r1527, 2;
	add.s32 	%r1529, %r784, %r783;
	shl.b32 	%r81, %r1526, 2;
	shr.u32 	%r785, %r1529, 31;
	shr.u32 	%r786, %r1527, 30;
	add.s32 	%r82, %r785, %r786;
	setp.eq.s32	%p45, %r785, 0;
	@%p45 bra 	BB11_45;

	not.b32 	%r787, %r1529;
	neg.s32 	%r1528, %r81;
	setp.eq.s32	%p46, %r81, 0;
	selp.u32	%r788, 1, 0, %p46;
	add.s32 	%r1529, %r788, %r787;
	xor.b32  	%r1530, %r72, -2147483648;
	bra.uni 	BB11_47;

BB11_45:
	mov.u32 	%r1528, %r81;
	mov.u32 	%r1530, %r72;

BB11_47:
	cvt.u64.u32	%rd161, %r1529;
	cvt.u64.u32	%rd162, %r1528;
	bfi.b64 	%rd163, %rd161, %rd162, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd163;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f498, %fd18;
	neg.f32 	%f499, %f498;
	setp.eq.s32	%p47, %r1530, 0;
	selp.f32	%f939, %f498, %f499, %p47;
	setp.eq.s32	%p48, %r72, 0;
	neg.s32 	%r789, %r82;
	selp.b32	%r1531, %r82, %r789, %p48;

BB11_49:
	add.s32 	%r91, %r1531, 1;
	and.b32  	%r92, %r91, 1;
	setp.eq.s32	%p49, %r92, 0;
	selp.f32	%f61, %f939, 0f3F800000, %p49;
	mul.rn.f32 	%f62, %f939, %f939;
	fma.rn.f32 	%f63, %f62, %f61, %f413;
	mov.f32 	%f940, 0fB94D4153;
	@%p49 bra 	BB11_51;

	mov.f32 	%f503, 0fBAB607ED;
	mov.f32 	%f504, 0f37CBAC00;
	fma.rn.f32 	%f940, %f504, %f62, %f503;

BB11_51:
	selp.f32	%f505, 0f3C0885E4, 0f3D2AAABB, %p49;
	fma.rn.f32 	%f506, %f940, %f62, %f505;
	selp.f32	%f507, 0fBE2AAAA8, 0fBEFFFFFF, %p49;
	fma.rn.f32 	%f508, %f506, %f62, %f507;
	fma.rn.f32 	%f941, %f508, %f63, %f61;
	and.b32  	%r790, %r91, 2;
	setp.eq.s32	%p51, %r790, 0;
	@%p51 bra 	BB11_53;

	mov.f32 	%f510, 0fBF800000;
	fma.rn.f32 	%f941, %f941, %f510, %f413;

BB11_53:
	@%p41 bra 	BB11_64;

	setp.eq.f32	%p53, %f57, 0f7F800000;
	@%p53 bra 	BB11_63;
	bra.uni 	BB11_55;

BB11_63:
	mul.rn.f32 	%f942, %f55, %f413;
	bra.uni 	BB11_64;

BB11_55:
	mov.b32 	 %r93, %f55;
	shl.b32 	%r793, %r93, 8;
	or.b32  	%r94, %r793, -2147483648;
	cvta.to.local.u64 	%rd328, %rd145;
	mov.u32 	%r1533, 0;
	mov.u64 	%rd327, __cudart_i2opi_f;
	mov.u32 	%r1532, -6;

BB11_56:
	.pragma "nounroll";
	ld.const.u32 	%r796, [%rd327];
	// inline asm
	{
	mad.lo.cc.u32   %r794, %r796, %r94, %r1533;
	madc.hi.u32     %r1533, %r796, %r94,  0;
	}
	// inline asm
	st.local.u32 	[%rd328], %r794;
	add.s64 	%rd328, %rd328, 4;
	add.s64 	%rd327, %rd327, 4;
	add.s32 	%r1532, %r1532, 1;
	setp.ne.s32	%p54, %r1532, 0;
	@%p54 bra 	BB11_56;

	bfe.u32 	%r799, %r93, 23, 8;
	add.s32 	%r800, %r799, -128;
	shr.u32 	%r801, %r800, 5;
	and.b32  	%r99, %r93, -2147483648;
	cvta.to.local.u64 	%rd167, %rd145;
	st.local.u32 	[%rd167+24], %r1533;
	bfe.u32 	%r100, %r93, 23, 5;
	mov.u32 	%r802, 6;
	sub.s32 	%r803, %r802, %r801;
	mul.wide.s32 	%rd168, %r803, 4;
	add.s64 	%rd24, %rd167, %rd168;
	ld.local.u32 	%r1535, [%rd24];
	ld.local.u32 	%r1534, [%rd24+-4];
	setp.eq.s32	%p55, %r100, 0;
	@%p55 bra 	BB11_59;

	mov.u32 	%r804, 32;
	sub.s32 	%r805, %r804, %r100;
	shr.u32 	%r806, %r1534, %r805;
	shl.b32 	%r807, %r1535, %r100;
	add.s32 	%r1535, %r806, %r807;
	ld.local.u32 	%r808, [%rd24+-8];
	shr.u32 	%r809, %r808, %r805;
	shl.b32 	%r810, %r1534, %r100;
	add.s32 	%r1534, %r809, %r810;

BB11_59:
	shr.u32 	%r811, %r1534, 30;
	shl.b32 	%r812, %r1535, 2;
	add.s32 	%r1537, %r812, %r811;
	shl.b32 	%r108, %r1534, 2;
	shr.u32 	%r813, %r1537, 31;
	shr.u32 	%r814, %r1535, 30;
	add.s32 	%r109, %r813, %r814;
	setp.eq.s32	%p56, %r813, 0;
	@%p56 bra 	BB11_60;

	not.b32 	%r815, %r1537;
	neg.s32 	%r1536, %r108;
	setp.eq.s32	%p57, %r108, 0;
	selp.u32	%r816, 1, 0, %p57;
	add.s32 	%r1537, %r816, %r815;
	xor.b32  	%r1538, %r99, -2147483648;
	bra.uni 	BB11_62;

BB11_60:
	mov.u32 	%r1536, %r108;
	mov.u32 	%r1538, %r99;

BB11_62:
	cvt.u64.u32	%rd169, %r1537;
	cvt.u64.u32	%rd170, %r1536;
	bfi.b64 	%rd171, %rd169, %rd170, 32, 32;
	cvt.rn.f64.s64	%fd19, %rd171;
	mul.f64 	%fd20, %fd19, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f511, %fd20;
	neg.f32 	%f512, %f511;
	setp.eq.s32	%p58, %r1538, 0;
	selp.f32	%f942, %f511, %f512, %p58;
	setp.eq.s32	%p59, %r99, 0;
	neg.s32 	%r817, %r109;
	selp.b32	%r1539, %r109, %r817, %p59;

BB11_64:
	and.b32  	%r118, %r1539, 1;
	setp.eq.s32	%p60, %r118, 0;
	selp.f32	%f72, %f942, 0f3F800000, %p60;
	mul.rn.f32 	%f73, %f942, %f942;
	fma.rn.f32 	%f74, %f73, %f72, %f413;
	mov.f32 	%f943, 0fB94D4153;
	@%p60 bra 	BB11_66;

	mov.f32 	%f516, 0fBAB607ED;
	mov.f32 	%f517, 0f37CBAC00;
	fma.rn.f32 	%f943, %f517, %f73, %f516;

BB11_66:
	selp.f32	%f518, 0f3C0885E4, 0f3D2AAABB, %p60;
	fma.rn.f32 	%f519, %f943, %f73, %f518;
	selp.f32	%f520, 0fBE2AAAA8, 0fBEFFFFFF, %p60;
	fma.rn.f32 	%f521, %f519, %f73, %f520;
	fma.rn.f32 	%f944, %f521, %f74, %f72;
	and.b32  	%r818, %r1539, 2;
	setp.eq.s32	%p62, %r818, 0;
	@%p62 bra 	BB11_68;

	mov.f32 	%f523, 0fBF800000;
	fma.rn.f32 	%f944, %f944, %f523, %f413;

BB11_68:
	and.b32  	%r819, %r1, 1;
	shl.b32 	%r820, %r1, 1;
	and.b32  	%r821, %r820, 1073741820;
	add.s32 	%r822, %r821, %r819;
	mul.f32 	%f524, %f54, %f944;
	mul.f32 	%f525, %f53, %f941;
	sub.f32 	%f526, %f525, %f524;
	mul.f32 	%f527, %f54, %f941;
	fma.rn.f32 	%f528, %f53, %f944, %f527;
	add.f32 	%f529, %f51, %f526;
	shl.b32 	%r823, %r822, 2;
	add.s32 	%r825, %r621, %r823;
	st.shared.f32 	[%r825], %f529;
	add.f32 	%f530, %f52, %f528;
	add.s32 	%r827, %r622, %r823;
	st.shared.f32 	[%r827], %f530;
	sub.f32 	%f531, %f51, %f526;
	st.shared.f32 	[%r825+8], %f531;
	sub.f32 	%f532, %f52, %f528;
	st.shared.f32 	[%r827+8], %f532;
	bar.sync 	0;
	ld.shared.f32 	%f80, [%r2];
	ld.shared.f32 	%f81, [%r3];
	ld.shared.f32 	%f82, [%r2+4096];
	ld.shared.f32 	%f83, [%r3+4096];
	shr.s32 	%r833, %r1, 31;
	shr.u32 	%r834, %r833, 30;
	add.s32 	%r835, %r1, %r834;
	and.b32  	%r836, %r835, 16777212;
	sub.s32 	%r837, %r1, %r836;
	shl.b32 	%r838, %r837, 8;
	cvt.rn.f32.s32	%f533, %r838;
	mul.f32 	%f534, %f533, 0f3A000000;
	cvt.f64.f32	%fd21, %f534;
	mul.f64 	%fd22, %fd21, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f84, %fd22;
	mul.f32 	%f535, %f84, 0f3F22F983;
	cvt.rni.s32.f32	%r1555, %f535;
	cvt.rn.f32.s32	%f536, %r1555;
	fma.rn.f32 	%f538, %f536, %f404, %f84;
	fma.rn.f32 	%f540, %f536, %f406, %f538;
	fma.rn.f32 	%f948, %f536, %f408, %f540;
	abs.f32 	%f86, %f84;
	setp.leu.f32	%p63, %f86, 0f47CE4780;
	mov.u32 	%r1547, %r1555;
	mov.f32 	%f945, %f948;
	@%p63 bra 	BB11_79;

	setp.eq.f32	%p64, %f86, 0f7F800000;
	@%p64 bra 	BB11_78;
	bra.uni 	BB11_70;

BB11_78:
	mul.rn.f32 	%f945, %f84, %f413;
	mov.u32 	%r1547, %r1555;
	bra.uni 	BB11_79;

BB11_70:
	mov.b32 	 %r121, %f84;
	shl.b32 	%r841, %r121, 8;
	or.b32  	%r122, %r841, -2147483648;
	cvta.to.local.u64 	%rd330, %rd145;
	mov.u32 	%r1541, 0;
	mov.u64 	%rd329, __cudart_i2opi_f;
	mov.u32 	%r1540, -6;

BB11_71:
	.pragma "nounroll";
	ld.const.u32 	%r844, [%rd329];
	// inline asm
	{
	mad.lo.cc.u32   %r842, %r844, %r122, %r1541;
	madc.hi.u32     %r1541, %r844, %r122,  0;
	}
	// inline asm
	st.local.u32 	[%rd330], %r842;
	add.s64 	%rd330, %rd330, 4;
	add.s64 	%rd329, %rd329, 4;
	add.s32 	%r1540, %r1540, 1;
	setp.ne.s32	%p65, %r1540, 0;
	@%p65 bra 	BB11_71;

	bfe.u32 	%r847, %r121, 23, 8;
	add.s32 	%r848, %r847, -128;
	shr.u32 	%r849, %r848, 5;
	and.b32  	%r127, %r121, -2147483648;
	cvta.to.local.u64 	%rd175, %rd145;
	st.local.u32 	[%rd175+24], %r1541;
	bfe.u32 	%r128, %r121, 23, 5;
	mov.u32 	%r850, 6;
	sub.s32 	%r851, %r850, %r849;
	mul.wide.s32 	%rd176, %r851, 4;
	add.s64 	%rd30, %rd175, %rd176;
	ld.local.u32 	%r1543, [%rd30];
	ld.local.u32 	%r1542, [%rd30+-4];
	setp.eq.s32	%p66, %r128, 0;
	@%p66 bra 	BB11_74;

	mov.u32 	%r852, 32;
	sub.s32 	%r853, %r852, %r128;
	shr.u32 	%r854, %r1542, %r853;
	shl.b32 	%r855, %r1543, %r128;
	add.s32 	%r1543, %r854, %r855;
	ld.local.u32 	%r856, [%rd30+-8];
	shr.u32 	%r857, %r856, %r853;
	shl.b32 	%r858, %r1542, %r128;
	add.s32 	%r1542, %r857, %r858;

BB11_74:
	shr.u32 	%r859, %r1542, 30;
	shl.b32 	%r860, %r1543, 2;
	add.s32 	%r1545, %r860, %r859;
	shl.b32 	%r136, %r1542, 2;
	shr.u32 	%r861, %r1545, 31;
	shr.u32 	%r862, %r1543, 30;
	add.s32 	%r137, %r861, %r862;
	setp.eq.s32	%p67, %r861, 0;
	@%p67 bra 	BB11_75;

	not.b32 	%r863, %r1545;
	neg.s32 	%r1544, %r136;
	setp.eq.s32	%p68, %r136, 0;
	selp.u32	%r864, 1, 0, %p68;
	add.s32 	%r1545, %r864, %r863;
	xor.b32  	%r1546, %r127, -2147483648;
	bra.uni 	BB11_77;

BB11_75:
	mov.u32 	%r1544, %r136;
	mov.u32 	%r1546, %r127;

BB11_77:
	cvt.u64.u32	%rd177, %r1545;
	cvt.u64.u32	%rd178, %r1544;
	bfi.b64 	%rd179, %rd177, %rd178, 32, 32;
	cvt.rn.f64.s64	%fd23, %rd179;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f542, %fd24;
	neg.f32 	%f543, %f542;
	setp.eq.s32	%p69, %r1546, 0;
	selp.f32	%f945, %f542, %f543, %p69;
	setp.eq.s32	%p70, %r127, 0;
	neg.s32 	%r865, %r137;
	selp.b32	%r1547, %r137, %r865, %p70;

BB11_79:
	add.s32 	%r146, %r1547, 1;
	and.b32  	%r147, %r146, 1;
	setp.eq.s32	%p71, %r147, 0;
	selp.f32	%f90, %f945, 0f3F800000, %p71;
	mul.rn.f32 	%f91, %f945, %f945;
	fma.rn.f32 	%f92, %f91, %f90, %f413;
	mov.f32 	%f946, 0fB94D4153;
	@%p71 bra 	BB11_81;

	mov.f32 	%f547, 0fBAB607ED;
	mov.f32 	%f548, 0f37CBAC00;
	fma.rn.f32 	%f946, %f548, %f91, %f547;

BB11_81:
	selp.f32	%f549, 0f3C0885E4, 0f3D2AAABB, %p71;
	fma.rn.f32 	%f550, %f946, %f91, %f549;
	selp.f32	%f551, 0fBE2AAAA8, 0fBEFFFFFF, %p71;
	fma.rn.f32 	%f552, %f550, %f91, %f551;
	fma.rn.f32 	%f947, %f552, %f92, %f90;
	and.b32  	%r866, %r146, 2;
	setp.eq.s32	%p73, %r866, 0;
	@%p73 bra 	BB11_83;

	mov.f32 	%f554, 0fBF800000;
	fma.rn.f32 	%f947, %f947, %f554, %f413;

BB11_83:
	@%p63 bra 	BB11_94;

	setp.eq.f32	%p75, %f86, 0f7F800000;
	@%p75 bra 	BB11_93;
	bra.uni 	BB11_85;

BB11_93:
	mul.rn.f32 	%f948, %f84, %f413;
	bra.uni 	BB11_94;

BB11_85:
	mov.b32 	 %r148, %f84;
	shl.b32 	%r869, %r148, 8;
	or.b32  	%r149, %r869, -2147483648;
	cvta.to.local.u64 	%rd332, %rd145;
	mov.u32 	%r1549, 0;
	mov.u64 	%rd331, __cudart_i2opi_f;
	mov.u32 	%r1548, -6;

BB11_86:
	.pragma "nounroll";
	ld.const.u32 	%r872, [%rd331];
	// inline asm
	{
	mad.lo.cc.u32   %r870, %r872, %r149, %r1549;
	madc.hi.u32     %r1549, %r872, %r149,  0;
	}
	// inline asm
	st.local.u32 	[%rd332], %r870;
	add.s64 	%rd332, %rd332, 4;
	add.s64 	%rd331, %rd331, 4;
	add.s32 	%r1548, %r1548, 1;
	setp.ne.s32	%p76, %r1548, 0;
	@%p76 bra 	BB11_86;

	bfe.u32 	%r875, %r148, 23, 8;
	add.s32 	%r876, %r875, -128;
	shr.u32 	%r877, %r876, 5;
	and.b32  	%r154, %r148, -2147483648;
	cvta.to.local.u64 	%rd183, %rd145;
	st.local.u32 	[%rd183+24], %r1549;
	bfe.u32 	%r155, %r148, 23, 5;
	mov.u32 	%r878, 6;
	sub.s32 	%r879, %r878, %r877;
	mul.wide.s32 	%rd184, %r879, 4;
	add.s64 	%rd36, %rd183, %rd184;
	ld.local.u32 	%r1551, [%rd36];
	ld.local.u32 	%r1550, [%rd36+-4];
	setp.eq.s32	%p77, %r155, 0;
	@%p77 bra 	BB11_89;

	mov.u32 	%r880, 32;
	sub.s32 	%r881, %r880, %r155;
	shr.u32 	%r882, %r1550, %r881;
	shl.b32 	%r883, %r1551, %r155;
	add.s32 	%r1551, %r882, %r883;
	ld.local.u32 	%r884, [%rd36+-8];
	shr.u32 	%r885, %r884, %r881;
	shl.b32 	%r886, %r1550, %r155;
	add.s32 	%r1550, %r885, %r886;

BB11_89:
	shr.u32 	%r887, %r1550, 30;
	shl.b32 	%r888, %r1551, 2;
	add.s32 	%r1553, %r888, %r887;
	shl.b32 	%r163, %r1550, 2;
	shr.u32 	%r889, %r1553, 31;
	shr.u32 	%r890, %r1551, 30;
	add.s32 	%r164, %r889, %r890;
	setp.eq.s32	%p78, %r889, 0;
	@%p78 bra 	BB11_90;

	not.b32 	%r891, %r1553;
	neg.s32 	%r1552, %r163;
	setp.eq.s32	%p79, %r163, 0;
	selp.u32	%r892, 1, 0, %p79;
	add.s32 	%r1553, %r892, %r891;
	xor.b32  	%r1554, %r154, -2147483648;
	bra.uni 	BB11_92;

BB11_90:
	mov.u32 	%r1552, %r163;
	mov.u32 	%r1554, %r154;

BB11_92:
	cvt.u64.u32	%rd185, %r1553;
	cvt.u64.u32	%rd186, %r1552;
	bfi.b64 	%rd187, %rd185, %rd186, 32, 32;
	cvt.rn.f64.s64	%fd25, %rd187;
	mul.f64 	%fd26, %fd25, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f555, %fd26;
	neg.f32 	%f556, %f555;
	setp.eq.s32	%p80, %r1554, 0;
	selp.f32	%f948, %f555, %f556, %p80;
	setp.eq.s32	%p81, %r154, 0;
	neg.s32 	%r893, %r164;
	selp.b32	%r1555, %r164, %r893, %p81;

BB11_94:
	and.b32  	%r173, %r1555, 1;
	setp.eq.s32	%p82, %r173, 0;
	selp.f32	%f101, %f948, 0f3F800000, %p82;
	mul.rn.f32 	%f102, %f948, %f948;
	fma.rn.f32 	%f103, %f102, %f101, %f413;
	mov.f32 	%f949, 0fB94D4153;
	@%p82 bra 	BB11_96;

	mov.f32 	%f560, 0fBAB607ED;
	mov.f32 	%f561, 0f37CBAC00;
	fma.rn.f32 	%f949, %f561, %f102, %f560;

BB11_96:
	selp.f32	%f562, 0f3C0885E4, 0f3D2AAABB, %p82;
	fma.rn.f32 	%f563, %f949, %f102, %f562;
	selp.f32	%f564, 0fBE2AAAA8, 0fBEFFFFFF, %p82;
	fma.rn.f32 	%f565, %f563, %f102, %f564;
	fma.rn.f32 	%f950, %f565, %f103, %f101;
	and.b32  	%r894, %r1555, 2;
	setp.eq.s32	%p84, %r894, 0;
	@%p84 bra 	BB11_98;

	mov.f32 	%f567, 0fBF800000;
	fma.rn.f32 	%f950, %f950, %f567, %f413;

BB11_98:
	and.b32  	%r895, %r1, 3;
	and.b32  	%r897, %r820, 1073741816;
	add.s32 	%r898, %r897, %r895;
	mul.f32 	%f568, %f83, %f950;
	mul.f32 	%f569, %f82, %f947;
	sub.f32 	%f570, %f569, %f568;
	mul.f32 	%f571, %f83, %f947;
	fma.rn.f32 	%f572, %f82, %f950, %f571;
	add.f32 	%f573, %f80, %f570;
	shl.b32 	%r899, %r898, 2;
	add.s32 	%r901, %r747, %r899;
	st.shared.f32 	[%r901], %f573;
	add.f32 	%f574, %f81, %f572;
	add.s32 	%r903, %r749, %r899;
	st.shared.f32 	[%r903], %f574;
	sub.f32 	%f575, %f80, %f570;
	st.shared.f32 	[%r901+16], %f575;
	sub.f32 	%f576, %f81, %f572;
	st.shared.f32 	[%r903+16], %f576;
	bar.sync 	0;
	ld.shared.f32 	%f109, [%r753];
	ld.shared.f32 	%f110, [%r755];
	ld.shared.f32 	%f111, [%r753+4096];
	ld.shared.f32 	%f112, [%r755+4096];
	shr.u32 	%r910, %r833, 29;
	add.s32 	%r911, %r1, %r910;
	and.b32  	%r912, %r911, 33554424;
	sub.s32 	%r913, %r1, %r912;
	shl.b32 	%r914, %r913, 7;
	cvt.rn.f32.s32	%f577, %r914;
	mul.f32 	%f578, %f577, 0f3A000000;
	cvt.f64.f32	%fd27, %f578;
	mul.f64 	%fd28, %fd27, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f113, %fd28;
	mul.f32 	%f579, %f113, 0f3F22F983;
	cvt.rni.s32.f32	%r1571, %f579;
	cvt.rn.f32.s32	%f580, %r1571;
	fma.rn.f32 	%f582, %f580, %f404, %f113;
	fma.rn.f32 	%f584, %f580, %f406, %f582;
	fma.rn.f32 	%f954, %f580, %f408, %f584;
	abs.f32 	%f115, %f113;
	setp.leu.f32	%p85, %f115, 0f47CE4780;
	mov.u32 	%r1563, %r1571;
	mov.f32 	%f951, %f954;
	@%p85 bra 	BB11_109;

	setp.eq.f32	%p86, %f115, 0f7F800000;
	@%p86 bra 	BB11_108;
	bra.uni 	BB11_100;

BB11_108:
	mul.rn.f32 	%f951, %f113, %f413;
	mov.u32 	%r1563, %r1571;
	bra.uni 	BB11_109;

BB11_100:
	mov.b32 	 %r176, %f113;
	shl.b32 	%r917, %r176, 8;
	or.b32  	%r177, %r917, -2147483648;
	cvta.to.local.u64 	%rd334, %rd145;
	mov.u32 	%r1557, 0;
	mov.u64 	%rd333, __cudart_i2opi_f;
	mov.u32 	%r1556, -6;

BB11_101:
	.pragma "nounroll";
	ld.const.u32 	%r920, [%rd333];
	// inline asm
	{
	mad.lo.cc.u32   %r918, %r920, %r177, %r1557;
	madc.hi.u32     %r1557, %r920, %r177,  0;
	}
	// inline asm
	st.local.u32 	[%rd334], %r918;
	add.s64 	%rd334, %rd334, 4;
	add.s64 	%rd333, %rd333, 4;
	add.s32 	%r1556, %r1556, 1;
	setp.ne.s32	%p87, %r1556, 0;
	@%p87 bra 	BB11_101;

	bfe.u32 	%r923, %r176, 23, 8;
	add.s32 	%r924, %r923, -128;
	shr.u32 	%r925, %r924, 5;
	and.b32  	%r182, %r176, -2147483648;
	cvta.to.local.u64 	%rd191, %rd145;
	st.local.u32 	[%rd191+24], %r1557;
	bfe.u32 	%r183, %r176, 23, 5;
	mov.u32 	%r926, 6;
	sub.s32 	%r927, %r926, %r925;
	mul.wide.s32 	%rd192, %r927, 4;
	add.s64 	%rd42, %rd191, %rd192;
	ld.local.u32 	%r1559, [%rd42];
	ld.local.u32 	%r1558, [%rd42+-4];
	setp.eq.s32	%p88, %r183, 0;
	@%p88 bra 	BB11_104;

	mov.u32 	%r928, 32;
	sub.s32 	%r929, %r928, %r183;
	shr.u32 	%r930, %r1558, %r929;
	shl.b32 	%r931, %r1559, %r183;
	add.s32 	%r1559, %r930, %r931;
	ld.local.u32 	%r932, [%rd42+-8];
	shr.u32 	%r933, %r932, %r929;
	shl.b32 	%r934, %r1558, %r183;
	add.s32 	%r1558, %r933, %r934;

BB11_104:
	shr.u32 	%r935, %r1558, 30;
	shl.b32 	%r936, %r1559, 2;
	add.s32 	%r1561, %r936, %r935;
	shl.b32 	%r191, %r1558, 2;
	shr.u32 	%r937, %r1561, 31;
	shr.u32 	%r938, %r1559, 30;
	add.s32 	%r192, %r937, %r938;
	setp.eq.s32	%p89, %r937, 0;
	@%p89 bra 	BB11_105;

	not.b32 	%r939, %r1561;
	neg.s32 	%r1560, %r191;
	setp.eq.s32	%p90, %r191, 0;
	selp.u32	%r940, 1, 0, %p90;
	add.s32 	%r1561, %r940, %r939;
	xor.b32  	%r1562, %r182, -2147483648;
	bra.uni 	BB11_107;

BB11_105:
	mov.u32 	%r1560, %r191;
	mov.u32 	%r1562, %r182;

BB11_107:
	cvt.u64.u32	%rd193, %r1561;
	cvt.u64.u32	%rd194, %r1560;
	bfi.b64 	%rd195, %rd193, %rd194, 32, 32;
	cvt.rn.f64.s64	%fd29, %rd195;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f586, %fd30;
	neg.f32 	%f587, %f586;
	setp.eq.s32	%p91, %r1562, 0;
	selp.f32	%f951, %f586, %f587, %p91;
	setp.eq.s32	%p92, %r182, 0;
	neg.s32 	%r941, %r192;
	selp.b32	%r1563, %r192, %r941, %p92;

BB11_109:
	add.s32 	%r201, %r1563, 1;
	and.b32  	%r202, %r201, 1;
	setp.eq.s32	%p93, %r202, 0;
	selp.f32	%f119, %f951, 0f3F800000, %p93;
	mul.rn.f32 	%f120, %f951, %f951;
	fma.rn.f32 	%f121, %f120, %f119, %f413;
	mov.f32 	%f952, 0fB94D4153;
	@%p93 bra 	BB11_111;

	mov.f32 	%f591, 0fBAB607ED;
	mov.f32 	%f592, 0f37CBAC00;
	fma.rn.f32 	%f952, %f592, %f120, %f591;

BB11_111:
	selp.f32	%f593, 0f3C0885E4, 0f3D2AAABB, %p93;
	fma.rn.f32 	%f594, %f952, %f120, %f593;
	selp.f32	%f595, 0fBE2AAAA8, 0fBEFFFFFF, %p93;
	fma.rn.f32 	%f596, %f594, %f120, %f595;
	fma.rn.f32 	%f953, %f596, %f121, %f119;
	and.b32  	%r942, %r201, 2;
	setp.eq.s32	%p95, %r942, 0;
	@%p95 bra 	BB11_113;

	mov.f32 	%f598, 0fBF800000;
	fma.rn.f32 	%f953, %f953, %f598, %f413;

BB11_113:
	@%p85 bra 	BB11_124;

	setp.eq.f32	%p97, %f115, 0f7F800000;
	@%p97 bra 	BB11_123;
	bra.uni 	BB11_115;

BB11_123:
	mul.rn.f32 	%f954, %f113, %f413;
	bra.uni 	BB11_124;

BB11_115:
	mov.b32 	 %r203, %f113;
	shl.b32 	%r945, %r203, 8;
	or.b32  	%r204, %r945, -2147483648;
	cvta.to.local.u64 	%rd336, %rd145;
	mov.u32 	%r1565, 0;
	mov.u64 	%rd335, __cudart_i2opi_f;
	mov.u32 	%r1564, -6;

BB11_116:
	.pragma "nounroll";
	ld.const.u32 	%r948, [%rd335];
	// inline asm
	{
	mad.lo.cc.u32   %r946, %r948, %r204, %r1565;
	madc.hi.u32     %r1565, %r948, %r204,  0;
	}
	// inline asm
	st.local.u32 	[%rd336], %r946;
	add.s64 	%rd336, %rd336, 4;
	add.s64 	%rd335, %rd335, 4;
	add.s32 	%r1564, %r1564, 1;
	setp.ne.s32	%p98, %r1564, 0;
	@%p98 bra 	BB11_116;

	bfe.u32 	%r951, %r203, 23, 8;
	add.s32 	%r952, %r951, -128;
	shr.u32 	%r953, %r952, 5;
	and.b32  	%r209, %r203, -2147483648;
	cvta.to.local.u64 	%rd199, %rd145;
	st.local.u32 	[%rd199+24], %r1565;
	bfe.u32 	%r210, %r203, 23, 5;
	mov.u32 	%r954, 6;
	sub.s32 	%r955, %r954, %r953;
	mul.wide.s32 	%rd200, %r955, 4;
	add.s64 	%rd48, %rd199, %rd200;
	ld.local.u32 	%r1567, [%rd48];
	ld.local.u32 	%r1566, [%rd48+-4];
	setp.eq.s32	%p99, %r210, 0;
	@%p99 bra 	BB11_119;

	mov.u32 	%r956, 32;
	sub.s32 	%r957, %r956, %r210;
	shr.u32 	%r958, %r1566, %r957;
	shl.b32 	%r959, %r1567, %r210;
	add.s32 	%r1567, %r958, %r959;
	ld.local.u32 	%r960, [%rd48+-8];
	shr.u32 	%r961, %r960, %r957;
	shl.b32 	%r962, %r1566, %r210;
	add.s32 	%r1566, %r961, %r962;

BB11_119:
	shr.u32 	%r963, %r1566, 30;
	shl.b32 	%r964, %r1567, 2;
	add.s32 	%r1569, %r964, %r963;
	shl.b32 	%r218, %r1566, 2;
	shr.u32 	%r965, %r1569, 31;
	shr.u32 	%r966, %r1567, 30;
	add.s32 	%r219, %r965, %r966;
	setp.eq.s32	%p100, %r965, 0;
	@%p100 bra 	BB11_120;

	not.b32 	%r967, %r1569;
	neg.s32 	%r1568, %r218;
	setp.eq.s32	%p101, %r218, 0;
	selp.u32	%r968, 1, 0, %p101;
	add.s32 	%r1569, %r968, %r967;
	xor.b32  	%r1570, %r209, -2147483648;
	bra.uni 	BB11_122;

BB11_120:
	mov.u32 	%r1568, %r218;
	mov.u32 	%r1570, %r209;

BB11_122:
	cvt.u64.u32	%rd201, %r1569;
	cvt.u64.u32	%rd202, %r1568;
	bfi.b64 	%rd203, %rd201, %rd202, 32, 32;
	cvt.rn.f64.s64	%fd31, %rd203;
	mul.f64 	%fd32, %fd31, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f599, %fd32;
	neg.f32 	%f600, %f599;
	setp.eq.s32	%p102, %r1570, 0;
	selp.f32	%f954, %f599, %f600, %p102;
	setp.eq.s32	%p103, %r209, 0;
	neg.s32 	%r969, %r219;
	selp.b32	%r1571, %r219, %r969, %p103;

BB11_124:
	and.b32  	%r228, %r1571, 1;
	setp.eq.s32	%p104, %r228, 0;
	selp.f32	%f130, %f954, 0f3F800000, %p104;
	mul.rn.f32 	%f131, %f954, %f954;
	fma.rn.f32 	%f132, %f131, %f130, %f413;
	mov.f32 	%f955, 0fB94D4153;
	@%p104 bra 	BB11_126;

	mov.f32 	%f604, 0fBAB607ED;
	mov.f32 	%f605, 0f37CBAC00;
	fma.rn.f32 	%f955, %f605, %f131, %f604;

BB11_126:
	selp.f32	%f606, 0f3C0885E4, 0f3D2AAABB, %p104;
	fma.rn.f32 	%f607, %f955, %f131, %f606;
	selp.f32	%f608, 0fBE2AAAA8, 0fBEFFFFFF, %p104;
	fma.rn.f32 	%f609, %f607, %f131, %f608;
	fma.rn.f32 	%f956, %f609, %f132, %f130;
	and.b32  	%r970, %r1571, 2;
	setp.eq.s32	%p106, %r970, 0;
	@%p106 bra 	BB11_128;

	mov.f32 	%f611, 0fBF800000;
	fma.rn.f32 	%f956, %f956, %f611, %f413;

BB11_128:
	and.b32  	%r971, %r1, 7;
	and.b32  	%r973, %r820, 1073741808;
	add.s32 	%r974, %r973, %r971;
	mul.f32 	%f612, %f112, %f956;
	mul.f32 	%f613, %f111, %f953;
	sub.f32 	%f614, %f613, %f612;
	mul.f32 	%f615, %f112, %f953;
	fma.rn.f32 	%f616, %f111, %f956, %f615;
	add.f32 	%f617, %f109, %f614;
	shl.b32 	%r975, %r974, 2;
	add.s32 	%r977, %r621, %r975;
	st.shared.f32 	[%r977], %f617;
	add.f32 	%f618, %f110, %f616;
	add.s32 	%r979, %r622, %r975;
	st.shared.f32 	[%r979], %f618;
	sub.f32 	%f619, %f109, %f614;
	st.shared.f32 	[%r977+32], %f619;
	sub.f32 	%f620, %f110, %f616;
	st.shared.f32 	[%r979+32], %f620;
	bar.sync 	0;
	ld.shared.f32 	%f138, [%r2];
	ld.shared.f32 	%f139, [%r3];
	ld.shared.f32 	%f140, [%r2+4096];
	ld.shared.f32 	%f141, [%r3+4096];
	shr.u32 	%r986, %r833, 28;
	add.s32 	%r987, %r1, %r986;
	and.b32  	%r988, %r987, 67108848;
	sub.s32 	%r989, %r1, %r988;
	shl.b32 	%r990, %r989, 6;
	cvt.rn.f32.s32	%f621, %r990;
	mul.f32 	%f622, %f621, 0f3A000000;
	cvt.f64.f32	%fd33, %f622;
	mul.f64 	%fd34, %fd33, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f142, %fd34;
	mul.f32 	%f623, %f142, 0f3F22F983;
	cvt.rni.s32.f32	%r1587, %f623;
	cvt.rn.f32.s32	%f624, %r1587;
	fma.rn.f32 	%f626, %f624, %f404, %f142;
	fma.rn.f32 	%f628, %f624, %f406, %f626;
	fma.rn.f32 	%f960, %f624, %f408, %f628;
	abs.f32 	%f144, %f142;
	setp.leu.f32	%p107, %f144, 0f47CE4780;
	mov.u32 	%r1579, %r1587;
	mov.f32 	%f957, %f960;
	@%p107 bra 	BB11_139;

	setp.eq.f32	%p108, %f144, 0f7F800000;
	@%p108 bra 	BB11_138;
	bra.uni 	BB11_130;

BB11_138:
	mul.rn.f32 	%f957, %f142, %f413;
	mov.u32 	%r1579, %r1587;
	bra.uni 	BB11_139;

BB11_130:
	mov.b32 	 %r231, %f142;
	shl.b32 	%r993, %r231, 8;
	or.b32  	%r232, %r993, -2147483648;
	cvta.to.local.u64 	%rd338, %rd145;
	mov.u32 	%r1573, 0;
	mov.u64 	%rd337, __cudart_i2opi_f;
	mov.u32 	%r1572, -6;

BB11_131:
	.pragma "nounroll";
	ld.const.u32 	%r996, [%rd337];
	// inline asm
	{
	mad.lo.cc.u32   %r994, %r996, %r232, %r1573;
	madc.hi.u32     %r1573, %r996, %r232,  0;
	}
	// inline asm
	st.local.u32 	[%rd338], %r994;
	add.s64 	%rd338, %rd338, 4;
	add.s64 	%rd337, %rd337, 4;
	add.s32 	%r1572, %r1572, 1;
	setp.ne.s32	%p109, %r1572, 0;
	@%p109 bra 	BB11_131;

	bfe.u32 	%r999, %r231, 23, 8;
	add.s32 	%r1000, %r999, -128;
	shr.u32 	%r1001, %r1000, 5;
	and.b32  	%r237, %r231, -2147483648;
	cvta.to.local.u64 	%rd207, %rd145;
	st.local.u32 	[%rd207+24], %r1573;
	bfe.u32 	%r238, %r231, 23, 5;
	mov.u32 	%r1002, 6;
	sub.s32 	%r1003, %r1002, %r1001;
	mul.wide.s32 	%rd208, %r1003, 4;
	add.s64 	%rd54, %rd207, %rd208;
	ld.local.u32 	%r1575, [%rd54];
	ld.local.u32 	%r1574, [%rd54+-4];
	setp.eq.s32	%p110, %r238, 0;
	@%p110 bra 	BB11_134;

	mov.u32 	%r1004, 32;
	sub.s32 	%r1005, %r1004, %r238;
	shr.u32 	%r1006, %r1574, %r1005;
	shl.b32 	%r1007, %r1575, %r238;
	add.s32 	%r1575, %r1006, %r1007;
	ld.local.u32 	%r1008, [%rd54+-8];
	shr.u32 	%r1009, %r1008, %r1005;
	shl.b32 	%r1010, %r1574, %r238;
	add.s32 	%r1574, %r1009, %r1010;

BB11_134:
	shr.u32 	%r1011, %r1574, 30;
	shl.b32 	%r1012, %r1575, 2;
	add.s32 	%r1577, %r1012, %r1011;
	shl.b32 	%r246, %r1574, 2;
	shr.u32 	%r1013, %r1577, 31;
	shr.u32 	%r1014, %r1575, 30;
	add.s32 	%r247, %r1013, %r1014;
	setp.eq.s32	%p111, %r1013, 0;
	@%p111 bra 	BB11_135;

	not.b32 	%r1015, %r1577;
	neg.s32 	%r1576, %r246;
	setp.eq.s32	%p112, %r246, 0;
	selp.u32	%r1016, 1, 0, %p112;
	add.s32 	%r1577, %r1016, %r1015;
	xor.b32  	%r1578, %r237, -2147483648;
	bra.uni 	BB11_137;

BB11_135:
	mov.u32 	%r1576, %r246;
	mov.u32 	%r1578, %r237;

BB11_137:
	cvt.u64.u32	%rd209, %r1577;
	cvt.u64.u32	%rd210, %r1576;
	bfi.b64 	%rd211, %rd209, %rd210, 32, 32;
	cvt.rn.f64.s64	%fd35, %rd211;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f630, %fd36;
	neg.f32 	%f631, %f630;
	setp.eq.s32	%p113, %r1578, 0;
	selp.f32	%f957, %f630, %f631, %p113;
	setp.eq.s32	%p114, %r237, 0;
	neg.s32 	%r1017, %r247;
	selp.b32	%r1579, %r247, %r1017, %p114;

BB11_139:
	add.s32 	%r256, %r1579, 1;
	and.b32  	%r257, %r256, 1;
	setp.eq.s32	%p115, %r257, 0;
	selp.f32	%f148, %f957, 0f3F800000, %p115;
	mul.rn.f32 	%f149, %f957, %f957;
	fma.rn.f32 	%f150, %f149, %f148, %f413;
	mov.f32 	%f958, 0fB94D4153;
	@%p115 bra 	BB11_141;

	mov.f32 	%f635, 0fBAB607ED;
	mov.f32 	%f636, 0f37CBAC00;
	fma.rn.f32 	%f958, %f636, %f149, %f635;

BB11_141:
	selp.f32	%f637, 0f3C0885E4, 0f3D2AAABB, %p115;
	fma.rn.f32 	%f638, %f958, %f149, %f637;
	selp.f32	%f639, 0fBE2AAAA8, 0fBEFFFFFF, %p115;
	fma.rn.f32 	%f640, %f638, %f149, %f639;
	fma.rn.f32 	%f959, %f640, %f150, %f148;
	and.b32  	%r1018, %r256, 2;
	setp.eq.s32	%p117, %r1018, 0;
	@%p117 bra 	BB11_143;

	mov.f32 	%f642, 0fBF800000;
	fma.rn.f32 	%f959, %f959, %f642, %f413;

BB11_143:
	@%p107 bra 	BB11_154;

	setp.eq.f32	%p119, %f144, 0f7F800000;
	@%p119 bra 	BB11_153;
	bra.uni 	BB11_145;

BB11_153:
	mul.rn.f32 	%f960, %f142, %f413;
	bra.uni 	BB11_154;

BB11_145:
	mov.b32 	 %r258, %f142;
	shl.b32 	%r1021, %r258, 8;
	or.b32  	%r259, %r1021, -2147483648;
	cvta.to.local.u64 	%rd340, %rd145;
	mov.u32 	%r1581, 0;
	mov.u64 	%rd339, __cudart_i2opi_f;
	mov.u32 	%r1580, -6;

BB11_146:
	.pragma "nounroll";
	ld.const.u32 	%r1024, [%rd339];
	// inline asm
	{
	mad.lo.cc.u32   %r1022, %r1024, %r259, %r1581;
	madc.hi.u32     %r1581, %r1024, %r259,  0;
	}
	// inline asm
	st.local.u32 	[%rd340], %r1022;
	add.s64 	%rd340, %rd340, 4;
	add.s64 	%rd339, %rd339, 4;
	add.s32 	%r1580, %r1580, 1;
	setp.ne.s32	%p120, %r1580, 0;
	@%p120 bra 	BB11_146;

	bfe.u32 	%r1027, %r258, 23, 8;
	add.s32 	%r1028, %r1027, -128;
	shr.u32 	%r1029, %r1028, 5;
	and.b32  	%r264, %r258, -2147483648;
	cvta.to.local.u64 	%rd215, %rd145;
	st.local.u32 	[%rd215+24], %r1581;
	bfe.u32 	%r265, %r258, 23, 5;
	mov.u32 	%r1030, 6;
	sub.s32 	%r1031, %r1030, %r1029;
	mul.wide.s32 	%rd216, %r1031, 4;
	add.s64 	%rd60, %rd215, %rd216;
	ld.local.u32 	%r1583, [%rd60];
	ld.local.u32 	%r1582, [%rd60+-4];
	setp.eq.s32	%p121, %r265, 0;
	@%p121 bra 	BB11_149;

	mov.u32 	%r1032, 32;
	sub.s32 	%r1033, %r1032, %r265;
	shr.u32 	%r1034, %r1582, %r1033;
	shl.b32 	%r1035, %r1583, %r265;
	add.s32 	%r1583, %r1034, %r1035;
	ld.local.u32 	%r1036, [%rd60+-8];
	shr.u32 	%r1037, %r1036, %r1033;
	shl.b32 	%r1038, %r1582, %r265;
	add.s32 	%r1582, %r1037, %r1038;

BB11_149:
	shr.u32 	%r1039, %r1582, 30;
	shl.b32 	%r1040, %r1583, 2;
	add.s32 	%r1585, %r1040, %r1039;
	shl.b32 	%r273, %r1582, 2;
	shr.u32 	%r1041, %r1585, 31;
	shr.u32 	%r1042, %r1583, 30;
	add.s32 	%r274, %r1041, %r1042;
	setp.eq.s32	%p122, %r1041, 0;
	@%p122 bra 	BB11_150;

	not.b32 	%r1043, %r1585;
	neg.s32 	%r1584, %r273;
	setp.eq.s32	%p123, %r273, 0;
	selp.u32	%r1044, 1, 0, %p123;
	add.s32 	%r1585, %r1044, %r1043;
	xor.b32  	%r1586, %r264, -2147483648;
	bra.uni 	BB11_152;

BB11_150:
	mov.u32 	%r1584, %r273;
	mov.u32 	%r1586, %r264;

BB11_152:
	cvt.u64.u32	%rd217, %r1585;
	cvt.u64.u32	%rd218, %r1584;
	bfi.b64 	%rd219, %rd217, %rd218, 32, 32;
	cvt.rn.f64.s64	%fd37, %rd219;
	mul.f64 	%fd38, %fd37, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f643, %fd38;
	neg.f32 	%f644, %f643;
	setp.eq.s32	%p124, %r1586, 0;
	selp.f32	%f960, %f643, %f644, %p124;
	setp.eq.s32	%p125, %r264, 0;
	neg.s32 	%r1045, %r274;
	selp.b32	%r1587, %r274, %r1045, %p125;

BB11_154:
	and.b32  	%r283, %r1587, 1;
	setp.eq.s32	%p126, %r283, 0;
	selp.f32	%f159, %f960, 0f3F800000, %p126;
	mul.rn.f32 	%f160, %f960, %f960;
	fma.rn.f32 	%f161, %f160, %f159, %f413;
	mov.f32 	%f961, 0fB94D4153;
	@%p126 bra 	BB11_156;

	mov.f32 	%f648, 0fBAB607ED;
	mov.f32 	%f649, 0f37CBAC00;
	fma.rn.f32 	%f961, %f649, %f160, %f648;

BB11_156:
	selp.f32	%f650, 0f3C0885E4, 0f3D2AAABB, %p126;
	fma.rn.f32 	%f651, %f961, %f160, %f650;
	selp.f32	%f652, 0fBE2AAAA8, 0fBEFFFFFF, %p126;
	fma.rn.f32 	%f653, %f651, %f160, %f652;
	fma.rn.f32 	%f962, %f653, %f161, %f159;
	and.b32  	%r1046, %r1587, 2;
	setp.eq.s32	%p128, %r1046, 0;
	@%p128 bra 	BB11_158;

	mov.f32 	%f655, 0fBF800000;
	fma.rn.f32 	%f962, %f962, %f655, %f413;

BB11_158:
	and.b32  	%r1047, %r1, 15;
	and.b32  	%r1049, %r820, 1073741792;
	add.s32 	%r1050, %r1049, %r1047;
	mul.f32 	%f656, %f141, %f962;
	mul.f32 	%f657, %f140, %f959;
	sub.f32 	%f658, %f657, %f656;
	mul.f32 	%f659, %f141, %f959;
	fma.rn.f32 	%f660, %f140, %f962, %f659;
	add.f32 	%f661, %f138, %f658;
	shl.b32 	%r1051, %r1050, 2;
	add.s32 	%r1053, %r747, %r1051;
	st.shared.f32 	[%r1053], %f661;
	add.f32 	%f662, %f139, %f660;
	add.s32 	%r1055, %r749, %r1051;
	st.shared.f32 	[%r1055], %f662;
	sub.f32 	%f663, %f138, %f658;
	st.shared.f32 	[%r1053+64], %f663;
	sub.f32 	%f664, %f139, %f660;
	st.shared.f32 	[%r1055+64], %f664;
	bar.sync 	0;
	ld.shared.f32 	%f167, [%r753];
	ld.shared.f32 	%f168, [%r755];
	ld.shared.f32 	%f169, [%r753+4096];
	ld.shared.f32 	%f170, [%r755+4096];
	shr.u32 	%r1062, %r833, 27;
	add.s32 	%r1063, %r1, %r1062;
	and.b32  	%r1064, %r1063, 134217696;
	sub.s32 	%r1065, %r1, %r1064;
	shl.b32 	%r1066, %r1065, 5;
	cvt.rn.f32.s32	%f665, %r1066;
	mul.f32 	%f666, %f665, 0f3A000000;
	cvt.f64.f32	%fd39, %f666;
	mul.f64 	%fd40, %fd39, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f171, %fd40;
	mul.f32 	%f667, %f171, 0f3F22F983;
	cvt.rni.s32.f32	%r1603, %f667;
	cvt.rn.f32.s32	%f668, %r1603;
	fma.rn.f32 	%f670, %f668, %f404, %f171;
	fma.rn.f32 	%f672, %f668, %f406, %f670;
	fma.rn.f32 	%f966, %f668, %f408, %f672;
	abs.f32 	%f173, %f171;
	setp.leu.f32	%p129, %f173, 0f47CE4780;
	mov.u32 	%r1595, %r1603;
	mov.f32 	%f963, %f966;
	@%p129 bra 	BB11_169;

	setp.eq.f32	%p130, %f173, 0f7F800000;
	@%p130 bra 	BB11_168;
	bra.uni 	BB11_160;

BB11_168:
	mul.rn.f32 	%f963, %f171, %f413;
	mov.u32 	%r1595, %r1603;
	bra.uni 	BB11_169;

BB11_160:
	mov.b32 	 %r286, %f171;
	shl.b32 	%r1069, %r286, 8;
	or.b32  	%r287, %r1069, -2147483648;
	cvta.to.local.u64 	%rd342, %rd145;
	mov.u32 	%r1589, 0;
	mov.u64 	%rd341, __cudart_i2opi_f;
	mov.u32 	%r1588, -6;

BB11_161:
	.pragma "nounroll";
	ld.const.u32 	%r1072, [%rd341];
	// inline asm
	{
	mad.lo.cc.u32   %r1070, %r1072, %r287, %r1589;
	madc.hi.u32     %r1589, %r1072, %r287,  0;
	}
	// inline asm
	st.local.u32 	[%rd342], %r1070;
	add.s64 	%rd342, %rd342, 4;
	add.s64 	%rd341, %rd341, 4;
	add.s32 	%r1588, %r1588, 1;
	setp.ne.s32	%p131, %r1588, 0;
	@%p131 bra 	BB11_161;

	bfe.u32 	%r1075, %r286, 23, 8;
	add.s32 	%r1076, %r1075, -128;
	shr.u32 	%r1077, %r1076, 5;
	and.b32  	%r292, %r286, -2147483648;
	cvta.to.local.u64 	%rd223, %rd145;
	st.local.u32 	[%rd223+24], %r1589;
	bfe.u32 	%r293, %r286, 23, 5;
	mov.u32 	%r1078, 6;
	sub.s32 	%r1079, %r1078, %r1077;
	mul.wide.s32 	%rd224, %r1079, 4;
	add.s64 	%rd66, %rd223, %rd224;
	ld.local.u32 	%r1591, [%rd66];
	ld.local.u32 	%r1590, [%rd66+-4];
	setp.eq.s32	%p132, %r293, 0;
	@%p132 bra 	BB11_164;

	mov.u32 	%r1080, 32;
	sub.s32 	%r1081, %r1080, %r293;
	shr.u32 	%r1082, %r1590, %r1081;
	shl.b32 	%r1083, %r1591, %r293;
	add.s32 	%r1591, %r1082, %r1083;
	ld.local.u32 	%r1084, [%rd66+-8];
	shr.u32 	%r1085, %r1084, %r1081;
	shl.b32 	%r1086, %r1590, %r293;
	add.s32 	%r1590, %r1085, %r1086;

BB11_164:
	shr.u32 	%r1087, %r1590, 30;
	shl.b32 	%r1088, %r1591, 2;
	add.s32 	%r1593, %r1088, %r1087;
	shl.b32 	%r301, %r1590, 2;
	shr.u32 	%r1089, %r1593, 31;
	shr.u32 	%r1090, %r1591, 30;
	add.s32 	%r302, %r1089, %r1090;
	setp.eq.s32	%p133, %r1089, 0;
	@%p133 bra 	BB11_165;

	not.b32 	%r1091, %r1593;
	neg.s32 	%r1592, %r301;
	setp.eq.s32	%p134, %r301, 0;
	selp.u32	%r1092, 1, 0, %p134;
	add.s32 	%r1593, %r1092, %r1091;
	xor.b32  	%r1594, %r292, -2147483648;
	bra.uni 	BB11_167;

BB11_165:
	mov.u32 	%r1592, %r301;
	mov.u32 	%r1594, %r292;

BB11_167:
	cvt.u64.u32	%rd225, %r1593;
	cvt.u64.u32	%rd226, %r1592;
	bfi.b64 	%rd227, %rd225, %rd226, 32, 32;
	cvt.rn.f64.s64	%fd41, %rd227;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f674, %fd42;
	neg.f32 	%f675, %f674;
	setp.eq.s32	%p135, %r1594, 0;
	selp.f32	%f963, %f674, %f675, %p135;
	setp.eq.s32	%p136, %r292, 0;
	neg.s32 	%r1093, %r302;
	selp.b32	%r1595, %r302, %r1093, %p136;

BB11_169:
	add.s32 	%r311, %r1595, 1;
	and.b32  	%r312, %r311, 1;
	setp.eq.s32	%p137, %r312, 0;
	selp.f32	%f177, %f963, 0f3F800000, %p137;
	mul.rn.f32 	%f178, %f963, %f963;
	fma.rn.f32 	%f179, %f178, %f177, %f413;
	mov.f32 	%f964, 0fB94D4153;
	@%p137 bra 	BB11_171;

	mov.f32 	%f679, 0fBAB607ED;
	mov.f32 	%f680, 0f37CBAC00;
	fma.rn.f32 	%f964, %f680, %f178, %f679;

BB11_171:
	selp.f32	%f681, 0f3C0885E4, 0f3D2AAABB, %p137;
	fma.rn.f32 	%f682, %f964, %f178, %f681;
	selp.f32	%f683, 0fBE2AAAA8, 0fBEFFFFFF, %p137;
	fma.rn.f32 	%f684, %f682, %f178, %f683;
	fma.rn.f32 	%f965, %f684, %f179, %f177;
	and.b32  	%r1094, %r311, 2;
	setp.eq.s32	%p139, %r1094, 0;
	@%p139 bra 	BB11_173;

	mov.f32 	%f686, 0fBF800000;
	fma.rn.f32 	%f965, %f965, %f686, %f413;

BB11_173:
	@%p129 bra 	BB11_184;

	setp.eq.f32	%p141, %f173, 0f7F800000;
	@%p141 bra 	BB11_183;
	bra.uni 	BB11_175;

BB11_183:
	mul.rn.f32 	%f966, %f171, %f413;
	bra.uni 	BB11_184;

BB11_175:
	mov.b32 	 %r313, %f171;
	shl.b32 	%r1097, %r313, 8;
	or.b32  	%r314, %r1097, -2147483648;
	cvta.to.local.u64 	%rd344, %rd145;
	mov.u32 	%r1597, 0;
	mov.u64 	%rd343, __cudart_i2opi_f;
	mov.u32 	%r1596, -6;

BB11_176:
	.pragma "nounroll";
	ld.const.u32 	%r1100, [%rd343];
	// inline asm
	{
	mad.lo.cc.u32   %r1098, %r1100, %r314, %r1597;
	madc.hi.u32     %r1597, %r1100, %r314,  0;
	}
	// inline asm
	st.local.u32 	[%rd344], %r1098;
	add.s64 	%rd344, %rd344, 4;
	add.s64 	%rd343, %rd343, 4;
	add.s32 	%r1596, %r1596, 1;
	setp.ne.s32	%p142, %r1596, 0;
	@%p142 bra 	BB11_176;

	bfe.u32 	%r1103, %r313, 23, 8;
	add.s32 	%r1104, %r1103, -128;
	shr.u32 	%r1105, %r1104, 5;
	and.b32  	%r319, %r313, -2147483648;
	cvta.to.local.u64 	%rd231, %rd145;
	st.local.u32 	[%rd231+24], %r1597;
	bfe.u32 	%r320, %r313, 23, 5;
	mov.u32 	%r1106, 6;
	sub.s32 	%r1107, %r1106, %r1105;
	mul.wide.s32 	%rd232, %r1107, 4;
	add.s64 	%rd72, %rd231, %rd232;
	ld.local.u32 	%r1599, [%rd72];
	ld.local.u32 	%r1598, [%rd72+-4];
	setp.eq.s32	%p143, %r320, 0;
	@%p143 bra 	BB11_179;

	mov.u32 	%r1108, 32;
	sub.s32 	%r1109, %r1108, %r320;
	shr.u32 	%r1110, %r1598, %r1109;
	shl.b32 	%r1111, %r1599, %r320;
	add.s32 	%r1599, %r1110, %r1111;
	ld.local.u32 	%r1112, [%rd72+-8];
	shr.u32 	%r1113, %r1112, %r1109;
	shl.b32 	%r1114, %r1598, %r320;
	add.s32 	%r1598, %r1113, %r1114;

BB11_179:
	shr.u32 	%r1115, %r1598, 30;
	shl.b32 	%r1116, %r1599, 2;
	add.s32 	%r1601, %r1116, %r1115;
	shl.b32 	%r328, %r1598, 2;
	shr.u32 	%r1117, %r1601, 31;
	shr.u32 	%r1118, %r1599, 30;
	add.s32 	%r329, %r1117, %r1118;
	setp.eq.s32	%p144, %r1117, 0;
	@%p144 bra 	BB11_180;

	not.b32 	%r1119, %r1601;
	neg.s32 	%r1600, %r328;
	setp.eq.s32	%p145, %r328, 0;
	selp.u32	%r1120, 1, 0, %p145;
	add.s32 	%r1601, %r1120, %r1119;
	xor.b32  	%r1602, %r319, -2147483648;
	bra.uni 	BB11_182;

BB11_180:
	mov.u32 	%r1600, %r328;
	mov.u32 	%r1602, %r319;

BB11_182:
	cvt.u64.u32	%rd233, %r1601;
	cvt.u64.u32	%rd234, %r1600;
	bfi.b64 	%rd235, %rd233, %rd234, 32, 32;
	cvt.rn.f64.s64	%fd43, %rd235;
	mul.f64 	%fd44, %fd43, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f687, %fd44;
	neg.f32 	%f688, %f687;
	setp.eq.s32	%p146, %r1602, 0;
	selp.f32	%f966, %f687, %f688, %p146;
	setp.eq.s32	%p147, %r319, 0;
	neg.s32 	%r1121, %r329;
	selp.b32	%r1603, %r329, %r1121, %p147;

BB11_184:
	and.b32  	%r338, %r1603, 1;
	setp.eq.s32	%p148, %r338, 0;
	selp.f32	%f188, %f966, 0f3F800000, %p148;
	mul.rn.f32 	%f189, %f966, %f966;
	fma.rn.f32 	%f190, %f189, %f188, %f413;
	mov.f32 	%f967, 0fB94D4153;
	@%p148 bra 	BB11_186;

	mov.f32 	%f692, 0fBAB607ED;
	mov.f32 	%f693, 0f37CBAC00;
	fma.rn.f32 	%f967, %f693, %f189, %f692;

BB11_186:
	selp.f32	%f694, 0f3C0885E4, 0f3D2AAABB, %p148;
	fma.rn.f32 	%f695, %f967, %f189, %f694;
	selp.f32	%f696, 0fBE2AAAA8, 0fBEFFFFFF, %p148;
	fma.rn.f32 	%f697, %f695, %f189, %f696;
	fma.rn.f32 	%f968, %f697, %f190, %f188;
	and.b32  	%r1122, %r1603, 2;
	setp.eq.s32	%p150, %r1122, 0;
	@%p150 bra 	BB11_188;

	mov.f32 	%f699, 0fBF800000;
	fma.rn.f32 	%f968, %f968, %f699, %f413;

BB11_188:
	and.b32  	%r1123, %r1, 31;
	and.b32  	%r1125, %r820, 1073741760;
	add.s32 	%r1126, %r1125, %r1123;
	mul.f32 	%f700, %f170, %f968;
	mul.f32 	%f701, %f169, %f965;
	sub.f32 	%f702, %f701, %f700;
	mul.f32 	%f703, %f170, %f965;
	fma.rn.f32 	%f704, %f169, %f968, %f703;
	add.f32 	%f705, %f167, %f702;
	shl.b32 	%r1127, %r1126, 2;
	add.s32 	%r1129, %r621, %r1127;
	st.shared.f32 	[%r1129], %f705;
	add.f32 	%f706, %f168, %f704;
	add.s32 	%r1131, %r622, %r1127;
	st.shared.f32 	[%r1131], %f706;
	sub.f32 	%f707, %f167, %f702;
	st.shared.f32 	[%r1129+128], %f707;
	sub.f32 	%f708, %f168, %f704;
	st.shared.f32 	[%r1131+128], %f708;
	bar.sync 	0;
	ld.shared.f32 	%f196, [%r2];
	ld.shared.f32 	%f197, [%r3];
	ld.shared.f32 	%f198, [%r2+4096];
	ld.shared.f32 	%f199, [%r3+4096];
	shr.u32 	%r1138, %r833, 26;
	add.s32 	%r1139, %r1, %r1138;
	and.b32  	%r1140, %r1139, 268435392;
	sub.s32 	%r1141, %r1, %r1140;
	shl.b32 	%r1142, %r1141, 4;
	cvt.rn.f32.s32	%f709, %r1142;
	mul.f32 	%f710, %f709, 0f3A000000;
	cvt.f64.f32	%fd45, %f710;
	mul.f64 	%fd46, %fd45, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f200, %fd46;
	mul.f32 	%f711, %f200, 0f3F22F983;
	cvt.rni.s32.f32	%r1619, %f711;
	cvt.rn.f32.s32	%f712, %r1619;
	fma.rn.f32 	%f714, %f712, %f404, %f200;
	fma.rn.f32 	%f716, %f712, %f406, %f714;
	fma.rn.f32 	%f972, %f712, %f408, %f716;
	abs.f32 	%f202, %f200;
	setp.leu.f32	%p151, %f202, 0f47CE4780;
	mov.u32 	%r1611, %r1619;
	mov.f32 	%f969, %f972;
	@%p151 bra 	BB11_199;

	setp.eq.f32	%p152, %f202, 0f7F800000;
	@%p152 bra 	BB11_198;
	bra.uni 	BB11_190;

BB11_198:
	mul.rn.f32 	%f969, %f200, %f413;
	mov.u32 	%r1611, %r1619;
	bra.uni 	BB11_199;

BB11_190:
	mov.b32 	 %r341, %f200;
	shl.b32 	%r1145, %r341, 8;
	or.b32  	%r342, %r1145, -2147483648;
	cvta.to.local.u64 	%rd346, %rd145;
	mov.u32 	%r1605, 0;
	mov.u64 	%rd345, __cudart_i2opi_f;
	mov.u32 	%r1604, -6;

BB11_191:
	.pragma "nounroll";
	ld.const.u32 	%r1148, [%rd345];
	// inline asm
	{
	mad.lo.cc.u32   %r1146, %r1148, %r342, %r1605;
	madc.hi.u32     %r1605, %r1148, %r342,  0;
	}
	// inline asm
	st.local.u32 	[%rd346], %r1146;
	add.s64 	%rd346, %rd346, 4;
	add.s64 	%rd345, %rd345, 4;
	add.s32 	%r1604, %r1604, 1;
	setp.ne.s32	%p153, %r1604, 0;
	@%p153 bra 	BB11_191;

	bfe.u32 	%r1151, %r341, 23, 8;
	add.s32 	%r1152, %r1151, -128;
	shr.u32 	%r1153, %r1152, 5;
	and.b32  	%r347, %r341, -2147483648;
	cvta.to.local.u64 	%rd239, %rd145;
	st.local.u32 	[%rd239+24], %r1605;
	bfe.u32 	%r348, %r341, 23, 5;
	mov.u32 	%r1154, 6;
	sub.s32 	%r1155, %r1154, %r1153;
	mul.wide.s32 	%rd240, %r1155, 4;
	add.s64 	%rd78, %rd239, %rd240;
	ld.local.u32 	%r1607, [%rd78];
	ld.local.u32 	%r1606, [%rd78+-4];
	setp.eq.s32	%p154, %r348, 0;
	@%p154 bra 	BB11_194;

	mov.u32 	%r1156, 32;
	sub.s32 	%r1157, %r1156, %r348;
	shr.u32 	%r1158, %r1606, %r1157;
	shl.b32 	%r1159, %r1607, %r348;
	add.s32 	%r1607, %r1158, %r1159;
	ld.local.u32 	%r1160, [%rd78+-8];
	shr.u32 	%r1161, %r1160, %r1157;
	shl.b32 	%r1162, %r1606, %r348;
	add.s32 	%r1606, %r1161, %r1162;

BB11_194:
	shr.u32 	%r1163, %r1606, 30;
	shl.b32 	%r1164, %r1607, 2;
	add.s32 	%r1609, %r1164, %r1163;
	shl.b32 	%r356, %r1606, 2;
	shr.u32 	%r1165, %r1609, 31;
	shr.u32 	%r1166, %r1607, 30;
	add.s32 	%r357, %r1165, %r1166;
	setp.eq.s32	%p155, %r1165, 0;
	@%p155 bra 	BB11_195;

	not.b32 	%r1167, %r1609;
	neg.s32 	%r1608, %r356;
	setp.eq.s32	%p156, %r356, 0;
	selp.u32	%r1168, 1, 0, %p156;
	add.s32 	%r1609, %r1168, %r1167;
	xor.b32  	%r1610, %r347, -2147483648;
	bra.uni 	BB11_197;

BB11_195:
	mov.u32 	%r1608, %r356;
	mov.u32 	%r1610, %r347;

BB11_197:
	cvt.u64.u32	%rd241, %r1609;
	cvt.u64.u32	%rd242, %r1608;
	bfi.b64 	%rd243, %rd241, %rd242, 32, 32;
	cvt.rn.f64.s64	%fd47, %rd243;
	mul.f64 	%fd48, %fd47, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f718, %fd48;
	neg.f32 	%f719, %f718;
	setp.eq.s32	%p157, %r1610, 0;
	selp.f32	%f969, %f718, %f719, %p157;
	setp.eq.s32	%p158, %r347, 0;
	neg.s32 	%r1169, %r357;
	selp.b32	%r1611, %r357, %r1169, %p158;

BB11_199:
	add.s32 	%r366, %r1611, 1;
	and.b32  	%r367, %r366, 1;
	setp.eq.s32	%p159, %r367, 0;
	selp.f32	%f206, %f969, 0f3F800000, %p159;
	mul.rn.f32 	%f207, %f969, %f969;
	fma.rn.f32 	%f208, %f207, %f206, %f413;
	mov.f32 	%f970, 0fB94D4153;
	@%p159 bra 	BB11_201;

	mov.f32 	%f723, 0fBAB607ED;
	mov.f32 	%f724, 0f37CBAC00;
	fma.rn.f32 	%f970, %f724, %f207, %f723;

BB11_201:
	selp.f32	%f725, 0f3C0885E4, 0f3D2AAABB, %p159;
	fma.rn.f32 	%f726, %f970, %f207, %f725;
	selp.f32	%f727, 0fBE2AAAA8, 0fBEFFFFFF, %p159;
	fma.rn.f32 	%f728, %f726, %f207, %f727;
	fma.rn.f32 	%f971, %f728, %f208, %f206;
	and.b32  	%r1170, %r366, 2;
	setp.eq.s32	%p161, %r1170, 0;
	@%p161 bra 	BB11_203;

	mov.f32 	%f730, 0fBF800000;
	fma.rn.f32 	%f971, %f971, %f730, %f413;

BB11_203:
	@%p151 bra 	BB11_214;

	setp.eq.f32	%p163, %f202, 0f7F800000;
	@%p163 bra 	BB11_213;
	bra.uni 	BB11_205;

BB11_213:
	mul.rn.f32 	%f972, %f200, %f413;
	bra.uni 	BB11_214;

BB11_205:
	mov.b32 	 %r368, %f200;
	shl.b32 	%r1173, %r368, 8;
	or.b32  	%r369, %r1173, -2147483648;
	cvta.to.local.u64 	%rd348, %rd145;
	mov.u32 	%r1613, 0;
	mov.u64 	%rd347, __cudart_i2opi_f;
	mov.u32 	%r1612, -6;

BB11_206:
	.pragma "nounroll";
	ld.const.u32 	%r1176, [%rd347];
	// inline asm
	{
	mad.lo.cc.u32   %r1174, %r1176, %r369, %r1613;
	madc.hi.u32     %r1613, %r1176, %r369,  0;
	}
	// inline asm
	st.local.u32 	[%rd348], %r1174;
	add.s64 	%rd348, %rd348, 4;
	add.s64 	%rd347, %rd347, 4;
	add.s32 	%r1612, %r1612, 1;
	setp.ne.s32	%p164, %r1612, 0;
	@%p164 bra 	BB11_206;

	bfe.u32 	%r1179, %r368, 23, 8;
	add.s32 	%r1180, %r1179, -128;
	shr.u32 	%r1181, %r1180, 5;
	and.b32  	%r374, %r368, -2147483648;
	cvta.to.local.u64 	%rd247, %rd145;
	st.local.u32 	[%rd247+24], %r1613;
	bfe.u32 	%r375, %r368, 23, 5;
	mov.u32 	%r1182, 6;
	sub.s32 	%r1183, %r1182, %r1181;
	mul.wide.s32 	%rd248, %r1183, 4;
	add.s64 	%rd84, %rd247, %rd248;
	ld.local.u32 	%r1615, [%rd84];
	ld.local.u32 	%r1614, [%rd84+-4];
	setp.eq.s32	%p165, %r375, 0;
	@%p165 bra 	BB11_209;

	mov.u32 	%r1184, 32;
	sub.s32 	%r1185, %r1184, %r375;
	shr.u32 	%r1186, %r1614, %r1185;
	shl.b32 	%r1187, %r1615, %r375;
	add.s32 	%r1615, %r1186, %r1187;
	ld.local.u32 	%r1188, [%rd84+-8];
	shr.u32 	%r1189, %r1188, %r1185;
	shl.b32 	%r1190, %r1614, %r375;
	add.s32 	%r1614, %r1189, %r1190;

BB11_209:
	shr.u32 	%r1191, %r1614, 30;
	shl.b32 	%r1192, %r1615, 2;
	add.s32 	%r1617, %r1192, %r1191;
	shl.b32 	%r383, %r1614, 2;
	shr.u32 	%r1193, %r1617, 31;
	shr.u32 	%r1194, %r1615, 30;
	add.s32 	%r384, %r1193, %r1194;
	setp.eq.s32	%p166, %r1193, 0;
	@%p166 bra 	BB11_210;

	not.b32 	%r1195, %r1617;
	neg.s32 	%r1616, %r383;
	setp.eq.s32	%p167, %r383, 0;
	selp.u32	%r1196, 1, 0, %p167;
	add.s32 	%r1617, %r1196, %r1195;
	xor.b32  	%r1618, %r374, -2147483648;
	bra.uni 	BB11_212;

BB11_210:
	mov.u32 	%r1616, %r383;
	mov.u32 	%r1618, %r374;

BB11_212:
	cvt.u64.u32	%rd249, %r1617;
	cvt.u64.u32	%rd250, %r1616;
	bfi.b64 	%rd251, %rd249, %rd250, 32, 32;
	cvt.rn.f64.s64	%fd49, %rd251;
	mul.f64 	%fd50, %fd49, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f731, %fd50;
	neg.f32 	%f732, %f731;
	setp.eq.s32	%p168, %r1618, 0;
	selp.f32	%f972, %f731, %f732, %p168;
	setp.eq.s32	%p169, %r374, 0;
	neg.s32 	%r1197, %r384;
	selp.b32	%r1619, %r384, %r1197, %p169;

BB11_214:
	and.b32  	%r393, %r1619, 1;
	setp.eq.s32	%p170, %r393, 0;
	selp.f32	%f217, %f972, 0f3F800000, %p170;
	mul.rn.f32 	%f218, %f972, %f972;
	fma.rn.f32 	%f219, %f218, %f217, %f413;
	mov.f32 	%f973, 0fB94D4153;
	@%p170 bra 	BB11_216;

	mov.f32 	%f736, 0fBAB607ED;
	mov.f32 	%f737, 0f37CBAC00;
	fma.rn.f32 	%f973, %f737, %f218, %f736;

BB11_216:
	selp.f32	%f738, 0f3C0885E4, 0f3D2AAABB, %p170;
	fma.rn.f32 	%f739, %f973, %f218, %f738;
	selp.f32	%f740, 0fBE2AAAA8, 0fBEFFFFFF, %p170;
	fma.rn.f32 	%f741, %f739, %f218, %f740;
	fma.rn.f32 	%f974, %f741, %f219, %f217;
	and.b32  	%r1198, %r1619, 2;
	setp.eq.s32	%p172, %r1198, 0;
	@%p172 bra 	BB11_218;

	mov.f32 	%f743, 0fBF800000;
	fma.rn.f32 	%f974, %f974, %f743, %f413;

BB11_218:
	and.b32  	%r1199, %r1, 63;
	and.b32  	%r1201, %r820, 1073741696;
	add.s32 	%r1202, %r1201, %r1199;
	mul.f32 	%f744, %f199, %f974;
	mul.f32 	%f745, %f198, %f971;
	sub.f32 	%f746, %f745, %f744;
	mul.f32 	%f747, %f199, %f971;
	fma.rn.f32 	%f748, %f198, %f974, %f747;
	add.f32 	%f749, %f196, %f746;
	shl.b32 	%r1203, %r1202, 2;
	add.s32 	%r1205, %r747, %r1203;
	st.shared.f32 	[%r1205], %f749;
	add.f32 	%f750, %f197, %f748;
	add.s32 	%r1207, %r749, %r1203;
	st.shared.f32 	[%r1207], %f750;
	sub.f32 	%f751, %f196, %f746;
	st.shared.f32 	[%r1205+256], %f751;
	sub.f32 	%f752, %f197, %f748;
	st.shared.f32 	[%r1207+256], %f752;
	bar.sync 	0;
	ld.shared.f32 	%f225, [%r753];
	ld.shared.f32 	%f226, [%r755];
	ld.shared.f32 	%f227, [%r753+4096];
	ld.shared.f32 	%f228, [%r755+4096];
	shr.u32 	%r1214, %r833, 25;
	add.s32 	%r1215, %r1, %r1214;
	and.b32  	%r1216, %r1215, 536870784;
	sub.s32 	%r1217, %r1, %r1216;
	shl.b32 	%r1218, %r1217, 3;
	cvt.rn.f32.s32	%f753, %r1218;
	mul.f32 	%f754, %f753, 0f3A000000;
	cvt.f64.f32	%fd51, %f754;
	mul.f64 	%fd52, %fd51, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f229, %fd52;
	mul.f32 	%f755, %f229, 0f3F22F983;
	cvt.rni.s32.f32	%r1635, %f755;
	cvt.rn.f32.s32	%f756, %r1635;
	fma.rn.f32 	%f758, %f756, %f404, %f229;
	fma.rn.f32 	%f760, %f756, %f406, %f758;
	fma.rn.f32 	%f978, %f756, %f408, %f760;
	abs.f32 	%f231, %f229;
	setp.leu.f32	%p173, %f231, 0f47CE4780;
	mov.u32 	%r1627, %r1635;
	mov.f32 	%f975, %f978;
	@%p173 bra 	BB11_229;

	setp.eq.f32	%p174, %f231, 0f7F800000;
	@%p174 bra 	BB11_228;
	bra.uni 	BB11_220;

BB11_228:
	mul.rn.f32 	%f975, %f229, %f413;
	mov.u32 	%r1627, %r1635;
	bra.uni 	BB11_229;

BB11_220:
	mov.b32 	 %r396, %f229;
	shl.b32 	%r1221, %r396, 8;
	or.b32  	%r397, %r1221, -2147483648;
	cvta.to.local.u64 	%rd350, %rd145;
	mov.u32 	%r1621, 0;
	mov.u64 	%rd349, __cudart_i2opi_f;
	mov.u32 	%r1620, -6;

BB11_221:
	.pragma "nounroll";
	ld.const.u32 	%r1224, [%rd349];
	// inline asm
	{
	mad.lo.cc.u32   %r1222, %r1224, %r397, %r1621;
	madc.hi.u32     %r1621, %r1224, %r397,  0;
	}
	// inline asm
	st.local.u32 	[%rd350], %r1222;
	add.s64 	%rd350, %rd350, 4;
	add.s64 	%rd349, %rd349, 4;
	add.s32 	%r1620, %r1620, 1;
	setp.ne.s32	%p175, %r1620, 0;
	@%p175 bra 	BB11_221;

	bfe.u32 	%r1227, %r396, 23, 8;
	add.s32 	%r1228, %r1227, -128;
	shr.u32 	%r1229, %r1228, 5;
	and.b32  	%r402, %r396, -2147483648;
	cvta.to.local.u64 	%rd255, %rd145;
	st.local.u32 	[%rd255+24], %r1621;
	bfe.u32 	%r403, %r396, 23, 5;
	mov.u32 	%r1230, 6;
	sub.s32 	%r1231, %r1230, %r1229;
	mul.wide.s32 	%rd256, %r1231, 4;
	add.s64 	%rd90, %rd255, %rd256;
	ld.local.u32 	%r1623, [%rd90];
	ld.local.u32 	%r1622, [%rd90+-4];
	setp.eq.s32	%p176, %r403, 0;
	@%p176 bra 	BB11_224;

	mov.u32 	%r1232, 32;
	sub.s32 	%r1233, %r1232, %r403;
	shr.u32 	%r1234, %r1622, %r1233;
	shl.b32 	%r1235, %r1623, %r403;
	add.s32 	%r1623, %r1234, %r1235;
	ld.local.u32 	%r1236, [%rd90+-8];
	shr.u32 	%r1237, %r1236, %r1233;
	shl.b32 	%r1238, %r1622, %r403;
	add.s32 	%r1622, %r1237, %r1238;

BB11_224:
	shr.u32 	%r1239, %r1622, 30;
	shl.b32 	%r1240, %r1623, 2;
	add.s32 	%r1625, %r1240, %r1239;
	shl.b32 	%r411, %r1622, 2;
	shr.u32 	%r1241, %r1625, 31;
	shr.u32 	%r1242, %r1623, 30;
	add.s32 	%r412, %r1241, %r1242;
	setp.eq.s32	%p177, %r1241, 0;
	@%p177 bra 	BB11_225;

	not.b32 	%r1243, %r1625;
	neg.s32 	%r1624, %r411;
	setp.eq.s32	%p178, %r411, 0;
	selp.u32	%r1244, 1, 0, %p178;
	add.s32 	%r1625, %r1244, %r1243;
	xor.b32  	%r1626, %r402, -2147483648;
	bra.uni 	BB11_227;

BB11_225:
	mov.u32 	%r1624, %r411;
	mov.u32 	%r1626, %r402;

BB11_227:
	cvt.u64.u32	%rd257, %r1625;
	cvt.u64.u32	%rd258, %r1624;
	bfi.b64 	%rd259, %rd257, %rd258, 32, 32;
	cvt.rn.f64.s64	%fd53, %rd259;
	mul.f64 	%fd54, %fd53, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f762, %fd54;
	neg.f32 	%f763, %f762;
	setp.eq.s32	%p179, %r1626, 0;
	selp.f32	%f975, %f762, %f763, %p179;
	setp.eq.s32	%p180, %r402, 0;
	neg.s32 	%r1245, %r412;
	selp.b32	%r1627, %r412, %r1245, %p180;

BB11_229:
	add.s32 	%r421, %r1627, 1;
	and.b32  	%r422, %r421, 1;
	setp.eq.s32	%p181, %r422, 0;
	selp.f32	%f235, %f975, 0f3F800000, %p181;
	mul.rn.f32 	%f236, %f975, %f975;
	fma.rn.f32 	%f237, %f236, %f235, %f413;
	mov.f32 	%f976, 0fB94D4153;
	@%p181 bra 	BB11_231;

	mov.f32 	%f767, 0fBAB607ED;
	mov.f32 	%f768, 0f37CBAC00;
	fma.rn.f32 	%f976, %f768, %f236, %f767;

BB11_231:
	selp.f32	%f769, 0f3C0885E4, 0f3D2AAABB, %p181;
	fma.rn.f32 	%f770, %f976, %f236, %f769;
	selp.f32	%f771, 0fBE2AAAA8, 0fBEFFFFFF, %p181;
	fma.rn.f32 	%f772, %f770, %f236, %f771;
	fma.rn.f32 	%f977, %f772, %f237, %f235;
	and.b32  	%r1246, %r421, 2;
	setp.eq.s32	%p183, %r1246, 0;
	@%p183 bra 	BB11_233;

	mov.f32 	%f774, 0fBF800000;
	fma.rn.f32 	%f977, %f977, %f774, %f413;

BB11_233:
	@%p173 bra 	BB11_244;

	setp.eq.f32	%p185, %f231, 0f7F800000;
	@%p185 bra 	BB11_243;
	bra.uni 	BB11_235;

BB11_243:
	mul.rn.f32 	%f978, %f229, %f413;
	bra.uni 	BB11_244;

BB11_235:
	mov.b32 	 %r423, %f229;
	shl.b32 	%r1249, %r423, 8;
	or.b32  	%r424, %r1249, -2147483648;
	cvta.to.local.u64 	%rd352, %rd145;
	mov.u32 	%r1629, 0;
	mov.u64 	%rd351, __cudart_i2opi_f;
	mov.u32 	%r1628, -6;

BB11_236:
	.pragma "nounroll";
	ld.const.u32 	%r1252, [%rd351];
	// inline asm
	{
	mad.lo.cc.u32   %r1250, %r1252, %r424, %r1629;
	madc.hi.u32     %r1629, %r1252, %r424,  0;
	}
	// inline asm
	st.local.u32 	[%rd352], %r1250;
	add.s64 	%rd352, %rd352, 4;
	add.s64 	%rd351, %rd351, 4;
	add.s32 	%r1628, %r1628, 1;
	setp.ne.s32	%p186, %r1628, 0;
	@%p186 bra 	BB11_236;

	bfe.u32 	%r1255, %r423, 23, 8;
	add.s32 	%r1256, %r1255, -128;
	shr.u32 	%r1257, %r1256, 5;
	and.b32  	%r429, %r423, -2147483648;
	cvta.to.local.u64 	%rd263, %rd145;
	st.local.u32 	[%rd263+24], %r1629;
	bfe.u32 	%r430, %r423, 23, 5;
	mov.u32 	%r1258, 6;
	sub.s32 	%r1259, %r1258, %r1257;
	mul.wide.s32 	%rd264, %r1259, 4;
	add.s64 	%rd96, %rd263, %rd264;
	ld.local.u32 	%r1631, [%rd96];
	ld.local.u32 	%r1630, [%rd96+-4];
	setp.eq.s32	%p187, %r430, 0;
	@%p187 bra 	BB11_239;

	mov.u32 	%r1260, 32;
	sub.s32 	%r1261, %r1260, %r430;
	shr.u32 	%r1262, %r1630, %r1261;
	shl.b32 	%r1263, %r1631, %r430;
	add.s32 	%r1631, %r1262, %r1263;
	ld.local.u32 	%r1264, [%rd96+-8];
	shr.u32 	%r1265, %r1264, %r1261;
	shl.b32 	%r1266, %r1630, %r430;
	add.s32 	%r1630, %r1265, %r1266;

BB11_239:
	shr.u32 	%r1267, %r1630, 30;
	shl.b32 	%r1268, %r1631, 2;
	add.s32 	%r1633, %r1268, %r1267;
	shl.b32 	%r438, %r1630, 2;
	shr.u32 	%r1269, %r1633, 31;
	shr.u32 	%r1270, %r1631, 30;
	add.s32 	%r439, %r1269, %r1270;
	setp.eq.s32	%p188, %r1269, 0;
	@%p188 bra 	BB11_240;

	not.b32 	%r1271, %r1633;
	neg.s32 	%r1632, %r438;
	setp.eq.s32	%p189, %r438, 0;
	selp.u32	%r1272, 1, 0, %p189;
	add.s32 	%r1633, %r1272, %r1271;
	xor.b32  	%r1634, %r429, -2147483648;
	bra.uni 	BB11_242;

BB11_240:
	mov.u32 	%r1632, %r438;
	mov.u32 	%r1634, %r429;

BB11_242:
	cvt.u64.u32	%rd265, %r1633;
	cvt.u64.u32	%rd266, %r1632;
	bfi.b64 	%rd267, %rd265, %rd266, 32, 32;
	cvt.rn.f64.s64	%fd55, %rd267;
	mul.f64 	%fd56, %fd55, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f775, %fd56;
	neg.f32 	%f776, %f775;
	setp.eq.s32	%p190, %r1634, 0;
	selp.f32	%f978, %f775, %f776, %p190;
	setp.eq.s32	%p191, %r429, 0;
	neg.s32 	%r1273, %r439;
	selp.b32	%r1635, %r439, %r1273, %p191;

BB11_244:
	and.b32  	%r448, %r1635, 1;
	setp.eq.s32	%p192, %r448, 0;
	selp.f32	%f246, %f978, 0f3F800000, %p192;
	mul.rn.f32 	%f247, %f978, %f978;
	fma.rn.f32 	%f248, %f247, %f246, %f413;
	mov.f32 	%f979, 0fB94D4153;
	@%p192 bra 	BB11_246;

	mov.f32 	%f780, 0fBAB607ED;
	mov.f32 	%f781, 0f37CBAC00;
	fma.rn.f32 	%f979, %f781, %f247, %f780;

BB11_246:
	selp.f32	%f782, 0f3C0885E4, 0f3D2AAABB, %p192;
	fma.rn.f32 	%f783, %f979, %f247, %f782;
	selp.f32	%f784, 0fBE2AAAA8, 0fBEFFFFFF, %p192;
	fma.rn.f32 	%f785, %f783, %f247, %f784;
	fma.rn.f32 	%f980, %f785, %f248, %f246;
	and.b32  	%r1274, %r1635, 2;
	setp.eq.s32	%p194, %r1274, 0;
	@%p194 bra 	BB11_248;

	mov.f32 	%f787, 0fBF800000;
	fma.rn.f32 	%f980, %f980, %f787, %f413;

BB11_248:
	and.b32  	%r1275, %r1, 127;
	and.b32  	%r1277, %r820, 1073741568;
	add.s32 	%r1278, %r1277, %r1275;
	mul.f32 	%f788, %f228, %f980;
	mul.f32 	%f789, %f227, %f977;
	sub.f32 	%f790, %f789, %f788;
	mul.f32 	%f791, %f228, %f977;
	fma.rn.f32 	%f792, %f227, %f980, %f791;
	add.f32 	%f793, %f225, %f790;
	shl.b32 	%r1279, %r1278, 2;
	add.s32 	%r1281, %r621, %r1279;
	st.shared.f32 	[%r1281], %f793;
	add.f32 	%f794, %f226, %f792;
	add.s32 	%r1283, %r622, %r1279;
	st.shared.f32 	[%r1283], %f794;
	sub.f32 	%f795, %f225, %f790;
	st.shared.f32 	[%r1281+512], %f795;
	sub.f32 	%f796, %f226, %f792;
	st.shared.f32 	[%r1283+512], %f796;
	bar.sync 	0;
	ld.shared.f32 	%f254, [%r2];
	ld.shared.f32 	%f255, [%r3];
	ld.shared.f32 	%f256, [%r2+4096];
	ld.shared.f32 	%f257, [%r3+4096];
	shr.u32 	%r1290, %r833, 24;
	add.s32 	%r1291, %r1, %r1290;
	and.b32  	%r1292, %r1291, 1073741568;
	sub.s32 	%r1293, %r1, %r1292;
	shl.b32 	%r1294, %r1293, 2;
	cvt.rn.f32.s32	%f797, %r1294;
	mul.f32 	%f798, %f797, 0f3A000000;
	cvt.f64.f32	%fd57, %f798;
	mul.f64 	%fd58, %fd57, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f258, %fd58;
	mul.f32 	%f799, %f258, 0f3F22F983;
	cvt.rni.s32.f32	%r1651, %f799;
	cvt.rn.f32.s32	%f800, %r1651;
	fma.rn.f32 	%f802, %f800, %f404, %f258;
	fma.rn.f32 	%f804, %f800, %f406, %f802;
	fma.rn.f32 	%f984, %f800, %f408, %f804;
	abs.f32 	%f260, %f258;
	setp.leu.f32	%p195, %f260, 0f47CE4780;
	mov.u32 	%r1643, %r1651;
	mov.f32 	%f981, %f984;
	@%p195 bra 	BB11_259;

	setp.eq.f32	%p196, %f260, 0f7F800000;
	@%p196 bra 	BB11_258;
	bra.uni 	BB11_250;

BB11_258:
	mul.rn.f32 	%f981, %f258, %f413;
	mov.u32 	%r1643, %r1651;
	bra.uni 	BB11_259;

BB11_250:
	mov.b32 	 %r451, %f258;
	shl.b32 	%r1297, %r451, 8;
	or.b32  	%r452, %r1297, -2147483648;
	cvta.to.local.u64 	%rd354, %rd145;
	mov.u32 	%r1637, 0;
	mov.u64 	%rd353, __cudart_i2opi_f;
	mov.u32 	%r1636, -6;

BB11_251:
	.pragma "nounroll";
	ld.const.u32 	%r1300, [%rd353];
	// inline asm
	{
	mad.lo.cc.u32   %r1298, %r1300, %r452, %r1637;
	madc.hi.u32     %r1637, %r1300, %r452,  0;
	}
	// inline asm
	st.local.u32 	[%rd354], %r1298;
	add.s64 	%rd354, %rd354, 4;
	add.s64 	%rd353, %rd353, 4;
	add.s32 	%r1636, %r1636, 1;
	setp.ne.s32	%p197, %r1636, 0;
	@%p197 bra 	BB11_251;

	bfe.u32 	%r1303, %r451, 23, 8;
	add.s32 	%r1304, %r1303, -128;
	shr.u32 	%r1305, %r1304, 5;
	and.b32  	%r457, %r451, -2147483648;
	cvta.to.local.u64 	%rd271, %rd145;
	st.local.u32 	[%rd271+24], %r1637;
	bfe.u32 	%r458, %r451, 23, 5;
	mov.u32 	%r1306, 6;
	sub.s32 	%r1307, %r1306, %r1305;
	mul.wide.s32 	%rd272, %r1307, 4;
	add.s64 	%rd102, %rd271, %rd272;
	ld.local.u32 	%r1639, [%rd102];
	ld.local.u32 	%r1638, [%rd102+-4];
	setp.eq.s32	%p198, %r458, 0;
	@%p198 bra 	BB11_254;

	mov.u32 	%r1308, 32;
	sub.s32 	%r1309, %r1308, %r458;
	shr.u32 	%r1310, %r1638, %r1309;
	shl.b32 	%r1311, %r1639, %r458;
	add.s32 	%r1639, %r1310, %r1311;
	ld.local.u32 	%r1312, [%rd102+-8];
	shr.u32 	%r1313, %r1312, %r1309;
	shl.b32 	%r1314, %r1638, %r458;
	add.s32 	%r1638, %r1313, %r1314;

BB11_254:
	shr.u32 	%r1315, %r1638, 30;
	shl.b32 	%r1316, %r1639, 2;
	add.s32 	%r1641, %r1316, %r1315;
	shl.b32 	%r466, %r1638, 2;
	shr.u32 	%r1317, %r1641, 31;
	shr.u32 	%r1318, %r1639, 30;
	add.s32 	%r467, %r1317, %r1318;
	setp.eq.s32	%p199, %r1317, 0;
	@%p199 bra 	BB11_255;

	not.b32 	%r1319, %r1641;
	neg.s32 	%r1640, %r466;
	setp.eq.s32	%p200, %r466, 0;
	selp.u32	%r1320, 1, 0, %p200;
	add.s32 	%r1641, %r1320, %r1319;
	xor.b32  	%r1642, %r457, -2147483648;
	bra.uni 	BB11_257;

BB11_255:
	mov.u32 	%r1640, %r466;
	mov.u32 	%r1642, %r457;

BB11_257:
	cvt.u64.u32	%rd273, %r1641;
	cvt.u64.u32	%rd274, %r1640;
	bfi.b64 	%rd275, %rd273, %rd274, 32, 32;
	cvt.rn.f64.s64	%fd59, %rd275;
	mul.f64 	%fd60, %fd59, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f806, %fd60;
	neg.f32 	%f807, %f806;
	setp.eq.s32	%p201, %r1642, 0;
	selp.f32	%f981, %f806, %f807, %p201;
	setp.eq.s32	%p202, %r457, 0;
	neg.s32 	%r1321, %r467;
	selp.b32	%r1643, %r467, %r1321, %p202;

BB11_259:
	add.s32 	%r476, %r1643, 1;
	and.b32  	%r477, %r476, 1;
	setp.eq.s32	%p203, %r477, 0;
	selp.f32	%f264, %f981, 0f3F800000, %p203;
	mul.rn.f32 	%f265, %f981, %f981;
	fma.rn.f32 	%f266, %f265, %f264, %f413;
	mov.f32 	%f982, 0fB94D4153;
	@%p203 bra 	BB11_261;

	mov.f32 	%f811, 0fBAB607ED;
	mov.f32 	%f812, 0f37CBAC00;
	fma.rn.f32 	%f982, %f812, %f265, %f811;

BB11_261:
	selp.f32	%f813, 0f3C0885E4, 0f3D2AAABB, %p203;
	fma.rn.f32 	%f814, %f982, %f265, %f813;
	selp.f32	%f815, 0fBE2AAAA8, 0fBEFFFFFF, %p203;
	fma.rn.f32 	%f816, %f814, %f265, %f815;
	fma.rn.f32 	%f983, %f816, %f266, %f264;
	and.b32  	%r1322, %r476, 2;
	setp.eq.s32	%p205, %r1322, 0;
	@%p205 bra 	BB11_263;

	mov.f32 	%f818, 0fBF800000;
	fma.rn.f32 	%f983, %f983, %f818, %f413;

BB11_263:
	@%p195 bra 	BB11_274;

	setp.eq.f32	%p207, %f260, 0f7F800000;
	@%p207 bra 	BB11_273;
	bra.uni 	BB11_265;

BB11_273:
	mul.rn.f32 	%f984, %f258, %f413;
	bra.uni 	BB11_274;

BB11_265:
	mov.b32 	 %r478, %f258;
	shl.b32 	%r1325, %r478, 8;
	or.b32  	%r479, %r1325, -2147483648;
	cvta.to.local.u64 	%rd356, %rd145;
	mov.u32 	%r1645, 0;
	mov.u64 	%rd355, __cudart_i2opi_f;
	mov.u32 	%r1644, -6;

BB11_266:
	.pragma "nounroll";
	ld.const.u32 	%r1328, [%rd355];
	// inline asm
	{
	mad.lo.cc.u32   %r1326, %r1328, %r479, %r1645;
	madc.hi.u32     %r1645, %r1328, %r479,  0;
	}
	// inline asm
	st.local.u32 	[%rd356], %r1326;
	add.s64 	%rd356, %rd356, 4;
	add.s64 	%rd355, %rd355, 4;
	add.s32 	%r1644, %r1644, 1;
	setp.ne.s32	%p208, %r1644, 0;
	@%p208 bra 	BB11_266;

	bfe.u32 	%r1331, %r478, 23, 8;
	add.s32 	%r1332, %r1331, -128;
	shr.u32 	%r1333, %r1332, 5;
	and.b32  	%r484, %r478, -2147483648;
	cvta.to.local.u64 	%rd279, %rd145;
	st.local.u32 	[%rd279+24], %r1645;
	bfe.u32 	%r485, %r478, 23, 5;
	mov.u32 	%r1334, 6;
	sub.s32 	%r1335, %r1334, %r1333;
	mul.wide.s32 	%rd280, %r1335, 4;
	add.s64 	%rd108, %rd279, %rd280;
	ld.local.u32 	%r1647, [%rd108];
	ld.local.u32 	%r1646, [%rd108+-4];
	setp.eq.s32	%p209, %r485, 0;
	@%p209 bra 	BB11_269;

	mov.u32 	%r1336, 32;
	sub.s32 	%r1337, %r1336, %r485;
	shr.u32 	%r1338, %r1646, %r1337;
	shl.b32 	%r1339, %r1647, %r485;
	add.s32 	%r1647, %r1338, %r1339;
	ld.local.u32 	%r1340, [%rd108+-8];
	shr.u32 	%r1341, %r1340, %r1337;
	shl.b32 	%r1342, %r1646, %r485;
	add.s32 	%r1646, %r1341, %r1342;

BB11_269:
	shr.u32 	%r1343, %r1646, 30;
	shl.b32 	%r1344, %r1647, 2;
	add.s32 	%r1649, %r1344, %r1343;
	shl.b32 	%r493, %r1646, 2;
	shr.u32 	%r1345, %r1649, 31;
	shr.u32 	%r1346, %r1647, 30;
	add.s32 	%r494, %r1345, %r1346;
	setp.eq.s32	%p210, %r1345, 0;
	@%p210 bra 	BB11_270;

	not.b32 	%r1347, %r1649;
	neg.s32 	%r1648, %r493;
	setp.eq.s32	%p211, %r493, 0;
	selp.u32	%r1348, 1, 0, %p211;
	add.s32 	%r1649, %r1348, %r1347;
	xor.b32  	%r1650, %r484, -2147483648;
	bra.uni 	BB11_272;

BB11_270:
	mov.u32 	%r1648, %r493;
	mov.u32 	%r1650, %r484;

BB11_272:
	cvt.u64.u32	%rd281, %r1649;
	cvt.u64.u32	%rd282, %r1648;
	bfi.b64 	%rd283, %rd281, %rd282, 32, 32;
	cvt.rn.f64.s64	%fd61, %rd283;
	mul.f64 	%fd62, %fd61, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f819, %fd62;
	neg.f32 	%f820, %f819;
	setp.eq.s32	%p212, %r1650, 0;
	selp.f32	%f984, %f819, %f820, %p212;
	setp.eq.s32	%p213, %r484, 0;
	neg.s32 	%r1349, %r494;
	selp.b32	%r1651, %r494, %r1349, %p213;

BB11_274:
	and.b32  	%r503, %r1651, 1;
	setp.eq.s32	%p214, %r503, 0;
	selp.f32	%f275, %f984, 0f3F800000, %p214;
	mul.rn.f32 	%f276, %f984, %f984;
	fma.rn.f32 	%f277, %f276, %f275, %f413;
	mov.f32 	%f985, 0fB94D4153;
	@%p214 bra 	BB11_276;

	mov.f32 	%f824, 0fBAB607ED;
	mov.f32 	%f825, 0f37CBAC00;
	fma.rn.f32 	%f985, %f825, %f276, %f824;

BB11_276:
	selp.f32	%f826, 0f3C0885E4, 0f3D2AAABB, %p214;
	fma.rn.f32 	%f827, %f985, %f276, %f826;
	selp.f32	%f828, 0fBE2AAAA8, 0fBEFFFFFF, %p214;
	fma.rn.f32 	%f829, %f827, %f276, %f828;
	fma.rn.f32 	%f986, %f829, %f277, %f275;
	and.b32  	%r1350, %r1651, 2;
	setp.eq.s32	%p216, %r1350, 0;
	@%p216 bra 	BB11_278;

	mov.f32 	%f831, 0fBF800000;
	fma.rn.f32 	%f986, %f986, %f831, %f413;

BB11_278:
	and.b32  	%r1351, %r1, 255;
	and.b32  	%r1353, %r820, 1073741312;
	add.s32 	%r1354, %r1353, %r1351;
	mul.f32 	%f832, %f257, %f986;
	mul.f32 	%f833, %f256, %f983;
	sub.f32 	%f834, %f833, %f832;
	mul.f32 	%f835, %f257, %f983;
	fma.rn.f32 	%f836, %f256, %f986, %f835;
	add.f32 	%f837, %f254, %f834;
	shl.b32 	%r1355, %r1354, 2;
	add.s32 	%r1357, %r747, %r1355;
	st.shared.f32 	[%r1357], %f837;
	add.f32 	%f838, %f255, %f836;
	add.s32 	%r1359, %r749, %r1355;
	st.shared.f32 	[%r1359], %f838;
	sub.f32 	%f839, %f254, %f834;
	st.shared.f32 	[%r1357+1024], %f839;
	sub.f32 	%f840, %f255, %f836;
	st.shared.f32 	[%r1359+1024], %f840;
	bar.sync 	0;
	ld.shared.f32 	%f283, [%r753];
	ld.shared.f32 	%f284, [%r755];
	ld.shared.f32 	%f285, [%r753+4096];
	ld.shared.f32 	%f286, [%r755+4096];
	shr.u32 	%r1366, %r833, 23;
	add.s32 	%r1367, %r1, %r1366;
	and.b32  	%r1368, %r1367, 2147483136;
	sub.s32 	%r1369, %r1, %r1368;
	shl.b32 	%r1370, %r1369, 1;
	cvt.rn.f32.s32	%f841, %r1370;
	mul.f32 	%f842, %f841, 0f3A000000;
	cvt.f64.f32	%fd63, %f842;
	mul.f64 	%fd64, %fd63, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f287, %fd64;
	mul.f32 	%f843, %f287, 0f3F22F983;
	cvt.rni.s32.f32	%r1667, %f843;
	cvt.rn.f32.s32	%f844, %r1667;
	fma.rn.f32 	%f846, %f844, %f404, %f287;
	fma.rn.f32 	%f848, %f844, %f406, %f846;
	fma.rn.f32 	%f990, %f844, %f408, %f848;
	abs.f32 	%f289, %f287;
	setp.leu.f32	%p217, %f289, 0f47CE4780;
	mov.u32 	%r1659, %r1667;
	mov.f32 	%f987, %f990;
	@%p217 bra 	BB11_289;

	setp.eq.f32	%p218, %f289, 0f7F800000;
	@%p218 bra 	BB11_288;
	bra.uni 	BB11_280;

BB11_288:
	mul.rn.f32 	%f987, %f287, %f413;
	mov.u32 	%r1659, %r1667;
	bra.uni 	BB11_289;

BB11_280:
	mov.b32 	 %r506, %f287;
	shl.b32 	%r1373, %r506, 8;
	or.b32  	%r507, %r1373, -2147483648;
	cvta.to.local.u64 	%rd358, %rd145;
	mov.u32 	%r1653, 0;
	mov.u64 	%rd357, __cudart_i2opi_f;
	mov.u32 	%r1652, -6;

BB11_281:
	.pragma "nounroll";
	ld.const.u32 	%r1376, [%rd357];
	// inline asm
	{
	mad.lo.cc.u32   %r1374, %r1376, %r507, %r1653;
	madc.hi.u32     %r1653, %r1376, %r507,  0;
	}
	// inline asm
	st.local.u32 	[%rd358], %r1374;
	add.s64 	%rd358, %rd358, 4;
	add.s64 	%rd357, %rd357, 4;
	add.s32 	%r1652, %r1652, 1;
	setp.ne.s32	%p219, %r1652, 0;
	@%p219 bra 	BB11_281;

	bfe.u32 	%r1379, %r506, 23, 8;
	add.s32 	%r1380, %r1379, -128;
	shr.u32 	%r1381, %r1380, 5;
	and.b32  	%r512, %r506, -2147483648;
	cvta.to.local.u64 	%rd287, %rd145;
	st.local.u32 	[%rd287+24], %r1653;
	bfe.u32 	%r513, %r506, 23, 5;
	mov.u32 	%r1382, 6;
	sub.s32 	%r1383, %r1382, %r1381;
	mul.wide.s32 	%rd288, %r1383, 4;
	add.s64 	%rd114, %rd287, %rd288;
	ld.local.u32 	%r1655, [%rd114];
	ld.local.u32 	%r1654, [%rd114+-4];
	setp.eq.s32	%p220, %r513, 0;
	@%p220 bra 	BB11_284;

	mov.u32 	%r1384, 32;
	sub.s32 	%r1385, %r1384, %r513;
	shr.u32 	%r1386, %r1654, %r1385;
	shl.b32 	%r1387, %r1655, %r513;
	add.s32 	%r1655, %r1386, %r1387;
	ld.local.u32 	%r1388, [%rd114+-8];
	shr.u32 	%r1389, %r1388, %r1385;
	shl.b32 	%r1390, %r1654, %r513;
	add.s32 	%r1654, %r1389, %r1390;

BB11_284:
	shr.u32 	%r1391, %r1654, 30;
	shl.b32 	%r1392, %r1655, 2;
	add.s32 	%r1657, %r1392, %r1391;
	shl.b32 	%r521, %r1654, 2;
	shr.u32 	%r1393, %r1657, 31;
	shr.u32 	%r1394, %r1655, 30;
	add.s32 	%r522, %r1393, %r1394;
	setp.eq.s32	%p221, %r1393, 0;
	@%p221 bra 	BB11_285;

	not.b32 	%r1395, %r1657;
	neg.s32 	%r1656, %r521;
	setp.eq.s32	%p222, %r521, 0;
	selp.u32	%r1396, 1, 0, %p222;
	add.s32 	%r1657, %r1396, %r1395;
	xor.b32  	%r1658, %r512, -2147483648;
	bra.uni 	BB11_287;

BB11_285:
	mov.u32 	%r1656, %r521;
	mov.u32 	%r1658, %r512;

BB11_287:
	cvt.u64.u32	%rd289, %r1657;
	cvt.u64.u32	%rd290, %r1656;
	bfi.b64 	%rd291, %rd289, %rd290, 32, 32;
	cvt.rn.f64.s64	%fd65, %rd291;
	mul.f64 	%fd66, %fd65, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f850, %fd66;
	neg.f32 	%f851, %f850;
	setp.eq.s32	%p223, %r1658, 0;
	selp.f32	%f987, %f850, %f851, %p223;
	setp.eq.s32	%p224, %r512, 0;
	neg.s32 	%r1397, %r522;
	selp.b32	%r1659, %r522, %r1397, %p224;

BB11_289:
	add.s32 	%r531, %r1659, 1;
	and.b32  	%r532, %r531, 1;
	setp.eq.s32	%p225, %r532, 0;
	selp.f32	%f293, %f987, 0f3F800000, %p225;
	mul.rn.f32 	%f294, %f987, %f987;
	fma.rn.f32 	%f295, %f294, %f293, %f413;
	mov.f32 	%f988, 0fB94D4153;
	@%p225 bra 	BB11_291;

	mov.f32 	%f855, 0fBAB607ED;
	mov.f32 	%f856, 0f37CBAC00;
	fma.rn.f32 	%f988, %f856, %f294, %f855;

BB11_291:
	selp.f32	%f857, 0f3C0885E4, 0f3D2AAABB, %p225;
	fma.rn.f32 	%f858, %f988, %f294, %f857;
	selp.f32	%f859, 0fBE2AAAA8, 0fBEFFFFFF, %p225;
	fma.rn.f32 	%f860, %f858, %f294, %f859;
	fma.rn.f32 	%f989, %f860, %f295, %f293;
	and.b32  	%r1398, %r531, 2;
	setp.eq.s32	%p227, %r1398, 0;
	@%p227 bra 	BB11_293;

	mov.f32 	%f862, 0fBF800000;
	fma.rn.f32 	%f989, %f989, %f862, %f413;

BB11_293:
	@%p217 bra 	BB11_304;

	setp.eq.f32	%p229, %f289, 0f7F800000;
	@%p229 bra 	BB11_303;
	bra.uni 	BB11_295;

BB11_303:
	mul.rn.f32 	%f990, %f287, %f413;
	bra.uni 	BB11_304;

BB11_295:
	mov.b32 	 %r533, %f287;
	shl.b32 	%r1401, %r533, 8;
	or.b32  	%r534, %r1401, -2147483648;
	cvta.to.local.u64 	%rd360, %rd145;
	mov.u32 	%r1661, 0;
	mov.u64 	%rd359, __cudart_i2opi_f;
	mov.u32 	%r1660, -6;

BB11_296:
	.pragma "nounroll";
	ld.const.u32 	%r1404, [%rd359];
	// inline asm
	{
	mad.lo.cc.u32   %r1402, %r1404, %r534, %r1661;
	madc.hi.u32     %r1661, %r1404, %r534,  0;
	}
	// inline asm
	st.local.u32 	[%rd360], %r1402;
	add.s64 	%rd360, %rd360, 4;
	add.s64 	%rd359, %rd359, 4;
	add.s32 	%r1660, %r1660, 1;
	setp.ne.s32	%p230, %r1660, 0;
	@%p230 bra 	BB11_296;

	bfe.u32 	%r1407, %r533, 23, 8;
	add.s32 	%r1408, %r1407, -128;
	shr.u32 	%r1409, %r1408, 5;
	and.b32  	%r539, %r533, -2147483648;
	cvta.to.local.u64 	%rd295, %rd145;
	st.local.u32 	[%rd295+24], %r1661;
	bfe.u32 	%r540, %r533, 23, 5;
	mov.u32 	%r1410, 6;
	sub.s32 	%r1411, %r1410, %r1409;
	mul.wide.s32 	%rd296, %r1411, 4;
	add.s64 	%rd120, %rd295, %rd296;
	ld.local.u32 	%r1663, [%rd120];
	ld.local.u32 	%r1662, [%rd120+-4];
	setp.eq.s32	%p231, %r540, 0;
	@%p231 bra 	BB11_299;

	mov.u32 	%r1412, 32;
	sub.s32 	%r1413, %r1412, %r540;
	shr.u32 	%r1414, %r1662, %r1413;
	shl.b32 	%r1415, %r1663, %r540;
	add.s32 	%r1663, %r1414, %r1415;
	ld.local.u32 	%r1416, [%rd120+-8];
	shr.u32 	%r1417, %r1416, %r1413;
	shl.b32 	%r1418, %r1662, %r540;
	add.s32 	%r1662, %r1417, %r1418;

BB11_299:
	shr.u32 	%r1419, %r1662, 30;
	shl.b32 	%r1420, %r1663, 2;
	add.s32 	%r1665, %r1420, %r1419;
	shl.b32 	%r548, %r1662, 2;
	shr.u32 	%r1421, %r1665, 31;
	shr.u32 	%r1422, %r1663, 30;
	add.s32 	%r549, %r1421, %r1422;
	setp.eq.s32	%p232, %r1421, 0;
	@%p232 bra 	BB11_300;

	not.b32 	%r1423, %r1665;
	neg.s32 	%r1664, %r548;
	setp.eq.s32	%p233, %r548, 0;
	selp.u32	%r1424, 1, 0, %p233;
	add.s32 	%r1665, %r1424, %r1423;
	xor.b32  	%r1666, %r539, -2147483648;
	bra.uni 	BB11_302;

BB11_300:
	mov.u32 	%r1664, %r548;
	mov.u32 	%r1666, %r539;

BB11_302:
	cvt.u64.u32	%rd297, %r1665;
	cvt.u64.u32	%rd298, %r1664;
	bfi.b64 	%rd299, %rd297, %rd298, 32, 32;
	cvt.rn.f64.s64	%fd67, %rd299;
	mul.f64 	%fd68, %fd67, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f863, %fd68;
	neg.f32 	%f864, %f863;
	setp.eq.s32	%p234, %r1666, 0;
	selp.f32	%f990, %f863, %f864, %p234;
	setp.eq.s32	%p235, %r539, 0;
	neg.s32 	%r1425, %r549;
	selp.b32	%r1667, %r549, %r1425, %p235;

BB11_304:
	and.b32  	%r558, %r1667, 1;
	setp.eq.s32	%p236, %r558, 0;
	selp.f32	%f304, %f990, 0f3F800000, %p236;
	mul.rn.f32 	%f305, %f990, %f990;
	fma.rn.f32 	%f306, %f305, %f304, %f413;
	mov.f32 	%f991, 0fB94D4153;
	@%p236 bra 	BB11_306;

	mov.f32 	%f868, 0fBAB607ED;
	mov.f32 	%f869, 0f37CBAC00;
	fma.rn.f32 	%f991, %f869, %f305, %f868;

BB11_306:
	selp.f32	%f870, 0f3C0885E4, 0f3D2AAABB, %p236;
	fma.rn.f32 	%f871, %f991, %f305, %f870;
	selp.f32	%f872, 0fBE2AAAA8, 0fBEFFFFFF, %p236;
	fma.rn.f32 	%f873, %f871, %f305, %f872;
	fma.rn.f32 	%f992, %f873, %f306, %f304;
	and.b32  	%r1426, %r1667, 2;
	setp.eq.s32	%p238, %r1426, 0;
	@%p238 bra 	BB11_308;

	mov.f32 	%f875, 0fBF800000;
	fma.rn.f32 	%f992, %f992, %f875, %f413;

BB11_308:
	and.b32  	%r1427, %r1, 511;
	and.b32  	%r1429, %r820, 1073740800;
	add.s32 	%r1430, %r1429, %r1427;
	mul.f32 	%f876, %f286, %f992;
	mul.f32 	%f877, %f285, %f989;
	sub.f32 	%f878, %f877, %f876;
	mul.f32 	%f879, %f286, %f989;
	fma.rn.f32 	%f880, %f285, %f992, %f879;
	add.f32 	%f881, %f283, %f878;
	shl.b32 	%r1431, %r1430, 2;
	add.s32 	%r1433, %r621, %r1431;
	st.shared.f32 	[%r1433], %f881;
	add.f32 	%f882, %f284, %f880;
	add.s32 	%r1435, %r622, %r1431;
	st.shared.f32 	[%r1435], %f882;
	sub.f32 	%f883, %f283, %f878;
	st.shared.f32 	[%r1433+2048], %f883;
	sub.f32 	%f884, %f284, %f880;
	st.shared.f32 	[%r1435+2048], %f884;
	bar.sync 	0;
	ld.shared.f32 	%f312, [%r2];
	ld.shared.f32 	%f313, [%r3];
	ld.shared.f32 	%f314, [%r2+4096];
	ld.shared.f32 	%f315, [%r3+4096];
	shr.u32 	%r1442, %r833, 22;
	add.s32 	%r1443, %r1, %r1442;
	and.b32  	%r1444, %r1443, -1024;
	sub.s32 	%r1445, %r1, %r1444;
	cvt.rn.f32.s32	%f885, %r1445;
	mul.f32 	%f886, %f885, 0f3A000000;
	cvt.f64.f32	%fd69, %f886;
	mul.f64 	%fd70, %fd69, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f316, %fd70;
	mul.f32 	%f887, %f316, 0f3F22F983;
	cvt.rni.s32.f32	%r1683, %f887;
	cvt.rn.f32.s32	%f888, %r1683;
	fma.rn.f32 	%f890, %f888, %f404, %f316;
	fma.rn.f32 	%f892, %f888, %f406, %f890;
	fma.rn.f32 	%f996, %f888, %f408, %f892;
	abs.f32 	%f318, %f316;
	setp.leu.f32	%p239, %f318, 0f47CE4780;
	mov.u32 	%r1675, %r1683;
	mov.f32 	%f993, %f996;
	@%p239 bra 	BB11_319;

	setp.eq.f32	%p240, %f318, 0f7F800000;
	@%p240 bra 	BB11_318;
	bra.uni 	BB11_310;

BB11_318:
	mul.rn.f32 	%f993, %f316, %f413;
	mov.u32 	%r1675, %r1683;
	bra.uni 	BB11_319;

BB11_310:
	mov.b32 	 %r561, %f316;
	shl.b32 	%r1448, %r561, 8;
	or.b32  	%r562, %r1448, -2147483648;
	cvta.to.local.u64 	%rd362, %rd145;
	mov.u32 	%r1669, 0;
	mov.u64 	%rd361, __cudart_i2opi_f;
	mov.u32 	%r1668, -6;

BB11_311:
	.pragma "nounroll";
	ld.const.u32 	%r1451, [%rd361];
	// inline asm
	{
	mad.lo.cc.u32   %r1449, %r1451, %r562, %r1669;
	madc.hi.u32     %r1669, %r1451, %r562,  0;
	}
	// inline asm
	st.local.u32 	[%rd362], %r1449;
	add.s64 	%rd362, %rd362, 4;
	add.s64 	%rd361, %rd361, 4;
	add.s32 	%r1668, %r1668, 1;
	setp.ne.s32	%p241, %r1668, 0;
	@%p241 bra 	BB11_311;

	bfe.u32 	%r1454, %r561, 23, 8;
	add.s32 	%r1455, %r1454, -128;
	shr.u32 	%r1456, %r1455, 5;
	and.b32  	%r567, %r561, -2147483648;
	cvta.to.local.u64 	%rd303, %rd145;
	st.local.u32 	[%rd303+24], %r1669;
	bfe.u32 	%r568, %r561, 23, 5;
	mov.u32 	%r1457, 6;
	sub.s32 	%r1458, %r1457, %r1456;
	mul.wide.s32 	%rd304, %r1458, 4;
	add.s64 	%rd126, %rd303, %rd304;
	ld.local.u32 	%r1671, [%rd126];
	ld.local.u32 	%r1670, [%rd126+-4];
	setp.eq.s32	%p242, %r568, 0;
	@%p242 bra 	BB11_314;

	mov.u32 	%r1459, 32;
	sub.s32 	%r1460, %r1459, %r568;
	shr.u32 	%r1461, %r1670, %r1460;
	shl.b32 	%r1462, %r1671, %r568;
	add.s32 	%r1671, %r1461, %r1462;
	ld.local.u32 	%r1463, [%rd126+-8];
	shr.u32 	%r1464, %r1463, %r1460;
	shl.b32 	%r1465, %r1670, %r568;
	add.s32 	%r1670, %r1464, %r1465;

BB11_314:
	shr.u32 	%r1466, %r1670, 30;
	shl.b32 	%r1467, %r1671, 2;
	add.s32 	%r1673, %r1467, %r1466;
	shl.b32 	%r576, %r1670, 2;
	shr.u32 	%r1468, %r1673, 31;
	shr.u32 	%r1469, %r1671, 30;
	add.s32 	%r577, %r1468, %r1469;
	setp.eq.s32	%p243, %r1468, 0;
	@%p243 bra 	BB11_315;

	not.b32 	%r1470, %r1673;
	neg.s32 	%r1672, %r576;
	setp.eq.s32	%p244, %r576, 0;
	selp.u32	%r1471, 1, 0, %p244;
	add.s32 	%r1673, %r1471, %r1470;
	xor.b32  	%r1674, %r567, -2147483648;
	bra.uni 	BB11_317;

BB11_315:
	mov.u32 	%r1672, %r576;
	mov.u32 	%r1674, %r567;

BB11_317:
	cvt.u64.u32	%rd305, %r1673;
	cvt.u64.u32	%rd306, %r1672;
	bfi.b64 	%rd307, %rd305, %rd306, 32, 32;
	cvt.rn.f64.s64	%fd71, %rd307;
	mul.f64 	%fd72, %fd71, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f894, %fd72;
	neg.f32 	%f895, %f894;
	setp.eq.s32	%p245, %r1674, 0;
	selp.f32	%f993, %f894, %f895, %p245;
	setp.eq.s32	%p246, %r567, 0;
	neg.s32 	%r1472, %r577;
	selp.b32	%r1675, %r577, %r1472, %p246;

BB11_319:
	add.s32 	%r586, %r1675, 1;
	and.b32  	%r587, %r586, 1;
	setp.eq.s32	%p247, %r587, 0;
	selp.f32	%f322, %f993, 0f3F800000, %p247;
	mul.rn.f32 	%f323, %f993, %f993;
	fma.rn.f32 	%f324, %f323, %f322, %f413;
	mov.f32 	%f994, 0fB94D4153;
	@%p247 bra 	BB11_321;

	mov.f32 	%f899, 0fBAB607ED;
	mov.f32 	%f900, 0f37CBAC00;
	fma.rn.f32 	%f994, %f900, %f323, %f899;

BB11_321:
	selp.f32	%f901, 0f3C0885E4, 0f3D2AAABB, %p247;
	fma.rn.f32 	%f902, %f994, %f323, %f901;
	selp.f32	%f903, 0fBE2AAAA8, 0fBEFFFFFF, %p247;
	fma.rn.f32 	%f904, %f902, %f323, %f903;
	fma.rn.f32 	%f995, %f904, %f324, %f322;
	and.b32  	%r1473, %r586, 2;
	setp.eq.s32	%p249, %r1473, 0;
	@%p249 bra 	BB11_323;

	mov.f32 	%f906, 0fBF800000;
	fma.rn.f32 	%f995, %f995, %f906, %f413;

BB11_323:
	@%p239 bra 	BB11_334;

	setp.eq.f32	%p251, %f318, 0f7F800000;
	@%p251 bra 	BB11_333;
	bra.uni 	BB11_325;

BB11_333:
	mul.rn.f32 	%f996, %f316, %f413;
	bra.uni 	BB11_334;

BB11_325:
	mov.b32 	 %r588, %f316;
	shl.b32 	%r1476, %r588, 8;
	or.b32  	%r589, %r1476, -2147483648;
	cvta.to.local.u64 	%rd364, %rd145;
	mov.u64 	%rd363, __cudart_i2opi_f;
	mov.u32 	%r1676, -6;

BB11_326:
	.pragma "nounroll";
	ld.const.u32 	%r1479, [%rd363];
	// inline asm
	{
	mad.lo.cc.u32   %r1477, %r1479, %r589, %r1677;
	madc.hi.u32     %r1677, %r1479, %r589,  0;
	}
	// inline asm
	st.local.u32 	[%rd364], %r1477;
	add.s64 	%rd364, %rd364, 4;
	add.s64 	%rd363, %rd363, 4;
	add.s32 	%r1676, %r1676, 1;
	setp.ne.s32	%p252, %r1676, 0;
	@%p252 bra 	BB11_326;

	bfe.u32 	%r1482, %r588, 23, 8;
	add.s32 	%r1483, %r1482, -128;
	shr.u32 	%r1484, %r1483, 5;
	and.b32  	%r594, %r588, -2147483648;
	cvta.to.local.u64 	%rd311, %rd145;
	st.local.u32 	[%rd311+24], %r1677;
	bfe.u32 	%r595, %r588, 23, 5;
	mov.u32 	%r1485, 6;
	sub.s32 	%r1486, %r1485, %r1484;
	mul.wide.s32 	%rd312, %r1486, 4;
	add.s64 	%rd132, %rd311, %rd312;
	ld.local.u32 	%r1679, [%rd132];
	ld.local.u32 	%r1678, [%rd132+-4];
	setp.eq.s32	%p253, %r595, 0;
	@%p253 bra 	BB11_329;

	mov.u32 	%r1487, 32;
	sub.s32 	%r1488, %r1487, %r595;
	shr.u32 	%r1489, %r1678, %r1488;
	shl.b32 	%r1490, %r1679, %r595;
	add.s32 	%r1679, %r1489, %r1490;
	ld.local.u32 	%r1491, [%rd132+-8];
	shr.u32 	%r1492, %r1491, %r1488;
	shl.b32 	%r1493, %r1678, %r595;
	add.s32 	%r1678, %r1492, %r1493;

BB11_329:
	shr.u32 	%r1494, %r1678, 30;
	shl.b32 	%r1495, %r1679, 2;
	add.s32 	%r1681, %r1495, %r1494;
	shl.b32 	%r603, %r1678, 2;
	shr.u32 	%r1496, %r1681, 31;
	shr.u32 	%r1497, %r1679, 30;
	add.s32 	%r604, %r1496, %r1497;
	setp.eq.s32	%p254, %r1496, 0;
	@%p254 bra 	BB11_330;

	not.b32 	%r1498, %r1681;
	neg.s32 	%r1680, %r603;
	setp.eq.s32	%p255, %r603, 0;
	selp.u32	%r1499, 1, 0, %p255;
	add.s32 	%r1681, %r1499, %r1498;
	xor.b32  	%r1682, %r594, -2147483648;
	bra.uni 	BB11_332;

BB11_330:
	mov.u32 	%r1680, %r603;
	mov.u32 	%r1682, %r594;

BB11_332:
	cvt.u64.u32	%rd313, %r1681;
	cvt.u64.u32	%rd314, %r1680;
	bfi.b64 	%rd315, %rd313, %rd314, 32, 32;
	cvt.rn.f64.s64	%fd73, %rd315;
	mul.f64 	%fd74, %fd73, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f907, %fd74;
	neg.f32 	%f908, %f907;
	setp.eq.s32	%p256, %r1682, 0;
	selp.f32	%f996, %f907, %f908, %p256;
	setp.eq.s32	%p257, %r594, 0;
	neg.s32 	%r1500, %r604;
	selp.b32	%r1683, %r604, %r1500, %p257;

BB11_334:
	and.b32  	%r613, %r1683, 1;
	setp.eq.s32	%p258, %r613, 0;
	selp.f32	%f333, %f996, 0f3F800000, %p258;
	mul.rn.f32 	%f334, %f996, %f996;
	fma.rn.f32 	%f335, %f334, %f333, %f413;
	mov.f32 	%f997, 0fB94D4153;
	@%p258 bra 	BB11_336;

	mov.f32 	%f912, 0fBAB607ED;
	mov.f32 	%f913, 0f37CBAC00;
	fma.rn.f32 	%f997, %f913, %f334, %f912;

BB11_336:
	selp.f32	%f914, 0f3C0885E4, 0f3D2AAABB, %p258;
	fma.rn.f32 	%f915, %f997, %f334, %f914;
	selp.f32	%f916, 0fBE2AAAA8, 0fBEFFFFFF, %p258;
	fma.rn.f32 	%f917, %f915, %f334, %f916;
	fma.rn.f32 	%f998, %f917, %f335, %f333;
	and.b32  	%r1501, %r1683, 2;
	setp.eq.s32	%p260, %r1501, 0;
	@%p260 bra 	BB11_338;

	mov.f32 	%f919, 0fBF800000;
	fma.rn.f32 	%f998, %f998, %f919, %f413;

BB11_338:
	mul.f32 	%f920, %f315, %f998;
	mul.f32 	%f921, %f314, %f995;
	sub.f32 	%f922, %f921, %f920;
	mul.f32 	%f923, %f315, %f995;
	fma.rn.f32 	%f924, %f314, %f998, %f923;
	add.f32 	%f925, %f312, %f922;
	cvta.to.global.u64 	%rd316, %rd133;
	shl.b32 	%r1503, %r616, 10;
	add.s32 	%r1504, %r1503, %r1;
	shl.b32 	%r1505, %r1504, 1;
	and.b32  	%r1506, %r1505, -2048;
	add.s32 	%r1507, %r1506, %r1;
	mul.wide.u32 	%rd317, %r1507, 4;
	add.s64 	%rd318, %rd316, %rd317;
	st.global.f32 	[%rd318], %f925;
	add.f32 	%f926, %f313, %f924;
	cvta.to.global.u64 	%rd319, %rd134;
	add.s64 	%rd320, %rd319, %rd317;
	st.global.f32 	[%rd320], %f926;
	sub.f32 	%f927, %f312, %f922;
	st.global.f32 	[%rd318+4096], %f927;
	sub.f32 	%f928, %f313, %f924;
	st.global.f32 	[%rd320+4096], %f928;
	ret;
}

	// .globl	_occa_Overlap_Common_0
.visible .entry _occa_Overlap_Common_0(
	.param .u64 _occa_Overlap_Common_0_param_0,
	.param .u32 _occa_Overlap_Common_0_param_1,
	.param .u32 _occa_Overlap_Common_0_param_2,
	.param .u32 _occa_Overlap_Common_0_param_3,
	.param .u32 _occa_Overlap_Common_0_param_4,
	.param .u64 _occa_Overlap_Common_0_param_5
)
.maxntid 64, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [_occa_Overlap_Common_0_param_0];
	ld.param.u32 	%r1, [_occa_Overlap_Common_0_param_2];
	ld.param.u32 	%r2, [_occa_Overlap_Common_0_param_3];
	ld.param.u32 	%r3, [_occa_Overlap_Common_0_param_4];
	ld.param.u64 	%rd2, [_occa_Overlap_Common_0_param_5];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mov.u32 	%r4, %ctaid.x;
	shl.b32 	%r5, %r4, 6;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r7, %r5, %r6;
	shr.u32 	%r8, %r7, %r2;
	mov.u32 	%r9, 1;
	shl.b32 	%r10, %r9, %r2;
	add.s32 	%r11, %r10, -1;
	and.b32  	%r12, %r7, %r11;
	mad.lo.s32 	%r13, %r8, %r3, %r12;
	setp.lt.u32	%p1, %r13, %r1;
	cvt.u64.u32	%rd5, %r13;
	selp.b64	%rd6, %rd5, 0, %p1;
	shl.b64 	%rd7, %rd6, 2;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.f32 	%f1, [%rd8];
	selp.u32	%r14, 1, 0, %p1;
	cvt.rn.f32.u32	%f2, %r14;
	mul.f32 	%f3, %f1, %f2;
	mul.wide.u32 	%rd9, %r7, 4;
	add.s64 	%rd10, %rd3, %rd9;
	st.global.f32 	[%rd10], %f3;
	ret;
}

	// .globl	_occa_Window_Hanning_0
.visible .entry _occa_Window_Hanning_0(
	.param .u64 _occa_Window_Hanning_0_param_0,
	.param .u32 _occa_Window_Hanning_0_param_1,
	.param .u32 _occa_Window_Hanning_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot13[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<12>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<83>;
	.reg .f64 	%fd<11>;
	.reg .b64 	%rd<25>;


	mov.u64 	%SPL, __local_depot13;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd6, [_occa_Window_Hanning_0_param_0];
	ld.param.u32 	%r29, [_occa_Window_Hanning_0_param_2];
	mov.u32 	%r30, %ctaid.x;
	shl.b32 	%r31, %r30, 6;
	mov.u32 	%r32, %tid.x;
	add.s32 	%r33, %r31, %r32;
	add.s32 	%r34, %r29, -1;
	and.b32  	%r35, %r33, %r34;
	cvt.rn.f64.s32	%fd1, %r35;
	mul.f64 	%fd2, %fd1, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f15, %r34;
	cvt.f64.f32	%fd3, %f15;
	div.rn.f64 	%fd4, %fd2, %fd3;
	cvt.rn.f32.f64	%f1, %fd4;
	mul.f32 	%f16, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r82, %f16;
	cvt.rn.f32.s32	%f17, %r82;
	mov.f32 	%f18, 0fBFC90FDA;
	fma.rn.f32 	%f19, %f17, %f18, %f1;
	mov.f32 	%f20, 0fB3A22168;
	fma.rn.f32 	%f21, %f17, %f20, %f19;
	mov.f32 	%f22, 0fA7C234C5;
	fma.rn.f32 	%f39, %f17, %f22, %f21;
	abs.f32 	%f3, %f1;
	setp.leu.f32	%p1, %f3, 0f47CE4780;
	@%p1 bra 	BB13_11;

	setp.eq.f32	%p2, %f3, 0f7F800000;
	@%p2 bra 	BB13_10;
	bra.uni 	BB13_2;

BB13_10:
	mov.f32 	%f25, 0f00000000;
	mul.rn.f32 	%f39, %f1, %f25;
	bra.uni 	BB13_11;

BB13_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r38, %r2, 8;
	or.b32  	%r3, %r38, -2147483648;
	add.u64 	%rd8, %SP, 0;
	add.u64 	%rd24, %SPL, 0;
	mov.u32 	%r76, 0;
	mov.u64 	%rd23, __cudart_i2opi_f;
	mov.u32 	%r75, -6;

BB13_3:
	.pragma "nounroll";
	ld.const.u32 	%r41, [%rd23];
	// inline asm
	{
	mad.lo.cc.u32   %r39, %r41, %r3, %r76;
	madc.hi.u32     %r76, %r41, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd24], %r39;
	add.s64 	%rd24, %rd24, 4;
	add.s64 	%rd23, %rd23, 4;
	add.s32 	%r75, %r75, 1;
	setp.ne.s32	%p3, %r75, 0;
	@%p3 bra 	BB13_3;

	shr.u32 	%r8, %r2, 23;
	bfe.u32 	%r44, %r2, 23, 8;
	add.s32 	%r45, %r44, -128;
	shr.u32 	%r46, %r45, 5;
	and.b32  	%r9, %r2, -2147483648;
	cvta.to.local.u64 	%rd10, %rd8;
	st.local.u32 	[%rd10+24], %r76;
	bfe.u32 	%r47, %r2, 23, 5;
	mov.u32 	%r48, 6;
	sub.s32 	%r49, %r48, %r46;
	mul.wide.s32 	%rd11, %r49, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.local.u32 	%r78, [%rd12];
	ld.local.u32 	%r77, [%rd12+-4];
	setp.eq.s32	%p4, %r47, 0;
	@%p4 bra 	BB13_6;

	and.b32  	%r50, %r8, 31;
	mov.u32 	%r51, 32;
	sub.s32 	%r52, %r51, %r50;
	shl.b32 	%r53, %r78, %r50;
	shr.u32 	%r54, %r77, %r52;
	add.s32 	%r78, %r54, %r53;
	shl.b32 	%r55, %r77, %r50;
	and.b32  	%r56, %r8, 255;
	add.s32 	%r57, %r56, -128;
	shr.u32 	%r58, %r57, 5;
	sub.s32 	%r60, %r48, %r58;
	mul.wide.s32 	%rd15, %r60, 4;
	add.s64 	%rd16, %rd10, %rd15;
	ld.local.u32 	%r61, [%rd16+-8];
	shr.u32 	%r62, %r61, %r52;
	add.s32 	%r77, %r62, %r55;

BB13_6:
	shr.u32 	%r63, %r77, 30;
	shl.b32 	%r64, %r78, 2;
	add.s32 	%r80, %r64, %r63;
	shl.b32 	%r17, %r77, 2;
	shr.u32 	%r65, %r80, 31;
	shr.u32 	%r66, %r78, 30;
	add.s32 	%r18, %r65, %r66;
	setp.eq.s32	%p5, %r65, 0;
	@%p5 bra 	BB13_7;

	not.b32 	%r67, %r80;
	neg.s32 	%r79, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r68, 1, 0, %p6;
	add.s32 	%r80, %r68, %r67;
	xor.b32  	%r81, %r9, -2147483648;
	bra.uni 	BB13_9;

BB13_7:
	mov.u32 	%r79, %r17;
	mov.u32 	%r81, %r9;

BB13_9:
	cvt.u64.u32	%rd17, %r80;
	cvt.u64.u32	%rd18, %r79;
	bfi.b64 	%rd19, %rd17, %rd18, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd19;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f23, %fd6;
	neg.f32 	%f24, %f23;
	setp.eq.s32	%p7, %r81, 0;
	selp.f32	%f39, %f23, %f24, %p7;
	setp.eq.s32	%p8, %r9, 0;
	neg.s32 	%r69, %r18;
	selp.b32	%r82, %r18, %r69, %p8;

BB13_11:
	add.s32 	%r27, %r82, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f7, %f39, 0f3F800000, %p9;
	mul.rn.f32 	%f8, %f39, %f39;
	mov.f32 	%f27, 0f00000000;
	fma.rn.f32 	%f9, %f8, %f7, %f27;
	mov.f32 	%f40, 0fB94D4153;
	@%p9 bra 	BB13_13;

	mov.f32 	%f28, 0fBAB607ED;
	mov.f32 	%f29, 0f37CBAC00;
	fma.rn.f32 	%f40, %f29, %f8, %f28;

BB13_13:
	selp.f32	%f30, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f31, %f40, %f8, %f30;
	selp.f32	%f32, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f33, %f31, %f8, %f32;
	fma.rn.f32 	%f41, %f33, %f9, %f7;
	and.b32  	%r70, %r27, 2;
	setp.eq.s32	%p11, %r70, 0;
	@%p11 bra 	BB13_15;

	mov.f32 	%f35, 0fBF800000;
	fma.rn.f32 	%f41, %f41, %f35, %f27;

BB13_15:
	cvt.f64.f32	%fd7, %f41;
	mov.f64 	%fd8, 0d3FF0000000000000;
	sub.f64 	%fd9, %fd8, %fd7;
	mul.f64 	%fd10, %fd9, 0d3FE0000000000000;
	cvt.rn.f32.f64	%f36, %fd10;
	cvta.to.global.u64 	%rd20, %rd6;
	mul.wide.u32 	%rd21, %r33, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.global.f32 	%f37, [%rd22];
	mul.f32 	%f38, %f37, %f36;
	st.global.f32 	[%rd22], %f38;
	ret;
}

	// .globl	_occa_Window_Hamming_0
.visible .entry _occa_Window_Hamming_0(
	.param .u64 _occa_Window_Hamming_0_param_0,
	.param .u32 _occa_Window_Hamming_0_param_1,
	.param .u32 _occa_Window_Hamming_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot14[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<12>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<83>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<25>;


	mov.u64 	%SPL, __local_depot14;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd6, [_occa_Window_Hamming_0_param_0];
	ld.param.u32 	%r29, [_occa_Window_Hamming_0_param_2];
	mov.u32 	%r30, %ctaid.x;
	shl.b32 	%r31, %r30, 6;
	mov.u32 	%r32, %tid.x;
	add.s32 	%r33, %r31, %r32;
	add.s32 	%r34, %r29, -1;
	and.b32  	%r35, %r33, %r34;
	cvt.rn.f64.s32	%fd1, %r35;
	mul.f64 	%fd2, %fd1, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f15, %r34;
	cvt.f64.f32	%fd3, %f15;
	div.rn.f64 	%fd4, %fd2, %fd3;
	cvt.rn.f32.f64	%f1, %fd4;
	mul.f32 	%f16, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r82, %f16;
	cvt.rn.f32.s32	%f17, %r82;
	mov.f32 	%f18, 0fBFC90FDA;
	fma.rn.f32 	%f19, %f17, %f18, %f1;
	mov.f32 	%f20, 0fB3A22168;
	fma.rn.f32 	%f21, %f17, %f20, %f19;
	mov.f32 	%f22, 0fA7C234C5;
	fma.rn.f32 	%f39, %f17, %f22, %f21;
	abs.f32 	%f3, %f1;
	setp.leu.f32	%p1, %f3, 0f47CE4780;
	@%p1 bra 	BB14_11;

	setp.eq.f32	%p2, %f3, 0f7F800000;
	@%p2 bra 	BB14_10;
	bra.uni 	BB14_2;

BB14_10:
	mov.f32 	%f25, 0f00000000;
	mul.rn.f32 	%f39, %f1, %f25;
	bra.uni 	BB14_11;

BB14_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r38, %r2, 8;
	or.b32  	%r3, %r38, -2147483648;
	add.u64 	%rd8, %SP, 0;
	add.u64 	%rd24, %SPL, 0;
	mov.u32 	%r76, 0;
	mov.u64 	%rd23, __cudart_i2opi_f;
	mov.u32 	%r75, -6;

BB14_3:
	.pragma "nounroll";
	ld.const.u32 	%r41, [%rd23];
	// inline asm
	{
	mad.lo.cc.u32   %r39, %r41, %r3, %r76;
	madc.hi.u32     %r76, %r41, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd24], %r39;
	add.s64 	%rd24, %rd24, 4;
	add.s64 	%rd23, %rd23, 4;
	add.s32 	%r75, %r75, 1;
	setp.ne.s32	%p3, %r75, 0;
	@%p3 bra 	BB14_3;

	shr.u32 	%r8, %r2, 23;
	bfe.u32 	%r44, %r2, 23, 8;
	add.s32 	%r45, %r44, -128;
	shr.u32 	%r46, %r45, 5;
	and.b32  	%r9, %r2, -2147483648;
	cvta.to.local.u64 	%rd10, %rd8;
	st.local.u32 	[%rd10+24], %r76;
	bfe.u32 	%r47, %r2, 23, 5;
	mov.u32 	%r48, 6;
	sub.s32 	%r49, %r48, %r46;
	mul.wide.s32 	%rd11, %r49, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.local.u32 	%r78, [%rd12];
	ld.local.u32 	%r77, [%rd12+-4];
	setp.eq.s32	%p4, %r47, 0;
	@%p4 bra 	BB14_6;

	and.b32  	%r50, %r8, 31;
	mov.u32 	%r51, 32;
	sub.s32 	%r52, %r51, %r50;
	shl.b32 	%r53, %r78, %r50;
	shr.u32 	%r54, %r77, %r52;
	add.s32 	%r78, %r54, %r53;
	shl.b32 	%r55, %r77, %r50;
	and.b32  	%r56, %r8, 255;
	add.s32 	%r57, %r56, -128;
	shr.u32 	%r58, %r57, 5;
	sub.s32 	%r60, %r48, %r58;
	mul.wide.s32 	%rd15, %r60, 4;
	add.s64 	%rd16, %rd10, %rd15;
	ld.local.u32 	%r61, [%rd16+-8];
	shr.u32 	%r62, %r61, %r52;
	add.s32 	%r77, %r62, %r55;

BB14_6:
	shr.u32 	%r63, %r77, 30;
	shl.b32 	%r64, %r78, 2;
	add.s32 	%r80, %r64, %r63;
	shl.b32 	%r17, %r77, 2;
	shr.u32 	%r65, %r80, 31;
	shr.u32 	%r66, %r78, 30;
	add.s32 	%r18, %r65, %r66;
	setp.eq.s32	%p5, %r65, 0;
	@%p5 bra 	BB14_7;

	not.b32 	%r67, %r80;
	neg.s32 	%r79, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r68, 1, 0, %p6;
	add.s32 	%r80, %r68, %r67;
	xor.b32  	%r81, %r9, -2147483648;
	bra.uni 	BB14_9;

BB14_7:
	mov.u32 	%r79, %r17;
	mov.u32 	%r81, %r9;

BB14_9:
	cvt.u64.u32	%rd17, %r80;
	cvt.u64.u32	%rd18, %r79;
	bfi.b64 	%rd19, %rd17, %rd18, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd19;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f23, %fd6;
	neg.f32 	%f24, %f23;
	setp.eq.s32	%p7, %r81, 0;
	selp.f32	%f39, %f23, %f24, %p7;
	setp.eq.s32	%p8, %r9, 0;
	neg.s32 	%r69, %r18;
	selp.b32	%r82, %r18, %r69, %p8;

BB14_11:
	add.s32 	%r27, %r82, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f7, %f39, 0f3F800000, %p9;
	mul.rn.f32 	%f8, %f39, %f39;
	mov.f32 	%f27, 0f00000000;
	fma.rn.f32 	%f9, %f8, %f7, %f27;
	mov.f32 	%f40, 0fB94D4153;
	@%p9 bra 	BB14_13;

	mov.f32 	%f28, 0fBAB607ED;
	mov.f32 	%f29, 0f37CBAC00;
	fma.rn.f32 	%f40, %f29, %f8, %f28;

BB14_13:
	selp.f32	%f30, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f31, %f40, %f8, %f30;
	selp.f32	%f32, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f33, %f31, %f8, %f32;
	fma.rn.f32 	%f41, %f33, %f9, %f7;
	and.b32  	%r70, %r27, 2;
	setp.eq.s32	%p11, %r70, 0;
	@%p11 bra 	BB14_15;

	mov.f32 	%f35, 0fBF800000;
	fma.rn.f32 	%f41, %f41, %f35, %f27;

BB14_15:
	cvt.f64.f32	%fd7, %f41;
	fma.rn.f64 	%fd8, %fd7, 0dBFDD70A3D70A3D71, 0d3FE147AE147AE148;
	cvt.rn.f32.f64	%f36, %fd8;
	cvta.to.global.u64 	%rd20, %rd6;
	mul.wide.u32 	%rd21, %r33, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.global.f32 	%f37, [%rd22];
	mul.f32 	%f38, %f37, %f36;
	st.global.f32 	[%rd22], %f38;
	ret;
}

	// .globl	_occa_Window_Blackman_0
.visible .entry _occa_Window_Blackman_0(
	.param .u64 _occa_Window_Blackman_0_param_0,
	.param .u32 _occa_Window_Blackman_0_param_1,
	.param .u32 _occa_Window_Blackman_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot15[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .f32 	%f<79>;
	.reg .b32 	%r<140>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<37>;


	mov.u64 	%SPL, __local_depot15;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd13, [_occa_Window_Blackman_0_param_0];
	ld.param.u32 	%r57, [_occa_Window_Blackman_0_param_2];
	mov.u32 	%r58, %ctaid.x;
	shl.b32 	%r59, %r58, 6;
	mov.u32 	%r60, %tid.x;
	add.s32 	%r61, %r59, %r60;
	add.s32 	%r62, %r57, -1;
	and.b32  	%r63, %r61, %r62;
	cvt.rn.f64.s32	%fd1, %r63;
	mul.f64 	%fd2, %fd1, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f29, %r57;
	cvt.f64.f32	%fd3, %f29;
	div.rn.f64 	%fd4, %fd2, %fd3;
	cvt.rn.f32.f64	%f1, %fd4;
	add.f32 	%f2, %f1, %f1;
	mul.f32 	%f30, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r131, %f30;
	cvt.rn.f32.s32	%f31, %r131;
	mov.f32 	%f32, 0fBFC90FDA;
	fma.rn.f32 	%f33, %f31, %f32, %f1;
	mov.f32 	%f34, 0fB3A22168;
	fma.rn.f32 	%f35, %f31, %f34, %f33;
	mov.f32 	%f36, 0fA7C234C5;
	fma.rn.f32 	%f73, %f31, %f36, %f35;
	abs.f32 	%f4, %f1;
	setp.leu.f32	%p1, %f4, 0f47CE4780;
	@%p1 bra 	BB15_11;

	setp.eq.f32	%p2, %f4, 0f7F800000;
	@%p2 bra 	BB15_10;
	bra.uni 	BB15_2;

BB15_10:
	mov.f32 	%f39, 0f00000000;
	mul.rn.f32 	%f73, %f1, %f39;
	bra.uni 	BB15_11;

BB15_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r66, %r2, 8;
	or.b32  	%r3, %r66, -2147483648;
	add.u64 	%rd15, %SP, 0;
	add.u64 	%rd34, %SPL, 0;
	mov.u32 	%r125, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
	mov.u32 	%r124, -6;

BB15_3:
	.pragma "nounroll";
	ld.const.u32 	%r69, [%rd33];
	// inline asm
	{
	mad.lo.cc.u32   %r67, %r69, %r3, %r125;
	madc.hi.u32     %r125, %r69, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd34], %r67;
	add.s64 	%rd34, %rd34, 4;
	add.s64 	%rd33, %rd33, 4;
	add.s32 	%r124, %r124, 1;
	setp.ne.s32	%p3, %r124, 0;
	@%p3 bra 	BB15_3;

	bfe.u32 	%r72, %r2, 23, 8;
	add.s32 	%r73, %r72, -128;
	shr.u32 	%r74, %r73, 5;
	and.b32  	%r8, %r2, -2147483648;
	cvta.to.local.u64 	%rd17, %rd15;
	st.local.u32 	[%rd17+24], %r125;
	bfe.u32 	%r9, %r2, 23, 5;
	mov.u32 	%r75, 6;
	sub.s32 	%r76, %r75, %r74;
	mul.wide.s32 	%rd18, %r76, 4;
	add.s64 	%rd6, %rd17, %rd18;
	ld.local.u32 	%r127, [%rd6];
	ld.local.u32 	%r126, [%rd6+-4];
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB15_6;

	mov.u32 	%r77, 32;
	sub.s32 	%r78, %r77, %r9;
	shr.u32 	%r79, %r126, %r78;
	shl.b32 	%r80, %r127, %r9;
	add.s32 	%r127, %r79, %r80;
	ld.local.u32 	%r81, [%rd6+-8];
	shr.u32 	%r82, %r81, %r78;
	shl.b32 	%r83, %r126, %r9;
	add.s32 	%r126, %r82, %r83;

BB15_6:
	shr.u32 	%r84, %r126, 30;
	shl.b32 	%r85, %r127, 2;
	add.s32 	%r129, %r85, %r84;
	shl.b32 	%r17, %r126, 2;
	shr.u32 	%r86, %r129, 31;
	shr.u32 	%r87, %r127, 30;
	add.s32 	%r18, %r86, %r87;
	setp.eq.s32	%p5, %r86, 0;
	@%p5 bra 	BB15_7;

	not.b32 	%r88, %r129;
	neg.s32 	%r128, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r89, 1, 0, %p6;
	add.s32 	%r129, %r89, %r88;
	xor.b32  	%r130, %r8, -2147483648;
	bra.uni 	BB15_9;

BB15_7:
	mov.u32 	%r128, %r17;
	mov.u32 	%r130, %r8;

BB15_9:
	cvt.u64.u32	%rd19, %r129;
	cvt.u64.u32	%rd20, %r128;
	bfi.b64 	%rd21, %rd19, %rd20, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd21;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f37, %fd6;
	neg.f32 	%f38, %f37;
	setp.eq.s32	%p7, %r130, 0;
	selp.f32	%f73, %f37, %f38, %p7;
	setp.eq.s32	%p8, %r8, 0;
	neg.s32 	%r90, %r18;
	selp.b32	%r131, %r18, %r90, %p8;

BB15_11:
	add.s32 	%r27, %r131, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f8, %f73, 0f3F800000, %p9;
	mul.rn.f32 	%f9, %f73, %f73;
	mov.f32 	%f41, 0f00000000;
	fma.rn.f32 	%f10, %f9, %f8, %f41;
	mov.f32 	%f74, 0fB94D4153;
	@%p9 bra 	BB15_13;

	mov.f32 	%f42, 0fBAB607ED;
	mov.f32 	%f43, 0f37CBAC00;
	fma.rn.f32 	%f74, %f43, %f9, %f42;

BB15_13:
	selp.f32	%f44, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f45, %f74, %f9, %f44;
	selp.f32	%f46, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f47, %f45, %f9, %f46;
	fma.rn.f32 	%f75, %f47, %f10, %f8;
	and.b32  	%r91, %r27, 2;
	setp.eq.s32	%p11, %r91, 0;
	@%p11 bra 	BB15_15;

	mov.f32 	%f49, 0fBF800000;
	fma.rn.f32 	%f75, %f75, %f49, %f41;

BB15_15:
	mul.f32 	%f50, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r139, %f50;
	cvt.rn.f32.s32	%f51, %r139;
	fma.rn.f32 	%f53, %f51, %f32, %f2;
	fma.rn.f32 	%f55, %f51, %f34, %f53;
	fma.rn.f32 	%f76, %f51, %f36, %f55;
	abs.f32 	%f17, %f2;
	setp.leu.f32	%p12, %f17, 0f47CE4780;
	@%p12 bra 	BB15_26;

	setp.eq.f32	%p13, %f17, 0f7F800000;
	@%p13 bra 	BB15_25;
	bra.uni 	BB15_17;

BB15_25:
	mul.rn.f32 	%f76, %f2, %f41;
	bra.uni 	BB15_26;

BB15_17:
	mov.b32 	 %r30, %f2;
	shl.b32 	%r94, %r30, 8;
	or.b32  	%r31, %r94, -2147483648;
	add.u64 	%rd23, %SP, 0;
	add.u64 	%rd36, %SPL, 0;
	mov.u32 	%r133, 0;
	mov.u64 	%rd35, __cudart_i2opi_f;
	mov.u32 	%r132, -6;

BB15_18:
	.pragma "nounroll";
	ld.const.u32 	%r97, [%rd35];
	// inline asm
	{
	mad.lo.cc.u32   %r95, %r97, %r31, %r133;
	madc.hi.u32     %r133, %r97, %r31,  0;
	}
	// inline asm
	st.local.u32 	[%rd36], %r95;
	add.s64 	%rd36, %rd36, 4;
	add.s64 	%rd35, %rd35, 4;
	add.s32 	%r132, %r132, 1;
	setp.ne.s32	%p14, %r132, 0;
	@%p14 bra 	BB15_18;

	bfe.u32 	%r100, %r30, 23, 8;
	add.s32 	%r101, %r100, -128;
	shr.u32 	%r102, %r101, 5;
	and.b32  	%r36, %r30, -2147483648;
	cvta.to.local.u64 	%rd25, %rd23;
	st.local.u32 	[%rd25+24], %r133;
	bfe.u32 	%r37, %r30, 23, 5;
	mov.u32 	%r103, 6;
	sub.s32 	%r104, %r103, %r102;
	mul.wide.s32 	%rd26, %r104, 4;
	add.s64 	%rd12, %rd25, %rd26;
	ld.local.u32 	%r135, [%rd12];
	ld.local.u32 	%r134, [%rd12+-4];
	setp.eq.s32	%p15, %r37, 0;
	@%p15 bra 	BB15_21;

	mov.u32 	%r105, 32;
	sub.s32 	%r106, %r105, %r37;
	shr.u32 	%r107, %r134, %r106;
	shl.b32 	%r108, %r135, %r37;
	add.s32 	%r135, %r107, %r108;
	ld.local.u32 	%r109, [%rd12+-8];
	shr.u32 	%r110, %r109, %r106;
	shl.b32 	%r111, %r134, %r37;
	add.s32 	%r134, %r110, %r111;

BB15_21:
	shr.u32 	%r112, %r134, 30;
	shl.b32 	%r113, %r135, 2;
	add.s32 	%r137, %r113, %r112;
	shl.b32 	%r45, %r134, 2;
	shr.u32 	%r114, %r137, 31;
	shr.u32 	%r115, %r135, 30;
	add.s32 	%r46, %r114, %r115;
	setp.eq.s32	%p16, %r114, 0;
	@%p16 bra 	BB15_22;

	not.b32 	%r116, %r137;
	neg.s32 	%r136, %r45;
	setp.eq.s32	%p17, %r45, 0;
	selp.u32	%r117, 1, 0, %p17;
	add.s32 	%r137, %r117, %r116;
	xor.b32  	%r138, %r36, -2147483648;
	bra.uni 	BB15_24;

BB15_22:
	mov.u32 	%r136, %r45;
	mov.u32 	%r138, %r36;

BB15_24:
	cvt.u64.u32	%rd27, %r137;
	cvt.u64.u32	%rd28, %r136;
	bfi.b64 	%rd29, %rd27, %rd28, 32, 32;
	cvt.rn.f64.s64	%fd7, %rd29;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f57, %fd8;
	neg.f32 	%f58, %f57;
	setp.eq.s32	%p18, %r138, 0;
	selp.f32	%f76, %f57, %f58, %p18;
	setp.eq.s32	%p19, %r36, 0;
	neg.s32 	%r118, %r46;
	selp.b32	%r139, %r46, %r118, %p19;

BB15_26:
	add.s32 	%r55, %r139, 1;
	and.b32  	%r56, %r55, 1;
	setp.eq.s32	%p20, %r56, 0;
	selp.f32	%f21, %f76, 0f3F800000, %p20;
	mul.rn.f32 	%f22, %f76, %f76;
	fma.rn.f32 	%f23, %f22, %f21, %f41;
	mov.f32 	%f77, 0fB94D4153;
	@%p20 bra 	BB15_28;

	mov.f32 	%f62, 0fBAB607ED;
	mov.f32 	%f63, 0f37CBAC00;
	fma.rn.f32 	%f77, %f63, %f22, %f62;

BB15_28:
	selp.f32	%f64, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f65, %f77, %f22, %f64;
	selp.f32	%f66, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f67, %f65, %f22, %f66;
	fma.rn.f32 	%f78, %f67, %f23, %f21;
	and.b32  	%r119, %r55, 2;
	setp.eq.s32	%p22, %r119, 0;
	@%p22 bra 	BB15_30;

	mov.f32 	%f69, 0fBF800000;
	fma.rn.f32 	%f78, %f78, %f69, %f41;

BB15_30:
	cvt.f64.f32	%fd9, %f78;
	cvt.f64.f32	%fd10, %f75;
	fma.rn.f64 	%fd11, %fd10, 0dBFE0000000000000, 0d3FDAE147AE147AE1;
	fma.rn.f64 	%fd12, %fd9, 0d3FB47AE147AE147B, %fd11;
	cvt.rn.f32.f64	%f70, %fd12;
	cvta.to.global.u64 	%rd30, %rd13;
	mul.wide.u32 	%rd31, %r61, 4;
	add.s64 	%rd32, %rd30, %rd31;
	ld.global.f32 	%f71, [%rd32];
	mul.f32 	%f72, %f71, %f70;
	st.global.f32 	[%rd32], %f72;
	ret;
}

	// .globl	_occa_Window_Nuttall_0
.visible .entry _occa_Window_Nuttall_0(
	.param .u64 _occa_Window_Nuttall_0_param_0,
	.param .u32 _occa_Window_Nuttall_0_param_1,
	.param .u32 _occa_Window_Nuttall_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot16[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<34>;
	.reg .f32 	%f<116>;
	.reg .b32 	%r<204>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<53>;


	mov.u64 	%SPL, __local_depot16;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [_occa_Window_Nuttall_0_param_0];
	ld.param.u32 	%r85, [_occa_Window_Nuttall_0_param_2];
	mov.u32 	%r86, %ctaid.x;
	shl.b32 	%r87, %r86, 6;
	mov.u32 	%r88, %tid.x;
	add.s32 	%r89, %r87, %r88;
	add.s32 	%r90, %r85, -1;
	and.b32  	%r91, %r89, %r90;
	cvt.rn.f64.s32	%fd2, %r91;
	mul.f64 	%fd3, %fd2, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f43, %r85;
	cvt.f64.f32	%fd4, %f43;
	div.rn.f64 	%fd5, %fd3, %fd4;
	cvt.rn.f32.f64	%f1, %fd5;
	add.f32 	%f2, %f1, %f1;
	mul.f32 	%f3, %f1, 0f40400000;
	mul.f32 	%f44, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r187, %f44;
	cvt.rn.f32.s32	%f45, %r187;
	mov.f32 	%f46, 0fBFC90FDA;
	fma.rn.f32 	%f47, %f45, %f46, %f1;
	mov.f32 	%f48, 0fB3A22168;
	fma.rn.f32 	%f49, %f45, %f48, %f47;
	mov.f32 	%f50, 0fA7C234C5;
	fma.rn.f32 	%f107, %f45, %f50, %f49;
	abs.f32 	%f5, %f1;
	setp.leu.f32	%p1, %f5, 0f47CE4780;
	@%p1 bra 	BB16_11;

	setp.eq.f32	%p2, %f5, 0f7F800000;
	@%p2 bra 	BB16_10;
	bra.uni 	BB16_2;

BB16_10:
	mov.f32 	%f53, 0f00000000;
	mul.rn.f32 	%f107, %f1, %f53;
	bra.uni 	BB16_11;

BB16_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r94, %r2, 8;
	or.b32  	%r3, %r94, -2147483648;
	add.u64 	%rd21, %SP, 0;
	add.u64 	%rd48, %SPL, 0;
	mov.u32 	%r181, 0;
	mov.u64 	%rd47, __cudart_i2opi_f;
	mov.u32 	%r180, -6;

BB16_3:
	.pragma "nounroll";
	ld.const.u32 	%r97, [%rd47];
	// inline asm
	{
	mad.lo.cc.u32   %r95, %r97, %r3, %r181;
	madc.hi.u32     %r181, %r97, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd48], %r95;
	add.s64 	%rd48, %rd48, 4;
	add.s64 	%rd47, %rd47, 4;
	add.s32 	%r180, %r180, 1;
	setp.ne.s32	%p3, %r180, 0;
	@%p3 bra 	BB16_3;

	bfe.u32 	%r100, %r2, 23, 8;
	add.s32 	%r101, %r100, -128;
	shr.u32 	%r102, %r101, 5;
	and.b32  	%r8, %r2, -2147483648;
	cvta.to.local.u64 	%rd23, %rd21;
	st.local.u32 	[%rd23+24], %r181;
	bfe.u32 	%r9, %r2, 23, 5;
	mov.u32 	%r103, 6;
	sub.s32 	%r104, %r103, %r102;
	mul.wide.s32 	%rd24, %r104, 4;
	add.s64 	%rd6, %rd23, %rd24;
	ld.local.u32 	%r183, [%rd6];
	ld.local.u32 	%r182, [%rd6+-4];
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB16_6;

	mov.u32 	%r105, 32;
	sub.s32 	%r106, %r105, %r9;
	shr.u32 	%r107, %r182, %r106;
	shl.b32 	%r108, %r183, %r9;
	add.s32 	%r183, %r107, %r108;
	ld.local.u32 	%r109, [%rd6+-8];
	shr.u32 	%r110, %r109, %r106;
	shl.b32 	%r111, %r182, %r9;
	add.s32 	%r182, %r110, %r111;

BB16_6:
	shr.u32 	%r112, %r182, 30;
	shl.b32 	%r113, %r183, 2;
	add.s32 	%r185, %r113, %r112;
	shl.b32 	%r17, %r182, 2;
	shr.u32 	%r114, %r185, 31;
	shr.u32 	%r115, %r183, 30;
	add.s32 	%r18, %r114, %r115;
	setp.eq.s32	%p5, %r114, 0;
	@%p5 bra 	BB16_7;

	not.b32 	%r116, %r185;
	neg.s32 	%r184, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r117, 1, 0, %p6;
	add.s32 	%r185, %r117, %r116;
	xor.b32  	%r186, %r8, -2147483648;
	bra.uni 	BB16_9;

BB16_7:
	mov.u32 	%r184, %r17;
	mov.u32 	%r186, %r8;

BB16_9:
	cvt.u64.u32	%rd25, %r185;
	cvt.u64.u32	%rd26, %r184;
	bfi.b64 	%rd27, %rd25, %rd26, 32, 32;
	cvt.rn.f64.s64	%fd6, %rd27;
	mul.f64 	%fd7, %fd6, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f51, %fd7;
	neg.f32 	%f52, %f51;
	setp.eq.s32	%p7, %r186, 0;
	selp.f32	%f107, %f51, %f52, %p7;
	setp.eq.s32	%p8, %r8, 0;
	neg.s32 	%r118, %r18;
	selp.b32	%r187, %r18, %r118, %p8;

BB16_11:
	add.s32 	%r27, %r187, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f9, %f107, 0f3F800000, %p9;
	mul.rn.f32 	%f10, %f107, %f107;
	mov.f32 	%f55, 0f00000000;
	fma.rn.f32 	%f11, %f10, %f9, %f55;
	mov.f32 	%f108, 0fB94D4153;
	@%p9 bra 	BB16_13;

	mov.f32 	%f56, 0fBAB607ED;
	mov.f32 	%f57, 0f37CBAC00;
	fma.rn.f32 	%f108, %f57, %f10, %f56;

BB16_13:
	selp.f32	%f58, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f59, %f108, %f10, %f58;
	selp.f32	%f60, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f61, %f59, %f10, %f60;
	fma.rn.f32 	%f109, %f61, %f11, %f9;
	and.b32  	%r119, %r27, 2;
	setp.eq.s32	%p11, %r119, 0;
	@%p11 bra 	BB16_15;

	mov.f32 	%f63, 0fBF800000;
	fma.rn.f32 	%f109, %f109, %f63, %f55;

BB16_15:
	mul.f32 	%f64, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r195, %f64;
	cvt.rn.f32.s32	%f65, %r195;
	fma.rn.f32 	%f67, %f65, %f46, %f2;
	fma.rn.f32 	%f69, %f65, %f48, %f67;
	fma.rn.f32 	%f110, %f65, %f50, %f69;
	abs.f32 	%f18, %f2;
	setp.leu.f32	%p12, %f18, 0f47CE4780;
	@%p12 bra 	BB16_26;

	setp.eq.f32	%p13, %f18, 0f7F800000;
	@%p13 bra 	BB16_25;
	bra.uni 	BB16_17;

BB16_25:
	mul.rn.f32 	%f110, %f2, %f55;
	bra.uni 	BB16_26;

BB16_17:
	mov.b32 	 %r30, %f2;
	shl.b32 	%r122, %r30, 8;
	or.b32  	%r31, %r122, -2147483648;
	add.u64 	%rd29, %SP, 0;
	add.u64 	%rd50, %SPL, 0;
	mov.u32 	%r189, 0;
	mov.u64 	%rd49, __cudart_i2opi_f;
	mov.u32 	%r188, -6;

BB16_18:
	.pragma "nounroll";
	ld.const.u32 	%r125, [%rd49];
	// inline asm
	{
	mad.lo.cc.u32   %r123, %r125, %r31, %r189;
	madc.hi.u32     %r189, %r125, %r31,  0;
	}
	// inline asm
	st.local.u32 	[%rd50], %r123;
	add.s64 	%rd50, %rd50, 4;
	add.s64 	%rd49, %rd49, 4;
	add.s32 	%r188, %r188, 1;
	setp.ne.s32	%p14, %r188, 0;
	@%p14 bra 	BB16_18;

	bfe.u32 	%r128, %r30, 23, 8;
	add.s32 	%r129, %r128, -128;
	shr.u32 	%r130, %r129, 5;
	and.b32  	%r36, %r30, -2147483648;
	cvta.to.local.u64 	%rd31, %rd29;
	st.local.u32 	[%rd31+24], %r189;
	bfe.u32 	%r37, %r30, 23, 5;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r130;
	mul.wide.s32 	%rd32, %r132, 4;
	add.s64 	%rd12, %rd31, %rd32;
	ld.local.u32 	%r191, [%rd12];
	ld.local.u32 	%r190, [%rd12+-4];
	setp.eq.s32	%p15, %r37, 0;
	@%p15 bra 	BB16_21;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r37;
	shr.u32 	%r135, %r190, %r134;
	shl.b32 	%r136, %r191, %r37;
	add.s32 	%r191, %r135, %r136;
	ld.local.u32 	%r137, [%rd12+-8];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r190, %r37;
	add.s32 	%r190, %r138, %r139;

BB16_21:
	shr.u32 	%r140, %r190, 30;
	shl.b32 	%r141, %r191, 2;
	add.s32 	%r193, %r141, %r140;
	shl.b32 	%r45, %r190, 2;
	shr.u32 	%r142, %r193, 31;
	shr.u32 	%r143, %r191, 30;
	add.s32 	%r46, %r142, %r143;
	setp.eq.s32	%p16, %r142, 0;
	@%p16 bra 	BB16_22;

	not.b32 	%r144, %r193;
	neg.s32 	%r192, %r45;
	setp.eq.s32	%p17, %r45, 0;
	selp.u32	%r145, 1, 0, %p17;
	add.s32 	%r193, %r145, %r144;
	xor.b32  	%r194, %r36, -2147483648;
	bra.uni 	BB16_24;

BB16_22:
	mov.u32 	%r192, %r45;
	mov.u32 	%r194, %r36;

BB16_24:
	cvt.u64.u32	%rd33, %r193;
	cvt.u64.u32	%rd34, %r192;
	bfi.b64 	%rd35, %rd33, %rd34, 32, 32;
	cvt.rn.f64.s64	%fd8, %rd35;
	mul.f64 	%fd9, %fd8, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f71, %fd9;
	neg.f32 	%f72, %f71;
	setp.eq.s32	%p18, %r194, 0;
	selp.f32	%f110, %f71, %f72, %p18;
	setp.eq.s32	%p19, %r36, 0;
	neg.s32 	%r146, %r46;
	selp.b32	%r195, %r46, %r146, %p19;

BB16_26:
	add.s32 	%r55, %r195, 1;
	and.b32  	%r56, %r55, 1;
	setp.eq.s32	%p20, %r56, 0;
	selp.f32	%f22, %f110, 0f3F800000, %p20;
	mul.rn.f32 	%f23, %f110, %f110;
	fma.rn.f32 	%f24, %f23, %f22, %f55;
	mov.f32 	%f111, 0fB94D4153;
	@%p20 bra 	BB16_28;

	mov.f32 	%f76, 0fBAB607ED;
	mov.f32 	%f77, 0f37CBAC00;
	fma.rn.f32 	%f111, %f77, %f23, %f76;

BB16_28:
	selp.f32	%f78, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f79, %f111, %f23, %f78;
	selp.f32	%f80, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f81, %f79, %f23, %f80;
	fma.rn.f32 	%f112, %f81, %f24, %f22;
	and.b32  	%r147, %r55, 2;
	setp.eq.s32	%p22, %r147, 0;
	@%p22 bra 	BB16_30;

	mov.f32 	%f83, 0fBF800000;
	fma.rn.f32 	%f112, %f112, %f83, %f55;

BB16_30:
	cvt.f64.f32	%fd10, %f112;
	cvt.f64.f32	%fd11, %f109;
	fma.rn.f64 	%fd12, %fd11, 0dBFDF317EFE0CE0B9, 0d3FD6C4E7253DA72A;
	fma.rn.f64 	%fd1, %fd10, 0d3FC27631B584B1AB, %fd12;
	mul.f32 	%f84, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r203, %f84;
	cvt.rn.f32.s32	%f85, %r203;
	fma.rn.f32 	%f87, %f85, %f46, %f3;
	fma.rn.f32 	%f89, %f85, %f48, %f87;
	fma.rn.f32 	%f113, %f85, %f50, %f89;
	abs.f32 	%f31, %f3;
	setp.leu.f32	%p23, %f31, 0f47CE4780;
	@%p23 bra 	BB16_41;

	setp.eq.f32	%p24, %f31, 0f7F800000;
	@%p24 bra 	BB16_40;
	bra.uni 	BB16_32;

BB16_40:
	mul.rn.f32 	%f113, %f3, %f55;
	bra.uni 	BB16_41;

BB16_32:
	mov.b32 	 %r58, %f3;
	shl.b32 	%r150, %r58, 8;
	or.b32  	%r59, %r150, -2147483648;
	add.u64 	%rd37, %SP, 0;
	add.u64 	%rd52, %SPL, 0;
	mov.u32 	%r197, 0;
	mov.u64 	%rd51, __cudart_i2opi_f;
	mov.u32 	%r196, -6;

BB16_33:
	.pragma "nounroll";
	ld.const.u32 	%r153, [%rd51];
	// inline asm
	{
	mad.lo.cc.u32   %r151, %r153, %r59, %r197;
	madc.hi.u32     %r197, %r153, %r59,  0;
	}
	// inline asm
	st.local.u32 	[%rd52], %r151;
	add.s64 	%rd52, %rd52, 4;
	add.s64 	%rd51, %rd51, 4;
	add.s32 	%r196, %r196, 1;
	setp.ne.s32	%p25, %r196, 0;
	@%p25 bra 	BB16_33;

	bfe.u32 	%r156, %r58, 23, 8;
	add.s32 	%r157, %r156, -128;
	shr.u32 	%r158, %r157, 5;
	and.b32  	%r64, %r58, -2147483648;
	cvta.to.local.u64 	%rd39, %rd37;
	st.local.u32 	[%rd39+24], %r197;
	bfe.u32 	%r65, %r58, 23, 5;
	mov.u32 	%r159, 6;
	sub.s32 	%r160, %r159, %r158;
	mul.wide.s32 	%rd40, %r160, 4;
	add.s64 	%rd18, %rd39, %rd40;
	ld.local.u32 	%r199, [%rd18];
	ld.local.u32 	%r198, [%rd18+-4];
	setp.eq.s32	%p26, %r65, 0;
	@%p26 bra 	BB16_36;

	mov.u32 	%r161, 32;
	sub.s32 	%r162, %r161, %r65;
	shr.u32 	%r163, %r198, %r162;
	shl.b32 	%r164, %r199, %r65;
	add.s32 	%r199, %r163, %r164;
	ld.local.u32 	%r165, [%rd18+-8];
	shr.u32 	%r166, %r165, %r162;
	shl.b32 	%r167, %r198, %r65;
	add.s32 	%r198, %r166, %r167;

BB16_36:
	shr.u32 	%r168, %r198, 30;
	shl.b32 	%r169, %r199, 2;
	add.s32 	%r201, %r169, %r168;
	shl.b32 	%r73, %r198, 2;
	shr.u32 	%r170, %r201, 31;
	shr.u32 	%r171, %r199, 30;
	add.s32 	%r74, %r170, %r171;
	setp.eq.s32	%p27, %r170, 0;
	@%p27 bra 	BB16_37;

	not.b32 	%r172, %r201;
	neg.s32 	%r200, %r73;
	setp.eq.s32	%p28, %r73, 0;
	selp.u32	%r173, 1, 0, %p28;
	add.s32 	%r201, %r173, %r172;
	xor.b32  	%r202, %r64, -2147483648;
	bra.uni 	BB16_39;

BB16_37:
	mov.u32 	%r200, %r73;
	mov.u32 	%r202, %r64;

BB16_39:
	cvt.u64.u32	%rd41, %r201;
	cvt.u64.u32	%rd42, %r200;
	bfi.b64 	%rd43, %rd41, %rd42, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd43;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f91, %fd14;
	neg.f32 	%f92, %f91;
	setp.eq.s32	%p29, %r202, 0;
	selp.f32	%f113, %f91, %f92, %p29;
	setp.eq.s32	%p30, %r64, 0;
	neg.s32 	%r174, %r74;
	selp.b32	%r203, %r74, %r174, %p30;

BB16_41:
	add.s32 	%r83, %r203, 1;
	and.b32  	%r84, %r83, 1;
	setp.eq.s32	%p31, %r84, 0;
	selp.f32	%f35, %f113, 0f3F800000, %p31;
	mul.rn.f32 	%f36, %f113, %f113;
	fma.rn.f32 	%f37, %f36, %f35, %f55;
	mov.f32 	%f114, 0fB94D4153;
	@%p31 bra 	BB16_43;

	mov.f32 	%f96, 0fBAB607ED;
	mov.f32 	%f97, 0f37CBAC00;
	fma.rn.f32 	%f114, %f97, %f36, %f96;

BB16_43:
	selp.f32	%f98, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f99, %f114, %f36, %f98;
	selp.f32	%f100, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f101, %f99, %f36, %f100;
	fma.rn.f32 	%f115, %f101, %f37, %f35;
	and.b32  	%r175, %r83, 2;
	setp.eq.s32	%p33, %r175, 0;
	@%p33 bra 	BB16_45;

	mov.f32 	%f103, 0fBF800000;
	fma.rn.f32 	%f115, %f115, %f103, %f55;

BB16_45:
	cvt.f64.f32	%fd15, %f115;
	fma.rn.f64 	%fd16, %fd15, 0dBF89D0203E63E8DE, %fd1;
	cvt.rn.f32.f64	%f104, %fd16;
	cvta.to.global.u64 	%rd44, %rd19;
	mul.wide.u32 	%rd45, %r89, 4;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.f32 	%f105, [%rd46];
	mul.f32 	%f106, %f105, %f104;
	st.global.f32 	[%rd46], %f106;
	ret;
}

	// .globl	_occa_Window_Blackman_Nuttall_0
.visible .entry _occa_Window_Blackman_Nuttall_0(
	.param .u64 _occa_Window_Blackman_Nuttall_0_param_0,
	.param .u32 _occa_Window_Blackman_Nuttall_0_param_1,
	.param .u32 _occa_Window_Blackman_Nuttall_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot17[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<34>;
	.reg .f32 	%f<116>;
	.reg .b32 	%r<204>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<53>;


	mov.u64 	%SPL, __local_depot17;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [_occa_Window_Blackman_Nuttall_0_param_0];
	ld.param.u32 	%r85, [_occa_Window_Blackman_Nuttall_0_param_2];
	mov.u32 	%r86, %ctaid.x;
	shl.b32 	%r87, %r86, 6;
	mov.u32 	%r88, %tid.x;
	add.s32 	%r89, %r87, %r88;
	add.s32 	%r90, %r85, -1;
	and.b32  	%r91, %r89, %r90;
	cvt.rn.f64.s32	%fd2, %r91;
	mul.f64 	%fd3, %fd2, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f43, %r85;
	cvt.f64.f32	%fd4, %f43;
	div.rn.f64 	%fd5, %fd3, %fd4;
	cvt.rn.f32.f64	%f1, %fd5;
	add.f32 	%f2, %f1, %f1;
	mul.f32 	%f3, %f1, 0f40400000;
	mul.f32 	%f44, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r187, %f44;
	cvt.rn.f32.s32	%f45, %r187;
	mov.f32 	%f46, 0fBFC90FDA;
	fma.rn.f32 	%f47, %f45, %f46, %f1;
	mov.f32 	%f48, 0fB3A22168;
	fma.rn.f32 	%f49, %f45, %f48, %f47;
	mov.f32 	%f50, 0fA7C234C5;
	fma.rn.f32 	%f107, %f45, %f50, %f49;
	abs.f32 	%f5, %f1;
	setp.leu.f32	%p1, %f5, 0f47CE4780;
	@%p1 bra 	BB17_11;

	setp.eq.f32	%p2, %f5, 0f7F800000;
	@%p2 bra 	BB17_10;
	bra.uni 	BB17_2;

BB17_10:
	mov.f32 	%f53, 0f00000000;
	mul.rn.f32 	%f107, %f1, %f53;
	bra.uni 	BB17_11;

BB17_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r94, %r2, 8;
	or.b32  	%r3, %r94, -2147483648;
	add.u64 	%rd21, %SP, 0;
	add.u64 	%rd48, %SPL, 0;
	mov.u32 	%r181, 0;
	mov.u64 	%rd47, __cudart_i2opi_f;
	mov.u32 	%r180, -6;

BB17_3:
	.pragma "nounroll";
	ld.const.u32 	%r97, [%rd47];
	// inline asm
	{
	mad.lo.cc.u32   %r95, %r97, %r3, %r181;
	madc.hi.u32     %r181, %r97, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd48], %r95;
	add.s64 	%rd48, %rd48, 4;
	add.s64 	%rd47, %rd47, 4;
	add.s32 	%r180, %r180, 1;
	setp.ne.s32	%p3, %r180, 0;
	@%p3 bra 	BB17_3;

	bfe.u32 	%r100, %r2, 23, 8;
	add.s32 	%r101, %r100, -128;
	shr.u32 	%r102, %r101, 5;
	and.b32  	%r8, %r2, -2147483648;
	cvta.to.local.u64 	%rd23, %rd21;
	st.local.u32 	[%rd23+24], %r181;
	bfe.u32 	%r9, %r2, 23, 5;
	mov.u32 	%r103, 6;
	sub.s32 	%r104, %r103, %r102;
	mul.wide.s32 	%rd24, %r104, 4;
	add.s64 	%rd6, %rd23, %rd24;
	ld.local.u32 	%r183, [%rd6];
	ld.local.u32 	%r182, [%rd6+-4];
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB17_6;

	mov.u32 	%r105, 32;
	sub.s32 	%r106, %r105, %r9;
	shr.u32 	%r107, %r182, %r106;
	shl.b32 	%r108, %r183, %r9;
	add.s32 	%r183, %r107, %r108;
	ld.local.u32 	%r109, [%rd6+-8];
	shr.u32 	%r110, %r109, %r106;
	shl.b32 	%r111, %r182, %r9;
	add.s32 	%r182, %r110, %r111;

BB17_6:
	shr.u32 	%r112, %r182, 30;
	shl.b32 	%r113, %r183, 2;
	add.s32 	%r185, %r113, %r112;
	shl.b32 	%r17, %r182, 2;
	shr.u32 	%r114, %r185, 31;
	shr.u32 	%r115, %r183, 30;
	add.s32 	%r18, %r114, %r115;
	setp.eq.s32	%p5, %r114, 0;
	@%p5 bra 	BB17_7;

	not.b32 	%r116, %r185;
	neg.s32 	%r184, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r117, 1, 0, %p6;
	add.s32 	%r185, %r117, %r116;
	xor.b32  	%r186, %r8, -2147483648;
	bra.uni 	BB17_9;

BB17_7:
	mov.u32 	%r184, %r17;
	mov.u32 	%r186, %r8;

BB17_9:
	cvt.u64.u32	%rd25, %r185;
	cvt.u64.u32	%rd26, %r184;
	bfi.b64 	%rd27, %rd25, %rd26, 32, 32;
	cvt.rn.f64.s64	%fd6, %rd27;
	mul.f64 	%fd7, %fd6, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f51, %fd7;
	neg.f32 	%f52, %f51;
	setp.eq.s32	%p7, %r186, 0;
	selp.f32	%f107, %f51, %f52, %p7;
	setp.eq.s32	%p8, %r8, 0;
	neg.s32 	%r118, %r18;
	selp.b32	%r187, %r18, %r118, %p8;

BB17_11:
	add.s32 	%r27, %r187, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f9, %f107, 0f3F800000, %p9;
	mul.rn.f32 	%f10, %f107, %f107;
	mov.f32 	%f55, 0f00000000;
	fma.rn.f32 	%f11, %f10, %f9, %f55;
	mov.f32 	%f108, 0fB94D4153;
	@%p9 bra 	BB17_13;

	mov.f32 	%f56, 0fBAB607ED;
	mov.f32 	%f57, 0f37CBAC00;
	fma.rn.f32 	%f108, %f57, %f10, %f56;

BB17_13:
	selp.f32	%f58, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f59, %f108, %f10, %f58;
	selp.f32	%f60, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f61, %f59, %f10, %f60;
	fma.rn.f32 	%f109, %f61, %f11, %f9;
	and.b32  	%r119, %r27, 2;
	setp.eq.s32	%p11, %r119, 0;
	@%p11 bra 	BB17_15;

	mov.f32 	%f63, 0fBF800000;
	fma.rn.f32 	%f109, %f109, %f63, %f55;

BB17_15:
	mul.f32 	%f64, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r195, %f64;
	cvt.rn.f32.s32	%f65, %r195;
	fma.rn.f32 	%f67, %f65, %f46, %f2;
	fma.rn.f32 	%f69, %f65, %f48, %f67;
	fma.rn.f32 	%f110, %f65, %f50, %f69;
	abs.f32 	%f18, %f2;
	setp.leu.f32	%p12, %f18, 0f47CE4780;
	@%p12 bra 	BB17_26;

	setp.eq.f32	%p13, %f18, 0f7F800000;
	@%p13 bra 	BB17_25;
	bra.uni 	BB17_17;

BB17_25:
	mul.rn.f32 	%f110, %f2, %f55;
	bra.uni 	BB17_26;

BB17_17:
	mov.b32 	 %r30, %f2;
	shl.b32 	%r122, %r30, 8;
	or.b32  	%r31, %r122, -2147483648;
	add.u64 	%rd29, %SP, 0;
	add.u64 	%rd50, %SPL, 0;
	mov.u32 	%r189, 0;
	mov.u64 	%rd49, __cudart_i2opi_f;
	mov.u32 	%r188, -6;

BB17_18:
	.pragma "nounroll";
	ld.const.u32 	%r125, [%rd49];
	// inline asm
	{
	mad.lo.cc.u32   %r123, %r125, %r31, %r189;
	madc.hi.u32     %r189, %r125, %r31,  0;
	}
	// inline asm
	st.local.u32 	[%rd50], %r123;
	add.s64 	%rd50, %rd50, 4;
	add.s64 	%rd49, %rd49, 4;
	add.s32 	%r188, %r188, 1;
	setp.ne.s32	%p14, %r188, 0;
	@%p14 bra 	BB17_18;

	bfe.u32 	%r128, %r30, 23, 8;
	add.s32 	%r129, %r128, -128;
	shr.u32 	%r130, %r129, 5;
	and.b32  	%r36, %r30, -2147483648;
	cvta.to.local.u64 	%rd31, %rd29;
	st.local.u32 	[%rd31+24], %r189;
	bfe.u32 	%r37, %r30, 23, 5;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r130;
	mul.wide.s32 	%rd32, %r132, 4;
	add.s64 	%rd12, %rd31, %rd32;
	ld.local.u32 	%r191, [%rd12];
	ld.local.u32 	%r190, [%rd12+-4];
	setp.eq.s32	%p15, %r37, 0;
	@%p15 bra 	BB17_21;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r37;
	shr.u32 	%r135, %r190, %r134;
	shl.b32 	%r136, %r191, %r37;
	add.s32 	%r191, %r135, %r136;
	ld.local.u32 	%r137, [%rd12+-8];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r190, %r37;
	add.s32 	%r190, %r138, %r139;

BB17_21:
	shr.u32 	%r140, %r190, 30;
	shl.b32 	%r141, %r191, 2;
	add.s32 	%r193, %r141, %r140;
	shl.b32 	%r45, %r190, 2;
	shr.u32 	%r142, %r193, 31;
	shr.u32 	%r143, %r191, 30;
	add.s32 	%r46, %r142, %r143;
	setp.eq.s32	%p16, %r142, 0;
	@%p16 bra 	BB17_22;

	not.b32 	%r144, %r193;
	neg.s32 	%r192, %r45;
	setp.eq.s32	%p17, %r45, 0;
	selp.u32	%r145, 1, 0, %p17;
	add.s32 	%r193, %r145, %r144;
	xor.b32  	%r194, %r36, -2147483648;
	bra.uni 	BB17_24;

BB17_22:
	mov.u32 	%r192, %r45;
	mov.u32 	%r194, %r36;

BB17_24:
	cvt.u64.u32	%rd33, %r193;
	cvt.u64.u32	%rd34, %r192;
	bfi.b64 	%rd35, %rd33, %rd34, 32, 32;
	cvt.rn.f64.s64	%fd8, %rd35;
	mul.f64 	%fd9, %fd8, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f71, %fd9;
	neg.f32 	%f72, %f71;
	setp.eq.s32	%p18, %r194, 0;
	selp.f32	%f110, %f71, %f72, %p18;
	setp.eq.s32	%p19, %r36, 0;
	neg.s32 	%r146, %r46;
	selp.b32	%r195, %r46, %r146, %p19;

BB17_26:
	add.s32 	%r55, %r195, 1;
	and.b32  	%r56, %r55, 1;
	setp.eq.s32	%p20, %r56, 0;
	selp.f32	%f22, %f110, 0f3F800000, %p20;
	mul.rn.f32 	%f23, %f110, %f110;
	fma.rn.f32 	%f24, %f23, %f22, %f55;
	mov.f32 	%f111, 0fB94D4153;
	@%p20 bra 	BB17_28;

	mov.f32 	%f76, 0fBAB607ED;
	mov.f32 	%f77, 0f37CBAC00;
	fma.rn.f32 	%f111, %f77, %f23, %f76;

BB17_28:
	selp.f32	%f78, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f79, %f111, %f23, %f78;
	selp.f32	%f80, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f81, %f79, %f23, %f80;
	fma.rn.f32 	%f112, %f81, %f24, %f22;
	and.b32  	%r147, %r55, 2;
	setp.eq.s32	%p22, %r147, 0;
	@%p22 bra 	BB17_30;

	mov.f32 	%f83, 0fBF800000;
	fma.rn.f32 	%f112, %f112, %f83, %f55;

BB17_30:
	cvt.f64.f32	%fd10, %f112;
	cvt.f64.f32	%fd11, %f109;
	fma.rn.f64 	%fd12, %fd11, 0dBFDF4EAF251C193B, 0d3FD744ED047AB904;
	fma.rn.f64 	%fd1, %fd10, 0d3FC17C17A89331A1, %fd12;
	mul.f32 	%f84, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r203, %f84;
	cvt.rn.f32.s32	%f85, %r203;
	fma.rn.f32 	%f87, %f85, %f46, %f3;
	fma.rn.f32 	%f89, %f85, %f48, %f87;
	fma.rn.f32 	%f113, %f85, %f50, %f89;
	abs.f32 	%f31, %f3;
	setp.leu.f32	%p23, %f31, 0f47CE4780;
	@%p23 bra 	BB17_41;

	setp.eq.f32	%p24, %f31, 0f7F800000;
	@%p24 bra 	BB17_40;
	bra.uni 	BB17_32;

BB17_40:
	mul.rn.f32 	%f113, %f3, %f55;
	bra.uni 	BB17_41;

BB17_32:
	mov.b32 	 %r58, %f3;
	shl.b32 	%r150, %r58, 8;
	or.b32  	%r59, %r150, -2147483648;
	add.u64 	%rd37, %SP, 0;
	add.u64 	%rd52, %SPL, 0;
	mov.u32 	%r197, 0;
	mov.u64 	%rd51, __cudart_i2opi_f;
	mov.u32 	%r196, -6;

BB17_33:
	.pragma "nounroll";
	ld.const.u32 	%r153, [%rd51];
	// inline asm
	{
	mad.lo.cc.u32   %r151, %r153, %r59, %r197;
	madc.hi.u32     %r197, %r153, %r59,  0;
	}
	// inline asm
	st.local.u32 	[%rd52], %r151;
	add.s64 	%rd52, %rd52, 4;
	add.s64 	%rd51, %rd51, 4;
	add.s32 	%r196, %r196, 1;
	setp.ne.s32	%p25, %r196, 0;
	@%p25 bra 	BB17_33;

	bfe.u32 	%r156, %r58, 23, 8;
	add.s32 	%r157, %r156, -128;
	shr.u32 	%r158, %r157, 5;
	and.b32  	%r64, %r58, -2147483648;
	cvta.to.local.u64 	%rd39, %rd37;
	st.local.u32 	[%rd39+24], %r197;
	bfe.u32 	%r65, %r58, 23, 5;
	mov.u32 	%r159, 6;
	sub.s32 	%r160, %r159, %r158;
	mul.wide.s32 	%rd40, %r160, 4;
	add.s64 	%rd18, %rd39, %rd40;
	ld.local.u32 	%r199, [%rd18];
	ld.local.u32 	%r198, [%rd18+-4];
	setp.eq.s32	%p26, %r65, 0;
	@%p26 bra 	BB17_36;

	mov.u32 	%r161, 32;
	sub.s32 	%r162, %r161, %r65;
	shr.u32 	%r163, %r198, %r162;
	shl.b32 	%r164, %r199, %r65;
	add.s32 	%r199, %r163, %r164;
	ld.local.u32 	%r165, [%rd18+-8];
	shr.u32 	%r166, %r165, %r162;
	shl.b32 	%r167, %r198, %r65;
	add.s32 	%r198, %r166, %r167;

BB17_36:
	shr.u32 	%r168, %r198, 30;
	shl.b32 	%r169, %r199, 2;
	add.s32 	%r201, %r169, %r168;
	shl.b32 	%r73, %r198, 2;
	shr.u32 	%r170, %r201, 31;
	shr.u32 	%r171, %r199, 30;
	add.s32 	%r74, %r170, %r171;
	setp.eq.s32	%p27, %r170, 0;
	@%p27 bra 	BB17_37;

	not.b32 	%r172, %r201;
	neg.s32 	%r200, %r73;
	setp.eq.s32	%p28, %r73, 0;
	selp.u32	%r173, 1, 0, %p28;
	add.s32 	%r201, %r173, %r172;
	xor.b32  	%r202, %r64, -2147483648;
	bra.uni 	BB17_39;

BB17_37:
	mov.u32 	%r200, %r73;
	mov.u32 	%r202, %r64;

BB17_39:
	cvt.u64.u32	%rd41, %r201;
	cvt.u64.u32	%rd42, %r200;
	bfi.b64 	%rd43, %rd41, %rd42, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd43;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f91, %fd14;
	neg.f32 	%f92, %f91;
	setp.eq.s32	%p29, %r202, 0;
	selp.f32	%f113, %f91, %f92, %p29;
	setp.eq.s32	%p30, %r64, 0;
	neg.s32 	%r174, %r74;
	selp.b32	%r203, %r74, %r174, %p30;

BB17_41:
	add.s32 	%r83, %r203, 1;
	and.b32  	%r84, %r83, 1;
	setp.eq.s32	%p31, %r84, 0;
	selp.f32	%f35, %f113, 0f3F800000, %p31;
	mul.rn.f32 	%f36, %f113, %f113;
	fma.rn.f32 	%f37, %f36, %f35, %f55;
	mov.f32 	%f114, 0fB94D4153;
	@%p31 bra 	BB17_43;

	mov.f32 	%f96, 0fBAB607ED;
	mov.f32 	%f97, 0f37CBAC00;
	fma.rn.f32 	%f114, %f97, %f36, %f96;

BB17_43:
	selp.f32	%f98, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f99, %f114, %f36, %f98;
	selp.f32	%f100, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f101, %f99, %f36, %f100;
	fma.rn.f32 	%f115, %f101, %f37, %f35;
	and.b32  	%r175, %r83, 2;
	setp.eq.s32	%p33, %r175, 0;
	@%p33 bra 	BB17_45;

	mov.f32 	%f103, 0fBF800000;
	fma.rn.f32 	%f115, %f115, %f103, %f55;

BB17_45:
	cvt.f64.f32	%fd15, %f115;
	fma.rn.f64 	%fd16, %fd15, 0dBF85CB0043F29E18, %fd1;
	cvt.rn.f32.f64	%f104, %fd16;
	cvta.to.global.u64 	%rd44, %rd19;
	mul.wide.u32 	%rd45, %r89, 4;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.f32 	%f105, [%rd46];
	mul.f32 	%f106, %f105, %f104;
	st.global.f32 	[%rd46], %f106;
	ret;
}

	// .globl	_occa_Window_Blackman_harris_0
.visible .entry _occa_Window_Blackman_harris_0(
	.param .u64 _occa_Window_Blackman_harris_0_param_0,
	.param .u32 _occa_Window_Blackman_harris_0_param_1,
	.param .u32 _occa_Window_Blackman_harris_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot18[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<34>;
	.reg .f32 	%f<116>;
	.reg .b32 	%r<204>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<53>;


	mov.u64 	%SPL, __local_depot18;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [_occa_Window_Blackman_harris_0_param_0];
	ld.param.u32 	%r85, [_occa_Window_Blackman_harris_0_param_2];
	mov.u32 	%r86, %ctaid.x;
	shl.b32 	%r87, %r86, 6;
	mov.u32 	%r88, %tid.x;
	add.s32 	%r89, %r87, %r88;
	add.s32 	%r90, %r85, -1;
	and.b32  	%r91, %r89, %r90;
	cvt.rn.f64.s32	%fd2, %r91;
	mul.f64 	%fd3, %fd2, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f43, %r85;
	cvt.f64.f32	%fd4, %f43;
	div.rn.f64 	%fd5, %fd3, %fd4;
	cvt.rn.f32.f64	%f1, %fd5;
	add.f32 	%f2, %f1, %f1;
	mul.f32 	%f3, %f1, 0f40400000;
	mul.f32 	%f44, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r187, %f44;
	cvt.rn.f32.s32	%f45, %r187;
	mov.f32 	%f46, 0fBFC90FDA;
	fma.rn.f32 	%f47, %f45, %f46, %f1;
	mov.f32 	%f48, 0fB3A22168;
	fma.rn.f32 	%f49, %f45, %f48, %f47;
	mov.f32 	%f50, 0fA7C234C5;
	fma.rn.f32 	%f107, %f45, %f50, %f49;
	abs.f32 	%f5, %f1;
	setp.leu.f32	%p1, %f5, 0f47CE4780;
	@%p1 bra 	BB18_11;

	setp.eq.f32	%p2, %f5, 0f7F800000;
	@%p2 bra 	BB18_10;
	bra.uni 	BB18_2;

BB18_10:
	mov.f32 	%f53, 0f00000000;
	mul.rn.f32 	%f107, %f1, %f53;
	bra.uni 	BB18_11;

BB18_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r94, %r2, 8;
	or.b32  	%r3, %r94, -2147483648;
	add.u64 	%rd21, %SP, 0;
	add.u64 	%rd48, %SPL, 0;
	mov.u32 	%r181, 0;
	mov.u64 	%rd47, __cudart_i2opi_f;
	mov.u32 	%r180, -6;

BB18_3:
	.pragma "nounroll";
	ld.const.u32 	%r97, [%rd47];
	// inline asm
	{
	mad.lo.cc.u32   %r95, %r97, %r3, %r181;
	madc.hi.u32     %r181, %r97, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd48], %r95;
	add.s64 	%rd48, %rd48, 4;
	add.s64 	%rd47, %rd47, 4;
	add.s32 	%r180, %r180, 1;
	setp.ne.s32	%p3, %r180, 0;
	@%p3 bra 	BB18_3;

	bfe.u32 	%r100, %r2, 23, 8;
	add.s32 	%r101, %r100, -128;
	shr.u32 	%r102, %r101, 5;
	and.b32  	%r8, %r2, -2147483648;
	cvta.to.local.u64 	%rd23, %rd21;
	st.local.u32 	[%rd23+24], %r181;
	bfe.u32 	%r9, %r2, 23, 5;
	mov.u32 	%r103, 6;
	sub.s32 	%r104, %r103, %r102;
	mul.wide.s32 	%rd24, %r104, 4;
	add.s64 	%rd6, %rd23, %rd24;
	ld.local.u32 	%r183, [%rd6];
	ld.local.u32 	%r182, [%rd6+-4];
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB18_6;

	mov.u32 	%r105, 32;
	sub.s32 	%r106, %r105, %r9;
	shr.u32 	%r107, %r182, %r106;
	shl.b32 	%r108, %r183, %r9;
	add.s32 	%r183, %r107, %r108;
	ld.local.u32 	%r109, [%rd6+-8];
	shr.u32 	%r110, %r109, %r106;
	shl.b32 	%r111, %r182, %r9;
	add.s32 	%r182, %r110, %r111;

BB18_6:
	shr.u32 	%r112, %r182, 30;
	shl.b32 	%r113, %r183, 2;
	add.s32 	%r185, %r113, %r112;
	shl.b32 	%r17, %r182, 2;
	shr.u32 	%r114, %r185, 31;
	shr.u32 	%r115, %r183, 30;
	add.s32 	%r18, %r114, %r115;
	setp.eq.s32	%p5, %r114, 0;
	@%p5 bra 	BB18_7;

	not.b32 	%r116, %r185;
	neg.s32 	%r184, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r117, 1, 0, %p6;
	add.s32 	%r185, %r117, %r116;
	xor.b32  	%r186, %r8, -2147483648;
	bra.uni 	BB18_9;

BB18_7:
	mov.u32 	%r184, %r17;
	mov.u32 	%r186, %r8;

BB18_9:
	cvt.u64.u32	%rd25, %r185;
	cvt.u64.u32	%rd26, %r184;
	bfi.b64 	%rd27, %rd25, %rd26, 32, 32;
	cvt.rn.f64.s64	%fd6, %rd27;
	mul.f64 	%fd7, %fd6, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f51, %fd7;
	neg.f32 	%f52, %f51;
	setp.eq.s32	%p7, %r186, 0;
	selp.f32	%f107, %f51, %f52, %p7;
	setp.eq.s32	%p8, %r8, 0;
	neg.s32 	%r118, %r18;
	selp.b32	%r187, %r18, %r118, %p8;

BB18_11:
	add.s32 	%r27, %r187, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f9, %f107, 0f3F800000, %p9;
	mul.rn.f32 	%f10, %f107, %f107;
	mov.f32 	%f55, 0f00000000;
	fma.rn.f32 	%f11, %f10, %f9, %f55;
	mov.f32 	%f108, 0fB94D4153;
	@%p9 bra 	BB18_13;

	mov.f32 	%f56, 0fBAB607ED;
	mov.f32 	%f57, 0f37CBAC00;
	fma.rn.f32 	%f108, %f57, %f10, %f56;

BB18_13:
	selp.f32	%f58, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f59, %f108, %f10, %f58;
	selp.f32	%f60, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f61, %f59, %f10, %f60;
	fma.rn.f32 	%f109, %f61, %f11, %f9;
	and.b32  	%r119, %r27, 2;
	setp.eq.s32	%p11, %r119, 0;
	@%p11 bra 	BB18_15;

	mov.f32 	%f63, 0fBF800000;
	fma.rn.f32 	%f109, %f109, %f63, %f55;

BB18_15:
	mul.f32 	%f64, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r195, %f64;
	cvt.rn.f32.s32	%f65, %r195;
	fma.rn.f32 	%f67, %f65, %f46, %f2;
	fma.rn.f32 	%f69, %f65, %f48, %f67;
	fma.rn.f32 	%f110, %f65, %f50, %f69;
	abs.f32 	%f18, %f2;
	setp.leu.f32	%p12, %f18, 0f47CE4780;
	@%p12 bra 	BB18_26;

	setp.eq.f32	%p13, %f18, 0f7F800000;
	@%p13 bra 	BB18_25;
	bra.uni 	BB18_17;

BB18_25:
	mul.rn.f32 	%f110, %f2, %f55;
	bra.uni 	BB18_26;

BB18_17:
	mov.b32 	 %r30, %f2;
	shl.b32 	%r122, %r30, 8;
	or.b32  	%r31, %r122, -2147483648;
	add.u64 	%rd29, %SP, 0;
	add.u64 	%rd50, %SPL, 0;
	mov.u32 	%r189, 0;
	mov.u64 	%rd49, __cudart_i2opi_f;
	mov.u32 	%r188, -6;

BB18_18:
	.pragma "nounroll";
	ld.const.u32 	%r125, [%rd49];
	// inline asm
	{
	mad.lo.cc.u32   %r123, %r125, %r31, %r189;
	madc.hi.u32     %r189, %r125, %r31,  0;
	}
	// inline asm
	st.local.u32 	[%rd50], %r123;
	add.s64 	%rd50, %rd50, 4;
	add.s64 	%rd49, %rd49, 4;
	add.s32 	%r188, %r188, 1;
	setp.ne.s32	%p14, %r188, 0;
	@%p14 bra 	BB18_18;

	bfe.u32 	%r128, %r30, 23, 8;
	add.s32 	%r129, %r128, -128;
	shr.u32 	%r130, %r129, 5;
	and.b32  	%r36, %r30, -2147483648;
	cvta.to.local.u64 	%rd31, %rd29;
	st.local.u32 	[%rd31+24], %r189;
	bfe.u32 	%r37, %r30, 23, 5;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r130;
	mul.wide.s32 	%rd32, %r132, 4;
	add.s64 	%rd12, %rd31, %rd32;
	ld.local.u32 	%r191, [%rd12];
	ld.local.u32 	%r190, [%rd12+-4];
	setp.eq.s32	%p15, %r37, 0;
	@%p15 bra 	BB18_21;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r37;
	shr.u32 	%r135, %r190, %r134;
	shl.b32 	%r136, %r191, %r37;
	add.s32 	%r191, %r135, %r136;
	ld.local.u32 	%r137, [%rd12+-8];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r190, %r37;
	add.s32 	%r190, %r138, %r139;

BB18_21:
	shr.u32 	%r140, %r190, 30;
	shl.b32 	%r141, %r191, 2;
	add.s32 	%r193, %r141, %r140;
	shl.b32 	%r45, %r190, 2;
	shr.u32 	%r142, %r193, 31;
	shr.u32 	%r143, %r191, 30;
	add.s32 	%r46, %r142, %r143;
	setp.eq.s32	%p16, %r142, 0;
	@%p16 bra 	BB18_22;

	not.b32 	%r144, %r193;
	neg.s32 	%r192, %r45;
	setp.eq.s32	%p17, %r45, 0;
	selp.u32	%r145, 1, 0, %p17;
	add.s32 	%r193, %r145, %r144;
	xor.b32  	%r194, %r36, -2147483648;
	bra.uni 	BB18_24;

BB18_22:
	mov.u32 	%r192, %r45;
	mov.u32 	%r194, %r36;

BB18_24:
	cvt.u64.u32	%rd33, %r193;
	cvt.u64.u32	%rd34, %r192;
	bfi.b64 	%rd35, %rd33, %rd34, 32, 32;
	cvt.rn.f64.s64	%fd8, %rd35;
	mul.f64 	%fd9, %fd8, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f71, %fd9;
	neg.f32 	%f72, %f71;
	setp.eq.s32	%p18, %r194, 0;
	selp.f32	%f110, %f71, %f72, %p18;
	setp.eq.s32	%p19, %r36, 0;
	neg.s32 	%r146, %r46;
	selp.b32	%r195, %r46, %r146, %p19;

BB18_26:
	add.s32 	%r55, %r195, 1;
	and.b32  	%r56, %r55, 1;
	setp.eq.s32	%p20, %r56, 0;
	selp.f32	%f22, %f110, 0f3F800000, %p20;
	mul.rn.f32 	%f23, %f110, %f110;
	fma.rn.f32 	%f24, %f23, %f22, %f55;
	mov.f32 	%f111, 0fB94D4153;
	@%p20 bra 	BB18_28;

	mov.f32 	%f76, 0fBAB607ED;
	mov.f32 	%f77, 0f37CBAC00;
	fma.rn.f32 	%f111, %f77, %f23, %f76;

BB18_28:
	selp.f32	%f78, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f79, %f111, %f23, %f78;
	selp.f32	%f80, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f81, %f79, %f23, %f80;
	fma.rn.f32 	%f112, %f81, %f24, %f22;
	and.b32  	%r147, %r55, 2;
	setp.eq.s32	%p22, %r147, 0;
	@%p22 bra 	BB18_30;

	mov.f32 	%f83, 0fBF800000;
	fma.rn.f32 	%f112, %f112, %f83, %f55;

BB18_30:
	cvt.f64.f32	%fd10, %f112;
	cvt.f64.f32	%fd11, %f109;
	fma.rn.f64 	%fd12, %fd11, 0dBFDF4024B33DAF8E, 0d3FD6F5C28F5C28F6;
	fma.rn.f64 	%fd1, %fd10, 0d3FC2157689CA18BD, %fd12;
	mul.f32 	%f84, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r203, %f84;
	cvt.rn.f32.s32	%f85, %r203;
	fma.rn.f32 	%f87, %f85, %f46, %f3;
	fma.rn.f32 	%f89, %f85, %f48, %f87;
	fma.rn.f32 	%f113, %f85, %f50, %f89;
	abs.f32 	%f31, %f3;
	setp.leu.f32	%p23, %f31, 0f47CE4780;
	@%p23 bra 	BB18_41;

	setp.eq.f32	%p24, %f31, 0f7F800000;
	@%p24 bra 	BB18_40;
	bra.uni 	BB18_32;

BB18_40:
	mul.rn.f32 	%f113, %f3, %f55;
	bra.uni 	BB18_41;

BB18_32:
	mov.b32 	 %r58, %f3;
	shl.b32 	%r150, %r58, 8;
	or.b32  	%r59, %r150, -2147483648;
	add.u64 	%rd37, %SP, 0;
	add.u64 	%rd52, %SPL, 0;
	mov.u32 	%r197, 0;
	mov.u64 	%rd51, __cudart_i2opi_f;
	mov.u32 	%r196, -6;

BB18_33:
	.pragma "nounroll";
	ld.const.u32 	%r153, [%rd51];
	// inline asm
	{
	mad.lo.cc.u32   %r151, %r153, %r59, %r197;
	madc.hi.u32     %r197, %r153, %r59,  0;
	}
	// inline asm
	st.local.u32 	[%rd52], %r151;
	add.s64 	%rd52, %rd52, 4;
	add.s64 	%rd51, %rd51, 4;
	add.s32 	%r196, %r196, 1;
	setp.ne.s32	%p25, %r196, 0;
	@%p25 bra 	BB18_33;

	bfe.u32 	%r156, %r58, 23, 8;
	add.s32 	%r157, %r156, -128;
	shr.u32 	%r158, %r157, 5;
	and.b32  	%r64, %r58, -2147483648;
	cvta.to.local.u64 	%rd39, %rd37;
	st.local.u32 	[%rd39+24], %r197;
	bfe.u32 	%r65, %r58, 23, 5;
	mov.u32 	%r159, 6;
	sub.s32 	%r160, %r159, %r158;
	mul.wide.s32 	%rd40, %r160, 4;
	add.s64 	%rd18, %rd39, %rd40;
	ld.local.u32 	%r199, [%rd18];
	ld.local.u32 	%r198, [%rd18+-4];
	setp.eq.s32	%p26, %r65, 0;
	@%p26 bra 	BB18_36;

	mov.u32 	%r161, 32;
	sub.s32 	%r162, %r161, %r65;
	shr.u32 	%r163, %r198, %r162;
	shl.b32 	%r164, %r199, %r65;
	add.s32 	%r199, %r163, %r164;
	ld.local.u32 	%r165, [%rd18+-8];
	shr.u32 	%r166, %r165, %r162;
	shl.b32 	%r167, %r198, %r65;
	add.s32 	%r198, %r166, %r167;

BB18_36:
	shr.u32 	%r168, %r198, 30;
	shl.b32 	%r169, %r199, 2;
	add.s32 	%r201, %r169, %r168;
	shl.b32 	%r73, %r198, 2;
	shr.u32 	%r170, %r201, 31;
	shr.u32 	%r171, %r199, 30;
	add.s32 	%r74, %r170, %r171;
	setp.eq.s32	%p27, %r170, 0;
	@%p27 bra 	BB18_37;

	not.b32 	%r172, %r201;
	neg.s32 	%r200, %r73;
	setp.eq.s32	%p28, %r73, 0;
	selp.u32	%r173, 1, 0, %p28;
	add.s32 	%r201, %r173, %r172;
	xor.b32  	%r202, %r64, -2147483648;
	bra.uni 	BB18_39;

BB18_37:
	mov.u32 	%r200, %r73;
	mov.u32 	%r202, %r64;

BB18_39:
	cvt.u64.u32	%rd41, %r201;
	cvt.u64.u32	%rd42, %r200;
	bfi.b64 	%rd43, %rd41, %rd42, 32, 32;
	cvt.rn.f64.s64	%fd13, %rd43;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f91, %fd14;
	neg.f32 	%f92, %f91;
	setp.eq.s32	%p29, %r202, 0;
	selp.f32	%f113, %f91, %f92, %p29;
	setp.eq.s32	%p30, %r64, 0;
	neg.s32 	%r174, %r74;
	selp.b32	%r203, %r74, %r174, %p30;

BB18_41:
	add.s32 	%r83, %r203, 1;
	and.b32  	%r84, %r83, 1;
	setp.eq.s32	%p31, %r84, 0;
	selp.f32	%f35, %f113, 0f3F800000, %p31;
	mul.rn.f32 	%f36, %f113, %f113;
	fma.rn.f32 	%f37, %f36, %f35, %f55;
	mov.f32 	%f114, 0fB94D4153;
	@%p31 bra 	BB18_43;

	mov.f32 	%f96, 0fBAB607ED;
	mov.f32 	%f97, 0f37CBAC00;
	fma.rn.f32 	%f114, %f97, %f36, %f96;

BB18_43:
	selp.f32	%f98, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f99, %f114, %f36, %f98;
	selp.f32	%f100, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f101, %f99, %f36, %f100;
	fma.rn.f32 	%f115, %f101, %f37, %f35;
	and.b32  	%r175, %r83, 2;
	setp.eq.s32	%p33, %r175, 0;
	@%p33 bra 	BB18_45;

	mov.f32 	%f103, 0fBF800000;
	fma.rn.f32 	%f115, %f115, %f103, %f55;

BB18_45:
	cvt.f64.f32	%fd15, %f115;
	fma.rn.f64 	%fd16, %fd15, 0dBF87EBAF102363B2, %fd1;
	cvt.rn.f32.f64	%f104, %fd16;
	cvta.to.global.u64 	%rd44, %rd19;
	mul.wide.u32 	%rd45, %r89, 4;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.f32 	%f105, [%rd46];
	mul.f32 	%f106, %f105, %f104;
	st.global.f32 	[%rd46], %f106;
	ret;
}

	// .globl	_occa_Window_FlatTop_0
.visible .entry _occa_Window_FlatTop_0(
	.param .u64 _occa_Window_FlatTop_0_param_0,
	.param .u32 _occa_Window_FlatTop_0_param_1,
	.param .u32 _occa_Window_FlatTop_0_param_2
)
.maxntid 64, 1, 1
{
	.local .align 4 .b8 	__local_depot19[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<45>;
	.reg .f32 	%f<153>;
	.reg .b32 	%r<268>;
	.reg .f64 	%fd<21>;
	.reg .b64 	%rd<69>;


	mov.u64 	%SPL, __local_depot19;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd25, [_occa_Window_FlatTop_0_param_0];
	ld.param.u32 	%r113, [_occa_Window_FlatTop_0_param_2];
	mov.u32 	%r114, %ctaid.x;
	shl.b32 	%r115, %r114, 6;
	mov.u32 	%r116, %tid.x;
	add.s32 	%r117, %r115, %r116;
	add.s32 	%r118, %r113, -1;
	and.b32  	%r119, %r117, %r118;
	cvt.rn.f64.s32	%fd3, %r119;
	mul.f64 	%fd4, %fd3, 0d401921FB54442D18;
	cvt.rn.f32.s32	%f57, %r113;
	cvt.f64.f32	%fd5, %f57;
	div.rn.f64 	%fd6, %fd4, %fd5;
	cvt.rn.f32.f64	%f1, %fd6;
	add.f32 	%f2, %f1, %f1;
	mul.f32 	%f3, %f1, 0f40400000;
	mul.f32 	%f4, %f1, 0f40800000;
	mul.f32 	%f58, %f1, 0f3F22F983;
	cvt.rni.s32.f32	%r243, %f58;
	cvt.rn.f32.s32	%f59, %r243;
	mov.f32 	%f60, 0fBFC90FDA;
	fma.rn.f32 	%f61, %f59, %f60, %f1;
	mov.f32 	%f62, 0fB3A22168;
	fma.rn.f32 	%f63, %f59, %f62, %f61;
	mov.f32 	%f64, 0fA7C234C5;
	fma.rn.f32 	%f141, %f59, %f64, %f63;
	abs.f32 	%f6, %f1;
	setp.leu.f32	%p1, %f6, 0f47CE4780;
	@%p1 bra 	BB19_11;

	setp.eq.f32	%p2, %f6, 0f7F800000;
	@%p2 bra 	BB19_10;
	bra.uni 	BB19_2;

BB19_10:
	mov.f32 	%f67, 0f00000000;
	mul.rn.f32 	%f141, %f1, %f67;
	bra.uni 	BB19_11;

BB19_2:
	mov.b32 	 %r2, %f1;
	shl.b32 	%r122, %r2, 8;
	or.b32  	%r3, %r122, -2147483648;
	add.u64 	%rd27, %SP, 0;
	add.u64 	%rd62, %SPL, 0;
	mov.u32 	%r237, 0;
	mov.u64 	%rd61, __cudart_i2opi_f;
	mov.u32 	%r236, -6;

BB19_3:
	.pragma "nounroll";
	ld.const.u32 	%r125, [%rd61];
	// inline asm
	{
	mad.lo.cc.u32   %r123, %r125, %r3, %r237;
	madc.hi.u32     %r237, %r125, %r3,  0;
	}
	// inline asm
	st.local.u32 	[%rd62], %r123;
	add.s64 	%rd62, %rd62, 4;
	add.s64 	%rd61, %rd61, 4;
	add.s32 	%r236, %r236, 1;
	setp.ne.s32	%p3, %r236, 0;
	@%p3 bra 	BB19_3;

	bfe.u32 	%r128, %r2, 23, 8;
	add.s32 	%r129, %r128, -128;
	shr.u32 	%r130, %r129, 5;
	and.b32  	%r8, %r2, -2147483648;
	cvta.to.local.u64 	%rd29, %rd27;
	st.local.u32 	[%rd29+24], %r237;
	bfe.u32 	%r9, %r2, 23, 5;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r130;
	mul.wide.s32 	%rd30, %r132, 4;
	add.s64 	%rd6, %rd29, %rd30;
	ld.local.u32 	%r239, [%rd6];
	ld.local.u32 	%r238, [%rd6+-4];
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB19_6;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r9;
	shr.u32 	%r135, %r238, %r134;
	shl.b32 	%r136, %r239, %r9;
	add.s32 	%r239, %r135, %r136;
	ld.local.u32 	%r137, [%rd6+-8];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r238, %r9;
	add.s32 	%r238, %r138, %r139;

BB19_6:
	shr.u32 	%r140, %r238, 30;
	shl.b32 	%r141, %r239, 2;
	add.s32 	%r241, %r141, %r140;
	shl.b32 	%r17, %r238, 2;
	shr.u32 	%r142, %r241, 31;
	shr.u32 	%r143, %r239, 30;
	add.s32 	%r18, %r142, %r143;
	setp.eq.s32	%p5, %r142, 0;
	@%p5 bra 	BB19_7;

	not.b32 	%r144, %r241;
	neg.s32 	%r240, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r145, 1, 0, %p6;
	add.s32 	%r241, %r145, %r144;
	xor.b32  	%r242, %r8, -2147483648;
	bra.uni 	BB19_9;

BB19_7:
	mov.u32 	%r240, %r17;
	mov.u32 	%r242, %r8;

BB19_9:
	cvt.u64.u32	%rd31, %r241;
	cvt.u64.u32	%rd32, %r240;
	bfi.b64 	%rd33, %rd31, %rd32, 32, 32;
	cvt.rn.f64.s64	%fd7, %rd33;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f65, %fd8;
	neg.f32 	%f66, %f65;
	setp.eq.s32	%p7, %r242, 0;
	selp.f32	%f141, %f65, %f66, %p7;
	setp.eq.s32	%p8, %r8, 0;
	neg.s32 	%r146, %r18;
	selp.b32	%r243, %r18, %r146, %p8;

BB19_11:
	add.s32 	%r27, %r243, 1;
	and.b32  	%r28, %r27, 1;
	setp.eq.s32	%p9, %r28, 0;
	selp.f32	%f10, %f141, 0f3F800000, %p9;
	mul.rn.f32 	%f11, %f141, %f141;
	mov.f32 	%f69, 0f00000000;
	fma.rn.f32 	%f12, %f11, %f10, %f69;
	mov.f32 	%f142, 0fB94D4153;
	@%p9 bra 	BB19_13;

	mov.f32 	%f70, 0fBAB607ED;
	mov.f32 	%f71, 0f37CBAC00;
	fma.rn.f32 	%f142, %f71, %f11, %f70;

BB19_13:
	selp.f32	%f72, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f73, %f142, %f11, %f72;
	selp.f32	%f74, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f75, %f73, %f11, %f74;
	fma.rn.f32 	%f143, %f75, %f12, %f10;
	and.b32  	%r147, %r27, 2;
	setp.eq.s32	%p11, %r147, 0;
	@%p11 bra 	BB19_15;

	mov.f32 	%f77, 0fBF800000;
	fma.rn.f32 	%f143, %f143, %f77, %f69;

BB19_15:
	mul.f32 	%f78, %f2, 0f3F22F983;
	cvt.rni.s32.f32	%r251, %f78;
	cvt.rn.f32.s32	%f79, %r251;
	fma.rn.f32 	%f81, %f79, %f60, %f2;
	fma.rn.f32 	%f83, %f79, %f62, %f81;
	fma.rn.f32 	%f144, %f79, %f64, %f83;
	abs.f32 	%f19, %f2;
	setp.leu.f32	%p12, %f19, 0f47CE4780;
	@%p12 bra 	BB19_26;

	setp.eq.f32	%p13, %f19, 0f7F800000;
	@%p13 bra 	BB19_25;
	bra.uni 	BB19_17;

BB19_25:
	mul.rn.f32 	%f144, %f2, %f69;
	bra.uni 	BB19_26;

BB19_17:
	mov.b32 	 %r30, %f2;
	shl.b32 	%r150, %r30, 8;
	or.b32  	%r31, %r150, -2147483648;
	add.u64 	%rd35, %SP, 0;
	add.u64 	%rd64, %SPL, 0;
	mov.u32 	%r245, 0;
	mov.u64 	%rd63, __cudart_i2opi_f;
	mov.u32 	%r244, -6;

BB19_18:
	.pragma "nounroll";
	ld.const.u32 	%r153, [%rd63];
	// inline asm
	{
	mad.lo.cc.u32   %r151, %r153, %r31, %r245;
	madc.hi.u32     %r245, %r153, %r31,  0;
	}
	// inline asm
	st.local.u32 	[%rd64], %r151;
	add.s64 	%rd64, %rd64, 4;
	add.s64 	%rd63, %rd63, 4;
	add.s32 	%r244, %r244, 1;
	setp.ne.s32	%p14, %r244, 0;
	@%p14 bra 	BB19_18;

	bfe.u32 	%r156, %r30, 23, 8;
	add.s32 	%r157, %r156, -128;
	shr.u32 	%r158, %r157, 5;
	and.b32  	%r36, %r30, -2147483648;
	cvta.to.local.u64 	%rd37, %rd35;
	st.local.u32 	[%rd37+24], %r245;
	bfe.u32 	%r37, %r30, 23, 5;
	mov.u32 	%r159, 6;
	sub.s32 	%r160, %r159, %r158;
	mul.wide.s32 	%rd38, %r160, 4;
	add.s64 	%rd12, %rd37, %rd38;
	ld.local.u32 	%r247, [%rd12];
	ld.local.u32 	%r246, [%rd12+-4];
	setp.eq.s32	%p15, %r37, 0;
	@%p15 bra 	BB19_21;

	mov.u32 	%r161, 32;
	sub.s32 	%r162, %r161, %r37;
	shr.u32 	%r163, %r246, %r162;
	shl.b32 	%r164, %r247, %r37;
	add.s32 	%r247, %r163, %r164;
	ld.local.u32 	%r165, [%rd12+-8];
	shr.u32 	%r166, %r165, %r162;
	shl.b32 	%r167, %r246, %r37;
	add.s32 	%r246, %r166, %r167;

BB19_21:
	shr.u32 	%r168, %r246, 30;
	shl.b32 	%r169, %r247, 2;
	add.s32 	%r249, %r169, %r168;
	shl.b32 	%r45, %r246, 2;
	shr.u32 	%r170, %r249, 31;
	shr.u32 	%r171, %r247, 30;
	add.s32 	%r46, %r170, %r171;
	setp.eq.s32	%p16, %r170, 0;
	@%p16 bra 	BB19_22;

	not.b32 	%r172, %r249;
	neg.s32 	%r248, %r45;
	setp.eq.s32	%p17, %r45, 0;
	selp.u32	%r173, 1, 0, %p17;
	add.s32 	%r249, %r173, %r172;
	xor.b32  	%r250, %r36, -2147483648;
	bra.uni 	BB19_24;

BB19_22:
	mov.u32 	%r248, %r45;
	mov.u32 	%r250, %r36;

BB19_24:
	cvt.u64.u32	%rd39, %r249;
	cvt.u64.u32	%rd40, %r248;
	bfi.b64 	%rd41, %rd39, %rd40, 32, 32;
	cvt.rn.f64.s64	%fd9, %rd41;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f85, %fd10;
	neg.f32 	%f86, %f85;
	setp.eq.s32	%p18, %r250, 0;
	selp.f32	%f144, %f85, %f86, %p18;
	setp.eq.s32	%p19, %r36, 0;
	neg.s32 	%r174, %r46;
	selp.b32	%r251, %r46, %r174, %p19;

BB19_26:
	add.s32 	%r55, %r251, 1;
	and.b32  	%r56, %r55, 1;
	setp.eq.s32	%p20, %r56, 0;
	selp.f32	%f23, %f144, 0f3F800000, %p20;
	mul.rn.f32 	%f24, %f144, %f144;
	fma.rn.f32 	%f25, %f24, %f23, %f69;
	mov.f32 	%f145, 0fB94D4153;
	@%p20 bra 	BB19_28;

	mov.f32 	%f90, 0fBAB607ED;
	mov.f32 	%f91, 0f37CBAC00;
	fma.rn.f32 	%f145, %f91, %f24, %f90;

BB19_28:
	selp.f32	%f92, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f93, %f145, %f24, %f92;
	selp.f32	%f94, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f95, %f93, %f24, %f94;
	fma.rn.f32 	%f146, %f95, %f25, %f23;
	and.b32  	%r175, %r55, 2;
	setp.eq.s32	%p22, %r175, 0;
	@%p22 bra 	BB19_30;

	mov.f32 	%f97, 0fBF800000;
	fma.rn.f32 	%f146, %f146, %f97, %f69;

BB19_30:
	cvt.f64.f32	%fd11, %f146;
	cvt.f64.f32	%fd12, %f143;
	fma.rn.f64 	%fd13, %fd12, 0dBFDAAA1780A52BF4, 0d3FCB98174DFA5ED6;
	fma.rn.f64 	%fd1, %fd11, 0d3FD1BEADF8FFB93C, %fd13;
	mul.f32 	%f98, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r259, %f98;
	cvt.rn.f32.s32	%f99, %r259;
	fma.rn.f32 	%f101, %f99, %f60, %f3;
	fma.rn.f32 	%f103, %f99, %f62, %f101;
	fma.rn.f32 	%f147, %f99, %f64, %f103;
	abs.f32 	%f32, %f3;
	setp.leu.f32	%p23, %f32, 0f47CE4780;
	@%p23 bra 	BB19_41;

	setp.eq.f32	%p24, %f32, 0f7F800000;
	@%p24 bra 	BB19_40;
	bra.uni 	BB19_32;

BB19_40:
	mul.rn.f32 	%f147, %f3, %f69;
	bra.uni 	BB19_41;

BB19_32:
	mov.b32 	 %r58, %f3;
	shl.b32 	%r178, %r58, 8;
	or.b32  	%r59, %r178, -2147483648;
	add.u64 	%rd43, %SP, 0;
	add.u64 	%rd66, %SPL, 0;
	mov.u32 	%r253, 0;
	mov.u64 	%rd65, __cudart_i2opi_f;
	mov.u32 	%r252, -6;

BB19_33:
	.pragma "nounroll";
	ld.const.u32 	%r181, [%rd65];
	// inline asm
	{
	mad.lo.cc.u32   %r179, %r181, %r59, %r253;
	madc.hi.u32     %r253, %r181, %r59,  0;
	}
	// inline asm
	st.local.u32 	[%rd66], %r179;
	add.s64 	%rd66, %rd66, 4;
	add.s64 	%rd65, %rd65, 4;
	add.s32 	%r252, %r252, 1;
	setp.ne.s32	%p25, %r252, 0;
	@%p25 bra 	BB19_33;

	bfe.u32 	%r184, %r58, 23, 8;
	add.s32 	%r185, %r184, -128;
	shr.u32 	%r186, %r185, 5;
	and.b32  	%r64, %r58, -2147483648;
	cvta.to.local.u64 	%rd45, %rd43;
	st.local.u32 	[%rd45+24], %r253;
	bfe.u32 	%r65, %r58, 23, 5;
	mov.u32 	%r187, 6;
	sub.s32 	%r188, %r187, %r186;
	mul.wide.s32 	%rd46, %r188, 4;
	add.s64 	%rd18, %rd45, %rd46;
	ld.local.u32 	%r255, [%rd18];
	ld.local.u32 	%r254, [%rd18+-4];
	setp.eq.s32	%p26, %r65, 0;
	@%p26 bra 	BB19_36;

	mov.u32 	%r189, 32;
	sub.s32 	%r190, %r189, %r65;
	shr.u32 	%r191, %r254, %r190;
	shl.b32 	%r192, %r255, %r65;
	add.s32 	%r255, %r191, %r192;
	ld.local.u32 	%r193, [%rd18+-8];
	shr.u32 	%r194, %r193, %r190;
	shl.b32 	%r195, %r254, %r65;
	add.s32 	%r254, %r194, %r195;

BB19_36:
	shr.u32 	%r196, %r254, 30;
	shl.b32 	%r197, %r255, 2;
	add.s32 	%r257, %r197, %r196;
	shl.b32 	%r73, %r254, 2;
	shr.u32 	%r198, %r257, 31;
	shr.u32 	%r199, %r255, 30;
	add.s32 	%r74, %r198, %r199;
	setp.eq.s32	%p27, %r198, 0;
	@%p27 bra 	BB19_37;

	not.b32 	%r200, %r257;
	neg.s32 	%r256, %r73;
	setp.eq.s32	%p28, %r73, 0;
	selp.u32	%r201, 1, 0, %p28;
	add.s32 	%r257, %r201, %r200;
	xor.b32  	%r258, %r64, -2147483648;
	bra.uni 	BB19_39;

BB19_37:
	mov.u32 	%r256, %r73;
	mov.u32 	%r258, %r64;

BB19_39:
	cvt.u64.u32	%rd47, %r257;
	cvt.u64.u32	%rd48, %r256;
	bfi.b64 	%rd49, %rd47, %rd48, 32, 32;
	cvt.rn.f64.s64	%fd14, %rd49;
	mul.f64 	%fd15, %fd14, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f105, %fd15;
	neg.f32 	%f106, %f105;
	setp.eq.s32	%p29, %r258, 0;
	selp.f32	%f147, %f105, %f106, %p29;
	setp.eq.s32	%p30, %r64, 0;
	neg.s32 	%r202, %r74;
	selp.b32	%r259, %r74, %r202, %p30;

BB19_41:
	add.s32 	%r83, %r259, 1;
	and.b32  	%r84, %r83, 1;
	setp.eq.s32	%p31, %r84, 0;
	selp.f32	%f36, %f147, 0f3F800000, %p31;
	mul.rn.f32 	%f37, %f147, %f147;
	fma.rn.f32 	%f38, %f37, %f36, %f69;
	mov.f32 	%f148, 0fB94D4153;
	@%p31 bra 	BB19_43;

	mov.f32 	%f110, 0fBAB607ED;
	mov.f32 	%f111, 0f37CBAC00;
	fma.rn.f32 	%f148, %f111, %f37, %f110;

BB19_43:
	selp.f32	%f112, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f113, %f148, %f37, %f112;
	selp.f32	%f114, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f115, %f113, %f37, %f114;
	fma.rn.f32 	%f149, %f115, %f38, %f36;
	and.b32  	%r203, %r83, 2;
	setp.eq.s32	%p33, %r203, 0;
	@%p33 bra 	BB19_45;

	mov.f32 	%f117, 0fBF800000;
	fma.rn.f32 	%f149, %f149, %f117, %f69;

BB19_45:
	cvt.f64.f32	%fd16, %f149;
	fma.rn.f64 	%fd2, %fd16, 0dBFB5656E0BFFC627, %fd1;
	mul.f32 	%f118, %f4, 0f3F22F983;
	cvt.rni.s32.f32	%r267, %f118;
	cvt.rn.f32.s32	%f119, %r267;
	fma.rn.f32 	%f121, %f119, %f60, %f4;
	fma.rn.f32 	%f123, %f119, %f62, %f121;
	fma.rn.f32 	%f150, %f119, %f64, %f123;
	abs.f32 	%f45, %f4;
	setp.leu.f32	%p34, %f45, 0f47CE4780;
	@%p34 bra 	BB19_56;

	setp.eq.f32	%p35, %f45, 0f7F800000;
	@%p35 bra 	BB19_55;
	bra.uni 	BB19_47;

BB19_55:
	mul.rn.f32 	%f150, %f4, %f69;
	bra.uni 	BB19_56;

BB19_47:
	mov.b32 	 %r86, %f4;
	shl.b32 	%r206, %r86, 8;
	or.b32  	%r87, %r206, -2147483648;
	add.u64 	%rd51, %SP, 0;
	add.u64 	%rd68, %SPL, 0;
	mov.u32 	%r261, 0;
	mov.u64 	%rd67, __cudart_i2opi_f;
	mov.u32 	%r260, -6;

BB19_48:
	.pragma "nounroll";
	ld.const.u32 	%r209, [%rd67];
	// inline asm
	{
	mad.lo.cc.u32   %r207, %r209, %r87, %r261;
	madc.hi.u32     %r261, %r209, %r87,  0;
	}
	// inline asm
	st.local.u32 	[%rd68], %r207;
	add.s64 	%rd68, %rd68, 4;
	add.s64 	%rd67, %rd67, 4;
	add.s32 	%r260, %r260, 1;
	setp.ne.s32	%p36, %r260, 0;
	@%p36 bra 	BB19_48;

	bfe.u32 	%r212, %r86, 23, 8;
	add.s32 	%r213, %r212, -128;
	shr.u32 	%r214, %r213, 5;
	and.b32  	%r92, %r86, -2147483648;
	cvta.to.local.u64 	%rd53, %rd51;
	st.local.u32 	[%rd53+24], %r261;
	bfe.u32 	%r93, %r86, 23, 5;
	mov.u32 	%r215, 6;
	sub.s32 	%r216, %r215, %r214;
	mul.wide.s32 	%rd54, %r216, 4;
	add.s64 	%rd24, %rd53, %rd54;
	ld.local.u32 	%r263, [%rd24];
	ld.local.u32 	%r262, [%rd24+-4];
	setp.eq.s32	%p37, %r93, 0;
	@%p37 bra 	BB19_51;

	mov.u32 	%r217, 32;
	sub.s32 	%r218, %r217, %r93;
	shr.u32 	%r219, %r262, %r218;
	shl.b32 	%r220, %r263, %r93;
	add.s32 	%r263, %r219, %r220;
	ld.local.u32 	%r221, [%rd24+-8];
	shr.u32 	%r222, %r221, %r218;
	shl.b32 	%r223, %r262, %r93;
	add.s32 	%r262, %r222, %r223;

BB19_51:
	shr.u32 	%r224, %r262, 30;
	shl.b32 	%r225, %r263, 2;
	add.s32 	%r265, %r225, %r224;
	shl.b32 	%r101, %r262, 2;
	shr.u32 	%r226, %r265, 31;
	shr.u32 	%r227, %r263, 30;
	add.s32 	%r102, %r226, %r227;
	setp.eq.s32	%p38, %r226, 0;
	@%p38 bra 	BB19_52;

	not.b32 	%r228, %r265;
	neg.s32 	%r264, %r101;
	setp.eq.s32	%p39, %r101, 0;
	selp.u32	%r229, 1, 0, %p39;
	add.s32 	%r265, %r229, %r228;
	xor.b32  	%r266, %r92, -2147483648;
	bra.uni 	BB19_54;

BB19_52:
	mov.u32 	%r264, %r101;
	mov.u32 	%r266, %r92;

BB19_54:
	cvt.u64.u32	%rd55, %r265;
	cvt.u64.u32	%rd56, %r264;
	bfi.b64 	%rd57, %rd55, %rd56, 32, 32;
	cvt.rn.f64.s64	%fd17, %rd57;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f125, %fd18;
	neg.f32 	%f126, %f125;
	setp.eq.s32	%p40, %r266, 0;
	selp.f32	%f150, %f125, %f126, %p40;
	setp.eq.s32	%p41, %r92, 0;
	neg.s32 	%r230, %r102;
	selp.b32	%r267, %r102, %r230, %p41;

BB19_56:
	add.s32 	%r111, %r267, 1;
	and.b32  	%r112, %r111, 1;
	setp.eq.s32	%p42, %r112, 0;
	selp.f32	%f49, %f150, 0f3F800000, %p42;
	mul.rn.f32 	%f50, %f150, %f150;
	fma.rn.f32 	%f51, %f50, %f49, %f69;
	mov.f32 	%f151, 0fB94D4153;
	@%p42 bra 	BB19_58;

	mov.f32 	%f130, 0fBAB607ED;
	mov.f32 	%f131, 0f37CBAC00;
	fma.rn.f32 	%f151, %f131, %f50, %f130;

BB19_58:
	selp.f32	%f132, 0f3C0885E4, 0f3D2AAABB, %p42;
	fma.rn.f32 	%f133, %f151, %f50, %f132;
	selp.f32	%f134, 0fBE2AAAA8, 0fBEFFFFFF, %p42;
	fma.rn.f32 	%f135, %f133, %f50, %f134;
	fma.rn.f32 	%f152, %f135, %f51, %f49;
	and.b32  	%r231, %r111, 2;
	setp.eq.s32	%p44, %r231, 0;
	@%p44 bra 	BB19_60;

	mov.f32 	%f137, 0fBF800000;
	fma.rn.f32 	%f152, %f152, %f137, %f69;

BB19_60:
	cvt.f64.f32	%fd19, %f152;
	fma.rn.f64 	%fd20, %fd19, 0d3F7C74D7E5A705B5, %fd2;
	cvt.rn.f32.f64	%f138, %fd20;
	cvta.to.global.u64 	%rd58, %rd25;
	mul.wide.u32 	%rd59, %r117, 4;
	add.s64 	%rd60, %rd58, %rd59;
	ld.global.f32 	%f139, [%rd60];
	mul.f32 	%f140, %f139, %f138;
	st.global.f32 	[%rd60], %f140;
	ret;
}

	// .globl	_occa_Window_Gaussian_0
.visible .entry _occa_Window_Gaussian_0(
	.param .u64 _occa_Window_Gaussian_0_param_0,
	.param .u32 _occa_Window_Gaussian_0_param_1,
	.param .u32 _occa_Window_Gaussian_0_param_2,
	.param .f32 _occa_Window_Gaussian_0_param_3
)
.maxntid 64, 1, 1
{
	.reg .f32 	%f<26>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_occa_Window_Gaussian_0_param_0];
	ld.param.u32 	%r1, [_occa_Window_Gaussian_0_param_2];
	ld.param.f32 	%f1, [_occa_Window_Gaussian_0_param_3];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r2, 6;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	add.s32 	%r6, %r1, -1;
	and.b32  	%r7, %r5, %r6;
	shr.s32 	%r8, %r1, 1;
	sub.s32 	%r9, %r7, %r8;
	cvt.rn.f32.s32	%f2, %r9;
	cvt.rn.f32.s32	%f3, %r8;
	mul.f32 	%f4, %f3, %f1;
	div.rn.f32 	%f5, %f2, %f4;
	mul.f32 	%f6, %f5, %f5;
	mul.f32 	%f7, %f6, 0fBF000000;
	mov.f32 	%f8, 0f3F000000;
	mov.f32 	%f9, 0f3BBB989D;
	fma.rn.f32 	%f10, %f7, %f9, %f8;
	cvt.sat.f32.f32	%f11, %f10;
	mov.f32 	%f12, 0f4B400001;
	mov.f32 	%f13, 0f437C0000;
	fma.rm.f32 	%f14, %f11, %f13, %f12;
	add.f32 	%f15, %f14, 0fCB40007F;
	neg.f32 	%f16, %f15;
	mov.f32 	%f17, 0f3FB8AA3B;
	fma.rn.f32 	%f18, %f7, %f17, %f16;
	mov.f32 	%f19, 0f32A57060;
	fma.rn.f32 	%f20, %f7, %f19, %f18;
	mov.b32 	 %r10, %f14;
	shl.b32 	%r11, %r10, 23;
	mov.b32 	 %f21, %r11;
	ex2.approx.ftz.f32 	%f22, %f20;
	mul.f32 	%f23, %f22, %f21;
	mul.wide.u32 	%rd3, %r5, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.f32 	%f24, [%rd4];
	mul.f32 	%f25, %f24, %f23;
	st.global.f32 	[%rd4], %f25;
	ret;
}

	// .globl	_occa_DCRemove_Common_0
.visible .entry _occa_DCRemove_Common_0(
	.param .u64 _occa_DCRemove_Common_0_param_0,
	.param .u32 _occa_DCRemove_Common_0_param_1,
	.param .u32 _occa_DCRemove_Common_0_param_2
)
.maxntid 64, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<40>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<7>;
	// demoted variable
	.shared .align 4 .b8 _ZZ23_occa_DCRemove_Common_0E5added[512];

	ld.param.u64 	%rd2, [_occa_DCRemove_Common_0_param_0];
	ld.param.u32 	%r15, [_occa_DCRemove_Common_0_param_2];
	cvta.to.global.u64 	%rd1, %rd2;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r16, %r2, 2;
	mov.u32 	%r17, _ZZ23_occa_DCRemove_Common_0E5added;
	add.s32 	%r3, %r17, %r16;
	mov.u32 	%r28, 0;
	st.shared.u32 	[%r3], %r28;
	bar.sync 	0;
	setp.eq.s32	%p2, %r15, 0;
	@%p2 bra 	BB21_3;

	mad.lo.s32 	%r27, %r1, %r15, %r2;

BB21_2:
	mul.wide.u32 	%rd3, %r27, 4;
	add.s64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f2, [%rd4];
	st.shared.f32 	[%r3+256], %f2;
	bar.sync 	0;
	ld.shared.f32 	%f3, [%r3];
	ld.shared.f32 	%f4, [%r3+256];
	add.f32 	%f5, %f4, %f3;
	st.shared.f32 	[%r3], %f5;
	bar.sync 	0;
	add.s32 	%r27, %r27, 64;
	add.s32 	%r28, %r28, 64;
	setp.lt.u32	%p3, %r28, %r15;
	@%p3 bra 	BB21_2;

BB21_3:
	ld.shared.f32 	%f6, [%r3+128];
	ld.shared.f32 	%f7, [%r3];
	add.f32 	%f8, %f7, %f6;
	setp.lt.u32	%p4, %r2, 32;
	selp.u32	%r20, 1, 0, %p4;
	cvt.rn.f32.u32	%f9, %r20;
	mul.f32 	%f10, %f9, %f8;
	st.shared.f32 	[%r3], %f10;
	bar.sync 	0;
	ld.shared.f32 	%f11, [%r3+64];
	ld.shared.f32 	%f12, [%r3];
	add.f32 	%f13, %f12, %f11;
	setp.lt.u32	%p5, %r2, 16;
	selp.u32	%r21, 1, 0, %p5;
	cvt.rn.f32.u32	%f14, %r21;
	mul.f32 	%f15, %f14, %f13;
	st.shared.f32 	[%r3], %f15;
	bar.sync 	0;
	ld.shared.f32 	%f16, [%r3+32];
	ld.shared.f32 	%f17, [%r3];
	add.f32 	%f18, %f17, %f16;
	setp.lt.u32	%p6, %r2, 8;
	selp.u32	%r22, 1, 0, %p6;
	cvt.rn.f32.u32	%f19, %r22;
	mul.f32 	%f20, %f19, %f18;
	st.shared.f32 	[%r3], %f20;
	bar.sync 	0;
	ld.shared.f32 	%f21, [%r3+16];
	ld.shared.f32 	%f22, [%r3];
	add.f32 	%f23, %f22, %f21;
	setp.lt.u32	%p7, %r2, 4;
	selp.u32	%r23, 1, 0, %p7;
	cvt.rn.f32.u32	%f24, %r23;
	mul.f32 	%f25, %f24, %f23;
	st.shared.f32 	[%r3], %f25;
	bar.sync 	0;
	ld.shared.f32 	%f26, [%r3+8];
	ld.shared.f32 	%f27, [%r3];
	add.f32 	%f28, %f27, %f26;
	setp.lt.u32	%p8, %r2, 2;
	selp.u32	%r24, 1, 0, %p8;
	cvt.rn.f32.u32	%f29, %r24;
	mul.f32 	%f30, %f29, %f28;
	st.shared.f32 	[%r3], %f30;
	bar.sync 	0;
	ld.shared.f32 	%f31, [%r3+4];
	ld.shared.f32 	%f32, [%r3];
	add.f32 	%f33, %f32, %f31;
	setp.eq.s32	%p9, %r2, 0;
	selp.u32	%r25, 1, 0, %p9;
	cvt.rn.f32.u32	%f34, %r25;
	mul.f32 	%f35, %f34, %f33;
	st.shared.f32 	[%r3], %f35;
	bar.sync 	0;
	@%p2 bra 	BB21_6;

	cvt.rn.f32.u32	%f1, %r15;
	mad.lo.s32 	%r29, %r1, %r15, %r2;
	mov.u32 	%r30, 0;

BB21_5:
	ld.shared.f32 	%f36, [_ZZ23_occa_DCRemove_Common_0E5added];
	div.rn.f32 	%f37, %f36, %f1;
	mul.wide.u32 	%rd5, %r29, 4;
	add.s64 	%rd6, %rd1, %rd5;
	ld.global.f32 	%f38, [%rd6];
	sub.f32 	%f39, %f38, %f37;
	st.global.f32 	[%rd6], %f39;
	bar.sync 	0;
	add.s32 	%r29, %r29, 64;
	add.s32 	%r30, %r30, 64;
	setp.lt.u32	%p10, %r30, %r15;
	@%p10 bra 	BB21_5;

BB21_6:
	ret;
}

	// .globl	_occa_StockHamCommon_0
.visible .entry _occa_StockHamCommon_0(
	.param .u64 _occa_StockHamCommon_0_param_0,
	.param .u64 _occa_StockHamCommon_0_param_1,
	.param .u64 _occa_StockHamCommon_0_param_2,
	.param .u64 _occa_StockHamCommon_0_param_3,
	.param .u32 _occa_StockHamCommon_0_param_4,
	.param .u32 _occa_StockHamCommon_0_param_5,
	.param .u32 _occa_StockHamCommon_0_param_6,
	.param .u32 _occa_StockHamCommon_0_param_7
)
.maxntid 256, 1, 1
{
	.local .align 4 .b8 	__local_depot22[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<23>;
	.reg .f32 	%f<81>;
	.reg .b32 	%r<154>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<48>;


	mov.u64 	%SPL, __local_depot22;
	ld.param.u64 	%rd15, [_occa_StockHamCommon_0_param_0];
	ld.param.u64 	%rd16, [_occa_StockHamCommon_0_param_1];
	ld.param.u64 	%rd13, [_occa_StockHamCommon_0_param_2];
	ld.param.u64 	%rd14, [_occa_StockHamCommon_0_param_3];
	ld.param.u32 	%r57, [_occa_StockHamCommon_0_param_4];
	ld.param.u32 	%r58, [_occa_StockHamCommon_0_param_5];
	ld.param.u32 	%r59, [_occa_StockHamCommon_0_param_7];
	mov.u32 	%r60, %ctaid.x;
	shl.b32 	%r61, %r60, 8;
	mov.u32 	%r62, %tid.x;
	add.s32 	%r63, %r61, %r62;
	add.s32 	%r64, %r59, -1;
	shr.u32 	%r65, %r63, %r64;
	add.s32 	%r66, %r57, -1;
	and.b32  	%r67, %r63, %r66;
	shl.b32 	%r68, %r57, 1;
	mov.u32 	%r69, 1;
	mul.lo.s32 	%r70, %r65, %r68;
	add.s32 	%r71, %r70, %r67;
	cvta.to.global.u64 	%rd17, %rd15;
	mul.wide.u32 	%rd18, %r71, 4;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.f32 	%f1, [%rd19];
	cvta.to.global.u64 	%rd20, %rd16;
	add.s64 	%rd21, %rd20, %rd18;
	ld.global.f32 	%f2, [%rd21];
	add.s32 	%r72, %r71, %r57;
	mul.wide.u32 	%rd22, %r72, 4;
	add.s64 	%rd23, %rd17, %rd22;
	ld.global.f32 	%f3, [%rd23];
	add.s64 	%rd24, %rd20, %rd22;
	ld.global.f32 	%f4, [%rd24];
	shr.u32 	%r73, %r67, %r58;
	shl.b32 	%r1, %r69, %r58;
	add.s32 	%r74, %r1, -1;
	and.b32  	%r75, %r67, %r74;
	shl.b32 	%r76, %r1, 1;
	add.s32 	%r77, %r70, %r75;
	mad.lo.s32 	%r2, %r76, %r73, %r77;
	rem.s32 	%r78, %r71, %r1;
	mul.lo.s32 	%r79, %r78, %r57;
	div.s32 	%r80, %r79, %r1;
	cvt.rn.f32.s32	%f30, %r80;
	cvt.rn.f32.s32	%f31, %r68;
	div.rn.f32 	%f32, %f30, %f31;
	cvt.f64.f32	%fd1, %f32;
	mul.f64 	%fd2, %fd1, 0dC01921FB54442D18;
	cvt.rn.f32.f64	%f5, %fd2;
	add.u64 	%rd1, %SPL, 0;
	mul.f32 	%f33, %f5, 0f3F22F983;
	cvt.rni.s32.f32	%r153, %f33;
	cvt.rn.f32.s32	%f34, %r153;
	mov.f32 	%f35, 0fBFC90FDA;
	fma.rn.f32 	%f36, %f34, %f35, %f5;
	mov.f32 	%f37, 0fB3A22168;
	fma.rn.f32 	%f38, %f34, %f37, %f36;
	mov.f32 	%f39, 0fA7C234C5;
	fma.rn.f32 	%f78, %f34, %f39, %f38;
	abs.f32 	%f7, %f5;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p1, %f7, 0f47CE4780;
	mov.u32 	%r145, %r153;
	mov.f32 	%f75, %f78;
	@%p1 bra 	BB22_11;

	setp.eq.f32	%p2, %f7, 0f7F800000;
	@%p2 bra 	BB22_10;
	bra.uni 	BB22_2;

BB22_10:
	mov.f32 	%f42, 0f00000000;
	mul.rn.f32 	%f75, %f5, %f42;
	mov.u32 	%r145, %r153;
	bra.uni 	BB22_11;

BB22_2:
	mov.b32 	 %r4, %f5;
	shl.b32 	%r83, %r4, 8;
	or.b32  	%r5, %r83, -2147483648;
	mov.u32 	%r139, 0;
	mov.u64 	%rd44, __cudart_i2opi_f;
	mov.u32 	%r138, -6;
	mov.u64 	%rd45, %rd1;

BB22_3:
	.pragma "nounroll";
	ld.const.u32 	%r86, [%rd44];
	// inline asm
	{
	mad.lo.cc.u32   %r84, %r86, %r5, %r139;
	madc.hi.u32     %r139, %r86, %r5,  0;
	}
	// inline asm
	st.local.u32 	[%rd45], %r84;
	add.s64 	%rd45, %rd45, 4;
	add.s64 	%rd44, %rd44, 4;
	add.s32 	%r138, %r138, 1;
	setp.ne.s32	%p3, %r138, 0;
	@%p3 bra 	BB22_3;

	bfe.u32 	%r89, %r4, 23, 8;
	add.s32 	%r90, %r89, -128;
	shr.u32 	%r91, %r90, 5;
	and.b32  	%r10, %r4, -2147483648;
	st.local.u32 	[%rd2], %r139;
	bfe.u32 	%r11, %r4, 23, 5;
	mov.u32 	%r92, 6;
	sub.s32 	%r93, %r92, %r91;
	mul.wide.s32 	%rd27, %r93, 4;
	add.s64 	%rd7, %rd1, %rd27;
	ld.local.u32 	%r141, [%rd7];
	ld.local.u32 	%r140, [%rd7+-4];
	setp.eq.s32	%p4, %r11, 0;
	@%p4 bra 	BB22_6;

	mov.u32 	%r94, 32;
	sub.s32 	%r95, %r94, %r11;
	shr.u32 	%r96, %r140, %r95;
	shl.b32 	%r97, %r141, %r11;
	add.s32 	%r141, %r96, %r97;
	ld.local.u32 	%r98, [%rd7+-8];
	shr.u32 	%r99, %r98, %r95;
	shl.b32 	%r100, %r140, %r11;
	add.s32 	%r140, %r99, %r100;

BB22_6:
	shr.u32 	%r101, %r140, 30;
	shl.b32 	%r102, %r141, 2;
	add.s32 	%r143, %r102, %r101;
	shl.b32 	%r19, %r140, 2;
	shr.u32 	%r103, %r143, 31;
	shr.u32 	%r104, %r141, 30;
	add.s32 	%r20, %r103, %r104;
	setp.eq.s32	%p5, %r103, 0;
	@%p5 bra 	BB22_7;

	not.b32 	%r105, %r143;
	neg.s32 	%r142, %r19;
	setp.eq.s32	%p6, %r19, 0;
	selp.u32	%r106, 1, 0, %p6;
	add.s32 	%r143, %r106, %r105;
	xor.b32  	%r144, %r10, -2147483648;
	bra.uni 	BB22_9;

BB22_7:
	mov.u32 	%r142, %r19;
	mov.u32 	%r144, %r10;

BB22_9:
	cvt.u64.u32	%rd28, %r143;
	cvt.u64.u32	%rd29, %r142;
	bfi.b64 	%rd30, %rd28, %rd29, 32, 32;
	cvt.rn.f64.s64	%fd3, %rd30;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f40, %fd4;
	neg.f32 	%f41, %f40;
	setp.eq.s32	%p7, %r144, 0;
	selp.f32	%f75, %f40, %f41, %p7;
	setp.eq.s32	%p8, %r10, 0;
	neg.s32 	%r107, %r20;
	selp.b32	%r145, %r20, %r107, %p8;

BB22_11:
	add.s32 	%r29, %r145, 1;
	and.b32  	%r30, %r29, 1;
	setp.eq.s32	%p9, %r30, 0;
	selp.f32	%f11, %f75, 0f3F800000, %p9;
	mul.rn.f32 	%f12, %f75, %f75;
	mov.f32 	%f44, 0f00000000;
	fma.rn.f32 	%f13, %f12, %f11, %f44;
	mov.f32 	%f76, 0fB94D4153;
	@%p9 bra 	BB22_13;

	mov.f32 	%f45, 0fBAB607ED;
	mov.f32 	%f46, 0f37CBAC00;
	fma.rn.f32 	%f76, %f46, %f12, %f45;

BB22_13:
	selp.f32	%f47, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f48, %f76, %f12, %f47;
	selp.f32	%f49, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f50, %f48, %f12, %f49;
	fma.rn.f32 	%f77, %f50, %f13, %f11;
	and.b32  	%r108, %r29, 2;
	setp.eq.s32	%p11, %r108, 0;
	@%p11 bra 	BB22_15;

	mov.f32 	%f52, 0fBF800000;
	fma.rn.f32 	%f77, %f77, %f52, %f44;

BB22_15:
	@%p1 bra 	BB22_26;

	setp.eq.f32	%p13, %f7, 0f7F800000;
	@%p13 bra 	BB22_25;
	bra.uni 	BB22_17;

BB22_25:
	mul.rn.f32 	%f78, %f5, %f44;
	bra.uni 	BB22_26;

BB22_17:
	mov.b32 	 %r31, %f5;
	shl.b32 	%r111, %r31, 8;
	or.b32  	%r32, %r111, -2147483648;
	mov.u32 	%r147, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
	mov.u32 	%r146, -6;
	mov.u64 	%rd47, %rd1;

BB22_18:
	.pragma "nounroll";
	ld.const.u32 	%r114, [%rd46];
	// inline asm
	{
	mad.lo.cc.u32   %r112, %r114, %r32, %r147;
	madc.hi.u32     %r147, %r114, %r32,  0;
	}
	// inline asm
	st.local.u32 	[%rd47], %r112;
	add.s64 	%rd47, %rd47, 4;
	add.s64 	%rd46, %rd46, 4;
	add.s32 	%r146, %r146, 1;
	setp.ne.s32	%p14, %r146, 0;
	@%p14 bra 	BB22_18;

	bfe.u32 	%r117, %r31, 23, 8;
	add.s32 	%r118, %r117, -128;
	shr.u32 	%r119, %r118, 5;
	and.b32  	%r37, %r31, -2147483648;
	st.local.u32 	[%rd2], %r147;
	bfe.u32 	%r38, %r31, 23, 5;
	mov.u32 	%r120, 6;
	sub.s32 	%r121, %r120, %r119;
	mul.wide.s32 	%rd32, %r121, 4;
	add.s64 	%rd12, %rd1, %rd32;
	ld.local.u32 	%r149, [%rd12];
	ld.local.u32 	%r148, [%rd12+-4];
	setp.eq.s32	%p15, %r38, 0;
	@%p15 bra 	BB22_21;

	mov.u32 	%r122, 32;
	sub.s32 	%r123, %r122, %r38;
	shr.u32 	%r124, %r148, %r123;
	shl.b32 	%r125, %r149, %r38;
	add.s32 	%r149, %r124, %r125;
	ld.local.u32 	%r126, [%rd12+-8];
	shr.u32 	%r127, %r126, %r123;
	shl.b32 	%r128, %r148, %r38;
	add.s32 	%r148, %r127, %r128;

BB22_21:
	shr.u32 	%r129, %r148, 30;
	shl.b32 	%r130, %r149, 2;
	add.s32 	%r151, %r130, %r129;
	shl.b32 	%r46, %r148, 2;
	shr.u32 	%r131, %r151, 31;
	shr.u32 	%r132, %r149, 30;
	add.s32 	%r47, %r131, %r132;
	setp.eq.s32	%p16, %r131, 0;
	@%p16 bra 	BB22_22;

	not.b32 	%r133, %r151;
	neg.s32 	%r150, %r46;
	setp.eq.s32	%p17, %r46, 0;
	selp.u32	%r134, 1, 0, %p17;
	add.s32 	%r151, %r134, %r133;
	xor.b32  	%r152, %r37, -2147483648;
	bra.uni 	BB22_24;

BB22_22:
	mov.u32 	%r150, %r46;
	mov.u32 	%r152, %r37;

BB22_24:
	cvt.u64.u32	%rd33, %r151;
	cvt.u64.u32	%rd34, %r150;
	bfi.b64 	%rd35, %rd33, %rd34, 32, 32;
	cvt.rn.f64.s64	%fd5, %rd35;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64	%f53, %fd6;
	neg.f32 	%f54, %f53;
	setp.eq.s32	%p18, %r152, 0;
	selp.f32	%f78, %f53, %f54, %p18;
	setp.eq.s32	%p19, %r37, 0;
	neg.s32 	%r135, %r47;
	selp.b32	%r153, %r47, %r135, %p19;

BB22_26:
	and.b32  	%r56, %r153, 1;
	setp.eq.s32	%p20, %r56, 0;
	selp.f32	%f22, %f78, 0f3F800000, %p20;
	mul.rn.f32 	%f23, %f78, %f78;
	fma.rn.f32 	%f24, %f23, %f22, %f44;
	mov.f32 	%f79, 0fB94D4153;
	@%p20 bra 	BB22_28;

	mov.f32 	%f58, 0fBAB607ED;
	mov.f32 	%f59, 0f37CBAC00;
	fma.rn.f32 	%f79, %f59, %f23, %f58;

BB22_28:
	selp.f32	%f60, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f61, %f79, %f23, %f60;
	selp.f32	%f62, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f63, %f61, %f23, %f62;
	fma.rn.f32 	%f80, %f63, %f24, %f22;
	and.b32  	%r136, %r153, 2;
	setp.eq.s32	%p22, %r136, 0;
	@%p22 bra 	BB22_30;

	mov.f32 	%f65, 0fBF800000;
	fma.rn.f32 	%f80, %f80, %f65, %f44;

BB22_30:
	cvta.to.global.u64 	%rd36, %rd14;
	mul.f32 	%f66, %f4, %f80;
	mul.f32 	%f67, %f3, %f77;
	sub.f32 	%f68, %f67, %f66;
	mul.f32 	%f69, %f4, %f77;
	fma.rn.f32 	%f70, %f3, %f80, %f69;
	add.f32 	%f71, %f1, %f68;
	cvta.to.global.u64 	%rd37, %rd13;
	mul.wide.u32 	%rd38, %r2, 4;
	add.s64 	%rd39, %rd37, %rd38;
	st.global.f32 	[%rd39], %f71;
	add.f32 	%f72, %f2, %f70;
	add.s64 	%rd40, %rd36, %rd38;
	st.global.f32 	[%rd40], %f72;
	sub.f32 	%f73, %f1, %f68;
	add.s32 	%r137, %r2, %r1;
	mul.wide.u32 	%rd41, %r137, 4;
	add.s64 	%rd42, %rd37, %rd41;
	st.global.f32 	[%rd42], %f73;
	sub.f32 	%f74, %f2, %f70;
	add.s64 	%rd43, %rd36, %rd41;
	st.global.f32 	[%rd43], %f74;
	ret;
}


